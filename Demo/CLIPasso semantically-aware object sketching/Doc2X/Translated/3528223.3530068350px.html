
    <!DOCTYPE html>
    <html lang="en">
      <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>3528223.3530068</title>
        <style>
            * {
              padding: 0;
              margin: 0;
              box-sizing: border-box;
            }
             html {
              line-height: 1.15; /* 1 */
              -webkit-text-size-adjust: 100%; /* 2 */
            }
            body {
              padding: 20px 350px;
              margin: 0;
            }
            main {
              display: block;
            }
            h1 {
              font-size: 2em;
              margin: 0.67em 0;
            }
            hr {
              box-sizing: content-box; /* 1 */
              height: 0; /* 1 */
              overflow: visible; /* 2 */
            }
            pre {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            a {
              background-color: transparent;
            }
            abbr[title] {
              border-bottom: none; /* 1 */
              text-decoration: underline; /* 2 */
              text-decoration: underline dotted; /* 2 */
            }
            b,
            strong {
              font-weight: bolder;
            }
            code,
            kbd,
            samp {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            small {
              font-size: 80%;
            }
            sub,
            sup {
              font-size: 75%;
              line-height: 0;
              position: relative;
              vertical-align: baseline;
            }
            sub {
              bottom: -0.25em;
            }
            sup {
              top: -0.5em;
            }
            img {
              border-style: none;
            }
            button,
            input,
            optgroup,
            select,
            textarea {
              font-family: inherit; /* 1 */
              font-size: 100%; /* 1 */
              line-height: 1.15; /* 1 */
              margin: 0; /* 2 */
            }
            button,
            input { /* 1 */
              overflow: visible;
            }
            button,
            select { /* 1 */
              text-transform: none;
            }
            button,
            [type="button"],
            [type="reset"],
            [type="submit"] {
              -webkit-appearance: button;
            }
            button::-moz-focus-inner,
            [type="button"]::-moz-focus-inner,
            [type="reset"]::-moz-focus-inner,
            [type="submit"]::-moz-focus-inner {
              border-style: none;
              padding: 0;
            }
            button:-moz-focusring,
            [type="button"]:-moz-focusring,
            [type="reset"]:-moz-focusring,
            [type="submit"]:-moz-focusring {
              outline: 1px dotted ButtonText;
            }
            fieldset {
              padding: 0.35em 0.75em 0.625em;
            }
            legend {
              box-sizing: border-box; /* 1 */
              color: inherit; /* 2 */
              display: table; /* 1 */
              max-width: 100%; /* 1 */
              padding: 0; /* 3 */
              white-space: normal; /* 1 */
            }
            progress {
              vertical-align: baseline;
            }
            textarea {
              overflow: auto;
            }
            [type="checkbox"],
            [type="radio"] {
              box-sizing: border-box; /* 1 */
              padding: 0; /* 2 */
            }
            [type="number"]::-webkit-inner-spin-button,
            [type="number"]::-webkit-outer-spin-button {
              height: auto;
            }
            [type="search"] {
              -webkit-appearance: textfield; /* 1 */
              outline-offset: -2px; /* 2 */
            }
            [type="search"]::-webkit-search-decoration {
              -webkit-appearance: none;
            }
            ::-webkit-file-upload-button {
              -webkit-appearance: button; /* 1 */
              font: inherit; /* 2 */
            }
            details {
              display: block;
            }
            summary {
              display: list-item;
            }
            [hidden] {
              display: none;
            }
             table {
                border-collapse: collapse;
                width: 100%;
                margin-top: 20px;
                margin-bottom: 20px;
              }
              table thead {
                background-color: #e5e5e5;
              }
              table td {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              table th {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              h1, h2, h3, h4, h5, h6 {
                margin-bottom: 20px;
              }
              p {
                margin-top: 20px;
                text-indent: 2em;
                margin-bottom: 20px;
              }
        </style>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      </head>
      <body>
        <div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-0="121,186">CLIPasso: Semantically-Aware Object Sketching<div style="background-color: #d6d6d6;margin: 12px 0;">CLIPasso：语义感知的对象素描</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-0="126,264">YAEL VINKER, Tel Aviv University, Israel<div style="background-color: #d6d6d6;margin: 12px 0;">YAEL VINKER，特拉维夫大学，以色列</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-0="126,302">ENSAN PAJOUHESHGAR, Swiss Federal Institute of Technology (EPFL), Switzerland<div style="background-color: #d6d6d6;margin: 12px 0;">ENSAN PAJOUHESHGAR，瑞士联邦理工学院（EPFL），瑞士</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-0="126,339">JESSICA Y. BO, Swiss Federal Institute of Technology (EPFL), Switzerland<div style="background-color: #d6d6d6;margin: 12px 0;">JESSICA Y. BO，瑞士联邦理工学院（EPFL），瑞士</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-0="126,375">ROMAN CHRISTIAN BACHMANN, Swiss Federal Institute of Technology (EPFL), Switzerland<div style="background-color: #d6d6d6;margin: 12px 0;">ROMAN CHRISTIAN BACHMANN，瑞士联邦理工学院（EPFL），瑞士</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-0="125,411">AMIT HAIM BERMANO, Tel Aviv University, Israel<div style="background-color: #d6d6d6;margin: 12px 0;">AMIT HAIM BERMANO，特拉维夫大学，以色列</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-0="126,447">DANIEL COHEN-OR, Tel Aviv University, Israel<div style="background-color: #d6d6d6;margin: 12px 0;">DANIEL COHEN-OR，特拉维夫大学，以色列</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-0="126,484">AMIR ZAMIR, Swiss Federal Institute of Technology (EPFL), Switzerland<div style="background-color: #d6d6d6;margin: 12px 0;">AMIR ZAMIR，瑞士联邦理工学院（EPFL），瑞士</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-0="125,520">ARIEL SHAMIR, Reichman University, Israel<div style="background-color: #d6d6d6;margin: 12px 0;">ARIEL SHAMIR，雷克曼大学，以色列</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-0="165,588"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_1.jpg?x=165&amp;y=588&amp;w=1258&amp;h=495"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-0="126,1110">Fig. 1. Our work converts an image of an object to a sketch, allowing for varying levels of abstraction, while preserving its key visual features. Even with a very minimal representation (the rightmost flaming ond horse are drawn with only a few strokes), one can recognize both the semantics and the structure of the subject depicted. The Thinker (Le Penseur), model 1880 by Auguste Rodin, Gift of Mrs. John W. Simpson [Public Domain] via (https://bit.ly/3F48Sxc); Flamingo from freepikps of com (Freepi/bit.ly/3FotipS): "Wild Horses" by firelizy/bit.ly/3F6tipS): "Wild Horses" by firelizard5 [CC BY 2.0] via (https://bit.ly/3P4KfX).<div style="background-color: #d6d6d6;margin: 12px 0;">图 1. 我们的工作将物体的图像转换为素描，允许有不同的抽象级别，同时保留其关键视觉特征。即使在非常简约的表现（最右边的火烈鸟和马只用几笔勾勒），人们也能识别出主题的语义和结构。《思想家》（Le Penseur），奥古斯特·罗丹于 1880 年的模型，约翰·W·辛普森夫人的礼物[公共领域]通过（https://bit.ly/3F48Sxc）访问；火烈鸟来自 freepikps 的 com（Freepi/bit.ly/3FotipS）；“野马”由 firelizy/bit.ly/3F6tipS 制作：firelizard5 [CC BY 2.0] 通过（https://bit.ly/3P4KfX）访问。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-0="127,1231">Abstraction is at the heart of sketching due to the simple and minimal nature of line drawings. Abstraction entails identifying the essential visual properties of an object or scene, which requires semantic understanding and prior knowledge of high-level concepts. Abstract depictions are therefore e.pajouheshgar@gmail.com; Jessica Y. Bo, Swiss Federal Institute of Technology (EPFL), Switzerland, jessica7bo@gmail.com; Roman Christian Bachmann, Swiss Federal Institute of Technology (EPFL), Switzerland, roman.bachmann@epfl.ch; Amit Haim Bermano, Tel Aviv University, Israel, amberman@tauex.tau.ac.il; Daniel Cohen-Or, Tel Aviv University, Israel, dcor@taux.tau.al.i; Amir Zamir, Swiss Federal Institute of Technology (EPFL), Switzerland, amir.zamir@epfLch; Ariel Shamir, Reichman University, Israel, arik@idc.ac.il.<div style="background-color: #d6d6d6;margin: 12px 0;">抽象是草图核心所在，因为线条画的简单和最小化特性。抽象涉及识别一个物体或场景的本质视觉属性，这需要语义理解和高级概念的前置知识。因此，抽象的描述 e.pajouheshgar@gmail.com；Jessica Y. Bo，瑞士联邦理工学院（EPFL），瑞士，jessica7bo@gmail.com；Roman Christian Bachmann，瑞士联邦理工学院（EPFL），瑞士，roman.bachmann@epfl.ch；Amit Haim Bermano，特拉维夫大学，以色列，amberman@tauex.tau.ac.il；Daniel Cohen-Or，特拉维夫大学，以色列，dcor@taux.tau.ac.il；Amir Zamir，瑞士联邦理工学院（EPFL），瑞士，amir.zamir@epfl.ch；Ariel Shamir，雷克曼大学，以色列，arik@idc.ac.il。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-0="127,1577">Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee pronted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM to post on servers or to redistribute to lists, requires prior specific permission and/or a challenging for artists, and even more so for machines. We present CLIPasso, an object sketching method that can achieve different levels of abstraction, guided by geometric and semantic simplifications. While sketch generation methods often rely on explicit sketch datasets for training, we utilize the remarkable ability of CLIP (Contrastive-Language-Image-Pretraining) to distill semantic concepts from sketches and images alike. We define a sketch as a set of Bézier curves and use a differentiable rasterizer to optimize the parameters of the curves directly with respect to a CLIP-based perceptual loss. The abstraction degree is controlled by varying the number of strokes. The generated sketches demonstrate multiple levels of abstraction while maintaining recognizability, underlying structure, and essential visual components of the subject drawn.<div style="background-color: #d6d6d6;margin: 12px 0;">允许免费进行数字或纸质复制本工作的全部或部分，供个人或课堂教学使用，但前提是复制品不是为了盈利或商业利益而制作或分发，并且复制品需包含此声明和第一页上的完整引文。对于本作品中由非ACM拥有的组件在服务器上发布或重新分发给列表，需要事先获得特定许可和/或对艺术家的挑战，对机器更是如此。我们提出了CLIPasso，这是一种对象草图绘制方法，能够在几何和语义简化的指导下实现不同级别的抽象。虽然草图生成方法通常依赖于显式的草图数据集进行训练，但我们利用CLIP（对比语言图像预训练）的显著能力，从草图和图像中提取语义概念。我们将草图定义为一组贝塞尔曲线，并使用可微分光栅化器直接根据基于CLIP的感知损失优化曲线的参数。抽象程度通过改变笔划数量来控制。生成的草图展示了多个级别的抽象，同时保持了可识别性、底层结构和主题绘制的关键视觉组件。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-0="816,1551">CCS Concepts: <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2474" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> Computing methodologies <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2475" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container> Computer graphics.<div style="background-color: #d6d6d6;margin: 12px 0;">CCS概念：<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2476" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> 计算方法 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2477" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container> 计算机图形学。</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-0="814,1593">Additional Key Words and Phrases: Sketch Synthesis, Image-based Rendering, Vector Line Art Generation<div style="background-color: #d6d6d6;margin: 12px 0;">其他关键词和短语：草图合成、基于图像的渲染、矢量线艺术生成</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-0="815,1661">ACM Reference Format:<div style="background-color: #d6d6d6;margin: 12px 0;">ACM参考文献格式：</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-65fe0faf-c9e7-4c9e-b705-7ce13bfb5f40" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-0="814,1687">Yael Vinker, Ehsan Pajouheshgar, Jessica Y. Bo, Roman Christian Bachmann, Amit Haim Bermano, Daniel Cohen-Or, Amir Zamir, and Ariel Shamir. 2022. CLIPasso: Semantically-Aware Object Sketching. ACM Trans. Graph. 41, 4, Article 86 (July 2022), 11 pages. https://doi.org/10.1145/3528223.3530068<div style="background-color: #d6d6d6;margin: 12px 0;">Yael Vinker, Ehsan Pajouheshgar, Jessica Y. Bo, Roman Christian Bachmann, Amit Haim Bermano, Daniel Cohen-Or, Amir Zamir, 和 Ariel Shamir。2022年。CLIPasso：语义感知对象草图绘制。ACM Trans. Graph. 41, 4, 文章86（2022年7月），11页。https://doi.org/10.1145/3528223.3530068</div></div></div></div></div></div></span></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-7ef1a682-2fd3-404b-a986-75cb0433c3f4" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-1="167,202"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_2.jpg?x=167&amp;y=202&amp;w=559&amp;h=310"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-7ef1a682-2fd3-404b-a986-75cb0433c3f4" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-1="128,543">Fig. 2. "Le Taureau" by Picasso - note how the abstraction process is achieved by gradually removing elements while the bull's essence is preserved. (c) Pasadena, Norton Simon Museum, Picasso P. The Bull, 1946" photo by Vahe Martirosyan, [CC BY-SA 2.0] via (https://bit.ly/3MFB3pm).<div style="background-color: #d6d6d6;margin: 12px 0;">图 2. 毕加索的“公牛” - 注意抽象过程是如何通过逐渐移除元素实现的，同时保留了公牛的本质。（c）帕萨迪纳，诺顿·西蒙博物馆，毕加索 P. 公牛，1946"，照片由 Vahe Martirosyan拍摄，[CC BY-SA 2.0] 通过（https://bit.ly/3MFB3pm）。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-7ef1a682-2fd3-404b-a986-75cb0433c3f4" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-1="127,727">1 INTRODUCTION<div style="background-color: #d6d6d6;margin: 12px 0;">1 引言</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-7ef1a682-2fd3-404b-a986-75cb0433c3f4" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-1="128,771">Free-hand sketching is a valuable visual tool for expressing ideas, concepts, and actions [Fan et al. 2018; Gryaditskaya et al. 2019; Hertzmann 2020; Tversky 2002; Xu et al. 2020]. As sketches consist of only strokes, sist of only strokes, and often only a limited number of strokes, the process of abstraction is central to sketching. An artist must make representational decisions to choose key visual features of the subject drawn to capture the relevant information she wishes to express, while omitting (many) others [Chamberlain and Wagemans 2016; Fan et al. 2019; Yang and Fan 2021].<div style="background-color: #d6d6d6;margin: 12px 0;">徒手草图是表达想法、概念和动作的有价值视觉工具 [Fan et al. 2018; Gryaditskaya et al. 2019; Hertzmann 2020; Tversky 2002; Xu et al. 2020]。由于草图仅由笔划组成，通常仅限于少数笔划，因此抽象过程在草图绘制中至关重要。艺术家必须做出表现性的决策，选择绘制对象的关键视觉特征，以捕捉她希望表达的相关信息，同时省略（许多）其他内容 [Chamberlain 和 Wagemans 2016; Fan et al. 2019; Yang 和 Fan 2021]。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-7ef1a682-2fd3-404b-a986-75cb0433c3f4" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-1="149,1029">For example, in the famous "Le Taureau" series (Figure 2), Picasso depicts the progressive abstraction of a bull. In this series of lithographs, the artist transforms a bull from a concrete, fully rendered, anatomical drawing, into a sketch composition of a few lines that still manages to capture the essence of the bull.<div style="background-color: #d6d6d6;margin: 12px 0;">例如，在著名的“公牛”系列（图 2）中，毕加索描绘了公牛的逐步抽象。在这一系列石版画中，艺术家将公牛从具体、完整呈现的解剖画转换成了仅用几笔线条构成的草图，这些线条仍然能够捕捉到公牛的本质。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-7ef1a682-2fd3-404b-a986-75cb0433c3f4" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-1="150,1170">In this paper, we pose the question - can computer renderings imitate such a process of sketching abstraction, converting a photograph from a concrete depiction to an abstract one?<div style="background-color: #d6d6d6;margin: 12px 0;">在本文中，我们提出一个问题 - 计算机渲染能否模仿草图绘制的抽象过程，将一张照片从具体的描绘转换成抽象的呢？</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-7ef1a682-2fd3-404b-a986-75cb0433c3f4" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-1="151,1256">Today, machines can render realistic sketches simply by applying mathematical and geometric operations to an input photograph [Canny 1986; Winnemöller et al. 2012]. However, creating abstractions is more difficult for machines to achieve. The abstraction process suggests that the artist selects visual features that capture the underlying structure and semantic meaning of the object or scene, to produce a minimal, yet descriptive rendering. This demands semantic understanding of the subject, which is more complex than applying simple geometric operations to the image. To fill this semantic gap, we use CLIP [Radford et al. 2021], a neural network trained on various styles of images paired with text. CLIP is exceptional at encoding the semantic meaning of visual depictions, regardless of their style [Goh et al. 2021].<div style="background-color: #d6d6d6;margin: 12px 0;">现在，机器可以通过应用数学和几何运算简单地对待输入照片生成逼真的草图 [Canny 1986; Winnemöller et al. 2012]。然而，对机器来说，创建抽象作品更具挑战性。抽象过程意味着艺术家选择能够捕捉对象或场景的基本结构和语义意义的视觉特征，以产生一种既简洁又具描述性的渲染。这需要对主题进行语义理解，这比简单地应用图像的几何运算更为复杂。为了填补这一语义鸿沟，我们使用了CLIP [Radford et al. 2021]，这是一种在多种风格的图像及其配对的文本上训练的神经网络。CLIP在编码视觉描述的语义意义上非常出色，无论其风格如何 [Goh et al. 2021]。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-7ef1a682-2fd3-404b-a986-75cb0433c3f4" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-1="149,1623">Previous works that attempt to replicate human-like sketching often use sketch datasets of the desired level of abstraction to guide the form and style of the generated sketch [Berger et al. 2013; Li et al. 2015; Muhammad et al. 2018]. While such data-driven approach can imitate the final rendering of human artwork, it requires the existence and availability of relevant datasets, and it restricts the output style to match this data. In contrast, we present an optimization-based photo-to-sketch generation technique that achieves different levels of abstraction without requiring an explicit sketch dataset. Our method uses the CLIP image encoder to guide the process of converting a photograph to an abstract sketch. CLIP encoding provides the semantic understanding of the concept depicted, while the photograph itself provides the geometric grounding of the sketch to the concrete subject.<div style="background-color: #d6d6d6;margin: 12px 0;">之前尝试复制类人绘画的作品通常使用所需抽象级别的草图数据集来指导生成草图的形式和风格 [Berger et al. 2013; Li et al. 2015; Muhammad et al. 2018]。虽然这种数据驱动的方法可以模仿人类艺术作品的最终渲染效果，但它需要相关数据集的存在和可用性，并且它限制了输出风格以匹配这些数据。相比之下，我们提出了一种基于优化的照片转草图生成技术，该技术在不要求显式草图数据集的情况下实现不同级别的抽象。我们的方法使用CLIP图像编码器来指导将照片转换为抽象草图的过程。CLIP编码提供了对描绘概念的语义理解，而照片本身为草图对具体主题的几何定位提供了依据。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-7ef1a682-2fd3-404b-a986-75cb0433c3f4" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-1="837,433">Our sketches are defined using a set of thin, black strokes (Bézier curves) placed on a white background, and the level of abstraction is dictated by the number of strokes used. Given the target image to be drawn, we use a differentiable rasterizer [Li et al. 2020] to directly optimize the strokes' parameters (control points positions) with respect to a CLIP-based loss. We combine the final and intermediate activations of a pre-trained CLIP model to achieve both geometric and semantic simplifications. For improved robustness, we propose a saliency-guided initialization process, based on the local attention maps of a pretrained vision transformer model.<div style="background-color: #d6d6d6;margin: 12px 0;">我们的草图的定义是使用一组放置在白色背景上的细黑线（贝塞尔曲线），抽象程度由所使用的线条数量决定。给定要绘制的目标图像，我们使用可微光栅化器 [Li et al. 2020] 直接优化线条参数（控制点位置），以适应基于CLIP的损失。我们结合了预训练CLIP模型的最终和中间激活，以实现几何和语义的简化。为了提高鲁棒性，我们提出了一种基于预训练视觉变换模型局部注意力图的显著度引导初始化过程。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-7ef1a682-2fd3-404b-a986-75cb0433c3f4" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-1="838,717">The resulting sketches (see Figure 1) demonstrate a combination of the semantic and visual features that capture the essence of the input object, while still being minimal and providing good category and instance level object recognition clues.<div style="background-color: #d6d6d6;margin: 12px 0;">生成的草图（见图1）展示了语义和视觉特征的结合，捕捉了输入对象的本质，同时仍然简洁，并为对象识别提供了良好的类别和实例级别线索。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-7ef1a682-2fd3-404b-a986-75cb0433c3f4" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-1="808,851"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_2.jpg?x=808&amp;y=851&amp;w=656&amp;h=678"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-7ef1a682-2fd3-404b-a986-75cb0433c3f4" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-1="813,1549">Fig. 3. Different levels of abstraction produced by our method. Left to right: input images and increased level of abstraction. The top three sketches were produced using 16,8 ,and 4 strokes in columns 2,3 ,and 4 respectively, and the man's sketch was produced using 32,16,and 8 strokes. @Rose by AndreaA - Can Stock Photo Inc. [Standard License Agreement] via (https: //bit.ly/39w8egS); Giraffe [Public Domain US] via (https://bit.ly/3s61Env); Camel [Public Domain] via (https://bit.ly/3s101KU); Face image from [Min-ear and Park 2004], used with permission.<div style="background-color: #d6d6d6;margin: 12px 0;">图3. 我们方法产生的不同抽象级别。从左到右：输入图像和增加的抽象级别。前三张草图分别使用16、8和4条线在第二、三、四列生成，而人像草图分别使用32、16和8条线。@Rose by AndreaA - Can Stock Photo Inc. [标准许可协议] 通过 (https://bit.ly/39w8egS)；长颈鹿 [美国公有领域] 通过 (https://bit.ly/3s61Env)；骆驼 [公有领域] 通过 (https://bit.ly/3s101KU)；面部图像来自 [Min-ear and Park 2004]，经许可使用。</div></div></div></div></div></div></span></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-2="127,196">2 RELATED WORK<div style="background-color: #d6d6d6;margin: 12px 0;">2 相关工作</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-2="127,240">Unlike edge-map extraction methods [Canny 1986; Winnemöller et al. 2012] which are purely based on geometry, free-hand sketch generation aims to produce sketches that are abstract in terms of structure and semantic interpretation so as to mimic a human-like style. This high-level goal varies among different works, as there are many styles and levels of abstraction that can be produced. Consequently, existing works tend to choose the desired output style based on a given dataset: from highly abstract - guided only by a category-based text prompt [Ha and Eck 2017], to more concrete [Arbeláez et al. 2011], which is guided by contour detection. Figure 4 illustrates this spectrum. While methods that rely on sketch datasets are limited to the abstraction levels present, our method is optimization based. Hence, it is capable of producing multiple levels of abstraction without relying on the existence of suitable sketch datasets or requiring a lengthy new training phase.<div style="background-color: #d6d6d6;margin: 12px 0;">与基于几何学的边缘图提取方法 [Canny 1986; Winnemöller et al. 2012] 不同，徒手草图生成旨在产生在结构和语义解释上抽象的草图，以模仿类似人类的风格。这一高级目标在不同作品中各不相同，因为可以产生许多风格和抽象级别。因此，现有作品倾向于根据给定的数据集选择所需的输出风格：从高度抽象的 - 仅由基于类别的文本提示 [Ha 和 Eck 2017] 引导，到更具体的 [Arbeláez et al. 2011]，由轮廓检测引导。图 4 展示了这一系列。虽然依赖于草图数据集的方法仅限于存在的抽象级别，我们的方法基于优化。因此，它能够在不依赖适合的草图数据集或需要漫长的重新训练阶段的情况下，产生多个抽象级别。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-2="130,688"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_3.jpg?x=130&amp;y=688&amp;w=632&amp;h=166"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-2="128,880">Fig. 4. Variations in style and abstraction among sketch datasets - examples are arranged from left to right by the degree of abstraction: from edge-based to category-based sketches. For datasets that have image references, the input image is placed alongside the sketch; otherwise, the input is just the category label (e.g., "elephant").<div style="background-color: #d6d6d6;margin: 12px 0;">图 4. 草图数据集中风格和抽象度的变化 - 示例按照抽象程度从左到右排列：从基于边缘的草图到基于类别的草图。对于具有图像参考的数据集，输入图像与草图并排放置；否则，输入只是一个类别标签（例如，“大象”）。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-2="151,1040">We provide a brief review of existing relevant photo-sketch synthesis works, which all rely on sketch-specific datasets. Table 1 summarizes the high-level characteristics that differentiate these methods.<div style="background-color: #d6d6d6;margin: 12px 0;">我们简要回顾了现有的与照片-草图合成相关的作品，这些作品都依赖于特定于草图的数据集。表 1 概述了区分这些方法的高级特征。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-2="151,1168">Photo-Sketch Synthesis. Early methods learn explicit models to synthesize facial sketches [Berger et al. 2013; Chen et al. 2001]. To generalise to categories beyond faces, Li et al. [2015] learn a deformable stroke model based on perceptual grouping.<div style="background-color: #d6d6d6;margin: 12px 0;">照片-草图合成。早期方法学习显式模型来合成面部草图 [Berger et al. 2013; Chen et al. 2001]。为了推广到超出面部的类别，Li 等人 [2015] 学习了一个基于感知组分的可变形笔划模型。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-2="150,1284">In the deep learning era, it is intuitive to think of photo-sketch generation as a domain translation task. However, the highly sparse and abstract nature of sketches introduces challenges for trivial methods [Isola et al. 2017; Wang et al. 2017] to adhere to the sketch domain, and therefore sketch-specific adjustments must be made.<div style="background-color: #d6d6d6;margin: 12px 0;">在深度学习时代，将照片-草图生成视为一个领域翻译任务是直观的。然而，草图的高度稀疏和抽象特性使得简单的方法 [Isola et al. 2017; Wang et al. 2017] 难以遵循草图领域，因此必须进行针对草图的特殊调整。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-2="150,1424">Song et al. [2018] propose a hybrid supervised-unsupervised-unsupervised-unsupervised multi-task learning approach with a shortcut cycle consistency constraint. Li et al. [2019] present a learning-based contour generation algorithm to resolve the diversity of the human drawings in the dataset. Kampelmuhler and Pinz [2020] propose an encoder-decoder architecture, where the loss is guided by a pretrained sketch classifier network. Qi and Su et al. [2021] propose a lattice representation for sketches, employing LSTM and graph models to generate a vector sketch from points sampled from the edge map. The density of points determines the abstraction level of the sketch.<div style="background-color: #d6d6d6;margin: 12px 0;">Song等人 [2018] 提出了一个混合监督-无监督-无监督-无监督的多任务学习方法，并具有捷径循环一致性约束。Li等人 [2019] 提出了一个基于学习的轮廓生成算法，以解决数据集中人类绘画的多样性问题。Kampelmuhler和Pinz [2020] 提出了一个编码器-解码器架构，其中损失由一个预训练的草图分类器网络引导。Qi和Su等人 [2021] 提出了草图的格子表示法，采用LSTM和图模型从边缘图中的采样点生成矢量草图。点的密度决定了草图的抽象级别。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-2="151,1708">A different approach for image-sketch synthesis formulates the sketching task as a multi-agent referential game in which two reinforcement learning agents must communicate visual concepts to each other through sketches [Mihai and Hare 2021b; Qiu et al. 2021]. Similarly to these works, we were inspired by cognitive processes to identify and formulate our problem and objective. However, our primary focus is on abstractions as an integral part of sketches, and our objective is to produce sketches that are interpertable by humans. Their primary focus is on building a visual communication channel between agents, using sketches as a tool, where drawing is done in context.<div style="background-color: #d6d6d6;margin: 12px 0;">图像-草图合成的另一种方法将草图绘制任务公式化为一个多代理参考游戏，其中两个强化学习代理必须通过草图相互传达视觉概念 [Mihai和Hare 2021b; Qiu et al. 2021]。与这些工作类似，我们受到了认知过程的启发来识别和制定我们的问题和目标。然而，我们的主要关注点是作为草图整体部分的抽象，我们的目标是生成人类可以解释的草图。他们的主要关注点是构建代理之间的视觉通信渠道，使用草图作为一种工具，并在上下文中进行绘制。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-2="814,455">Table 1. Comparison of sketch synthesis algorithms. (A) Is not restricted to categories from training dataset, (B) Can produce different levels of abstractions, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2478" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D402 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">C</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> Is not limited to abstractions in the dataset, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2479" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D403 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">D</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> Can produce vector sketches, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2480" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>E</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> Can produce a sequential sketch <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2481" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>F</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> Is not directly relying on the edge map.<div style="background-color: #d6d6d6;margin: 12px 0;">表1. 草图合成算法比较。（A）不受训练数据集类别的限制，（B）能够生成不同级别的抽象，<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2482" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D402 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">C</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 不局限于数据集中的抽象，<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2483" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D403 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">D</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 能够生成矢量草图，<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2484" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>E</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 能够生成顺序草图 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2485" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>F</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 不直接依赖边缘图。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-2="813,611"><div class="table-container"><table class="fixed-table"><thead><tr><th>Method</th><th>A</th><th>B</th><th>C</th><th>D</th><th>E</th><th>F</th></tr></thead><tbody><tr><td>Berger et al. [2013]</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2486" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td>3</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2487" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2488" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td>3</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2489" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td></tr><tr><td>Li et al. [2015]</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2490" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2491" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2492" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math></mjx-assistive-mml></mjx-container></td><td>3</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2493" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2494" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td></tr><tr><td>Muhammad et al. [2018]</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2495" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td>3</td><td>3</td><td>3</td><td>3</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2496" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td></tr><tr><td>Song et al. [2018]</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2497" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2498" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2499" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td>3</td><td>3</td><td>3</td></tr><tr><td>Li et al. [2019]</td><td>3</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2500" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2501" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2502" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2503" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td>3</td></tr><tr><td>Kampelmühler and Pinz [2020]</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2504" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2505" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2506" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2507" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2508" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td>3</td></tr><tr><td>Qi and Su et al. [2021]</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2509" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td>3</td><td>3</td><td>3</td><td>3</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2510" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td></tr><tr><td>Ours</td><td>3</td><td>3</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2511" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c2713 TEX-A"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>✓</mi></math></mjx-assistive-mml></mjx-container></td><td>3</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2512" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></td><td>3</td></tr></tbody></table></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-2="839,983">Vector Graphics. There is a substantial literature on stroke-based rendering, contour visualization, and feature line rendering, summarized in the surveys by Hertzmann [2003], and by Bénard and Hertzmann [2019]. Vector representations are widely used for a variety of sketching tasks and applications, employing a number of deep learning models including RNN [Ha and Eck 2017], BERT [Lin et al. 2020, Transformers [Bhunia et al. 2020; Ribeiro et al. 2020], CNNs [Chen et al. 2017], GANs [Varshaneya et al. 2021] and reinforcement learning algorithms [Ganin et al. 2018; Mellor et al. 2019; Zhou et al. 2018]. The recent development of differentiable rendering algorithms [Li et al. 2020; Mihai and Hare 2021a; Zheng et al. 2019 makes it possible to manipulate or synthesize vector content by using raster-based loss functions. We use the method of Li et al. [2020], as it can handle a wide range of curves and strokes, including Bézier curves.<div style="background-color: #d6d6d6;margin: 12px 0;">向量图形。关于基于笔划的渲染、轮廓可视化和特征线渲染的文献相当丰富，这在Hertzmann [2003]和Bénard与Hertzmann [2019]的综述中有所总结。向量表示法被广泛应用于各种草图任务和应用中，采用包括RNN [Ha和Eck 2017]、BERT [Lin等人2020]、Transformer [Bhunia等人2020；Ribeiro等人2020]、CNN [Chen等人2017]、GAN [Varshaneya等人2021]以及强化学习算法 [Ganin等人2018；Mellor等人2019；Zhou等人2018]。最近可微分渲染算法的发展 [Li等人2020；Mihai和Hare 2021a；Zheng等人2019] 使得通过使用基于光栅的损失函数操纵或合成向量内容成为可能。我们使用Li等人 [2020] 的方法，因为它能够处理广泛的曲线和笔划，包括贝塞尔曲线。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-2="837,1421">Sketches Abstraction. Sketches Abstraction. Only two previous works propose a unified model to produce sketches of a given image at different levels of abstraction. Berger et al. [2013] collected a dataset of portraits drawn by professional artists at different levels of abstraction. For each artist, a library of strokes is created indexed by shape, curvature, and length, and these are used to replace curves extracted from the image edge map. Their method is limited to portraits and requires a new dataset for each level of abstraction.<div style="background-color: #d6d6d6;margin: 12px 0;">草图抽象。只有两项之前的工作提出了一个统一的模型，用于生成给定图像在不同抽象层次上的草图。Berger等人[2013]收集了一个由专业艺术家在不同抽象层次上绘制的肖像数据集。对于每位艺术家，创建了一个按形状、曲率和长度索引的笔画库，并使用这些笔画替换从图像边缘图提取的曲线。他们的方法仅限于肖像，并且对于每个抽象层次都需要一个新的数据集。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-73df8ef9-fc7e-4deb-993a-73fe61813e03" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-2="835,1651">Muhammad et al. [2018] propose a stroke-level sketch abstraction model. A reinforcement learning agent is trained to select which strokes can be removed from an edge map representation of the input image without affecting its recognizability. The recognition signal is provided by a sketch classifier trained on 9 classes from the QuickDraw dataset [Ha and Eck 2017], and hence to operate on new classes, a fine-tuning stage is required.<div style="background-color: #d6d6d6;margin: 12px 0;">Muhammad等人[2018]提出了一个基于笔画的草图抽象模型。训练一个强化学习代理，以选择可以从输入图像的边缘图表示中移除哪些笔画，而不会影响其可识别性。识别信号由一个在QuickDraw数据集[Ha和Eck 2017]的9个类别上训练的草图分类器提供，因此，为了在新的类别上操作，需要一个微调阶段。</div></div></div></div></div></div></span></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-9e14aa50-e5d0-4626-825a-9e9d62e15e50" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-3="193,197"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_4.jpg?x=193&amp;y=197&amp;w=1172&amp;h=273"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-9e14aa50-e5d0-4626-825a-9e9d62e15e50" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-3="128,493">Fig. 5. Method overview - Given a target image <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2513" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>I</mi></math></mjx-assistive-mml></mjx-container> ,and the number of strokes <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2514" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container> ,a saliency map is used as the distribution to sample the initial strokes locations <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2515" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2E"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2E"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mrow data-mjx-texclass="ORD"><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub><mo>,</mo><mo>.</mo><mo>.</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msub></mrow><mo data-mjx-texclass="CLOSE">}</mo></mrow></math></mjx-assistive-mml></mjx-container> . A differentiable rasterizer <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2516" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow></math></mjx-assistive-mml></mjx-container> is used to create a resterized sketch <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2517" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></math></mjx-assistive-mml></mjx-container> . Both the sketch and the image are fed into a pretrained CLIP model to evaluate the geometric distance <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2518" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D454 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>L</mi></mrow><mrow data-mjx-texclass="ORD"><mi>g</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> and semantic distance <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2519" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>L</mi></mrow><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> between the two. The loss is backpropagated through <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2520" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.105em; padding-left: 0.507em; margin-bottom: -0.597em;"><mjx-mo class="mjx-sop" style="width: 0px; margin-left: -0.278em;"><mjx-c class="mjx-c2DC TEX-S1"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-base></mjx-mover></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mover><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow><mo>~</mo></mover></mrow></math></mjx-assistive-mml></mjx-container> to optimize the strokes parameters until convergence. The learned parameters and loss terms are highlighted in red, while the blue components are frozen during the entire optimization process, solid arrows are used to mark the backpropagation path. OHorse from cadnav.com [Personal and Commercial] via (https://bit.ly/3vzopm).<div style="background-color: #d6d6d6;margin: 12px 0;">图5. 方法概述 - 给定一个目标图像 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2521" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>I</mi></math></mjx-assistive-mml></mjx-container>，和笔画数量 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2522" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container>，使用显著性图作为分布来抽样初始笔画位置 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2523" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2E"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2E"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mrow data-mjx-texclass="ORD"><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub><mo>,</mo><mo>.</mo><mo>.</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msub></mrow><mo data-mjx-texclass="CLOSE">}</mo></mrow></math></mjx-assistive-mml></mjx-container>。使用一个可微分的光栅化器 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2524" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow></math></mjx-assistive-mml></mjx-container> 创建一个光栅化草图 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2525" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></math></mjx-assistive-mml></mjx-container>。草图和图像都被送入一个预训练的CLIP模型，以评估两者之间的几何距离 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2526" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D454 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>L</mi></mrow><mrow data-mjx-texclass="ORD"><mi>g</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> 和语义距离 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2527" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>L</mi></mrow><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>。损失通过 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2528" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.105em; padding-left: 0.507em; margin-bottom: -0.597em;"><mjx-mo class="mjx-sop" style="width: 0px; margin-left: -0.278em;"><mjx-c class="mjx-c2DC TEX-S1"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-base></mjx-mover></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mover><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow><mo>~</mo></mover></mrow></math></mjx-assistive-mml></mjx-container> 反向传播以优化笔画参数直到收敛。学习的参数和损失项以红色突出显示，而蓝色组件在整个优化过程中保持冻结，实线箭头用于标记反向传播路径。OHorse来自cadnav.com [个人和商业] 通过 (https://bit.ly/3vzopm)。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-9e14aa50-e5d0-4626-825a-9e9d62e15e50" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-3="153,748">CLIP-based Image Abstraction. CLIP [Radford et al. 2021] is a neural network trained on 400 million image-text pairs collected from the internet with the objective of creating a joint latent space using contrastive learning. Being trained on a wide variety of image domains along with lingual concepts, CLIP models are found to be very useful for a wide range of zero-shot tasks. The most relevant works within our context are by Frans et al. [2021] (CLIPDraw), and Tian and Ha [2021]. CLIPDraw optimizes a set of random Bezier curves to create a drawing that maximizes the CLIP similarity for a given text prompt. Likewise, we also use a differentiable rasterizer [Li et al. 2020] and a CLIP-based loss. However, while CLIPDraw is purely text-driven, we allow control over the output appearance, conditioned on the input image. For this purpose, we introduce a new geometric loss term and a saliency-guided initialization procedure.<div style="background-color: #d6d6d6;margin: 12px 0;">基于CLIP的图像抽象。CLIP [Radford等人2021] 是一个在4亿个从互联网收集的图像-文本对上训练的神经网络，其目标是通过对比学习创建一个联合潜在空间。由于CLIP模型在广泛的图像域和语言概念上进行了训练，它们被发现在广泛的零样本任务中非常有用。在我们研究的背景下，最相关的工作是由Frans等人[2021]（CLIPDraw）以及Tian和Ha [2021]进行的。CLIPDraw优化一组随机贝塞尔曲线来创建一个绘画，该绘画针对给定文本提示最大化CLIP相似性。同样，我们还使用了一个可微光栅化器[Li等人2020]和一个基于CLIP的损失函数。然而，与CLIPDraw纯粹由文本驱动不同，我们允许根据输入图像控制输出外观。为此，我们引入了一个新的几何损失项和一个显著性引导的初始化过程。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-9e14aa50-e5d0-4626-825a-9e9d62e15e50" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-3="150,1148">Tian and Ha [2021] employ evolutionary algorithms combined with CLIP, to produce creative abstract concepts represented by colored triangles guided by text or shape. Their results are limited to either fully semantic (using CLIP's text encoder) or entirely geometric (using L2), whereas we are able to integrate both.<div style="background-color: #d6d6d6;margin: 12px 0;">Tian和Ha [2021] 结合使用进化算法和CLIP，生成由文本或形状引导的彩色三角形表示的创造性抽象概念。他们的结果仅限于完全语义（使用CLIP的文本编码器）或完全几何（使用L2），而我们能够将这两者结合起来。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-9e14aa50-e5d0-4626-825a-9e9d62e15e50" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-3="127,1315">3 METHOD<div style="background-color: #d6d6d6;margin: 12px 0;">3 方法</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-9e14aa50-e5d0-4626-825a-9e9d62e15e50" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-3="126,1356">We define a sketch as a set of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2529" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container> black strokes <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2530" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2E"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2E"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mrow data-mjx-texclass="ORD"><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub><mo>,</mo><mo>.</mo><mo>.</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msub></mrow><mo data-mjx-texclass="CLOSE">}</mo></mrow></math></mjx-assistive-mml></mjx-container> placed on a white background. We use a two-dimensional Bézier curve with four control points <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2531" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7B TEX-S2"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.294em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7D TEX-S2"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.685em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 1.09em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7B TEX-S2"></mjx-c></mjx-mo><mjx-msup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: 0.477em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7D TEX-S2"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.685em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 1.09em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo>=</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></msubsup><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup><mo>=</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msub><mrow data-mjx-texclass="ORD"><mi>x</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo>,</mo><msub><mrow data-mjx-texclass="ORD"><mi>y</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></msup><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup></math></mjx-assistive-mml></mjx-container> to represent each stroke. For simplicity, we only optimize the position of control points and choose to keep the degree, width, and opacity of the strokes fixed. However, these parameters can later be used to achieve variations in style (see Figure 10a). The parameters of the strokes are fed to a differentiable rasterizer <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2532" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow></math></mjx-assistive-mml></mjx-container> ,which forms the rasterized sketch <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2533" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-lop"><mjx-c class="mjx-c28 TEX-S2"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.297em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-texatom><mjx-script style="vertical-align: -0.288em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2026"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.139em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-texatom><mjx-script style="vertical-align: -0.288em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup></mjx-texatom><mjx-mo class="mjx-lop"><mjx-c class="mjx-c29 TEX-S2"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2026"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow><mo>=</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mo fence="false" stretchy="false">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></msubsup><msubsup><mrow data-mjx-texclass="ORD"><mo fence="false" stretchy="false">}</mo></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup><mo>,</mo><mo>…</mo><mo fence="false" stretchy="false">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></msubsup><msubsup><mrow data-mjx-texclass="ORD"><mo fence="false" stretchy="false">}</mo></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>=</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub><mo>,</mo><mo>…</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msub></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> . As is often conventional [Mellor et al. 2019; Muhammad et al. 2018; Tian and Ha 2021], we vary the number of strokes <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2534" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container> to create different levels of abstraction.<div style="background-color: #d6d6d6;margin: 12px 0;">我们将草图定义为放置在白色背景上的一组 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2535" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container> 黑色笔划 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2536" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2E"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2E"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mrow data-mjx-texclass="ORD"><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub><mo>,</mo><mo>.</mo><mo>.</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msub></mrow><mo data-mjx-texclass="CLOSE">}</mo></mrow></math></mjx-assistive-mml></mjx-container>。我们使用具有四个控制点的二维贝塞尔曲线 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2537" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7B TEX-S2"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.294em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7D TEX-S2"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.685em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 1.09em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7B TEX-S2"></mjx-c></mjx-mo><mjx-msup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: 0.477em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7D TEX-S2"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.685em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 1.09em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo>=</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></msubsup><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup><mo>=</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msub><mrow data-mjx-texclass="ORD"><mi>x</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo>,</mo><msub><mrow data-mjx-texclass="ORD"><mi>y</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></msup><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup></math></mjx-assistive-mml></mjx-container> 来表示每一笔划。为了简化，我们只优化控制点的位置，并选择保持笔划的次数、宽度和不透明度固定。然而，这些参数以后可以用来实现样式的变化（见图10a）。笔划的参数被输入到一个可微光栅化器 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2538" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow></math></mjx-assistive-mml></mjx-container> 中，它形成了光栅化草图 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2539" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-lop"><mjx-c class="mjx-c28 TEX-S2"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.297em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-texatom><mjx-script style="vertical-align: -0.288em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2026"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.139em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-texatom><mjx-script style="vertical-align: -0.288em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup></mjx-texatom><mjx-mo class="mjx-lop"><mjx-c class="mjx-c29 TEX-S2"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2026"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow><mo>=</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mo fence="false" stretchy="false">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></msubsup><msubsup><mrow data-mjx-texclass="ORD"><mo fence="false" stretchy="false">}</mo></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup><mo>,</mo><mo>…</mo><mo fence="false" stretchy="false">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></msubsup><msubsup><mrow data-mjx-texclass="ORD"><mo fence="false" stretchy="false">}</mo></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>=</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub><mo>,</mo><mo>…</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msub></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>。如通常惯例 [Mellor et al. 2019; Muhammad et al. 2018; Tian and Ha 2021] 所示，我们改变笔划的数量 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2540" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container> 以创建不同级别的抽象。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-9e14aa50-e5d0-4626-825a-9e9d62e15e50" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-3="151,1680">An overview of our method can be seen in Figure 5. Given a target image <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2541" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>I</mi></math></mjx-assistive-mml></mjx-container> of the desired subject,our goal is to synthesize the corresponding sketch <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2542" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></math></mjx-assistive-mml></mjx-container> while maintaining both the semantic and geometric attributes of the subject. We begin by extracting the salient regions of the input image to define the initial locations of the strokes. Next, in each step of the optimization we feed the stroke parameters to a differentiable rasterizer <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2543" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow></math></mjx-assistive-mml></mjx-container> to produce the rasterized sketch. The resulting sketch, as well as the original in-age are then fed into CLIP to define a CLIP-based perceptual loss. We back-propagate the loss through the differentiable rasterizer and update the strokes' control points directly at each step until convergence of the loss function.<div style="background-color: #d6d6d6;margin: 12px 0;">我们的方法的概述可以在图5中看到。给定一个目标图像 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2544" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>I</mi></math></mjx-assistive-mml></mjx-container> 作为所需主题，我们的目标是合成相应的草图 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2545" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></math></mjx-assistive-mml></mjx-container>，同时保持主题的语义和几何属性。我们首先提取输入图像的显著区域来定义笔划的初始位置。接下来，在优化的每一步中，我们将笔划参数输入到一个可微光栅化器 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2546" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow></math></mjx-assistive-mml></mjx-container> 中以产生光栅化草图。得到的草图以及原始图像随后被输入到CLIP中，以定义基于CLIP的感知损失。我们通过可微光栅化器反向传播损失，并直接在每一步更新笔划的控制点，直到损失函数收敛。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-9e14aa50-e5d0-4626-825a-9e9d62e15e50" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-3="813,913">3.1 Loss Function<div style="background-color: #d6d6d6;margin: 12px 0;">3.1 损失函数</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-9e14aa50-e5d0-4626-825a-9e9d62e15e50" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-3="814,953">As sketches are highly sparse and abstract, pixel-wise metrics are not sufficient to measure the distance between a sketch and an image. Additionally, even though perceptual losses such as LPIPS [Zhang et al. 2018] can encode semantic information from images, they may not be suitable to encode abstract sketches, as illustrated in Figure 6 (for further analysis, please refer to the supplementary material). One solution is to train task-specific encoders to learn a shared embedding space of images and sketches under which the distance between the two modalities can be computed [Kam-pelmühler and Pinz 2020; Song et al. 2018]. This approach depends on the availability of such datasets, and requires additional effort for training the models.<div style="background-color: #d6d6d6;margin: 12px 0;">由于草图高度稀疏和抽象，像素级度量不足以衡量草图与图像之间的距离。此外，尽管感知损失如LPIPS [Zhang et al. 2018] 能够编码图像中的语义信息，但它们可能不适合编码抽象草图，如图6所示（进一步分析，请参见补充材料）。一种解决方案是训练特定任务的编码器，以学习图像和草图之间的共享嵌入空间，在该空间下可以计算两种模态之间的距离 [Kam-pelmühler和Pinz 2020; Song et al. 2018]。这种方法依赖于此类数据集的可用性，并且需要额外的努力来训练模型。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-9e14aa50-e5d0-4626-825a-9e9d62e15e50" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-3="836,1296">Instead, we utilize the pretrained image encoder model of CLIP, which was trained on various image modalities so that it can encode information from both natural images and sketches without the need for further training. CLIP encodes high-level semantic attributes in the last layer since it was trained on both images and text. We therefore define the distance between the embeddings of the sketch <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2547" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.284em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-mo class="mjx-n" style="vertical-align: 0.25em;"></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>L</mi><mi>I</mi><mi>P</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mo data-mjx-texclass="CLOSE" fence="true" stretchy="true" symmetric="true"></mo></mrow></math></mjx-assistive-mml></mjx-container> and image <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2548" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c49 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>L</mi><mi>I</mi><mi>P</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">I</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> as:<div style="background-color: #d6d6d6;margin: 12px 0;">相反，我们使用了在多种图像模态上预训练的CLIP图像编码器模型，因此它可以编码自然图像和草图的信息，而无需进一步训练。由于CLIP既在图像也在文本上进行了训练，它在最后一层编码了高级语义属性。因此，我们定义了草图 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2549" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.284em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-mo class="mjx-n" style="vertical-align: 0.25em;"></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>L</mi><mi>I</mi><mi>P</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mo data-mjx-texclass="CLOSE" fence="true" stretchy="true" symmetric="true"></mo></mrow></math></mjx-assistive-mml></mjx-container> 和图像 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2550" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c49 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>L</mi><mi>I</mi><mi>P</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">I</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 嵌入之间的距离为：</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-9e14aa50-e5d0-4626-825a-9e9d62e15e50" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><paragraphpositioning data-position-3="910,1514"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" width="full" tabindex="0" ctxtmenu_counter="2551" style="font-size: 122.8%; min-width: 24.513em; position: relative;"><mjx-math width="full" display="true" class="MJX-TEX" aria-hidden="true"><mjx-mtable width="full" side="right" style="min-width: 24.513em;"><mjx-table style="width: auto; min-width: 20.357em; margin: 0px 2.078em;"><mjx-itable width="full"><mjx-mlabeledtr><mjx-mtd><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mi class="mjx-n" space="4"><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c74"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c43"></mjx-c><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c49"></mjx-c><mjx-c class="mjx-c50"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c49 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-n" space="2"><mjx-c class="mjx-c43"></mjx-c><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c49"></mjx-c><mjx-c class="mjx-c50"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.284em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo></mjx-texatom><mjx-mo class="mjx-n" style="vertical-align: 0.25em;"></mjx-mo></mjx-mrow><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mlabeledtr></mjx-itable></mjx-table><mjx-labels style="width: 24.513em;"><mjx-itable align="right" style="right: 0px;"><mjx-mtr style="height: 1.199em;"><mjx-mtd id="mjx-eqn:1"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c28"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c29"></mjx-c></mjx-mtext><mjx-tstrut style="height: 1.199em; vertical-align: -0.35em;"></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-labels></mjx-mtable></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd><mtext>(1)</mtext></mtd><mtd><msub><mrow data-mjx-texclass="ORD"><mi>L</mi></mrow><mrow data-mjx-texclass="ORD"><mtext>semantic&nbsp;</mtext></mrow></msub><mo>=</mo><mi>dist</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>CLIP</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">I</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>,</mo><mi>CLIP</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>,</mo></mrow><mo data-mjx-texclass="CLOSE" fence="true" stretchy="true" symmetric="true"></mo></mrow></mtd></mlabeledtr></mtable></math></mjx-assistive-mml></mjx-container></paragraphpositioning></div></div></div></div><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-9e14aa50-e5d0-4626-825a-9e9d62e15e50" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-3="838,1555">where <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2552" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo></mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo></mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo></mjx-mrow></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mrow><mi>x</mi><mo>⋅</mo><mi>y</mi></mrow><mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow><mi>x</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow><mo>⋅</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow><mi>y</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow></mrow></mfrac></math></mjx-assistive-mml></mjx-container> is the cosine distance. However, the final encoding of the network is agnostic to low-level spatial features such as pose and structure. To measure the geometric similarity between the image and the sketch, and consequently, allow some control over the appearance of the output,we compute the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2553" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>L</mi></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msub></math></mjx-assistive-mml></mjx-container> distance between intermediate level activations of CLIP:<div style="background-color: #d6d6d6;margin: 12px 0;">其中 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2554" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo></mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo></mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo></mjx-mrow></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mrow><mi>x</mi><mo>⋅</mo><mi>y</mi></mrow><mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow><mi>x</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow><mo>⋅</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow><mi>y</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow></mrow></mfrac></math></mjx-assistive-mml></mjx-container> 是余弦距离。然而，网络的最终编码对低级空间特征如姿态和结构是不可知的。为了衡量图像和草图之间的几何相似性，从而对输出的外观进行一定程度的控制，我们计算了CLIP中间层激活之间的 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2555" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>L</mi></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msub></math></mjx-assistive-mml></mjx-container> 距离：</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-9e14aa50-e5d0-4626-825a-9e9d62e15e50" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><paragraphpositioning data-position-3="870,1731"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" width="full" tabindex="0" ctxtmenu_counter="2556" style="font-size: 122.8%; min-width: 27.465em; position: relative;"><mjx-math width="full" display="true" class="MJX-TEX" aria-hidden="true"><mjx-mtable width="full" side="right" style="min-width: 27.465em;"><mjx-table style="width: auto; min-width: 23.309em; margin: 0px 2.078em;"><mjx-itable width="full"><mjx-mlabeledtr><mjx-mtd><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-munder space="4"><mjx-row><mjx-base><mjx-texatom texclass="OP"><mjx-mo class="mjx-lop"><mjx-c class="mjx-c2211 TEX-S2"></mjx-c></mjx-mo></mjx-texatom></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.167em; padding-left: 0.617em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-under></mjx-row></mjx-munder><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-msubsup space="2"><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-stretchy-v class="mjx-c2016" style="height: 1.199em; vertical-align: -0.349em;"><mjx-ext><mjx-c></mjx-c></mjx-ext><mjx-mark></mjx-mark></mjx-stretchy-v></mjx-mo><mjx-mtable justify="left" style="min-width: 14.61em;"><mjx-table><mjx-itable><mjx-mtr><mjx-mtd><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c49 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mrow space="2"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.284em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-table></mjx-mtable><mjx-mo class="mjx-n"><mjx-stretchy-v class="mjx-c2016" style="height: 1.199em; vertical-align: -0.349em;"><mjx-ext><mjx-c></mjx-c></mjx-ext><mjx-mark></mjx-mark></mjx-stretchy-v></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.385em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.49em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mlabeledtr></mjx-itable></mjx-table><mjx-labels style="width: 27.465em;"><mjx-itable align="right" style="right: 0px;"><mjx-mtr style="height: 2.263em;"><mjx-mtd id="mjx-eqn:2"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c28"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c29"></mjx-c></mjx-mtext><mjx-tstrut style="height: 2.263em; vertical-align: -1.216em;"></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-labels></mjx-mtable></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd><mtext>(2)</mtext></mtd><mtd><msub><mrow data-mjx-texclass="ORD"><mi>L</mi></mrow><mrow data-mjx-texclass="ORD"><mtext>geometric&nbsp;</mtext></mrow></msub><mo>=</mo><munder><mrow data-mjx-texclass="OP"><mo data-mjx-texclass="OP" movablelimits="false">∑</mo></mrow><mrow data-mjx-texclass="ORD"><mi>l</mi></mrow></munder><mo data-mjx-texclass="NONE">⁡</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN" symmetric="true">‖</mo><mtable columnspacing="1em" rowspacing="4pt"><mtr><mtd><mi>C</mi><mi>L</mi><mi>I</mi><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>l</mi></mrow></msub><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">I</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>−</mo><mi>C</mi><mi>L</mi><mi>I</mi><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>l</mi></mrow></msub><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></mtd></mtr></mtable><mo data-mjx-texclass="CLOSE" symmetric="true">‖</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msubsup><mo>,</mo></mtd></mlabeledtr></mtable></math></mjx-assistive-mml></mjx-container></paragraphpositioning></div></div></div></div><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div></div></div></div></div></span></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-4="131,222"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_5.jpg?x=131&amp;y=222&amp;w=630&amp;h=173"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-4="128,416">Fig. 6. Loss functions comparison - we optimize the strokes by minimizing different losses: L2 loss simply encourages the filling of colored pixels, LPIPS is more semantically aware, but the resulting sketch is still close to the edge map (see the XDog edges for comparison). In contrast, our CLIP-based loss allows better semantic depiction while preserving the morphology of the subject. (c) "Cat" by Burnt Pineapple Productions [Public Domain], via (https://bit.ly/3y4IG4H).<div style="background-color: #d6d6d6;margin: 12px 0;">图6. 损失函数比较 - 我们通过最小化不同的损失来优化笔画：L2损失仅鼓励填充彩色像素，LPIPS在语义上更加敏感，但生成的草图仍然接近边缘图（参见图中XDog边缘进行比较）。相比之下，我们基于CLIP的损失允许在保持主题形态的同时进行更好的语义描述。（c）“猫”由Burnt Pineapple Productions创作[公用领域]，通过（https://bit.ly/3y4IG4H）提供。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-4="151,646">where <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2557" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>L</mi><mi>I</mi></mrow><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>l</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> is the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2558" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>L</mi><mi>I</mi></mrow><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>l</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> is the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2559" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>L</mi><mi>I</mi><mi>P</mi></mrow></math></mjx-assistive-mml></mjx-container> encoder activation at layer <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2560" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>l</mi></math></mjx-assistive-mml></mjx-container> . Specifically, we use layers 3 and 4 of the ResNet101 CLIP model. The final objective of the optimization is then defined as:<div style="background-color: #d6d6d6;margin: 12px 0;">其中 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2561" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>L</mi><mi>I</mi></mrow><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>l</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> 是 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2562" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>L</mi><mi>I</mi></mrow><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>l</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> 是 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2563" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>L</mi><mi>I</mi><mi>P</mi></mrow></math></mjx-assistive-mml></mjx-container> 编码器在层 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2564" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>l</mi></math></mjx-assistive-mml></mjx-container> 的激活。具体来说，我们使用了ResNet101 CLIP模型的第3层和第4层。优化的最终目标随后定义为：</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><paragraphpositioning data-position-4="283,738"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" width="full" tabindex="0" ctxtmenu_counter="2565" style="font-size: 122.8%; min-width: 17.261em; position: relative;"><mjx-math width="full" display="true" class="MJX-TEX" aria-hidden="true"><mjx-mtable width="full" side="right" style="min-width: 17.261em;"><mjx-table style="width: auto; min-width: 13.105em; margin: 0px 2.078em;"><mjx-itable width="full"><mjx-mlabeledtr><mjx-mtd><mjx-munder><mjx-row><mjx-base style="padding-left: 0.237em;"><mjx-texatom texclass="OP"><mjx-mo class="mjx-n"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c></mjx-mo></mjx-texatom></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.167em;"><mjx-texatom size="s" texclass="ORD"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.284em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup></mjx-texatom></mjx-under></mjx-row></mjx-munder><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D464 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mlabeledtr></mjx-itable></mjx-table><mjx-labels style="width: 17.261em;"><mjx-itable align="right" style="right: 0px;"><mjx-mtr style="height: 1.818em;"><mjx-mtd id="mjx-eqn:3"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c28"></mjx-c><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c29"></mjx-c></mjx-mtext><mjx-tstrut style="height: 1.818em; vertical-align: -1.068em;"></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-labels></mjx-mtable></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd><mtext>(3)</mtext></mtd><mtd><munder><mrow data-mjx-texclass="OP"><mo data-mjx-texclass="OP">min</mo></mrow><mrow data-mjx-texclass="ORD"><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup></mrow></munder><mo data-mjx-texclass="NONE">⁡</mo><msub><mrow data-mjx-texclass="ORD"><mi>L</mi></mrow><mrow data-mjx-texclass="ORD"><mtext>geometry&nbsp;</mtext></mrow></msub><mo>+</mo><msub><mrow data-mjx-texclass="ORD"><mi>w</mi></mrow><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow></msub><mo>⋅</mo><msub><mrow data-mjx-texclass="ORD"><mi>L</mi></mrow><mrow data-mjx-texclass="ORD"><mtext>semantic&nbsp;</mtext></mrow></msub><mo>,</mo></mtd></mlabeledtr></mtable></math></mjx-assistive-mml></mjx-container></paragraphpositioning></div></div></div></div><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-4="127,798">with <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2566" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D464 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>w</mi></mrow><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow></msub><mo>=</mo><mrow data-mjx-texclass="ORD"><mn>0.1</mn></mrow></math></mjx-assistive-mml></mjx-container> . We analyze the contribution of different layers and weights, as well as the results of using different CLIP models in the supplementary material.<div style="background-color: #d6d6d6;margin: 12px 0;">其中 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2567" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D464 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>w</mi></mrow><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow></msub><mo>=</mo><mrow data-mjx-texclass="ORD"><mn>0.1</mn></mrow></math></mjx-assistive-mml></mjx-container> 。我们在补充材料中分析了不同层和权重的贡献，以及使用不同CLIP模型的结果。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-4="129,902">3.2 Optimization<div style="background-color: #d6d6d6;margin: 12px 0;">3.2 优化</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-4="127,941">Our goal is to optimize the set of parameters <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2568" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.284em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-s3"><mjx-c class="mjx-c7B TEX-S3"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7B TEX-S2"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.294em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7D TEX-S2"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.685em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 1.09em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-s3"><mjx-c class="mjx-c7D TEX-S3"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.985em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 1.683em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup><mo>=</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></msubsup><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup></math></mjx-assistive-mml></mjx-container> to define a sketch that closely resembles the target image <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2569" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>I</mi></math></mjx-assistive-mml></mjx-container> in terms of both geometry and semantics. At each step of the optimization, we use the Adam optimizer [Kingma and Ba 2015] to compute the gradients of the loss with respect to the strokes’ parameters <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2570" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.284em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup></math></mjx-assistive-mml></mjx-container> . We follow the same data augmentation scheme suggested in CLIP-Draw [Frans et al. 2021] and apply random affine augmentations to both the sketch and the target image before feed-forwarding into CLIP. The transformations we use and onPerspective and RandomResizedCrop. These augmentations prevent the generation of adversarial sketches, which minimize the objective but are not meaningful to humans. We repeat this process until convergence, (when the difference in loss between two successive evaluations is less than 0.00001 . This typically takes around 2000 iterations. Figure 7 illustrates the progression of the generated sketch as the optimization evolves. The learning rate is set to 1 and we evaluate the output sketch every 10 iterations. Evaluation is done by computing the loss without random augmentations. It takes 6 minutes to run 2000 iterations on a single Tesla V100 GPU.<div style="background-color: #d6d6d6;margin: 12px 0;">我们的目标是优化参数集 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2571" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.284em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-s3"><mjx-c class="mjx-c7B TEX-S3"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7B TEX-S2"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.294em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7D TEX-S2"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.685em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 1.09em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-s3"><mjx-c class="mjx-c7D TEX-S3"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.985em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 1.683em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup><mo>=</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></msubsup><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup></math></mjx-assistive-mml></mjx-container>，以定义一个草图，该草图在几何和语义两个方面都与目标图像 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2572" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>I</mi></math></mjx-assistive-mml></mjx-container> 高度相似。在优化的每一步，我们使用 Adam 优化器 [Kingma 和 Ba 2015] 来计算损失相对于笔触参数 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2573" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.284em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup></math></mjx-assistive-mml></mjx-container> 的梯度。我们遵循 CLIP-Draw [Frans 等人 2021] 中建议的同样数据增强方案，并在前向传播到 CLIP 之前，对草图和目标图像应用随机仿射增强。我们使用的变换包括 onPerspective 和 RandomResizedCrop。这些增强防止生成对抗性草图，这些草图虽然可以最小化目标函数，但对人类来说却没有意义。我们重复这个过程直到收敛（即两次连续评估之间的损失差异小于 0.00001）。这通常需要大约 2000 次迭代。图 7 展示了随着优化过程的进行，生成草图的变化。学习率设置为 1，我们每 10 次迭代评估一次输出草图。评估是通过计算没有随机增强的损失来完成的。在单个 Tesla V100 GPU 上运行 2000 次迭代需要 6 分钟。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-4="154,1517"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_5.jpg?x=154&amp;y=1517&amp;w=583&amp;h=156"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-4="127,1696">Fig. 7. The sketch appearance throughout the optimization iterations. (Face image from [Minear and Park 2004], used with permission.<div style="background-color: #d6d6d6;margin: 12px 0;">图 7。优化迭代过程中草图的外观变化。（面部图像来自 [Minear 和 Park 2004]，经许可使用。）</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-4="815,198"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_5.jpg?x=815&amp;y=198&amp;w=612&amp;h=359"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-4="906,565">(b) Automatic selection procedure of the final sketch<div style="background-color: #d6d6d6;margin: 12px 0;">(b) 最终草图的自动选择过程</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-4="813,621">Fig. 8. Strokes Initialization. (a) Left to right: input, the saliency map produced from CLIP ViT activations, final distribution map (adjusted to adhere to image edges) with sampled initial stroke locations (in red), the sketch produced using the proposed initialization procedure, and the sketch produced when using random initialization. (b) Results of three different initializations with the same number of strokes. The sketches marked in blue produced the lowest loss value, and would thus be used as the final output. CFace image from [Minear and Park 2004], used with permission.<div style="background-color: #d6d6d6;margin: 12px 0;">图 8. 笔触初始化。 (a) 从左到右：输入，由 CLIP ViT 激活产生的显著性图，调整以贴合图像边缘的最终分布图（以红色标记的初始笔触位置），使用所提出初始化过程产生的草图，以及使用随机初始化产生的草图。 (b) 使用相同数量的笔触的三种不同初始化结果。标记为蓝色的草图产生了最低的损失值，因此将作为最终输出。CFace 图像来自 [Minear 和 Park 2004]，经许可使用。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-4="812,913">3.3 Strokes Initialization<div style="background-color: #d6d6d6;margin: 12px 0;">3.3 笔触初始化</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-4="814,955">Our objective function is highly non-convex. Therefore, the optimization process is susceptible to the initialization (i.e., the initialization (i.e., the initial location of the strokes). This is especially significant at higher levels of abstraction - where very few strokes must be wisely placed to emphasize semantic components. For example, in Figure 8a, the sketches in the last two columns were produced using the same number of strokes, however, in the "Random" initialization case, more strokes were devoted to the hair while the eyes, nose, and mouth are more salient and critical features of the face.<div style="background-color: #d6d6d6;margin: 12px 0;">我们的目标函数高度非凸。因此，优化过程容易受到初始化（即，笔触的初始位置）的影响。这在更高层次的抽象中尤为重要 - 在这一层次上，必须明智地放置很少的笔触以强调语义组件。例如，在图 8a 中，最后两列的草图使用了相同数量的笔触，然而，在“随机”初始化情况下，更多的笔触用于头发，而眼睛、鼻子和嘴巴是面部更为显著和关键的特征。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-c6db10ec-4ab7-419b-aebe-7e2265293b6f" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-4="837,1213">To improve convergence towards semantic depictions, we place the initial strokes based on the salient regions of the target image. To find these regions, we use the pretrained vision transformer [Kolesnikov et al. 2021] ViT-B/32 model of CLIP, that performs global context modeling using self-attention between patches of a given image to capture meaningful features. We use the recent transformer interpretability method by Chefer et al. [2021] to extract a relevancy map from the self-attention heads, without any text supervision. Next, we multiply the relevancy map with an edge map of the image extracted using XDoG method [Winnemöller et al. 2012]. Multiplying with XDoG is used to strengthen the morphological positioning of the strokes, motivated by the hypothesis that edges are effective in predicting where people draw lines [Hertzmann 2021]. Finally, we normalize the final relevancy map using softmax and use it as a distribution map so that pixels in salient regions are assigned a higher probability. We sample <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2574" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container> positions (pixels),and use them as the position of the first control point <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2575" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.284em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msubsup></math></mjx-assistive-mml></mjx-container> of each Bezier curve. The other 3 additional points <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2576" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.284em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msubsup space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.294em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msubsup space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.284em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-texatom><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msubsup><mo>,</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mn>3</mn></mrow></msubsup><mo>,</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> are sampled within a small radius (0.05 of image size) around <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2577" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.284em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msubsup></math></mjx-assistive-mml></mjx-container> to define the initial set of Bezier curves <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2578" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-s3"><mjx-c class="mjx-c7B TEX-S3"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7B TEX-S2"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.294em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7D TEX-S2"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.685em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 1.09em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-s3"><mjx-c class="mjx-c7D TEX-S3"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.985em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 1.683em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></msubsup><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #d6d6d6;margin: 12px 0;">为了提高向语义描述的收敛性，我们根据目标图像的显著区域放置初始笔画。为了找到这些区域，我们使用了预训练的视觉转换器 [Kolesnikov et al. 2021] ViT-B/32 模型，这是 CLIP 的一部分，它通过给定图像的斑块之间的自注意力进行全局上下文建模，以捕捉有意义特征。我们使用了 Chefer 等人 [2021] 最近提出的转换器可解释性方法，从自注意力头部提取相关性图，而不需要任何文本监督。接下来，我们将相关性图与使用 XDoG 方法 [Winnemöller et al. 2012] 提取的图像边缘图相乘。与 XDoG 相乘是为了加强笔画的形态定位，这是基于边缘在预测人们画线位置时有效的假设 [Hertzmann 2021]。最后，我们使用 softmax 对最终的相关性图进行归一化，并将其作为分布图，使得显著区域内的像素被分配更高的概率。我们采样 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2579" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container> 位置（像素），并将它们作为每条贝塞尔曲线的第一个控制点 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2580" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.284em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msubsup></math></mjx-assistive-mml></mjx-container> 的位置。其他 3 个附加点 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2581" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.284em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msubsup space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.294em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msubsup space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.284em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-texatom><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msubsup><mo>,</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mn>3</mn></mrow></msubsup><mo>,</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 在 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2582" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.284em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msubsup></math></mjx-assistive-mml></mjx-container> 周围的小半径（图像大小的 0.05）内采样，以定义初始的贝塞尔曲线集 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2583" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-s3"><mjx-c class="mjx-c7B TEX-S3"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7B TEX-S2"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.294em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-lop"><mjx-c class="mjx-c7D TEX-S2"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.685em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-spacer style="margin-top: 1.09em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-s3"><mjx-c class="mjx-c7D TEX-S3"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.985em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 1.683em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>p</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></msubsup><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mn>4</mn></mrow></msubsup><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup></math></mjx-assistive-mml></mjx-container>。</div></div></div></div></div></div></span></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-5="149,205">Figure 8a illustrates this procedure. It can be seen that our saliency-based initialization contributes significantly to the quality of the final sketch compared to random initialization.<div style="background-color: #d6d6d6;margin: 12px 0;">图 8a 描述了这一过程。可以看出，与随机初始化相比，我们的基于显著性的初始化显著提高了最终草图的质量。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-5="153,292">This sampling-based approach also lends itself to providing variability in the results. In all our examples we use 3 initializations and automatically choose the one that yields the lowest loss (see Figure 8b). Only for the highly abstract cases of Figure 3 (rightmost column) we used 5 initializations. We further analyze the initialization procedure and variability in the supplementary material.<div style="background-color: #d6d6d6;margin: 12px 0;">这种基于采样的方法也使得结果具有可变性。在所有的示例中，我们使用3次初始化，并自动选择损失最低的那次（见图8b）。仅在图3（最右列）中高度抽象的案例，我们使用了5次初始化。我们进一步在补充材料中分析了初始化过程和结果的可变性。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-5="127,479">4 RESULTS<div style="background-color: #d6d6d6;margin: 12px 0;">4 结果</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-5="127,520">Section 4.1 provide qualitative evaluations. In section 4.2 we compare our method with existing image-to-sketch methods, which were all trained on sketch-specific datasets. In Section 4.3, we supply a quantitative evaluation of our method's ability to produce recognizable sketches testing both category and instance recognition. For images with background, we use an automatic method (U2-Net [Qin et al. 2020]) to mask out their background. We provide further analysis of our method, extra results, and extended comparison with other methods in the supplemental file.<div style="background-color: #d6d6d6;margin: 12px 0;">第4.1节提供了定性评估。在第4.2节中，我们将我们的方法与现有的图像到素描方法进行了比较，这些方法都是在特定的素描数据集上训练的。在第4.3节中，我们提供了定量评估，以检验我们的方法在生成可识别素描方面的能力，包括类别和实例识别。对于带有背景的图像，我们使用自动方法（U2-Net [Qin et al. 2020]）来遮蔽它们的背景。我们在补充文件中提供了我们方法的进一步分析、额外的结果以及与其他方法的扩展比较。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-5="151,802"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_6.jpg?x=151&amp;y=802&amp;w=583&amp;h=349"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-5="128,1174">Fig. 9. Sketches produced by our method for infrequent categories. (Pegasus from rawpixel [Public Domain], via (https://bit.ly/3w1a5lv); "Ballerina" by Gerald Pereira [CC BY 2.0, via (https://bit.ly/3KxxiAP); Unicorn from rawpixel [Commercial License (https://www.rawpixel.com/services/ licenses)], via (https://bit.ly/3F9zyxi); Lego [Public Domain] from rawpixel, via (https://bit.ly/3s54LMN); Origami [Public Domain] from rawpixel, via (https://bit.ly/3vxtgUH).<div style="background-color: #d6d6d6;margin: 12px 0;">图9. 我们的方法为不常见类别生成的素描。（Pegasus from rawpixel [公共领域]，通过（https://bit.ly/3w1a5lv）；"Ballerina" 由 Gerald Pereira [CC BY 2.0，通过（https://bit.ly/3KxxiAP）；独角兽 from rawpixel [商业许可 (https://www.rawpixel.com/services/licenses)]，通过（https://bit.ly/3F9zyxi）；乐高 [公共领域] from rawpixel，通过（https://bit.ly/3s54LMN）；折纸 [公共领域] from rawpixel，通过（https://bit.ly/3vxtgUH)。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-5="129,1407">4.1 Qualitative Evaluation<div style="background-color: #d6d6d6;margin: 12px 0;">4.1 定性评估</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-5="128,1450">Our approach is different from conventional sketching methods in that it does not utilize a sketch dataset for training, rather it is optimized under the guidance of CLIP. Thus, our method is not limited to specific categories observed during training, as no category definition was introduced at any stage. This makes our method robust to various inputs, as shown in Figures 1 and 9.<div style="background-color: #d6d6d6;margin: 12px 0;">我们的方法与传统的草图绘制方法不同，因为它在训练过程中不使用草图数据集，而是在CLIP的指导下进行优化。因此，我们的方法不受训练期间观察到的特定类别的限制，因为在任何阶段都没有引入类别定义。这使得我们的方法能够应对各种输入，如图1和图9所示。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-5="150,1623">In Figures 1 and 3 we demonstrate the ability of our method to produce sketches at different levels of abstraction. As the number of strokes decreases, the task of minimizing the loss becomes more challenging, forcing the strokes to capture the essence of the object. For example, in the abstraction process of the flamingo in Figure 1 , the transition from 16 to 4 strokes led to the removal of details such as the eyes, feathers, and feet, while maintaining the important visual features such as the general pose, the neck and legs which are iconic characteristics of a flamingo.<div style="background-color: #d6d6d6;margin: 12px 0;">在图1和图3中，我们展示了我们的方法能够生成不同抽象级别的草图。随着笔画数量的减少，最小化损失的任务变得更加困难，迫使笔画捕捉对象的本质。例如，在图1中火烈鸟的抽象过程中，从16笔减少到4笔导致了细节的删除，如眼睛、羽毛和脚，同时保持了重要的视觉特征，如整体的姿势、脖子和腿，这些都是火烈鸟的标志性特征。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-5="825,198"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_6.jpg?x=825&amp;y=198&amp;w=623&amp;h=167"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-5="814,373">(a) Changing the degree of the curves (b) Editing the brush style on SVGs<div style="background-color: #d6d6d6;margin: 12px 0;">(a) 改变曲线的度数 (b) 在SVG上编辑笔刷样式</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-5="814,430">Fig. 10. Changing sketch style. (a) From left to right are the results produced by our method when using Bézier curves with 4,3 , and 2 control points (cp), respectively. We can see how this affects the style of the output sketch. (b) Using Adobe Illustrator, horse - pencil feather, flamingo - dry brush.<div style="background-color: #d6d6d6;margin: 12px 0;">图10. 改变草图风格。 (a) 从左到右分别是我们的方法在使用具有4、3和2个控制点(cp)的Bézier曲线时产生的结果。我们可以看到这对输出草图风格的影响。 (b) 使用Adobe Illustrator，马 - 铅笔羽毛，火烈鸟 - 干刷笔。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-5="835,688">Besides changing the number of strokes, different sketch styles can be achieved by varying the degree of the strokes (Figure 10a) or using a brush style on top of the vector strokes (Figure 10b).<div style="background-color: #d6d6d6;margin: 12px 0;">除了改变笔画数量外，通过改变笔画的度数（图10a）或在矢量笔画上使用笔刷样式（图10b），可以实现不同的草图风格。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-5="816,792">4.2 Comparison with Existing Methods<div style="background-color: #d6d6d6;margin: 12px 0;">4.2 与现有方法的比较</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-5="837,835">Sketches with different levels of abstraction. Only a few works have attempted to sketch objects at different levels of abstraction. In Figure 11 we compare with Muhammad et al. [2018] and Berger et al. [2013]. The results by Muhammad et al. demonstrate four levels of abstraction on two simple inputs - a shoe and a chair (in the absence of their code, the results were taken directly from the paper). We produce sketches at four levels of abstraction using 32,16,8, and 4 strokes. The sketches by Muhammad et al. are coherent with the geometry of the image; but to achieve higher levels of abstraction, they only remove strokes from the generated sketch without changing the remaining ones. This can result in losing class-level recognizability at higher levels of abstraction (rightmost sketches). Such an approach is sub-optimal, since a better arrangement may be possible for fewer strokes. Our method successfully produces a recognizable rendition of the subject while preserving its geometry, even in the challenging 4 stroke case (rightmost sketch).<div style="background-color: #d6d6d6;margin: 12px 0;">不同抽象级别的草图。只有少数作品尝试在不同抽象级别上绘制对象。在图11中，我们与Muhammad等人[2018]和Berger等人[2013]进行了比较。Muhammad等人的结果展示了在两个简单输入上的四种抽象级别 - 一只鞋和一把椅子（由于没有他们的代码，结果直接取自论文）。我们使用32、16、8和4笔触分别制作了四种抽象级别的草图。Muhammad等人的草图与图像的几何形状一致；但为了达到更高的抽象级别，他们只是从生成的草图中删除笔触，而没有改变剩余的笔触。这可能导致在更高抽象级别时失去类级别的可识别性（最右边的草图）。这种方法是次优的，因为可能存在更少的笔触的更好排列。我们的方法成功制作了主题的可识别版本，同时保留了其几何形状，即使在具有挑战性的4笔触情况下（最右边的草图）也是如此。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-5="835,1292">In the right bottom part of Figure 11 we compare with the method of Berger et al. [2013]. Their results were provided by the authors and demonstrate two levels of abstraction generated based on the style of a particular artist. We use 64 and 8 strokes, respectively, to achieve two comparable levels of abstraction and place a pencil style on top of the generated sketch to better fit the artist's style. As can be seen, our approach is more geometrically coherent while still allowing abstraction. Their results fit better to a specific style, but can only work with faces and are limited to the dataset gathered.<div style="background-color: #d6d6d6;margin: 12px 0;">在图11右下角部分，我们与Berger等人[2013]的方法进行了比较。他们的结果由作者提供，展示了基于特定艺术家的风格生成的两种抽象级别。我们分别使用64和8笔触来达到两种可比较的抽象级别，并在生成的草图上放置铅笔风格，以更好地适应艺术家的风格。如图所示，我们的方法在保持抽象的同时具有更好的几何一致性。他们的结果更适合特定的风格，但只能用于面部，并且局限于收集的数据集。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c586273e-4094-4d62-b586-6807de05f222" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-5="838,1564">Photo-Sketch Synthesis. In Figure 12 we present a comparison with the five works outlined in Table 1. The results by Kampelmühler and Pinz [2020] (A), Li et al. [2015] (B) and Li et al. [2019] (C) were generated based on the authors' implementation and best practice. Due to the lack of a publicly available implementation of SketchLattice [Qi et al. 2021] (E), their results are taken directly from the paper. We present the sketches of Song et al. [2018] (D) on shoe images, since their method only works with shoes and chairs.<div style="background-color: #d6d6d6;margin: 12px 0;">照片-草图合成。在图12中，我们展示了与表1中概述的五项工作的比较。Kampelmühler和Pinz [2020]（A）、Li等人[2015]（B）和Li等人[2019]（C）的结果是基于作者的实施和最佳实践生成的。由于SketchLattice [Qi等人2021]（E）的公开实现不可用，他们的结果直接取自论文。我们展示了Song等人[2018]（D）在鞋子图片上的草图，因为他们的方法只适用于鞋子和椅子。</div></div></div></div></div></div></span></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-dd4a6df3-3446-4f17-8a3d-42dccad2ee22" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-6="126,206"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_7.jpg?x=126&amp;y=206&amp;w=640&amp;h=399"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-dd4a6df3-3446-4f17-8a3d-42dccad2ee22" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-6="128,626">Fig. 11. Levels of Abstraction Comparison - in the top and left part are comparisons to Muhammad et al. [2018]. The leftmost column shows the input image, and the next four columns show different levels of abstraction. For the shoe and chair our results were produced using 32,16,8,and 4 curves (from left to right). In the right bottom part is a comparison to Berger et al. [2013], we use 64 and 8 strokes to generate our sketches. OF ace image from [Minear and Park 2004], used with permission.<div style="background-color: #d6d6d6;margin: 12px 0;">图11. 抽象级别比较 - 顶部和左侧部分是与Muhammad等人[2018]的比较。最左侧的列显示输入图像，接下来的四列显示不同的抽象级别。对于鞋子和椅子，我们的结果是使用32、16、8和4条曲线（从左到右）生成的。在右下部分是与Berger等人[2013]的比较，我们使用64和8笔触来生成我们的草图。使用了Minear和Park [2004]的OF脸部图像，并得到许可。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-dd4a6df3-3446-4f17-8a3d-42dccad2ee22" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-6="150,885">Each of these methods define a specific objective which influences their dataset selection and final output style. Li et al. [2019] (C) aim for boundary-like drawings, and indeed, geometric coherence is achieved with the input image, capturing salient outlines. The other methods are designed to produce human-like sketches of non-experts, and indeed, the synthesized sketches exhibit a "doodle-like" style. Furthermore, style. Furthermore, the methods learn highly abstract concepts (such as highlighting the eyes) while maintaining some relation to the geometry of the input object.<div style="background-color: #d6d6d6;margin: 12px 0;">这些方法中的每一种都定义了一个特定的目标，这影响了它们的数据集选择和最终输出风格。Li等人[2019]（C）旨在实现类似边界的绘画，实际上，输入图像的几何连贯性得到了实现，捕捉到了显著轮廓。其他方法旨在产生非专家的类人草图，实际上，合成的草图展现了一种“涂鸦式”的风格。此外，这些方法学习高度抽象的概念（例如突出眼睛），同时保持与输入物体几何形状的某些联系。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-dd4a6df3-3446-4f17-8a3d-42dccad2ee22" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-6="150,1141">Each method accomplishes their respective objective, but we wish to emphasize the particular benefits of our method. First, all of the above methods are sketch-data dependent, meaning they can only be used with the style and level of abstraction observed during training. With our framework, we can handle images of all categories and produce sketches of various levels of abstraction simply by changing the number of strokes. Although every method can be retrained with new datasets, this is neither convenient nor practical, and depends on the availability of such datasets. Second, while each method leans towards a more semantic or a more geometric sketching style, our method can provide both. For example, our method did not produce a perfect alignment of the legs of the horse, as in (C), but it captured the movement of the horse in a minimal way.<div style="background-color: #d6d6d6;margin: 12px 0;">每种方法都实现了其各自的目标，但我们希望强调我们方法的特定优势。首先，以上所有方法都依赖于草图数据，这意味着它们只能用于训练期间观察到的风格和抽象级别。使用我们的框架，我们可以处理所有类别的图像，并且只需通过改变笔划数量就能生成各种抽象级别的草图。尽管每种方法都可以用新的数据集重新训练，但这既不方便也不实用，且依赖于此类数据集的可用性。其次，虽然每种方法都倾向于更语义化或更几何化的草图风格，我们的方法可以提供两者。例如，我们的方法没有像（C）中那样完美地对齐马腿，但它以最简方式捕捉了马的运动。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-dd4a6df3-3446-4f17-8a3d-42dccad2ee22" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-6="150,1509">In Figure 13 we provide a comparison with CLIPDraw [Frans et al. 2021]. The text input for CLIPDraw is replaced with the target image. This was made possible since CLIP encodes both text and images to the same latent space. To provide a comparable visualization, we constrain the output primitives of CLIPDraw in the same manner as we defined our strokes. As can be seen, although the parts of the subject can be recognizable using CLIPDraw, since there is no geometric grounding to the image, the overall structure is destroyed. Further comparisons of CLIPDraw incorporating text and color can be found in the supplemental file.<div style="background-color: #d6d6d6;margin: 12px 0;">在图13中，我们提供了与CLIPDraw [Frans等人2021]的比较。CLIPDraw的文本输入被目标图像替换。这是由于CLIP将文本和图像编码到相同的潜在空间中而成为可能的。为了提供可比较的可视化，我们以与我们定义的笔划相同的方式限制CLIPDraw的输出基元。正如所见，尽管可以使用CLIPDraw识别主题的部分，但由于图像没有几何基础，整体结构被破坏了。关于CLIPDraw结合文本和颜色的进一步比较可以在补充文件中找到。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-dd4a6df3-3446-4f17-8a3d-42dccad2ee22" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-6="814,193"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_7.jpg?x=814&amp;y=193&amp;w=632&amp;h=492"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-dd4a6df3-3446-4f17-8a3d-42dccad2ee22" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-6="814,704">Fig. 12. Comparison to Existing Image-to-Sketch Works - the leftmost column shows the input images. The methods presented are (A) Kampelmühler and Pinz [2020], (B) Li et al. [2015], (C) Li et al. [2015], (D) Li et al. [2019] (D) Song et al. [2018], (E) Sketch Lattice (Qi et al. 2021). (C) Thestnut Horse" by James Wood [CC BY-SA 2.0], via (https://bit.ly/3vzgZzc); "Bauer Teapot" by Hollie Glassner, used with permission, via (https://bit.ly/3kth3G); Face image from [Minear and Park 2004], used with permission.<div style="background-color: #d6d6d6;margin: 12px 0;">图 12. 与现有图像转素描作品的比较 - 最左侧的列显示了输入图像。所展示的方法包括：（A）Kampelmühler 和 Pinz [2020]，（B）Li et al. [2015]，（C）Li et al. [2015]，（D）Li et al. [2019] （D）Song et al. [2018]，（E）Sketch Lattice（Qi et al. 2021）。（C）“Thestnut Horse”由James Wood [CC BY-SA 2.0]创作，通过（https://bit.ly/3vzgZzc）提供；（"Bauer Teapot"由Hollie Glassner创作，经授权使用，通过（https://bit.ly/3kth3G）提供；人脸图像来自[Minear和Park 2004]，经授权使用。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-dd4a6df3-3446-4f17-8a3d-42dccad2ee22" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-6="816,921"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_7.jpg?x=816&amp;y=921&amp;w=636&amp;h=151"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-dd4a6df3-3446-4f17-8a3d-42dccad2ee22" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-6="814,1091">Fig. 13. Comparison to CLIPDraw [Frans et al. 2021]. All sketches were produced using 16 strokes. (Face from the face database of the Center for Vital Longevity [Minear and Park 2004], used with permission; "Chestnut Horse" by James Wood [CC BY-SA 2.0], via (https://bit.ly/3vzgZzc).<div style="background-color: #d6d6d6;margin: 12px 0;">图 13. 与CLIPDraw [Frans et al. 2021]的比较。所有素描都是使用16笔划生成的。（来自Center for Vital Longevity的人脸数据库[Minear和Park 2004]，经授权使用；“Chestnut Horse”由James Wood [CC BY-SA 2.0]创作，通过（https://bit.ly/3vzgZzc）提供）。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-dd4a6df3-3446-4f17-8a3d-42dccad2ee22" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-6="814,1246">4.3 Quantitative Evaluation<div style="background-color: #d6d6d6;margin: 12px 0;">4.3 定量评估</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-dd4a6df3-3446-4f17-8a3d-42dccad2ee22" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-6="814,1290">We conduct a perceptual study to assess both the category-level and instance-level recognizability of the sketches generated by our method at different levels of abstraction. Additionally, similar to previous image-to-sketch works [Kampelmühler and Pinz 2020; Muhammad et al. 2018; Song et al. 2018; Song et al. 2018], we also use pretrained classifier networks to evaluate the category-level recognizability of the sketches generated by our method.<div style="background-color: #d6d6d6;margin: 12px 0;">我们进行了一项感知研究，以评估我们方法生成的素描在不同抽象级别上的类别级和实例级识别度。此外，与之前的图像转素描作品类似[Kampelmühler和Pinz 2020; Muhammad et al. 2018; Song et al. 2018; Song et al. 2018]，我们还使用预训练的分类器网络来评估我们方法生成的素描的类别级识别度。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-dd4a6df3-3446-4f17-8a3d-42dccad2ee22" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-6="838,1507">Perceptual Study. We choose five popular animal classes (cat, dog, elephant, giraffe, and horse) from the SketchyCOCO dataset (Gao et al. 2020] and randomly sample five images per class. We synthesize sketches at four levels of abstraction for each image, with 4,8,16, and 32 strokes. In total, we generate 100 sketches. We compare the recognition rates with the two recent photo-sketch synthesis methods by Kampelmühler and Pinz [2020] and Li et al. [2019]. The sketches were produced with one level of abstraction, suited to the capabilities of the methods. We had 121 participants in total, out of which 60 were assigned to evaluate our sketches at different levels of abstraction, 38 to the sketches by Kampelmühler and Pinz [2020], and 24 to the sketches by Li et al. [2019].<div style="background-color: #d6d6d6;margin: 12px 0;">感知研究。我们从SketchyCOCO数据集（Gao等人，2020年）中选取了五种受欢迎的动物类别（猫、狗、大象、长颈鹿和马），并随机抽取了每个类别的五张图像。我们对每张图像合成了四个抽象级别的草图，分别包含4、8、16和32笔划。总共，我们生成了100张草图。我们将识别率与Kampelmühler和Pinz（2020年）以及Li等人（2019年）提出的两种近期照片-草图合成方法进行了比较。这些草图是采用一个抽象级别制作的，以适应这些方法的能力。我们共有121名参与者，其中60名被分配来评估不同抽象级别的我们的草图，38名评估Kampelmühler和Pinz（2020年）的草图，24名评估Li等人（2019年）的草图。</div></div></div></div></div></div></span></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-7="148,264">Each participant was presented with randomly selected sketches of a single method. To examine category-level recognition, participants were asked to choose the correct category text description alongside four confound categories and the option 'None'. For the instance-level recognition experiment, the distractors are images from the same object category. Table 2 shows the average recognition rates attained from the perceptual study. Both the category-level and instance-level recognizability are inversely correlated with the level of abstraction. At four strokes, we can see that our sketches are hardly recognizable at the category level <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2584" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mn>36</mn></mrow><mi mathvariant="normal">%</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> ,which illustrates a "breaking point" of our method. At eight strokes and above, both instance and class level rates are high. Li et al. [2019] demonstrate full recognition at the instance level; this is understandable given that the sketches are contour-based and not abstract. At 16 and 32 strokes, we achieve comparable rates, and even with the high level of abstraction when using only eight strokes, we achieve 95% instance level recognizability. The sketches by Kampelmühler and Pinz are more abstract, which explains their low accuracy at the instance and class level.<div style="background-color: #d6d6d6;margin: 12px 0;">每位参与者被呈现了随机选择的单一方法的草图。为了检验类别级别的识别，参与者被要求在四个混淆类别和“无”选项旁边选择正确的类别文本描述。对于实例级别的识别实验，干扰项是来自同一物体类别的图像。表2显示了感知研究中获得的平均识别率。类别级别和实例级别的可识别性都与抽象程度成反比。在四笔划时，我们可以看到我们的草图在类别级别上几乎无法识别 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2585" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mn>36</mn></mrow><mi mathvariant="normal">%</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> ，这说明了我们方法的“断裂点”。在八笔划及以上时，实例和类别的识别率都很高。Li等人[2019]证明了在实例级别上的完全识别；这是可以理解的，因为草图是基于轮廓的，而不是抽象的。在16和32笔划时，我们达到了可比的识别率，甚至在只用八笔划的高抽象水平下，我们也实现了95%的实例级别可识别性。Kampelmühler和Pinz的草图更为抽象，这解释了它们在实例和类别级别上的低准确性。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-7="126,822">Table 2. Perceptual study results - average recognition rates. (A) Kam-pelmühler and Pinz [2020], (B) Li et al. [2019].<div style="background-color: #d6d6d6;margin: 12px 0;">表2. 感知研究结果 - 平均识别率。 (A) Kam-pelmühler和Pinz [2020]，(B) Li等人 [2019]。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-7="127,903"><div class="table-container"><table class="fixed-table"><thead><tr><th></th><th>A</th><th>B</th><th>Ours4</th><th>Ours8</th><th>Ours16</th><th>Ours32</th></tr></thead><tbody><tr><td>Category-</td><td>65%</td><td>96.9%</td><td>36%</td><td>87%</td><td>97.9%</td><td>99.3%</td></tr><tr><td>Level</td><td>±2%</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2586" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cB1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>±</mo><mrow data-mjx-texclass="ORD"><mn>0.7</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2587" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cB1"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>±</mo><mn>3</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container></td><td>±2%</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2588" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cB1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>±</mo><mrow data-mjx-texclass="ORD"><mn>0.8</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2589" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cB1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>±</mo><mrow data-mjx-texclass="ORD"><mn>0.5</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container></td></tr><tr><td>Instance-</td><td>65%</td><td>99.1%</td><td>72%</td><td>95%</td><td>96%</td><td>97%</td></tr><tr><td>Level</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2590" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cB1"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>±</mo><mn>2</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2591" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cB1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>±</mo><mrow data-mjx-texclass="ORD"><mn>0.4</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2592" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cB1"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>±</mo><mn>3</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2593" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cB1"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>±</mo><mn>1</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2594" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cB1"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>±</mo><mn>1</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container></td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2595" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cB1"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>±</mo><mn>1</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container></td></tr></tbody></table></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-7="148,1125">In Figure 14 we provide the confusion matrices for analyzing the sources of errors made in the category recognition task at the abstraction levels with higher error rates. Specifically, our sketches produced with 4 and 8 strokes, and those of Kampelmühler and Pinz [2020]. The three matrices show that the majority of the classification errors can be attributed to insufficient confidence (selecting 'None'). Overall, the 'dog' class achieved the lowest rates of correct answers. In the four strokes case dogs were mostly confused with elephants, whereas in the case of Kampelmühler and Pinz, the errors beside 'None' resulted from a confusion with the cat class. The 'horse' class achieved the second lowest scores. In the four strokes case, most of the errors were due to insufficient confidence, while in Kampelmühler and Pinz, besides the 'None' answers, horses were mostly miscategorized as elephants.<div style="background-color: #d6d6d6;margin: 12px 0;">在图14中，我们提供了用于分析在较高错误率抽象级别上类别识别任务中错误来源的混淆矩阵。具体来说，我们的4笔和8笔素描，以及Kampelmühler和Pinz [2020]的素描。这三个矩阵表明，大多数分类错误可以归因于信心不足（选择'None'）。总体而言，'狗'类获得了最低的正确率。在4笔的情况下，狗通常与象混淆，而在Kampelmühler和Pinz的情况下，除了'None'之外，错误是由于与猫类的混淆造成的。'马'类获得了第二低的分数。在4笔的情况下，大多数错误是由于信心不足，而在Kampelmühler和Pinz的情况下，除了'None'答案外，马通常被错误分类为象。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-7="151,1535">Sketch classifier. Sketch classifier. Two different classifiers are used for evaluating the synthesized sketches; a ResNet34 classifier from Kampelmühler and Pinz [2020] trained on the Sketchy-Database [Sangkloy et al. 2016 with 125 categories, and a CLIP ViT-B/32 zero-shot classifier using text prompts defined as "A sketch of a(n) class-name". Note that this is not the CLIP model we use for training.<div style="background-color: #d6d6d6;margin: 12px 0;">素描分类器。两种不同的分类器用于评估合成的素描；一个是Kampelmühler和Pinz [2020]的ResNet34分类器，该分类器在Sketchy-Database [Sangkloy等人2016，共125个类别]上训练，另一个是使用文本提示定义为“一个类名的素描”的CLIP ViT-B/32零样本分类器。请注意，这不是我们用于训练的CLIP模型。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-7="151,1708">Table 3 compares the sketch-classifier recognition accuracy of our sketches to that of Kampelmühler and Pinz [2020] and Li et al. [2019] based upon 200 randomly selected images of 10 categories from the<div style="background-color: #d6d6d6;margin: 12px 0;">表3比较了我们的素描与Kampelmühler和Pinz [2020]以及Li等人[2019]的素描分类器识别准确度，基于从Sketchy-Database中随机选取的10个类别的200张图像。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-7="812,190"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_8.jpg?x=812&amp;y=190&amp;w=636&amp;h=225"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-7="814,436">Fig. 14. Confusion matrices of category-level recognition of the perceptual study of our method with four and eight strokes (left and middle matrices) and the method of Kampelmühler and Pinz [2020].<div style="background-color: #d6d6d6;margin: 12px 0;">图14。我们方法中4笔和8笔的类别级别识别混淆矩阵（左和中矩阵）以及Kampelmühler和Pinz [2020]方法的混淆矩阵。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-7="814,558">SketchyCOCO dataset [Gao et al. 2020]. The recognition accuracy on human sketches from the SketchyCOCO dataset is also calculated as a baseline. The method by Kampelmühler and Pinz achieves the highest scores for ResNet34 classifier, possibly since they use the same model and dataset during training. Despite the distribution differences, our method still achieves good recognition rates under this classifier. With CLIP classifier, our method achieves very high accuracy levels of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2596" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c37"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>78</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> with 16 strokes and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2597" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>91</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> with 32 strokes. For more details and analysis please refer to the supplementary material.<div style="background-color: #d6d6d6;margin: 12px 0;">SketchyCOCO数据集 [Gao等人 2020]。SketchyCOCO数据集上的人体草图识别精度也被计算为基线。Kampelmühler和Pinz的方法在ResNet34分类器上取得了最高分，可能是因为他们在训练期间使用了相同的模型和数据集。尽管分布存在差异，我们的方法在这种分类器下仍然取得了良好的识别率。使用CLIP分类器时，我们的方法在16笔划时达到了<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2598" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c37"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>78</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container>的高精度水平，在32笔划时达到了<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2599" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>91</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container>的高精度水平。更多细节和分析，请参考补充材料。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-7="812,841">Table 3. Top-1 and Top-3 sketch recognition accuracy computed with ResNet34 and CLIP ViT-B/32 on 200 sketches from 10 categories. (A) Kam-pelmühler and Pinz [2020], (B) Li et al. [2019]<div style="background-color: #d6d6d6;margin: 12px 0;">表3。使用ResNet34和CLIP ViT-B/32在10个类别的200个草图上计算得到的Top-1和Top-3草图识别精度。（A）Kam-pelmühler和Pinz [2020]，（B）Li等人 [2019]</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-7="811,949"><div class="table-container"><table class="fixed-table"><thead><tr><th colspan="2">Classifier</th><th>Human Sketches</th><th>A</th><th>B</th><th>Ours16</th><th>Ours32</th></tr></thead><tbody><tr><td rowspan="2">ResNet34</td><td>Top1</td><td>98%</td><td>67%</td><td>61%</td><td>54%</td><td>63%</td></tr><tr><td>Top3</td><td>99%</td><td>82%</td><td>78%</td><td>75%</td><td>77%</td></tr><tr><td rowspan="2">CLIP ViT-B/32</td><td>Top1</td><td>75%</td><td>49%</td><td>60%</td><td>78%</td><td>91%</td></tr><tr><td>Top3</td><td>93%</td><td>65%</td><td>77%</td><td>93%</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2600" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>97</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container></td></tr></tbody></table></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-7="835,1179">Sketch diversity. We conduct an analysis to quantify the diversity of the sketches produced at different levels of abstraction. The input images for this study are identical to those used in the perceptual study (i.e., five random samples from five different animals classes). In total, we produce 1000 sketches - ten sketches per image, for each level of abstraction, using 10 different initializations. We measure the diversity of each set of sketches <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2601" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.036em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.284em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup><mo>,</mo><mi>n</mi><mo>=</mo><mrow data-mjx-texclass="ORD"><mn>10</mn></mrow></math></mjx-assistive-mml></mjx-container> derived from the same image and at the same abstraction level <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2602" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math></mjx-assistive-mml></mjx-container> as the normalized average variance of the sketches:<div style="background-color: #d6d6d6;margin: 12px 0;">草图多样性。我们进行了一项分析，以量化在不同抽象级别上生成的草图的多样性。本研究中使用的输入图像与感知研究中使用的图像相同（即来自五个不同动物类别的五个随机样本）。总共，我们生成了1000个草图 - 每个图像在每个抽象级别上生成十个草图，使用10次不同的初始化。我们测量了从同一图像和同一抽象级别<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2603" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math></mjx-assistive-mml></mjx-container>派生出的每一组草图<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2604" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.036em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.284em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msubsup><mo>,</mo><mi>n</mi><mo>=</mo><mrow data-mjx-texclass="ORD"><mn>10</mn></mrow></math></mjx-assistive-mml></mjx-container>的多样性，作为草图归一化平均方差：</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><paragraphpositioning data-position-7="971,1447"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" width="full" tabindex="0" ctxtmenu_counter="2605" style="font-size: 122.8%; min-width: 16.869em; position: relative;"><mjx-math width="full" display="true" class="MJX-TEX" aria-hidden="true"><mjx-mtable width="full" side="right" style="min-width: 16.869em;"><mjx-table style="width: auto; min-width: 12.713em; margin: 0px 2.078em;"><mjx-itable width="full"><mjx-mlabeledtr><mjx-mtd><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-stretchy-v class="mjx-c2016" style="height: 2.408em; vertical-align: -0.954em;"><mjx-ext><mjx-c></mjx-c></mjx-ext><mjx-mark></mjx-mark></mjx-stretchy-v></mjx-mo><mjx-mtable justify="left" style="min-width: 8.665em;"><mjx-table><mjx-itable><mjx-mtr><mjx-mtd><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c2225"></mjx-c></mjx-mo><mjx-mtable justify="left" style="min-width: 1.018em;"><mjx-table><mjx-itable><mjx-mtr><mjx-mtd><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D707 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-table></mjx-mtable><mjx-mo class="mjx-n"><mjx-c class="mjx-c2225"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-munderover space="2"><mjx-over style="padding-bottom: 0.192em; padding-left: 0.362em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-over><mjx-box><mjx-munder><mjx-row><mjx-base style="padding-left: 0.046em;"><mjx-texatom texclass="OP"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c2211 TEX-S1"></mjx-c></mjx-mo></mjx-texatom></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.167em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-texatom></mjx-under></mjx-row></mjx-munder></mjx-box></mjx-munderover><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-msup space="2"><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.036em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D707 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: 0.477em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-table></mjx-mtable><mjx-mo class="mjx-n"><mjx-stretchy-v class="mjx-c2016" style="height: 2.408em; vertical-align: -0.954em;"><mjx-ext><mjx-c></mjx-c></mjx-ext><mjx-mark></mjx-mark></mjx-stretchy-v></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.99em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mlabeledtr></mjx-itable></mjx-table><mjx-labels style="width: 16.869em;"><mjx-itable align="right" style="right: 0px;"><mjx-mtr style="height: 2.444em;"><mjx-mtd id="mjx-eqn:4"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c28"></mjx-c><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c29"></mjx-c></mjx-mtext><mjx-tstrut style="height: 2.444em; vertical-align: -0.99em;"></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-labels></mjx-mtable></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd><mtext>(4)</mtext></mtd><mtd><msub><mrow data-mjx-texclass="ORD"><mi>D</mi></mrow><mrow data-mjx-texclass="ORD"><mi>t</mi></mrow></msub><mo>=</mo><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN" symmetric="true">‖</mo><mtable columnspacing="1em" rowspacing="4pt"><mtr><mtd><mfrac><mn>1</mn><mrow><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN" symmetric="true">‖</mo><mtable columnspacing="1em" rowspacing="4pt"><mtr><mtd><msub><mrow data-mjx-texclass="ORD"><mi>μ</mi></mrow><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow></msub></mtd></mtr></mtable><mo data-mjx-texclass="CLOSE" symmetric="true">‖</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub><mo>⋅</mo><mi>n</mi></mrow></mfrac><munderover><mrow data-mjx-texclass="OP"><mo data-mjx-texclass="OP" movablelimits="false">∑</mo></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></munderover><mo data-mjx-texclass="NONE">⁡</mo><msup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow data-mjx-texclass="ORD"><mi>μ</mi></mrow><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow></msub><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msup></mtd></mtr></mtable><mo data-mjx-texclass="CLOSE" symmetric="true">‖</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub></mtd></mlabeledtr></mtable></math></mjx-assistive-mml></mjx-container></paragraphpositioning></div></div></div></div><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-f6c42505-e639-486c-af50-78ea7486d99e" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-7="838,1535">Where <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2606" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D707 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-munderover space="2"><mjx-over style="padding-bottom: 0.192em; padding-left: 0.362em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-over><mjx-box><mjx-munder><mjx-row><mjx-base style="padding-left: 0.046em;"><mjx-texatom texclass="OP"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c2211 TEX-S1"></mjx-c></mjx-mo></mjx-texatom></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.167em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-texatom></mjx-under></mjx-row></mjx-munder></mjx-box></mjx-munderover><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.036em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>μ</mi></mrow><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mrow data-mjx-texclass="OP"><mo data-mjx-texclass="OP" movablelimits="false">∑</mo></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></munderover><mo data-mjx-texclass="NONE">⁡</mo><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> is the pixel-wise mean sketch. To be able to compare different abstraction levels, we normalize the variance with respect to the magnitude of the average sketch <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2607" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c2225"></mjx-c></mjx-mo><mjx-mtable justify="left" style="min-width: 1.018em;"><mjx-table><mjx-itable><mjx-mtr><mjx-mtd><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D707 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-table></mjx-mtable><mjx-mo class="mjx-n"><mjx-c class="mjx-c2225"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN" symmetric="true">‖</mo><mtable columnspacing="1em" rowspacing="4pt"><mtr><mtd><msub><mrow data-mjx-texclass="ORD"><mi>μ</mi></mrow><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow></msub></mtd></mtr></mtable><mo data-mjx-texclass="CLOSE" symmetric="true">‖</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub></math></mjx-assistive-mml></mjx-container> at a specific level of abstraction. This normalization is needed because as the level of abstraction increases, the number of strokes decrease so the average magnitude is smaller. Figure 15 shows an example of a few sketches from the highest and lowest and lowest levels of abstraction along with the mean sketch at each level. Figure 16a shows the average diversity score for each class and level of abstraction. We can see that the diversity increases with the abstraction level and that similar patterns were observed among different classes.<div style="background-color: #d6d6d6;margin: 12px 0;">其中 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2608" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D707 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-munderover space="2"><mjx-over style="padding-bottom: 0.192em; padding-left: 0.362em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-over><mjx-box><mjx-munder><mjx-row><mjx-base style="padding-left: 0.046em;"><mjx-texatom texclass="OP"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c2211 TEX-S1"></mjx-c></mjx-mo></mjx-texatom></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.167em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-texatom></mjx-under></mjx-row></mjx-munder></mjx-box></mjx-munderover><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.036em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>μ</mi></mrow><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mrow data-mjx-texclass="OP"><mo data-mjx-texclass="OP" movablelimits="false">∑</mo></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></munderover><mo data-mjx-texclass="NONE">⁡</mo><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> 是像素级的平均草图。为了能够比较不同的抽象级别，我们通过平均草图 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2609" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c2225"></mjx-c></mjx-mo><mjx-mtable justify="left" style="min-width: 1.018em;"><mjx-table><mjx-itable><mjx-mtr><mjx-mtd><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D707 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-table></mjx-mtable><mjx-mo class="mjx-n"><mjx-c class="mjx-c2225"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.285em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN" symmetric="true">‖</mo><mtable columnspacing="1em" rowspacing="4pt"><mtr><mtd><msub><mrow data-mjx-texclass="ORD"><mi>μ</mi></mrow><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow></msub></mtd></mtr></mtable><mo data-mjx-texclass="CLOSE" symmetric="true">‖</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub></math></mjx-assistive-mml></mjx-container> 在特定抽象级别上的大小来归一化方差。这种归一化是必要的，因为随着抽象级别的增加，笔划的数量减少，因此平均幅度较小。图15展示了最高和最低抽象级别的一些草图示例以及每个级别的平均草图。图16a显示了每个类别和抽象级别的平均多样性分数。我们可以看到多样性随着抽象级别的增加而增加，并且在不同的类别中观察到了类似的模式。</div></div></div></div></div></div></span></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-680f1d67-7df9-41e1-91a8-10a887b531f8" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-8="129,284"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_9.jpg?x=129&amp;y=284&amp;w=639&amp;h=159"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-680f1d67-7df9-41e1-91a8-10a887b531f8" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-8="127,463">Fig. 15. A visualisation of the appearance of the mean sketch <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2610" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D707 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>μ</mi></mrow><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> (the larger giraffes) at two levels of abstraction, next to six samples of distinct sketches from the corresponding set.<div style="background-color: #d6d6d6;margin: 12px 0;">图15。展示了在两个抽象级别下的平均草图 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2611" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D707 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>μ</mi></mrow><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> 的外观（较大的长颈鹿），旁边是相应集合中的六个不同草图的样本。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-680f1d67-7df9-41e1-91a8-10a887b531f8" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-8="127,595"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_9.jpg?x=127&amp;y=595&amp;w=634&amp;h=349"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-680f1d67-7df9-41e1-91a8-10a887b531f8" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-8="184,965">Fig. 16. Diversity score as a function of the abstraction level.<div style="background-color: #d6d6d6;margin: 12px 0;">图16。多样性分数作为抽象级别的函数。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-680f1d67-7df9-41e1-91a8-10a887b531f8" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-8="150,1026">We also compare the diversity of the sketches generated by our method to the ones drawn by humans. For this study, we use the dataset collected by Berger et al. [2013], which contains 672 portraits sketches drawn by 7 different artists at 4 levels of abstraction, of 24 faces from the face database of the Center for Vital Longevity [Minear and Park 2004]. The abstractions were created by limiting the amount of time available for the artists to produce the drawings, which is a common exercise in drawing classes, and therefore, a more natural way for people to produce abstractions. To compare visually similar level of abstraction, we use 8 strokes for the highest abstraction level and 64 for the lowest one. We generate 7 sketches using our method for each face and level of abstraction using 7 different seeds, each seed imitates a different artist in this case.<div style="background-color: #d6d6d6;margin: 12px 0;">我们还将我们方法生成的草图的多样性与人绘制的草图进行了比较。为此研究，我们使用了Berger等人于2013年收集的数据集，该数据集包含7位不同艺术家在4个抽象级别上绘制的672幅肖像草图，这些肖像草图描绘的是中心长寿数据库 [Minear和Park 2004] 中的24张面孔。这些抽象是通过限制艺术家绘画的时间来创建的，这是绘画课程中常见的练习，因此，对于人们来说，这是一种更自然的产生抽象的方式。为了比较视觉上相似的抽象级别，我们在最高抽象级别使用8笔划，在最低级别使用64笔划。我们使用7个不同的种子，为每个面孔和抽象级别生成7幅草图，每个种子模仿一个不同的艺术家。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-680f1d67-7df9-41e1-91a8-10a887b531f8" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-8="150,1396">Figure 17 illustrates examples of the sketches produced by the seven artists as well as examples of the sketches generated by our method on a single input face at the lowest and highest abstraction levels. As can be seen, human sketches are more varied in style and semantic choices, which is understandable considering that they were created by different people, while our sketches appear to be less diverse (but still distinct). This visual observation is also expressed through our diversity measure presented in Figure 16b, showing the diversity score of sketches produced by the artists (blue) is larger than our method (orange). However, as can be seen, the graphs follow a similar pattern (diversity decreases with the level of abstraction).<div style="background-color: #d6d6d6;margin: 12px 0;">图17展示了七位艺术家创作的草图示例，以及我们的方法在最低和最高抽象级别下对单个输入面部生成的草图示例。可以看出，人类草图在风格和语义选择上更为多样化，这考虑到它们是由不同的人创作的，是可以理解的，而我们的草图则显得较少多样化（但仍然独特）。这种视觉观察也通过我们在图16b中展示的多样性度量得到体现，该图显示了艺术家创作的草图（蓝色）的多样性评分高于我们的方法（橙色）。然而，可以看出，图表遵循类似的模式（随着抽象级别的提高，多样性降低）。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-680f1d67-7df9-41e1-91a8-10a887b531f8" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-8="149,1735">Finally, we show outputs from a large set of diverse input classes in Figure 19. We present 108 sketches of different classes sampled randomly from the SketchyDatabase dataset [Sangkloy et al. 2016]. We also present sketches of 100 random cats from the SketchyCOCO dataset [Gao et al. 2020] in Figure 20. We use a default number of 16 strokes to produce the sketches presented in both figures.<div style="background-color: #d6d6d6;margin: 12px 0;">最后，我们在图19中展示了来自一系列多样化输入类的输出。我们展示了从SketchyDatabase数据集[Sangkloy等人2016年]中随机采样的不同类别的108张草图。我们还在图20中展示了从SketchyCOCO数据集[Gao等人2020年]中随机选取的100只猫的草图。我们在两个图中展示的草图都使用了默认的16笔划数。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-680f1d67-7df9-41e1-91a8-10a887b531f8" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-8="814,194"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_9.jpg?x=814&amp;y=194&amp;w=645&amp;h=408"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-680f1d67-7df9-41e1-91a8-10a887b531f8" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-8="814,626">Fig. 17. An example of the sketches used in the diversity study. In each row, we show seven distinct sketches generated from a single input face, along with the average sketch that corresponds to this set in the rightmost column. The first two rows show the sketches drawn by the seven artists at 15 seconds in the first row and 270 seconds in the second row. The third and fourth rows show the sketches produced by our method with 8 and 64 strokes respectively. (The portraits in the first two rows are from Berger et al. [2013], used with permission.<div style="background-color: #d6d6d6;margin: 12px 0;">图17. 多样性研究使用的草图示例。在每一行中，我们展示了从单个输入面部生成的七个不同草图，以及对应于这一组的最右侧列的平均草图。前两行显示了七位艺术家分别在第一行的15秒和第二行的270秒内绘制的草图。第三行和第四行分别展示了我们的方法使用8和64笔划生成的草图。（前两行的肖像来自Berger等人[2013年]，经允许使用。）</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-680f1d67-7df9-41e1-91a8-10a887b531f8" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-8="813,1036">5 LIMITATIONS AND FUTURE WORK<div style="background-color: #d6d6d6;margin: 12px 0;">5 限制与未来工作</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-680f1d67-7df9-41e1-91a8-10a887b531f8" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-8="813,1083">For images with background, our method's performance is reduced at higher abstraction levels. This limitation can be addressed by using an automatic mask. However, a potential future development would be to include such a remedial term within the loss function. In addition, our sketches are not created sequentially and all strokes are optimized simultaneously, which differs from the conventional way of sketching. Furthermore, the number of strokes must be determined in advance to achieve the desired level of abstraction. Another possible extension could be to make this a learned parameter, as different images may require different numbers of strokes to reach similar levels of abstraction.<div style="background-color: #d6d6d6;margin: 12px 0;">对于带有背景的图像，我们的方法在更高抽象级别上的性能会降低。这种限制可以通过使用自动遮罩来克服。然而，一个潜在的未来发展方向可能是在损失函数中包含这样一个补救项。此外，我们的草图不是按顺序创建的，所有笔触都是同时优化的，这与传统的绘图方式不同。另外，为了达到所需的抽象级别，必须提前确定笔触的数量。另一个可能的扩展可以是使这成为一个学习参数，因为不同的图像可能需要不同数量的笔触以达到相似的抽象级别。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-680f1d67-7df9-41e1-91a8-10a887b531f8" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-8="837,1395">Future potential uses of our method could include leveraging its ability to generalize to a variety of new categories in order to build datasets containing corresponding pairs of images and sketches that could be applied to the inverse problem as well.<div style="background-color: #d6d6d6;margin: 12px 0;">我们的方法未来潜在的应用可能包括利用其泛化到各种新类别的能力，以构建包含相应图像和草图对的数据库，这些数据库可以应用于逆问题。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-680f1d67-7df9-41e1-91a8-10a887b531f8" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-8="835,1510">Finally, as our framework is based on CLIP and its latent encoding, there are limitations of CLIP that carry over to our technique. As noted by the authors of CLIP, one example is CLIP's poor performance on a simple dataset such as MNIST [LeCun and Cortes 2005], which is caused by the lack of similar images in CLIP's training dataset. Figure 18a illustrates that our approach does in fact fail to draw such a simple subject, and the semantic gap may account for this failure. Another example reported in the CLIP paper is the poor performance on several types of fine-grained classification, such as distinguishing types of cars. Figure 18b illustrates this point, as the abstraction focuses on painting the cars, whereas the semantics should focus on the brands of the cars.<div style="background-color: #d6d6d6;margin: 12px 0;">最后，由于我们的框架基于CLIP及其潜在编码，因此CLIP的限制也延续到了我们的技术中。正如CLIP的作者所指出的，一个例子是CLIP在MNIST [LeCun和Cortes 2005] 这样的简单数据集上的表现不佳，这是由于CLIP的训练数据集中缺乏类似图像。图18a说明我们的方法确实无法绘制这样一个简单的主题，语义差距可能是造成这种失败的原因。CLIP论文中报告的另一个例子是在几种细粒度分类任务上的表现不佳，例如区分不同类型的汽车。图18b说明了这一点，因为抽象专注于绘制汽车，而语义应该关注汽车的品牌。</div></div></div></div></div></div></span></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-9="159,286"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=159&amp;y=286&amp;w=598&amp;h=185"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="128,491">Fig. 18. Limitations inherited from CLIP. Figure (a) illustrates that the semantics of the input image (e.g. the digit three) are missing. This results in our method being unable to convey this meaning, which could potentially be expressed with only four strokes. Rather, as we can see, the strokes lie close to the edges of the digit. This conclusion also applies to the 16 stroke case. As shown in figure (b), CLIP's difficulty distinguishing fine-grain attributes is also present in our method. When semantics are considered, the two cars are distinguished by their brands, and this could be shown potentially by using a few strokes in the sketch; however, the optimization focuses on class-level depictions. Parked Cars" by Gosdin [Public Domain], via(https://bit.ly/3LAbKFd).<div style="background-color: #d6d6d6;margin: 12px 0;">图 18. 从 CLIP 继承的限制。图 (a) 说明输入图像（例如数字 3）的语义丢失。这导致我们的方法无法传达这个含义，该含义可能仅用四笔就能表达。相反，正如我们所看到的，笔画靠近数字的边缘。这一结论也适用于 16 笔的情况。如图 (b) 所示，CLIP 区分细粒度属性的困难也体现在我们的方法中。当考虑语义时，两辆车通过品牌区分，这可以通过在草图中使用几笔来展示；然而，优化关注的是类别级别的描绘。"Parked Cars" 由 Gosdin 制作 [公用领域]，通过 (https://bit.ly/3LAbKFd)。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-9="128,835">6 CONCLUSIONS<div style="background-color: #d6d6d6;margin: 12px 0;">6 结论</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="127,879">We presented a method for photo-sketch synthesis, producing sketches with different levels of abstraction, without the need to train on specific sketch datasets. Our method can generalize to various categories and cope with challenging levels of abstraction, while maintaining the semantic visual clues that allow for instance-level and class-level recognition.<div style="background-color: #d6d6d6;margin: 12px 0;">我们提出了一种照片-草图合成方法，可以生成不同抽象级别的草图，而无需在特定的草图数据集上进行训练。我们的方法可以推广到各种类别，并应对具有挑战性的抽象级别，同时保持允许实例级别和类别级别识别的语义视觉线索。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-9="129,1069">ACKNOWLEDGMENTS<div style="background-color: #d6d6d6;margin: 12px 0;">致谢</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="127,1110">This work was supported in part by the Israel Science Foundation (grants no 2492/20 and 3441/21) and by the Deutsch Foundation and the Yandex Initiative in Machine Learning.<div style="background-color: #d6d6d6;margin: 12px 0;">这项工作得到了以色列科学基金会（项目编号 2492/20 和 3441/21）的部分支持，以及 Deutsch 基金会和 Yandex 机器学习倡议的支持。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><h2><div><div><div class="locator-translate" data-positiontag-9="126,1216">REFERENCES<div style="background-color: #d6d6d6;margin: 12px 0;">参考文献</div></div></div></div></h2></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="127,1251">Pablo Arbeláez, Michael Maire, Charless Fowlkes, and Jitendra Malik. 2011. Contour Detection and Hierarchical Image Segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence 33,5 (2011), 898-916. https://doi.org/10.1109/ TPAMI.2010.161</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="128,1336">Pierre Bénard and Aaron Hertzmann. 2019. Line Drawings from 3D Models. Found. Trends Comput. Graph. Vis. 11 (2019), 1-159.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="125,1378">Itamar Berger, Ariel Shamir, Moshe Mahler, Elizabeth Carter, and Jessica Hodgins. 2013. Style and Abstraction in Portrait Sketching. ACM Trans. Graph. 32, 4, Article 55 (jul 2013), 12 pages. https://doi.org/10.1145/2461912.2461964</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="127,1440">Ayan Kumar Bhunia, Ayan Das, Umar Riaz Muhammad, Yongxin Yang, Timothy M. Hospedales, Tao Xiang, Yulia Gryaditskaya, and Yi-Zhe Song. 2020. Pixelor: a competitive sketching AI agent. so you think you can sketch? ACM Trans. Graph. <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2612" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c39"></mjx-c></mjx-mn></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-texatom space="2" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3A"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3A"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>39</mn></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mn>2020</mn></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>,</mo><mrow data-mjx-texclass="ORD"><mn>166</mn></mrow><mo>:</mo><mn>1</mn><mo>−</mo><mrow data-mjx-texclass="ORD"><mn>166</mn></mrow><mo>:</mo><mrow data-mjx-texclass="ORD"><mn>15</mn></mrow></math></mjx-assistive-mml></mjx-container> .</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="129,1522">John Canny. 1986. A computational approach to edge detection. IEEE Transactions on pattern analysis and machine intelligence 6 (1986), 679-698.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="126,1564">Rebecca Chamberlain and Johan Wagemans. 2016. The genesis of errors in drawing. Neuroscience &amp; Biobehavioral Reviews 65 (2016), 195-207.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="127,1605">Hila Chefer, Shir Gur, and Lior Wolf. 2021. Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers. 2021 IEEE/CVF International Conference on Computer Vision (ICCV) (2021), 387-396.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="124,1667">Hong Chen, Ying-Qing Xu, Harry Shum, Song-Chun Zhu, and Nanning Zheng. 2001. Example-based facial sketch generation with non-parametric sampling. Proceedings Eight <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2613" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.105em; padding-left: 0.26em; margin-bottom: -0.549em;"><mjx-mo class="mjx-n" style="width: 0px; margin-left: -0.25em;"><mjx-c class="mjx-c2D9"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c class="mjx-c210E TEX-I"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mover><mi>h</mi><mo>˙</mo></mover></mrow></math></mjx-assistive-mml></mjx-container> IEEE International Conference on Computer Vision. ICCV 20012 (2001),433-438 vol.2.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="127,1748">Yajing Chen, Shikui Tu, Yuqi Yi, and Lei Xu. 2017. Sketch-pix2seq: a Model to Generate Sketches of Multiple Categories. ArXiv abs/1709.04121 (2017).</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-9="814,181"><div class="table-container"><table class="fixed-table"><tbody><tr><td>zebra</td><td>rifle</td><td>couch</td><td>church</td><td>hat</td><td>sailboat</td><td>racket</td><td>songbird</td><td>shoe</td></tr><tr><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=831&amp;y=233&amp;w=49&amp;h=54"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=902&amp;y=237&amp;w=61&amp;h=41"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=972&amp;y=237&amp;w=61&amp;h=42"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1043&amp;y=239&amp;w=52&amp;h=49"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1108&amp;y=233&amp;w=53&amp;h=48"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1188&amp;y=230&amp;w=39&amp;h=55"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1246&amp;y=229&amp;w=54&amp;h=55"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1321&amp;y=232&amp;w=59&amp;h=39"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1398&amp;y=230&amp;w=52&amp;h=54"></div></td></tr><tr><td>knife</td><td>sea turtle</td><td>banana</td><td>tank</td><td>swan</td><td>mouse</td><td>snail</td><td>blimp</td><td>pizza</td></tr><tr><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=823&amp;y=345&amp;w=66&amp;h=59"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=907&amp;y=354&amp;w=54&amp;h=43"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=970&amp;y=349&amp;w=57&amp;h=48"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1044&amp;y=354&amp;w=49&amp;h=38"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1111&amp;y=357&amp;w=36&amp;h=26"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1167&amp;y=348&amp;w=58&amp;h=49"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1255&amp;y=347&amp;w=33&amp;h=36"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1327&amp;y=353&amp;w=46&amp;h=26"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1394&amp;y=340&amp;w=56&amp;h=60"></div></td></tr><tr><td>trumpet</td><td>camel</td><td>fish</td><td>horse</td><td>pear</td><td>cannon</td><td>bat</td><td>teddy bear</td><td>starfish</td></tr><tr><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=838&amp;y=466&amp;w=58&amp;h=53"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=904&amp;y=467&amp;w=41&amp;h=50"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=978&amp;y=461&amp;w=47&amp;h=39"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1036&amp;y=461&amp;w=60&amp;h=52"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1108&amp;y=460&amp;w=54&amp;h=52"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1173&amp;y=461&amp;w=49&amp;h=53"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1262&amp;y=471&amp;w=27&amp;h=36"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1319&amp;y=462&amp;w=50&amp;h=54"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1398&amp;y=455&amp;w=53&amp;h=62"></div></td></tr><tr><td>tree</td><td>window</td><td>frog</td><td>piano</td><td>lizard</td><td>bear</td><td>scor- pion</td><td>saxo- phone</td><td>door</td></tr><tr><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=837&amp;y=580&amp;w=40&amp;h=55"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=908&amp;y=576&amp;w=51&amp;h=47"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=974&amp;y=579&amp;w=60&amp;h=51"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1048&amp;y=578&amp;w=41&amp;h=55"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1102&amp;y=578&amp;w=57&amp;h=49"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1178&amp;y=589&amp;w=45&amp;h=40"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1247&amp;y=581&amp;w=48&amp;h=48"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1333&amp;y=577&amp;w=49&amp;h=56"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1405&amp;y=584&amp;w=33&amp;h=45"></div></td></tr><tr><td>turtle</td><td>crab</td><td>straw- berry</td><td>spider</td><td>snake</td><td>flower</td><td>hour- glass</td><td>shark</td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1406&amp;y=653&amp;w=35&amp;h=26"></div></td></tr><tr><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=827&amp;y=696&amp;w=60&amp;h=50"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=903&amp;y=696&amp;w=56&amp;h=50"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=983&amp;y=703&amp;w=37&amp;h=33"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1054&amp;y=695&amp;w=27&amp;h=35"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1101&amp;y=688&amp;w=60&amp;h=63"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1177&amp;y=689&amp;w=42&amp;h=60"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1246&amp;y=688&amp;w=56&amp;h=64"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1321&amp;y=698&amp;w=52&amp;h=41"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1399&amp;y=693&amp;w=42&amp;h=49"></div></td></tr><tr><td>rocket</td><td>chicken</td><td>wading bird</td><td>apple</td><td>sky scraper</td><td>hot-air balloon</td><td>armor</td><td>jack-o- lantern</td><td>cow</td></tr><tr><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=834&amp;y=805&amp;w=44&amp;h=57"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=905&amp;y=811&amp;w=54&amp;h=47"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=976&amp;y=810&amp;w=51&amp;h=45"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1043&amp;y=811&amp;w=48&amp;h=43"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1115&amp;y=809&amp;w=39&amp;h=56"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1173&amp;y=807&amp;w=57&amp;h=55"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1248&amp;y=805&amp;w=54&amp;h=57"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1336&amp;y=808&amp;w=39&amp;h=53"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1404&amp;y=811&amp;w=54&amp;h=51"></div></td></tr><tr><td>seagull</td><td>hotdog</td><td>eye- glasses</td><td>heli- copter</td><td>axe</td><td>mush- room</td><td>deer</td><td>bread</td><td>pine- apple</td></tr><tr><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=840&amp;y=931&amp;w=41&amp;h=43"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=912&amp;y=927&amp;w=47&amp;h=49"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=971&amp;y=925&amp;w=56&amp;h=57"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1038&amp;y=923&amp;w=52&amp;h=47"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1111&amp;y=924&amp;w=50&amp;h=56"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1174&amp;y=926&amp;w=51&amp;h=42"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1253&amp;y=923&amp;w=34&amp;h=44"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1321&amp;y=925&amp;w=59&amp;h=50"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1395&amp;y=922&amp;w=56&amp;h=58"></div></td></tr><tr><td>squirrel</td><td>fan</td><td>duck</td><td>racc- oon</td><td>spoon</td><td>pretzel</td><td>penguin</td><td>rhino- ceros</td><td>seal</td></tr><tr><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=834&amp;y=1034&amp;w=54&amp;h=63"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=906&amp;y=1032&amp;w=50&amp;h=62"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=982&amp;y=1044&amp;w=46&amp;h=39"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1046&amp;y=1041&amp;w=44&amp;h=46"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1118&amp;y=1037&amp;w=28&amp;h=53"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1181&amp;y=1041&amp;w=44&amp;h=48"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1265&amp;y=1045&amp;w=33&amp;h=44"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1332&amp;y=1047&amp;w=37&amp;h=28"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1412&amp;y=1050&amp;w=41&amp;h=45"></div></td></tr><tr><td>candle</td><td>ham- burger</td><td>guitar</td><td>beetle</td><td>ape</td><td>wind- mill</td><td>bee</td><td>castle</td><td>jelly- fish</td></tr><tr><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=832&amp;y=1151&amp;w=31&amp;h=50"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=906&amp;y=1155&amp;w=53&amp;h=47"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=981&amp;y=1150&amp;w=44&amp;h=57"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1038&amp;y=1157&amp;w=54&amp;h=51"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1111&amp;y=1155&amp;w=53&amp;h=54"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1177&amp;y=1153&amp;w=44&amp;h=52"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1252&amp;y=1151&amp;w=43&amp;h=63"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1332&amp;y=1160&amp;w=37&amp;h=37"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1411&amp;y=1159&amp;w=33&amp;h=46"></div></td></tr><tr><td>butter- fly</td><td>parrot</td><td>tiger</td><td>cup</td><td>pistol</td><td>kan- garoo</td><td>owl</td><td>scissors</td><td>chair</td></tr><tr><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=827&amp;y=1275&amp;w=63&amp;h=40"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=902&amp;y=1268&amp;w=61&amp;h=58"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=971&amp;y=1270&amp;w=56&amp;h=57"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1038&amp;y=1280&amp;w=56&amp;h=43"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1102&amp;y=1272&amp;w=60&amp;h=48"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1184&amp;y=1270&amp;w=34&amp;h=48"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1247&amp;y=1268&amp;w=53&amp;h=59"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1319&amp;y=1267&amp;w=61&amp;h=57"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1403&amp;y=1283&amp;w=31&amp;h=40"></div></td></tr><tr><td>teapot</td><td>bell</td><td>violin</td><td>wheel- chair</td><td>hedg- ehog</td><td>motor- cycle</td><td>wine bottle</td><td>cabin</td><td>lobster</td></tr><tr><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=826&amp;y=1380&amp;w=67&amp;h=62"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=910&amp;y=1379&amp;w=47&amp;h=62"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=973&amp;y=1391&amp;w=62&amp;h=51"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1051&amp;y=1392&amp;w=44&amp;h=50"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1101&amp;y=1388&amp;w=54&amp;h=48"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1175&amp;y=1388&amp;w=53&amp;h=52"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1256&amp;y=1386&amp;w=37&amp;h=54"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1330&amp;y=1393&amp;w=48&amp;h=37"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1394&amp;y=1391&amp;w=56&amp;h=47"></div></td></tr><tr><td>bench</td><td>sword</td><td>lion</td><td>alarm clock</td><td>umbre- lla</td><td>table</td><td>pickup truck</td><td>rabbit</td><td>dolphin</td></tr><tr><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=826&amp;y=1501&amp;w=65&amp;h=58"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=901&amp;y=1499&amp;w=58&amp;h=57"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=972&amp;y=1498&amp;w=65&amp;h=55"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1057&amp;y=1502&amp;w=41&amp;h=54"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1110&amp;y=1505&amp;w=48&amp;h=51"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1175&amp;y=1501&amp;w=46&amp;h=51"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1243&amp;y=1499&amp;w=64&amp;h=54"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1320&amp;y=1495&amp;w=56&amp;h=59"></div></td><td><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_10.jpg?x=1395&amp;y=1494&amp;w=64&amp;h=60"></div></td></tr></tbody></table></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="814,1590">Fig. 19. Results of 108 random images from 108 classes from the Sketchy-Database [Sangkloy et al. 2016]. The class name is presented on top of each sketch.<div style="background-color: #d6d6d6;margin: 12px 0;">图 19。来自 Sketchy-Database [Sangkloy 等人 2016] 中 108 个类别的 108 张随机图像的结果。每个草图的顶部展示了类别名称。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-46bf5fbb-a691-48f3-8cf2-7c152e953385" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-9="812,1724">Judith E. Fan, Daniel L. K. Yamins, and Nicholas B. Turk-Browne. 2018. Common Object Representations for Visual Production and Recognition. Cognitive science 428 (2018), <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2614" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c37"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>2670</mn></mrow><mo>−</mo><mrow data-mjx-texclass="ORD"><mn>2698</mn></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #d6d6d6;margin: 12px 0;">Judith E. Fan, Daniel L. K. Yamins, 和 Nicholas B. Turk-Browne。2018。视觉生成和识别的通用对象表示。认知科学 428 (2018), <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2615" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c37"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>2670</mn></mrow><mo>−</mo><mrow data-mjx-texclass="ORD"><mn>2698</mn></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div></div></div></span></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div class="locator-translate" data-positiontag-10="128,190"><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01916011-3bd0-74f2-a233-19637c4a95d7_11.jpg?x=128&amp;y=190&amp;w=624&amp;h=664"></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="128,877">Fig. 20. Sketching "in the wild": results of 100 random images of cats from SketchyCOCO [Gao et al. 2020].<div style="background-color: #d6d6d6;margin: 12px 0;">图 20. 现场速写：来自 SketchyCOCO [Gao et al. 2020] 的 100 张随机猫图像的结果。</div></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="126,983">Judith W. Fan, Robert D. Hawkins, Mike Wu, and Noah D. Goodman. 2019. Pragmatic Inference and Visual Abstraction Enable Contextual Flexibility During Visual Communication. Computational Brain &amp; Behavior 3 (2019), 86-101.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="127,1049">Kevin Frans, Lisa B. Soros, and Olaf Witkowski. 2021. CLIPDraw: Exploring Text-to-Drawing Synthesis through Language-Image Encoders. CoRR abs/2106.14843 (2021). arXiv: <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2616" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>2106.14843</mn></mrow></math></mjx-assistive-mml></mjx-container> https://arxiv.org/abs/2106.14843</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="128,1110">Yaroslav Ganin, Tejas D. Kulkarni, Igor Babuschkin, S. M. Ali Eslami, and Oriol Vinyals. 2018. Synthesizing Programs for Images using Reinforced Adversarial Learning.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="127,1172">Chengying Gao, Qi Liu, Qi Xu, Limin Wang, Jianzhuang Liu, and Changqing Zou. 2020. SketchyCOCO: Image Generation From Freehand Scene Sketches. In Proceedings of the IEE/CVF Conference on Computer Vision and Pattern Recognition. 5174-5183.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="128,1235">Gabriel Goh, Nick Cammarata +, Chelsea Voss +, Shan Carter, Michael Petrov, Ludwig Schubert, Alec Radford, and Chris Olah. 2021. Multimodal Neurons in Artificial Neural Networks. Distill (2021). https://doi.org/10.23915/distill.00030 https://distill.pub/2021/multimodal-neurons.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="129,1317">Yulia Gryaditskaya, Mark Sypesteyn, Jan Willem Hoftijzer, Sylvia C. Pont, Frédo Durand, design sketches. ACM Trans. Graph. 38 (2019), 232:1-232:16.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="134,1378">David Ha and Douglas Eck. 2017. A Neural Representation of Sketch Drawings. CoRR abs/1704.03477 (2017). arXiv:1704.03477 http://arxiv.org/abs/1704.03477</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="133,1420">A. Hertzmann. 2003. A survey of stroke-based rendering. IEEE Computer Graphics and Applications 23,4 (2003), 70-81. https://doi.org/10.1109/MCG.2003.1210867</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="126,1461">Aaron Hertzmann. 2020. Why Do Line Drawings Work? A Realism Hypothesis. Perception 49 (2020), 439 - 451 .</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="124,1501">Aaron Hertzmann. 2021. The Role of Edges in Line Drawing Perception. Perception 50 (2021), 266-275.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="125,1542">Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. 2017. Image-to-Image-Translation with Conditional Adversarial Networks. In CVPR.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="126,1584">Moritz Kampelmühler and Axel Pinz. 2020. Synthesizing human-like sketches from natural images using a conditional convolutional decoder. CoRR abs/2003.07101 (2020). arXiv:2003.07101 https://arxiv.org/abs/2003.07101</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="125,1647">Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. CoRR abs/1412.6980 (2015).</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="126,1686">Alexander Kolesnikov, Alexey Dosovitskiy, Dirk Weissenborn, Georg Heigold, Jakob Uszkoreit, Lucas Beyer, Matthias Minderer, Mostafa Dehghani, Neil Houlsby, Sylvain</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="151,1728">Gelly, Thomas Unterthiner, and Xiaohua Zhai. 2021. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. In ICLR '21.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="127,1770">Yann LeCun and Corinna Corinna Corinna Corina Corina Corina Corina Actabase of handwritten digits.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="815,209">Mengtian Li, Zhe Lin, Radomir Mech, Ersin Yumer, and Deva Ramanan. 2019. Photo-Sketching: Inferring Contour Drawings from Images. arXiv: 1901.00542 [cs.CV]</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="814,254">Tzu-Mac Li, Michal Lukáč, Gharbi Michaël, and Jonathan Ragan-Kelley. 2020. Differentiable Vector Graphics Rasterization for Editing and Learning. ACM Trans. Graph. (Proc. SIGGRAPH Asia) 39,6 (2020), 193:1-193:15. Sketch Synthesis with Deformable Stroke Models. CoRR abs/1510.02644 (2015). arXiv:1510.02644 http://arxiv.org/abs/1510.02644</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="813,377">Hangyu Lin, Yanwei Fu, Yunwei Fu, Yu-Gang Jiang, and X. Xue. 2020. Sketch-BERT: Learning Sketch Bidirectional Encoder Representation From Transformers by Self-Supervised Learning of Sketch Gestalt. 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2020), 6757-6766.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="811,460">John F. J. Mellor, Eunbyung Park, Yaroslav Ganin, Igor Babuschkin, Tejas Kulkarni, Dan Rosenbaum, Andy Ballard, Theophane Weber, Oriol Vinyals, and S. M. Ali abs <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2617" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c39"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mrow data-mjx-texclass="ORD"><mn>1910.01007</mn></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mn>2019</mn></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> . arXiv: <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2618" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>1910.01007</mn></mrow></math></mjx-assistive-mml></mjx-container> http://arxiv.org/abs <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2619" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mrow data-mjx-texclass="ORD"><mn>1910.01007</mn></mrow></math></mjx-assistive-mml></mjx-container></div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="813,541">Daniela Mihai and Jonathon S. Hare. 2021a. Differentiable Drawing and Sketching. ArXiv abs/2103.16194 (2021).</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="819,582">Daniela Mihai and Jonathon S. Hare. 2021b. Learning to Draw: Emergent Communication through Sketching. ArXiv abs/2106.02067 (2021).</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="811,624">Meredith Minear and Denise C. Park. 2004. A lifespan database of adult facial stimuli. Behavior Research Methods, Instruments, &amp; Computers 36 (2004), 630-633.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="813,665">Umar Riaz Muhammad, Yongxin Yang, Yi-Zhe Song, Tao Xiang, and Timothy M. arXiv:1804.04804 http://arxiv.org/abs/1804.04804</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="812,727">Yonggang Qi, Guoyao Su, Pinaki Nath Chowdhury, Mingkang Li, and Yi-Zhe Song. 2021. SketchLattice: Latticed Representation for Sketch Manipulation. ArXiv abs/2108.11636 (2021).</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="813,789">Xuebin Qin, Zichen Zhang, Chenyang Huang, Masood Dehghan, Osmar Zaiane, and Martin Jagersand. 2020. U2-Net: Going Deeper with Nested U-Structure for Salient Object Detection. Pattern Recognition 106, 107404.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="813,851">Shuwen Qiu, Sirui Xie, Lifeng Fan, Tao Gao, Song-Chun Zhu, and Yixin Zhu. 2021. Emergent Graphical Conventions in a Visual Communication Game.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="812,892">Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. 2021. Learning Transferable Visual Models From Natural Language Supervision. CoRR abs/2103.00020 (2021). arXiv:2103.00020 https://arxiv.org/abs/2103.00020</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="809,994">Leo Sampaio Ferraz Ribeiro, Tu Bui, John P. Collomosse, and Moacir Antonelli Ponti. 2020. Sketchformer: Transformer-Based Representation for Sketched Structure. 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2020), <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2620" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>14141</mn></mrow><mo>−</mo><mrow data-mjx-texclass="ORD"><mn>14150</mn></mrow></math></mjx-assistive-mml></mjx-container> .</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="811,1076">Patsorn Sangkloy, Nathan Burnell, Cusuh Ham, and James Hays. 2016. The Sketchy Database: Learning to Retrieve Badly Drawn Bunnies. ACM Trans. Graph. 35, 4, Article 119 (jul 2016), 12 pages. https://doi.org/10.1145/2897824.2925954</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="813,1139">Jifei Song, Kaiyue Pang, Yi-Zhe Song, Tao Xiang, and Timothy Hospedales. 2018. Learning to Sketch with Shortcut Cycle Consistency. arXiv:1805.00247 [cs.CV]</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="812,1181">Yingtao Tian and David Ha. 2021. Modern Evolution Strategies for Creativity: Fitting Concrete Images and Abstract Concepts. CoRR abs/2109.08857 (2021) arXiv: <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2621" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>2109.08857</mn></mrow></math></mjx-assistive-mml></mjx-container> https://arxiv.org/abs/2109.08857</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="814,1242">Barbara Tversky. 2002. What do Sketches Say about Thinking.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="811,1263">V Varshaneya, Sangeetha Balasubramanian, and Vineeth N. Balasubramanian. 2021. Teaching GANs to sketch in vector format. Proceedings of the Twelfth Indian Conference on Computer Vision, Graphics and Image Processing (2021).</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="813,1325">Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, and Bryan Catanzaro. 2017. High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs. CoRR abs/1711.11585 (2017). arXiv:1711.11585 http:</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="812,1406">Holger Winnemöller, Jan Eric Kyprianidis, and Sven C. Olsen. 2012. XDoG: An eXtended difference-of-Gaussians compendium including advanced image stylization. Comput. Graph. 36 (2012), 740-753.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="812,1468">Peng Xu, Timothy M. Hospedales, Qiyue Yin, Yi-Zhe Song, Tao Xiang, and Liang Wang. 2020. Deep Learning for Free-Hand Sketch: A Survey and A Toolbox. arXiv:2001.02600 [cs.CV]</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="812,1530">Justin Yang and Judith E. Fan. 2021. Visual communication of object concepts at different levels of abstraction. ArXiv abs/2106.02775 (2021). The Unreasonable Effectiveness of Deep Features as a Perceptual Metric. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (2018), 586-595.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="812,1634">N. Zheng, Yf Jiang, and Ding jiang Huang. 2019. StrokeNet: A Neural Painting Environment. In ICLR.</div></div></div></div></div></span></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-fd01cc56-36ac-4f59-8dfd-0732d6e25691" class="markdown-parser-view mb-5 relative"><div><span style="display: block;"><div class="cursor-pointer"><div><div><div></div></div></div></div><div class="cursor-pointer"><div><div><div><div class="locator-translate" data-positiontag-10="817,1673">Tao Zhou, Chen Fang, Zhaowen Wang, Jimei Yang, Byungmoon Kim, Zhili Chen, Jonathan Brandt, and Demetri Terzopoulos. 2018. Learning to Sketch with Deep Q Networks and Demonstrated Strokes. ArXiv abs/1810.05977 (2018).</div></div></div></div></div></span></div></div></div></div></div>
      </body>
    </html>
  