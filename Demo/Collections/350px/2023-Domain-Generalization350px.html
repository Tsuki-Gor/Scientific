
    <!DOCTYPE html>
    <html lang="en">
      <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>2023-Domain Generalization</title>
        <style>
            * {
              padding: 0;
              margin: 0;
              box-sizing: border-box;
            }
             html {
              line-height: 1.15; /* 1 */
              -webkit-text-size-adjust: 100%; /* 2 */
            }
            body {
              padding: 20px 350px;
              margin: 0;
            }
            main {
              display: block;
            }
            h1 {
              font-size: 2em;
              margin: 0.67em 0;
            }
            hr {
              box-sizing: content-box; /* 1 */
              height: 0; /* 1 */
              overflow: visible; /* 2 */
            }
            pre {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            a {
              background-color: transparent;
            }
            abbr[title] {
              border-bottom: none; /* 1 */
              text-decoration: underline; /* 2 */
              text-decoration: underline dotted; /* 2 */
            }
            b,
            strong {
              font-weight: bolder;
            }
            code,
            kbd,
            samp {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            small {
              font-size: 80%;
            }
            sub,
            sup {
              font-size: 75%;
              line-height: 0;
              position: relative;
              vertical-align: baseline;
            }
            sub {
              bottom: -0.25em;
            }
            sup {
              top: -0.5em;
            }
            img {
              border-style: none;
            }
            button,
            input,
            optgroup,
            select,
            textarea {
              font-family: inherit; /* 1 */
              font-size: 100%; /* 1 */
              line-height: 1.15; /* 1 */
              margin: 0; /* 2 */
            }
            button,
            input { /* 1 */
              overflow: visible;
            }
            button,
            select { /* 1 */
              text-transform: none;
            }
            button,
            [type="button"],
            [type="reset"],
            [type="submit"] {
              -webkit-appearance: button;
            }
            button::-moz-focus-inner,
            [type="button"]::-moz-focus-inner,
            [type="reset"]::-moz-focus-inner,
            [type="submit"]::-moz-focus-inner {
              border-style: none;
              padding: 0;
            }
            button:-moz-focusring,
            [type="button"]:-moz-focusring,
            [type="reset"]:-moz-focusring,
            [type="submit"]:-moz-focusring {
              outline: 1px dotted ButtonText;
            }
            fieldset {
              padding: 0.35em 0.75em 0.625em;
            }
            legend {
              box-sizing: border-box; /* 1 */
              color: inherit; /* 2 */
              display: table; /* 1 */
              max-width: 100%; /* 1 */
              padding: 0; /* 3 */
              white-space: normal; /* 1 */
            }
            progress {
              vertical-align: baseline;
            }
            textarea {
              overflow: auto;
            }
            [type="checkbox"],
            [type="radio"] {
              box-sizing: border-box; /* 1 */
              padding: 0; /* 2 */
            }
            [type="number"]::-webkit-inner-spin-button,
            [type="number"]::-webkit-outer-spin-button {
              height: auto;
            }
            [type="search"] {
              -webkit-appearance: textfield; /* 1 */
              outline-offset: -2px; /* 2 */
            }
            [type="search"]::-webkit-search-decoration {
              -webkit-appearance: none;
            }
            ::-webkit-file-upload-button {
              -webkit-appearance: button; /* 1 */
              font: inherit; /* 2 */
            }
            details {
              display: block;
            }
            summary {
              display: list-item;
            }
            [hidden] {
              display: none;
            }
             table {
                border-collapse: collapse;
                width: 100%;
                margin-top: 20px;
                margin-bottom: 20px;
              }
              table thead {
                background-color: #e5e5e5;
              }
              table td {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              table th {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              h1, h2, h3, h4, h5, h6 {
                margin-bottom: 20px;
              }
              p {
                margin-top: 20px;
                text-indent: 2em;
                margin-bottom: 20px;
              }
        </style>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      </head>
      <body>
        <div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-e76f2ec4-b67b-4195-8c68-9747742ad3ed" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-0="0,0"><div style="height: auto;"><h1><div><div>Domain Generalization: A Survey<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">领域泛化：综述</div></div></div></h1><div><br></div><div><div><div>Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen Change Loy<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">周开阳、刘子微、乔宇、向涛和罗平</div></div></div></div><div><br></div><div><div><div>Abstract-Generalization to out-of-distribution (OOD) data is a capability natural to humans yet challenging for machines to reproduce. This is because most learning algorithms strongly rely on the i.i.d. assumption on source/target data, which is often violate in practice due to domain shift. Domain generalization (DG) aims to achieve OOD generalization by using only source data for model learning. Over the last ten years, research in DG has made great progress, leading to a broad spectrum of methodologies, e.g., those based on domain alignment, meta-learning, data augmentation, or ensemble learning, to name a few; DG has also been studied in various application areas including computer vision, speech recognition, natural language processing, medical imaging, and reinforcement learning. In this paper, for the first time a comprehensive literature review in DG is provided to summarize the developments over the past decade. Specifically, we first cover the background by formally defining DG and relating it to other relevant fields like domain adaptation and transfer learning. Then, we conduct a thorough review into existing methods and theories. Finally, we conclude this survey with insights and discussions on future research directions.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">摘要——对分布外（OOD）数据进行泛化是人类天生具备的能力，但机器要实现这一点却颇具挑战。这是因为大多数学习算法严重依赖源/目标数据的独立同分布（i.i.d.）假设，而在实际应用中，由于领域偏移，这一假设常常被打破。领域泛化（DG）旨在仅使用源数据进行模型学习，从而实现分布外泛化。在过去十年中，领域泛化的研究取得了巨大进展，催生了广泛的方法，例如基于领域对齐、元学习、数据增强或集成学习等方法；领域泛化也在包括计算机视觉、语音识别、自然语言处理、医学成像和强化学习等多个应用领域得到了研究。本文首次对领域泛化进行了全面的文献综述，总结了过去十年的发展。具体而言，我们首先通过正式定义领域泛化并将其与领域自适应和迁移学习等相关领域联系起来，介绍了研究背景。然后，我们对现有方法和理论进行了深入的回顾。最后，我们对未来的研究方向进行了展望和讨论，总结了本综述。</div></div></div></div><div><br></div><div><div><div>Index Terms-Out-of-Distribution Generalization, Domain Shift, Model Robustness, Machine Learning<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">关键词——分布外泛化、领域偏移、模型鲁棒性、机器学习</div></div></div></div><div><br></div><h2><div><div>1 INTRODUCTION<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">1 引言</div></div></div></h2><div><br></div><div><div><div>IF an image classifier was trained on photo images, would it work on sketch images? What if a car detector trained using urban images is tested in rural environments? Is it possible to deploy a semantic segmentation model trained using sunny images under rainy or snowy weather conditions? Can a health status classifier trained using one patient's electrocardiogram data be used to diagnose another patient's health status? Answers to all these questions depend on how well the machine learning models can deal with one common problem, namely the domain shift problem. Such a problem refers to the distribution shift between a set of training (source) data and a set of test (target) data [1], [2], [3], [4], [5].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">如果一个图像分类器是在照片图像上训练的，它在素描图像上是否能正常工作？如果一个使用城市图像训练的汽车检测器在农村环境中进行测试，结果会如何？是否可以将使用晴天图像训练的语义分割模型应用于雨天或雪天的天气条件下？使用一名患者的心电图数据训练的健康状态分类器能否用于诊断另一名患者的健康状态？所有这些问题的答案都取决于机器学习模型处理一个常见问题的能力，即领域偏移问题。这个问题指的是一组训练（源）数据和一组测试（目标）数据之间的分布偏移 [1]、[2]、[3]、[4]、[5]。</div></div></div></div><div><br></div><div><div><div>Most statistical learning algorithms strongly rely on an over-simplified assumption, that is, the source and target data are independent and identically distributed (i.i.d.), while ignoring out-of-distribution (OOD) scenarios commonly encountered in practice. This means that they are not designed with the domain shift problem in mind, and as a consequence, a learning agent trained only with source data will typically suffer significant performance drops on an OOD target domain.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">大多数统计学习算法严重依赖一个过于简化的假设，即源数据和目标数据是独立同分布（i.i.d.）的，而忽略了实际应用中常见的分布外（OOD）场景。这意味着它们在设计时没有考虑到领域偏移问题，因此，仅使用源数据训练的学习代理在分布外的目标领域上通常会出现显著的性能下降。</div></div></div></div><div><br></div><div><div><div>The domain shift problem has seriously impeded large-scale deployments of machine learning models. One might be curious if recent advances in deep neural networks [6], [7], known as deep learning [8], can mitigate this problem. Studies in [2], [9], [10] suggest that deep learning models' performance degrades significantly on OOD datasets, even with just small variations in the data generating process. This highlights the fact that the successes achieved by deep learning so far have been largely driven by supervised learning with large-scale annotated datasets like ImageNet [11]— again, relying on the i.i.d. assumption.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">领域偏移问题严重阻碍了机器学习模型的大规模部署。有人可能会好奇，近年来被称为深度学习 [8] 的深度神经网络 [6]、[7] 的进展是否能缓解这个问题。文献 [2]、[9]、[10] 的研究表明，即使数据生成过程只有微小的变化，深度学习模型在分布外数据集上的性能也会显著下降。这凸显了一个事实，即到目前为止，深度学习取得的成功在很大程度上是由使用像 ImageNet [11] 这样的大规模标注数据集进行监督学习推动的——同样依赖于独立同分布假设。</div></div></div></div><div><br></div><div><div><div>Research on how to deal with domain shift has been extensively conducted in the literature. A straightforward solution to bypass the OOD data issue is to collect some data from the target domain to adapt a source-domain-trained model. Indeed, this domain adaptation (DA) problem has received much attention [12], [13], [14], [15], [16], [17], [18]. However, DA relies on a strong assumption that target data is accessible for model adaptation, which does not always hold in practice.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">关于如何处理领域偏移的研究在文献中已有广泛开展。绕过分布外数据问题的一个直接解决方案是从目标领域收集一些数据，以调整在源领域训练的模型。实际上，这个领域自适应（DA）问题已经受到了广泛关注 [12]、[13]、[14]、[15]、[16]、[17]、[18]。然而，领域自适应依赖于一个很强的假设，即目标数据可用于模型调整，而这在实际应用中并不总是成立。</div></div></div></div><div><br></div><div><div><div>In many applications, target data is difficult to obtain or even unknown before deploying the model. For example, in biomedical applications where domain shift occurs between different patients' data, it is impractical to collect each new patient's data in advance [19]; in traffic scene semantic segmentation it is infeasible to collect data capturing all different scenes and under all possible weather conditions [20]; when dealing with data stream, the model is also required to be intrinsically generalizable [21].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在许多应用中，目标数据在模型部署之前很难获取，甚至是未知的。例如，在生物医学应用中，不同患者的数据之间会出现领域偏移，提前收集每个新患者的数据是不切实际的 [19]；在交通场景语义分割中，收集涵盖所有不同场景和所有可能天气条件的数据是不可行的 [20]；在处理数据流时，模型也需要具备内在的泛化能力 [21]。</div></div></div></div><div><br></div><div><div><div>To overcome the domain shift problem, as well as the absence of target data, the problem of domain generalization (DG) was introduced [22]. Specifically, the goal in DG is to learn a model using data from a single or multiple related but distinct source domains in such a way that the model can generalize well to any OOD target domain.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">为了克服领域偏移问题以及目标数据缺失的问题，领域泛化（DG）问题被提出 [22]。具体而言，领域泛化的目标是使用来自单个或多个相关但不同的源领域的数据来学习一个模型，使得该模型能够很好地泛化到任何分布外的目标领域。</div></div></div></div><div><br></div><div><div><div>Since the first formal introduction in 2011 by Blanchard et al. [22], a plethora of methods have been developed to tackle the OOD generalization issue [23], [24], [25], [26], [27], [28], [29], [30]. This includes methods based on aligning source domain distributions for domain-invariant representation learning [31], [32], exposing the model to domain shift during training via meta-learning [33], [34], and augmenting data with domain synthesis [35], [36], to name a few. From the application point of view, DG has not only been studied in computer vision like object recognition [37], [38], semantic segmentation [20], [39] and person re-identification [23], [35], but also in other domains such as speech recognition [40], natural language processing [34], medical imaging [41], [42], and reinforcement learning [23].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">自2011年布兰查德（Blanchard）等人[22]首次正式提出以来，已经开发出了大量方法来解决分布外泛化（OOD generalization）问题[23]、[24]、[25]、[26]、[27]、[28]、[29]、[30]。这包括基于对齐源域分布以进行领域不变表示学习的方法[31]、[32]，通过元学习在训练期间让模型经历领域偏移的方法[33]、[34]，以及通过领域合成来扩充数据的方法[35]、[36]等等。从应用的角度来看，领域泛化（DG）不仅在计算机视觉领域得到了研究，如目标识别[37]、[38]、语义分割[20]、[39]和行人重识别[23]、[35]，还在其他领域有所涉及，如语音识别[40]、自然语言处理[34]、医学成像[41]、[42]和强化学习[23]。</div></div></div></div><div><br><hr><ul><li>K. Zhou, Z. Liu and C.C. Loy are with the S-Lab, Nanyang Technological University, Singapore. E-mail: \{kaiyang.zhou, ziwei.liu, ccloy\}@ntu.edu.sg.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>周凯阳（K. Zhou）、刘子微（Z. Liu）和罗平（C.C. Loy）就职于新加坡南洋理工大学S-Lab。电子邮件：\{kaiyang.zhou, ziwei.liu, ccloy\}@ntu.edu.sg。</li></ul></div><br><ul><li>Y. Qiao is with Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, China, and also with Shanghai AI Lab, Shanghai, China. E-mail: yu.qiao@siat.ac.cn.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>乔宇（Y. Qiao）就职于中国科学院深圳先进技术研究院，同时也就职于中国上海人工智能实验室。电子邮件：yu.qiao@siat.ac.cn。</li></ul></div><br><ul><li>T. Xiang is with the Centre for Vision Speech and Signal Processing, University of Surrey, Guildford, UK. E-mail: t.xiang@surrey.ac.uk.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>向涛（T. Xiang）就职于英国吉尔福德萨里大学视觉、语音与信号处理中心。电子邮件：t.xiang@surrey.ac.uk。</li></ul></div><br><hr></div><div><div><div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-970c657c-38c4-4c3f-925b-b4c108ee6b54" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-1="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-1="0,0">In this survey, we aim to provide a timely and comprehensive literature review to summarize, mainly from the technical perspective, the learning algorithms developed over the last decade, and provide insights on potential directions for future research. 2 BACKGROUND<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在本综述中，我们旨在提供一份及时且全面的文献综述，主要从技术角度总结过去十年中开发的学习算法，并为未来的研究方向提供见解。2 背景</div></paragraphpositioning></div></div></div><div><br></div><h3><div><div>2.1 A Brief History of Domain Generalization<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2.1 领域泛化简史</div></div></div></h3><div><br></div><div><div><div>The domain generalization (DG) problem was first formally introduced by Blanchard et al. [22] as a machine learning problem, while the term domain generalization was later coined by Muandet et al. [19]. Unlike other related learning problems such as domain adaptation or transfer learning, DG considers the scenarios where target data is inaccessible during model learning. In [22], the motivation behind DG originates from a medical application called automatic gating of flow cytometry data. The objective is to design algorithms to automate the process of classifying cells in patients' blood samples based on different properties, e.g., to distinguish between lymphocytes and non-lymphocytes. Such a technology is crucial in facilitating the diagnosis of the health of patients since manual gating is extremely time-consuming and requires domain-specific expertise. However, due to distribution shift between different patients' data, a classifier learned using data from historic patients does not generalize to new patients, and meanwhile, collecting new data for model fine-tuning is impractical, thus motivating research on the DG problem.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">领域泛化（DG）问题最初由布兰查德（Blanchard）等人[22]作为一个机器学习问题正式提出，而“领域泛化”这一术语后来由穆安代特（Muandet）等人[19]提出。与其他相关学习问题（如领域自适应或迁移学习）不同，领域泛化考虑的是在模型学习期间无法获取目标数据的场景。在文献[22]中，领域泛化的动机源于一个名为流式细胞术数据自动门控的医学应用。其目标是设计算法，根据不同属性自动对患者血液样本中的细胞进行分类，例如区分淋巴细胞和非淋巴细胞。由于手动门控极其耗时且需要特定领域的专业知识，因此这项技术对于促进患者健康诊断至关重要。然而，由于不同患者数据之间存在分布偏移，使用历史患者数据学习得到的分类器无法推广到新患者，同时，收集新数据进行模型微调也不切实际，因此引发了对领域泛化问题的研究。</div></div></div></div><div><br></div><div><div><div>In computer vision, a seminal work done by Torralba and Efros [43] raised attention on the cross-domain generalization issue. They performed a thorough investigation into the cross-dataset generalization performance of object recognition models using six popular benchmark datasets. Their findings suggested that dataset biases, which are difficult to avoid, can lead to poor generalization performance. For example, as shown in [43], a person classifier trained on Caltech101 [44] obtained a very low accuracy (11.8%) on La-belMe [45], though its same-dataset performance was near-perfect (99.6%). Following [43], Khosla et al. [46] targeted the cross-dataset generalization problem in classification and detection tasks, and proposed to learn domain-specific bias vectors and domain-agnostic weight vectors based on support vector machine (SVM) classifiers.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在计算机视觉领域，托拉尔巴（Torralba）和埃弗罗斯（Efros）[43]的开创性工作引起了人们对跨领域泛化问题的关注。他们使用六个流行的基准数据集，对目标识别模型的跨数据集泛化性能进行了全面研究。他们的研究结果表明，难以避免的数据集偏差会导致泛化性能不佳。例如，如文献[43]所示，在Caltech101数据集[44]上训练的行人分类器在LabelMe数据集[45]上的准确率非常低（11.8%），尽管其在同一数据集上的性能几乎完美（99.6%）。在文献[43]之后，科斯拉（Khosla）等人[46]针对分类和检测任务中的跨数据集泛化问题，提出基于支持向量机（SVM）分类器学习特定领域的偏差向量和领域无关的权重向量。</div></div></div></div><div><br></div><h3><div><div>2.2 Problem Definition<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2.2 问题定义</div></div></div></h3><div><br></div><div><div><div>We first introduce some notations that will be used throughout this survey. Let <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10096" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c58 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">X</mi></mrow></math></mjx-assistive-mml></mjx-container> be the input (feature) space and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10097" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> the target (label) space, a domain is defined as a joint distribution <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10098" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> on <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10099" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c58 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-msup><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2E"></mjx-c></mjx-mo></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">X</mi></mrow><mo>×</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow><msup><mrow data-mjx-texclass="ORD"><mo>.</mo></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msup></math></mjx-assistive-mml></mjx-container> For a specific domain <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10100" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> ,we refer to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10101" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> as the marginal distribution on <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10102" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.177em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2223"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi><mo>,</mo><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>Y</mi><mo>∣</mo><mi>X</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> the posterior distribution of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10103" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math></mjx-assistive-mml></mjx-container> given <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10104" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math></mjx-assistive-mml></mjx-container> ,and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10105" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.177em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2223"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mo>∣</mo><mi>Y</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> the class-conditional distribution of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10106" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math></mjx-assistive-mml></mjx-container> given <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10107" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">我们首先介绍一些本综述中会一直使用的符号。设<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10108" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c58 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">X</mi></mrow></math></mjx-assistive-mml></mjx-container>为输入（特征）空间，<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10109" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container>为目标（标签）空间，一个领域定义为<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10110" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c58 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-msup><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2E"></mjx-c></mjx-mo></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">X</mi></mrow><mo>×</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow><msup><mrow data-mjx-texclass="ORD"><mo>.</mo></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msup></math></mjx-assistive-mml></mjx-container>上的联合分布<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10111" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>。对于特定领域<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10112" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>，我们将<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10113" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>称为<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10114" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.177em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2223"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi><mo>,</mo><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>Y</mi><mo>∣</mo><mi>X</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>上的边缘分布，<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10115" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math></mjx-assistive-mml></mjx-container>给定<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10116" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math></mjx-assistive-mml></mjx-container>的后验分布，以及<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10117" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math></mjx-assistive-mml></mjx-container>给定<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10118" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math></mjx-assistive-mml></mjx-container>的类条件分布。</div></div></div></div><div><br></div><div><div><div>In the context of DG,we have access to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10119" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></mjx-assistive-mml></mjx-container> similar but distinct source domains <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10120" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c7B TEX-S1"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mrow space="4"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c7B TEX-S1"></mjx-c></mjx-mo><mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msup space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c7D TEX-S1"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c7D TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.385em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.515em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow><mo>=</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mrow data-mjx-texclass="ORD"><mi>S</mi></mrow><mrow data-mjx-texclass="ORD"><mi>k</mi></mrow></msub><mo>=</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msup><mrow data-mjx-texclass="ORD"><mi>x</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>k</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow></msup><mo>,</mo><msup><mrow data-mjx-texclass="ORD"><mi>y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>k</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow></msup><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo data-mjx-texclass="CLOSE">}</mo></mrow><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>K</mi></mrow></msubsup></math></mjx-assistive-mml></mjx-container> ,each associated with a joint distribution <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10121" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>k</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container> . Note that <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10122" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>k</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow></msubsup><mo>≠</mo></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10123" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom texclass="ORD" style="font-size: 71.4%;"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msup><mrow data-mjx-texclass="ORD"><mi>k</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container> with <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10124" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>≠</mo><msup><mrow data-mjx-texclass="ORD"><mi>k</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10125" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msup space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2026"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>,</mo><msup><mrow data-mjx-texclass="ORD"><mi>k</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mo>∈</mo><mo fence="false" stretchy="false">{</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>K</mi><mo fence="false" stretchy="false">}</mo></math></mjx-assistive-mml></mjx-container> . The goal of DG is to learn a predictive model <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10126" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3A"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c58 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo>:</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">X</mi></mrow><mo stretchy="false">→</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> using only source domain data such that the prediction error on an unseen target domain <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10127" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mrow space="4"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c7B TEX-S1"></mjx-c></mjx-mo><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-sop"><mjx-c class="mjx-c7D TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow><mo>=</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msup><mrow data-mjx-texclass="ORD"><mi>x</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msup><mo data-mjx-texclass="CLOSE">}</mo></mrow></math></mjx-assistive-mml></mjx-container> is minimized. The corresponding joint distribution of the target domain <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10128" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></math></mjx-assistive-mml></mjx-container> is denoted by <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10129" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container> . Also, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10130" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-n" space="2"><mjx-c class="mjx-c2200"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2026"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup><mo>≠</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>k</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow></msubsup><mo>,</mo><mi mathvariant="normal">∀</mi><mi>k</mi><mo>∈</mo><mo fence="false" stretchy="false">{</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>K</mi><mo fence="false" stretchy="false">}</mo></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在领域泛化（Domain Generalization，DG）的背景下，我们可以获取 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10131" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></mjx-assistive-mml></mjx-container> 个相似但不同的源领域 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10132" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c7B TEX-S1"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mrow space="4"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c7B TEX-S1"></mjx-c></mjx-mo><mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msup space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c7D TEX-S1"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c7D TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-script style="vertical-align: -0.385em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.515em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow><mo>=</mo><msubsup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mrow data-mjx-texclass="ORD"><mi>S</mi></mrow><mrow data-mjx-texclass="ORD"><mi>k</mi></mrow></msub><mo>=</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msup><mrow data-mjx-texclass="ORD"><mi>x</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>k</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow></msup><mo>,</mo><msup><mrow data-mjx-texclass="ORD"><mi>y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>k</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow></msup><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo data-mjx-texclass="CLOSE">}</mo></mrow><mo data-mjx-texclass="CLOSE">}</mo></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>K</mi></mrow></msubsup></math></mjx-assistive-mml></mjx-container>，每个源领域都与一个联合分布 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10133" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>k</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container> 相关联。请注意，<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10134" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>k</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow></msubsup><mo>≠</mo></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10135" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom texclass="ORD" style="font-size: 71.4%;"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msup><mrow data-mjx-texclass="ORD"><mi>k</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container>，其中 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10136" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>≠</mo><msup><mrow data-mjx-texclass="ORD"><mi>k</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup></math></mjx-assistive-mml></mjx-container> 且 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10137" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msup space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2026"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>,</mo><msup><mrow data-mjx-texclass="ORD"><mi>k</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mo>∈</mo><mo fence="false" stretchy="false">{</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>K</mi><mo fence="false" stretchy="false">}</mo></math></mjx-assistive-mml></mjx-container>。领域泛化的目标是仅使用源领域数据学习一个预测模型 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10138" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3A"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c58 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo>:</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">X</mi></mrow><mo stretchy="false">→</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container>，使得在一个未见过的目标领域 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10139" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mrow space="4"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c7B TEX-S1"></mjx-c></mjx-mo><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-sop"><mjx-c class="mjx-c7D TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow><mo>=</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msup><mrow data-mjx-texclass="ORD"><mi>x</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msup><mo data-mjx-texclass="CLOSE">}</mo></mrow></math></mjx-assistive-mml></mjx-container> 上的预测误差最小化。目标领域 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10140" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></math></mjx-assistive-mml></mjx-container> 对应的联合分布用 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10141" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container> 表示。此外，<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10142" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-n" space="2"><mjx-c class="mjx-c2200"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2026"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup><mo>≠</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>k</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow></msubsup><mo>,</mo><mi mathvariant="normal">∀</mi><mi>k</mi><mo>∈</mo><mo fence="false" stretchy="false">{</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>K</mi><mo fence="false" stretchy="false">}</mo></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Multi-Source DG DG has typically been studied under two different settings, namely multi-source DG and single-source DG. The majority of research has been dedicated to the multi-source setting, which assumes multiple distinct but relevant domains are available (i.e., <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10143" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi><mo>&gt;</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container> ). As stated in [22], the original motivation for studying DG is to leverage multi-source data to learn representations that are invariant to different marginal distributions. This makes sense because without having access to the target data, it is challenging for a source-learned model to generalize well. As such, using multiple domains allows a model to discover stable patterns across source domains, which generalize better to unseen domains.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">多源领域泛化 领域泛化通常在两种不同的设置下进行研究，即多源领域泛化和单源领域泛化。大多数研究都致力于多源设置，该设置假设存在多个不同但相关的领域（即 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10144" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi><mo>&gt;</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container>）。正如文献 [22] 中所述，研究领域泛化的最初动机是利用多源数据来学习对不同边缘分布不变的表示。这是有道理的，因为在无法获取目标数据的情况下，一个从源数据学习的模型很难实现良好的泛化。因此，使用多个领域可以让模型发现源领域之间的稳定模式，从而更好地泛化到未见过的领域。</div></div></div></div><div><br></div><div><div><div>Single-Source DG In contrast, the single-source setting assumes training data is homogeneous, i.e., they are sampled from a single domain <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10145" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>K</mi><mo>=</mo><mn>1</mn></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> . This problem is closely related to the topic of OOD robustness [9], [47], [48], which investigates model robustness under image corruptions. Essentially, single-source DG methods do not require domain labels for learning and thus they are applicable to multi-source scenarios as well. In fact, most existing methods able to solve single-source DG do not distinguish themselves as a single- or a multi-source approach, but rather a more generic solution to OOD generalization, with experiments covering both single- and multi-source datasets [49], [50], [51], [52].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">单源领域泛化 相比之下，单源设置假设训练数据是同质的，即它们是从单个领域 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10146" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>K</mi><mo>=</mo><mn>1</mn></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 中采样得到的。这个问题与分布外（Out-of-Distribution，OOD）鲁棒性的主题密切相关 [9]、[47]、[48]，该主题研究模型在图像损坏情况下的鲁棒性。本质上，单源领域泛化方法在学习时不需要领域标签，因此它们也适用于多源场景。事实上，大多数现有的能够解决单源领域泛化问题的方法并不将自己区分为单源或多源方法，而是将其作为一种更通用的分布外泛化解决方案，相关实验涵盖了单源和多源数据集 [49]、[50]、[51]、[52]。</div></div></div></div><div><br></div><h3><div><div>2.3 Datasets and Applications<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2.3 数据集与应用</div></div></div></h3><div><br></div><div><div><div>DG has been studied across many application areas including computer vision, speech recognition, medical imaging, and so on. Table 1 summarizes the commonly used datasets based on different applications. Below we briefly discuss their basics.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">领域泛化已经在许多应用领域得到了研究，包括计算机视觉、语音识别、医学成像等等。表 1 总结了基于不同应用的常用数据集。下面我们简要讨论它们的基本情况。</div></div></div></div><div><br></div><div><div><div>Handwritten Digit Recognition The commonly used digit datasets include MNIST [54], MNIST-M [15], SVHN [55], and SYN [15]. In general, these datasets differ in font style, stroke color, and background. MNIST contains images of handwritten digits. MNIST-M mixes MNIST's images with random color patches. SVHN comprises images of street view house numbers while SYN is a synthetic dataset. See Fig. 1(a) for some example images. Rotation has also been exploited to synthesize domain shift [53].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">手写数字识别 常用的数字数据集包括 MNIST [54]、MNIST - M [15]、SVHN [55] 和 SYN [15]。一般来说，这些数据集在字体样式、笔画颜色和背景方面有所不同。MNIST 包含手写数字的图像。MNIST - M 将 MNIST 的图像与随机颜色块混合。SVHN 包含街景房屋号码的图像，而 SYN 是一个合成数据集。一些示例图像见图 1(a)。旋转也被用于合成领域偏移 [53]。</div></div></div></div><div><br></div><div><div><div>Object Recognition has been the most common task in DG where the domain shift varies substantially across different datasets. In VLCS [56] and Office-31 [12], the domain shift is mainly caused by changes in environments or viewpoints. As exemplified in Fig. 1(b), the scenes in VLCS vary from urban to rural areas and the viewpoints are often biased toward either a side-view or a non-canonical view. Image style changes have also been commonly studied, such as PACS [37] (see Fig. 1(c)), OfficeHome [59], Domain-Net [60], and ImageNet-Sketch [51]. Other types of domain shift include synthetic-vs-real [56], artificial corruptions [9], and data sources [67]. Action Recognition Learning generalizable representations is also crucial for video understanding like action recognition. IXMAS [68] has been widely used as a cross-view action recognition benchmark [31], [94], which contains action videos collected from five different views. In addition to view changes, different subjects or environments (like indoor vs outdoor) can also create domain shift and lead to model failures.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">目标识别一直是领域泛化（DG）中最常见的任务，在不同的数据集中，领域偏移存在显著差异。在VLCS [56]和Office - 31 [12]数据集中，领域偏移主要由环境或视角的变化引起。如图1（b）所示，VLCS数据集中的场景从城市地区到农村地区各不相同，并且视角通常偏向侧视图或非标准视图。图像风格的变化也经常被研究，例如PACS [37]（见图1（c））、OfficeHome [59]、Domain - Net [60]和ImageNet - Sketch [51]。其他类型的领域偏移包括合成数据与真实数据的差异[56]、人为损坏[9]以及数据源的不同[67]。动作识别学习具有泛化能力的表征对于视频理解（如动作识别）也至关重要。IXMAS [68]已被广泛用作跨视角动作识别基准[31, 94]，其中包含从五个不同视角收集的动作视频。除了视角变化外，不同的主体或环境（如室内与室外）也会造成领域偏移，导致模型失效。</div></div></div></div><div><br><hr><ol><li value="1">We use <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10147" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10148" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>X</mi><mo>,</mo><mi>Y</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> interchangeably.</li></ol><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ol><li value="1">我们可以互换使用<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10149" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>和<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10150" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>X</mi><mo>,</mo><mi>Y</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>。</li></ol></div><br><hr></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-ca09f21b-f28b-4b32-bba4-9d2d111f3bcd" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-2="0,0"><div style="height: auto;"><div><paragraphpositioning data-position-2="0,0"><!-- Media --><br></paragraphpositioning></div><div><div><div>TABLE 1</div></div></div><div><br></div><div><div><div>Commonly used domain generalization datasets (categorized mainly based on applications).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">常用的领域泛化数据集（主要根据应用进行分类）。</div></div></div></div><div><br><div class="table-container"><table class="fixed-table"><tbody><tr><td></td><td>#samples</td><td>#domains</td><td>Characterization of domain shift</td></tr><tr><td colspan="4">Handwritten digit recognition</td></tr><tr><td>- Rotated MNIST [53]</td><td>70,000</td><td>6</td><td>Rotations (0, 15, 30, 45, 60 &amp; 75)</td></tr><tr><td>- Digits-DG [35]</td><td>24,000</td><td>4</td><td>MNIST [54], MNIST-M [15], SVHN [55], SYN [15]</td></tr><tr><td colspan="4">Object recognition</td></tr><tr><td>- VLCS [56]</td><td>10,729</td><td>4</td><td>Caltech101 [44], LabelMe [45], PASCAL [57], SUN09 [58]</td></tr><tr><td>- Office-31 [12]</td><td>4,652</td><td>3</td><td>Amazon, webcam, dslr</td></tr><tr><td>- OfficeHome [59]</td><td>15,588</td><td>4</td><td>Art, clipart, product, real</td></tr><tr><td>- PACS [37]</td><td>9,991</td><td>4</td><td>Photo, art, cartoon, sketch</td></tr><tr><td>- DomainNet [60]</td><td>586,575</td><td>6</td><td>Clipart, infograph, painting, quickdraw, real, sketch</td></tr><tr><td>- miniDomainNet [61]</td><td>140,006</td><td>4</td><td>Clipart, painting, real, sketch</td></tr><tr><td>- ImageNet-Sketch [51]</td><td>50,000</td><td>2</td><td>Real vs sketch images</td></tr><tr><td>- VisDA-17 [62]</td><td>280,157</td><td>2</td><td>Synthetic vs real images</td></tr><tr><td>- CIFAR-10-C [9]</td><td>60,000</td><td>-</td><td>Artificial corruptions</td></tr><tr><td>- CIFAR-100-C [9]</td><td>60,000</td><td>-</td><td>Artificial corruptions</td></tr><tr><td>- ImageNet-C [9]</td><td>≈1.3M</td><td>-</td><td>Artificial corruptions</td></tr><tr><td>- ImageNet-R [63]</td><td>30k</td><td>-</td><td>Image style changes</td></tr><tr><td>- ImageNet-A [64]</td><td>7,500</td><td>-</td><td>Naturally adversarial examples</td></tr><tr><td>- TerraInc [65]</td><td>24,788</td><td>4</td><td>Geographical locations</td></tr><tr><td>- NICO++ [66]</td><td>232.4k</td><td>10</td><td>Contexts (e.g., grass, water, winter, indoor, outdoor)</td></tr><tr><td>- Visual Decathlon [67]</td><td>1,659,142</td><td>10</td><td>Data sources (10 datasets)</td></tr><tr><td colspan="4">Action recognition</td></tr><tr><td>- IXMAS [68]</td><td>1,650</td><td>5</td><td>5 camera views, 10 subjects (see [31])</td></tr><tr><td>- UCF-HMDB [69], [70]</td><td>3,809</td><td>2</td><td>Data sources (2 datasets) (see [71])</td></tr><tr><td colspan="4">Semantic segmentation</td></tr><tr><td>- SYNTHIA [72]</td><td>2,700</td><td>15</td><td>4 locations, 5 weather conditions (see [73])</td></tr><tr><td>- GTA5-Cityscapes [74], [75]</td><td>29,966</td><td>2</td><td>Synthetic vs real images</td></tr><tr><td colspan="4">Person re-identification</td></tr><tr><td>- Market-Duke [76], [77]</td><td>69,079</td><td>2</td><td>Camera views, cities, streets, etc.</td></tr><tr><td colspan="4">Face recognition</td></tr><tr><td>- Face [78]</td><td>&gt;5M</td><td>9</td><td>Data sources (9 datasets)</td></tr><tr><td colspan="4">Face anti-spoofing</td></tr><tr><td>- COMI [79], [80], [81], [82]</td><td>≈8,500</td><td>4</td><td>Data sources (4 datasets)</td></tr><tr><td colspan="4">Speech recognition</td></tr><tr><td>- Google Speech Command [83]</td><td>65k</td><td>1,888</td><td>Speakers</td></tr><tr><td colspan="4">Sentiment classification</td></tr><tr><td>- Amazon Reviews [84]</td><td>&gt;340k</td><td>4</td><td>Books, DVD, electronics, kitchen appliances</td></tr><tr><td colspan="4">WILDS [85] (only show 3 out of 10 datasets here)</td></tr><tr><td>- Camelyon17-WILDS [86]</td><td>455,954</td><td>5</td><td>Hospitals</td></tr><tr><td>- FMoW-WILDS [87]</td><td>523,846</td><td>80</td><td>Time, geographical regions</td></tr><tr><td>- iWildCam-WILDS [88]</td><td>203,029</td><td>323</td><td>Camera traps</td></tr><tr><td colspan="4">Medical imaging</td></tr><tr><td>- Multi-site Prostate MRI Segmentation [42]</td><td>116</td><td>6</td><td>Clinical centers</td></tr><tr><td>- Chest X-rays [89]</td><td>-</td><td>3</td><td>Data sources (NIH [90], ChexPert [91], RSNA)</td></tr><tr><td colspan="4">Reinforcement learning</td></tr><tr><td>- Coinrun [92]</td><td>-</td><td>-</td><td>Scenes, difficulty levels</td></tr><tr><td>- OpenAI Procgen Benchmark [93]</td><td>-</td><td>-</td><td>States, scenes, rewards, difficulty levels</td></tr></tbody></table></div><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><div class="table-container"><table class="fixed-table"><tbody><tr><td></td><td>样本数量</td><td>领域数量</td><td>领域偏移的特征描述</td></tr><tr><td colspan="4">手写数字识别</td></tr><tr><td>- 旋转MNIST数据集 [53]</td><td>70,000</td><td>6</td><td>旋转角度 (0、15、30、45、60 和 75度)</td></tr><tr><td>- 数字领域泛化数据集（Digits-DG） [35]</td><td>24,000</td><td>4</td><td>MNIST数据集 [54]、MNIST-M数据集 [15]、街景门牌号数据集（SVHN） [55]、合成数据集（SYN） [15]</td></tr><tr><td colspan="4">目标识别</td></tr><tr><td>- VLCS数据集 [56]</td><td>10,729</td><td>4</td><td>加州理工101图像数据集（Caltech101） [44]、LabelMe数据集 [45]、PASCAL数据集 [57]、SUN09数据集 [58]</td></tr><tr><td>- Office-31数据集 [12]</td><td>4,652</td><td>3</td><td>亚马逊、网络摄像头、数码单反相机</td></tr><tr><td>- OfficeHome数据集 [59]</td><td>15,588</td><td>4</td><td>艺术、剪贴画、产品、真实场景</td></tr><tr><td>- PACS数据集 [37]</td><td>9,991</td><td>4</td><td>照片、艺术画、卡通、素描</td></tr><tr><td>- DomainNet数据集 [60]</td><td>586,575</td><td>6</td><td>剪贴画、信息图、绘画、快速绘图、真实场景、素描</td></tr><tr><td>- 迷你DomainNet数据集 [61]</td><td>140,006</td><td>4</td><td>剪贴画、绘画、真实场景、素描</td></tr><tr><td>- ImageNet素描数据集 [51]</td><td>50,000</td><td>2</td><td>真实图像与素描图像</td></tr><tr><td>- VisDA-17数据集 [62]</td><td>280,157</td><td>2</td><td>合成图像与真实图像</td></tr><tr><td>- CIFAR-10-C数据集 [9]</td><td>60,000</td><td>-</td><td>人为损坏</td></tr><tr><td>- CIFAR-100-C数据集 [9]</td><td>60,000</td><td>-</td><td>人为损坏</td></tr><tr><td>- ImageNet-C数据集 [9]</td><td>约130万</td><td>-</td><td>人为损坏</td></tr><tr><td>- ImageNet-R数据集 [63]</td><td>30k</td><td>-</td><td>图像风格变化</td></tr><tr><td>- ImageNet-A数据集 [64]</td><td>7,500</td><td>-</td><td>自然对抗样本</td></tr><tr><td>- TerraInc数据集 [65]</td><td>24,788</td><td>4</td><td>地理位置</td></tr><tr><td>- NICO++数据集 [66]</td><td>232.4k</td><td>10</td><td>上下文（例如，草地、水、冬季、室内、室外）</td></tr><tr><td>- 视觉十项全能数据集 [67]</td><td>1,659,142</td><td>10</td><td>数据来源（10个数据集）</td></tr><tr><td colspan="4">动作识别</td></tr><tr><td>- IXMAS数据集 [68]</td><td>1,650</td><td>5</td><td>5个摄像头视角，10个受试者（见 [31]）</td></tr><tr><td>- UCF-HMDB数据集 [69]、[70]</td><td>3,809</td><td>2</td><td>数据来源（2个数据集）（见 [71]）</td></tr><tr><td colspan="4">语义分割</td></tr><tr><td>- SYNTHIA数据集 [72]</td><td>2,700</td><td>15</td><td>4个地点，5种天气条件（见 [73]）</td></tr><tr><td>- GTA5 - 城市景观数据集 [74]、[75]</td><td>29,966</td><td>2</td><td>合成图像与真实图像</td></tr><tr><td colspan="4">行人重识别</td></tr><tr><td>- Market - Duke数据集 [76]、[77]</td><td>69,079</td><td>2</td><td>摄像头视角、城市、街道等</td></tr><tr><td colspan="4">人脸识别</td></tr><tr><td>- 人脸数据集 [78]</td><td>&gt;5M</td><td>9</td><td>数据来源（9个数据集）</td></tr><tr><td colspan="4">人脸反欺骗</td></tr><tr><td>- COMI数据集 [79]、[80]、[81]、[82]</td><td>约8500</td><td>4</td><td>数据来源（4个数据集）</td></tr><tr><td colspan="4">语音识别</td></tr><tr><td>- 谷歌语音命令数据集 [83]</td><td>65k</td><td>1,888</td><td>说话人</td></tr><tr><td colspan="4">情感分类</td></tr><tr><td>- 亚马逊评论数据集 [84]</td><td>&gt;340k</td><td>4</td><td>书籍、DVD、电子产品、厨房电器</td></tr><tr><td colspan="4">WILDS数据集 [85]（此处仅展示10个数据集中的3个）</td></tr><tr><td>- 卡米利恩17 - WILDS数据集 [86]</td><td>455,954</td><td>5</td><td>医院</td></tr><tr><td>- 功能地图 - WILDS数据集 [87]</td><td>523,846</td><td>80</td><td>时间、地理区域</td></tr><tr><td>- 野生相机 - WILDS数据集 [88]</td><td>203,029</td><td>323</td><td>相机陷阱</td></tr><tr><td colspan="4">医学影像</td></tr><tr><td>- 多站点前列腺磁共振成像分割数据集 [42]</td><td>116</td><td>6</td><td>临床中心</td></tr><tr><td>- 胸部X光片 [89]</td><td>-</td><td>3</td><td>数据来源（美国国立卫生研究院 [90]、ChexPert数据集 [91]、美国放射学会）</td></tr><tr><td colspan="4">强化学习</td></tr><tr><td>- 硬币奔跑游戏 [92]</td><td>-</td><td>-</td><td>场景、难度等级</td></tr><tr><td>- OpenAI过程生成基准测试 [93]</td><td>-</td><td>-</td><td>状态、场景、奖励、难度等级</td></tr></tbody></table></div></div><br><!-- Media --><br></div><div><div><div>Semantic Segmentation is critical to autonomous driving. Though this task has been greatly advanced by deep neural networks, the performance is still far from being satisfactory when deploying trained deep models in novel scenarios, such as new cities or unseen weather conditions [95]. Since it is impractical to collect data covering all possible scenarios, DG is pivotal in facilitating large-scale deployment of semantic segmentation systems. The SYNTHIA dataset [72] contains synthetic images of different locations under different weather conditions. Generalization from GTA5 [74] to real image datasets like Cityscapes [75] has also been extensively studied [96].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">语义分割（Semantic Segmentation）对自动驾驶至关重要。尽管深度神经网络已极大推动了这项任务的发展，但在将训练好的深度模型部署到新场景（如陌生城市或未见的天气条件）时，其性能仍远不能令人满意 [95]。由于收集涵盖所有可能场景的数据并不现实，因此领域泛化（Domain Generalization，DG）对于促进语义分割系统的大规模部署至关重要。SYNTHIA 数据集 [72] 包含不同天气条件下不同地点的合成图像。从 GTA5 [74] 到像 Cityscapes [75] 这样的真实图像数据集的泛化也得到了广泛研究 [96]。</div></div></div></div><div><div><div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-8812bab9-96c9-4fa6-9584-bcbdcdf3f317" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-3="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-3="0,0"></paragraphpositioning></div></div></div><div><!-- Media --><br></div><div><div><div>4</div></div></div><div><br><!-- figureText: MNIST MNIST-M SVHN SYN Caltech101 LabelMe PASCAL SUN09 Art Cartoon Photo Sketch 头冠 (b) VLCS (c) PACS (a) Digits --><br></div><img src="https://cdn.noedgeai.com/0195d149-280f-7e81-bc6e-e908e6b9148e_3.jpg?x=170&amp;y=112&amp;w=1458&amp;h=321&amp;r=0" alt="https://cdn.noedgeai.com/0195d149-280f-7e81-bc6e-e908e6b9148e_3.jpg?x=170&amp;y=112&amp;w=1458&amp;h=321&amp;r=0"><div><br></div><div><div><div>Fig. 1. Example images from three domain generalization benchmarks manifesting different types of domain shift. In (a), the domain shift mainly corresponds to changes in font style, color and background. In (b), dataset-specific biases are clear, which are caused by changes in environment/scene and viewpoint. In (c), image style changes are the main reason for domain shift.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">图 1. 来自三个领域泛化基准的示例图像，展示了不同类型的领域偏移。在 (a) 中，领域偏移主要对应于字体样式、颜色和背景的变化。在 (b) 中，特定数据集的偏差很明显，这是由环境/场景和视角的变化引起的。在 (c) 中，图像风格的变化是领域偏移的主要原因。</div></div></div></div><div><br><!-- Media --><br></div><div><div><div>Person Re-Identification (Re-ID) plays a key role in security and surveillance applications. Person re-ID is essentially an instance retrieval task, aiming to match people across disjoint camera views (each seen as a distinct domain). Most existing methods in re-ID [97], [98], [99], [100], [101] have been focused on the same-dataset setting, i.e., training and test are done on the same set of camera views, with performance almost reaching saturation. Recently, cross-dataset re-ID [102], [103], [104] has gained much attention: the objective is to generalize a model from source camera views to unseen target camera views, a more challenging but realistic setting. The domain shift often occurs in image resolution, viewpoint, lighting condition, background, etc.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">行人重识别（Person Re-Identification，Re-ID）在安全和监控应用中起着关键作用。行人重识别本质上是一个实例检索任务，旨在跨不相交的相机视角（每个视角视为一个不同的领域）匹配行人。现有的大多数行人重识别方法 [97]、[98]、[99]、[100]、[101] 都集中在同数据集设置上，即训练和测试在同一组相机视角上进行，性能几乎达到饱和。最近，跨数据集行人重识别 [102]、[103]、[104] 受到了广泛关注：目标是将模型从源相机视角泛化到未见的目标相机视角，这是一个更具挑战性但更现实的设置。领域偏移通常发生在图像分辨率、视角、光照条件、背景等方面。</div></div></div></div><div><br></div><div><div><div>Face Recognition has witnessed significant advances driven by deep learning in recent years [105], [106], [107]. However, several studies [78] have suggested that deep models trained even on large-scale datasets like MS-Celeb- <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10151" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4D"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c5D"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">M</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">[</mo><mrow data-mjx-texclass="ORD"><mn>108</mn></mrow><mo data-mjx-texclass="CLOSE">]</mo></mrow></math></mjx-assistive-mml></mjx-container> suffer substantial performance drops when deployed in new datasets with previously unseen domains, such as low resolution [109], [110], [111], large variations in illumination/occlusion/head pose [112], [113], [114], or drastically different viewpoints [115].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">近年来，在深度学习的推动下，人脸识别（Face Recognition）取得了显著进展 [105]、[106]、[107]。然而，多项研究 [78] 表明，即使在像 MS-Celeb- <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10152" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4D"></mjx-c></mjx-mi></mjx-texatom><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c5D"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">M</mi></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">[</mo><mrow data-mjx-texclass="ORD"><mn>108</mn></mrow><mo data-mjx-texclass="CLOSE">]</mo></mrow></math></mjx-assistive-mml></mjx-container> 这样的大规模数据集上训练的深度模型，在部署到具有先前未见领域的新数据集时，性能也会大幅下降，例如低分辨率 [109]、[110]、[111]，光照/遮挡/头部姿态的大幅变化 [112]、[113]、[114]，或截然不同的视角 [115]。</div></div></div></div><div><br></div><div><div><div>Face Anti-Spoofing aims to prevent face recognition systems from being attacked using fake faces [116], such as printed photos, videos or 3D masks. Conventional face anti-spoofing methods do not take into account distribution shift, making them vulnerable to unseen attack types [117]. There is no specifically designed DG dataset for this task. A common practice is to combine several face anti-spoofing datasets for model training and do evaluation on an unseen dataset, e.g., using CASIA-MFSD [79], Oulu-NPU [80] and MSU-MFSD [81] as the sources and Idiap Replay-Attack [82] as the target.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">人脸反欺骗（Face Anti-Spoofing）旨在防止人脸识别系统受到使用假人脸（如打印照片、视频或 3D 面具）的攻击 [116]。传统的人脸反欺骗方法没有考虑分布偏移，这使得它们容易受到未见攻击类型的影响 [117]。目前没有专门为这项任务设计的领域泛化数据集。常见的做法是将几个人脸反欺骗数据集组合起来进行模型训练，并在一个未见的数据集上进行评估，例如，使用 CASIA - MFSD [79]、Oulu - NPU [80] 和 MSU - MFSD [81] 作为源数据集，Idiap Replay - Attack [82] 作为目标数据集。</div></div></div></div><div><br></div><div><div><div>Speech Recognition Since people speak differently (e.g., different tones or pitches) it is natural to regard each speaker as a domain [40]. The commonly used dataset is Google Speech Command [83], which consists of 1,888 domains (speakers) and around 65,000 samples.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">语音识别（Speech Recognition）由于人们说话方式不同（如不同的语调或音高），自然可以将每个说话者视为一个领域 [40]。常用的数据集是 Google 语音命令数据集 [83]，它由 1888 个领域（说话者）和约 65000 个样本组成。</div></div></div></div><div><br></div><div><div><div>Sentiment Classification is a common task studied in natural language processing, which aims to classify opinions in texts as either positive or negative (hence a binary classification problem) [34]. Amazon Reviews [84] contains reviews for four categories (domains) of products: books, DVD, electronics and kitchen appliances.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">情感分类（Sentiment Classification）是自然语言处理中研究的常见任务，旨在将文本中的观点分类为积极或消极（因此是一个二分类问题）[34]。亚马逊评论数据集 [84] 包含四类（领域）产品的评论：书籍、DVD、电子产品和厨房电器。</div></div></div></div><div><br></div><div><div><div>The WILDS Benchmark has been recently introduced, with a goal to study distribution shift faced in the wild [85]. The benchmark contains a total of ten datasets, which cover a wide range of pattern recognition tasks, such as animal classification, cancer detection, molecule classification, and satellite imaging. Table 1 shows three datasets from WILDS that have been commonly used by the DG community [118], [119], [120].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">WILDS 基准最近被引入，旨在研究现实世界中面临的分布偏移 [85]。该基准总共包含十个数据集，涵盖了广泛的模式识别任务，如动物分类、癌症检测、分子分类和卫星成像。表 1 展示了 WILDS 中被领域泛化社区常用的三个数据集 [118]、[119]、[120]。</div></div></div></div><div><br></div><div><div><div>Medical Imaging DG is also critical to medical imaging where domain shift is often related to variations in clinical centers or patients [42], [121]. Two commonly used medical imaging datasets are Multi-site Prostate MRI Segmentation [42] and Chest X-rays [89], each containing data aggregated from multiple clinical centers with domain shift caused by, e.g., different scanners or acquisition protocols.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">医学影像领域泛化（Medical Imaging DG）在医学影像中也至关重要，其中领域偏移通常与临床中心或患者的差异有关 [42]、[121]。两个常用的医学影像数据集是多站点前列腺 MRI 分割数据集 [42] 和胸部 X 光数据集 [89]，每个数据集都包含从多个临床中心汇总的数据，领域偏移由不同的扫描仪或采集协议等因素引起。</div></div></div></div><div><br></div><div><div><div>Reinforcement Learning (RL) has a dramatically different paradigm than supervised or unsupervised learning: RL aims to maximize rewards obtained through continuous interactions with an environment. Generalization in RL has been a critical issue where agents or policies learned in a training environment often suffer from overfitting and hence generalize poorly to unseen environments [92], [122], [123], [124]. Domain shift in RL is mostly associated with environmental changes, such as different scenes, states, or even rewards. There is a large body of work focused on improving generalization in RL. We refer readers to [125] for a more comprehensive survey in the topic of generalizable RL.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">强化学习（Reinforcement Learning，RL）与监督学习或无监督学习有着截然不同的范式：强化学习旨在通过与环境的持续交互来最大化所获得的奖励。强化学习中的泛化一直是一个关键问题，在训练环境中学习到的智能体或策略往往会出现过拟合问题，因此在未见过的环境中泛化能力较差 [92]、[122]、[123]、[124]。强化学习中的领域偏移大多与环境变化有关，例如不同的场景、状态甚至奖励。有大量的工作致力于提高强化学习的泛化能力。关于可泛化强化学习这一主题的更全面综述，我们建议读者参考 [125]。</div></div></div></div><div><br></div><h3><div><div>2.4 Evaluation<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2.4 评估</div></div></div></h3><div><br></div><div><div><div>Evaluation of DG algorithms often follows the leave-one-domain-out rule [37]: given a dataset containing at least two distinct domains, one or multiple of them are used as source domain(s) for model training while the rest are treated as target domain(s); a model learned from the source domain(s) is directly tested in the target domain(s) without any form of adaptation. Two problem scenarios have been studied: single- vs multi-source DG. It is worth noting that some datasets contain label shift, meaning that the label space between source and target changes (termed heterogeneous DG [38]). For instance, in the problem of person re-ID, identities between training and test are different; in this case the source-learned representation is directly used for image matching.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">领域泛化（DG）算法的评估通常遵循留一领域法规则 [37]：给定一个包含至少两个不同领域的数据集，其中一个或多个领域用作模型训练的源领域，而其余领域则视为目标领域；从源领域学习到的模型在目标领域中直接进行测试，无需进行任何形式的调整。目前已经研究了两种问题场景：单源领域泛化与多源领域泛化。值得注意的是，一些数据集存在标签偏移，这意味着源领域和目标领域之间的标签空间发生了变化（称为异构领域泛化 [38]）。例如，在行人重识别问题中，训练集和测试集的身份不同；在这种情况下，从源领域学习到的特征表示直接用于图像匹配。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-4bede165-7708-4acc-bb6f-cdb34f83de72" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-4="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-4="0,0"></paragraphpositioning></div></div></div><div><!-- Media --><br></div><div><div><div>TABLE 2</div></div></div><div><br></div><div><div><div>Comparison between domain generalization and its related topics.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">领域泛化与其相关主题的比较。</div></div></div></div><div><br><div class="table-container"><table class="fixed-table"><tbody><tr><td rowspan="2"></td><td colspan="2"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10153" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></mjx-assistive-mml></mjx-container></td><td colspan="2"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10154" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container> vs <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10155" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container></td><td colspan="2"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10156" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.046em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>S</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> vs <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10157" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.046em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>T</mi></mrow></msub></math></mjx-assistive-mml></mjx-container></td><td rowspan="2">Access to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10158" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container> ?</td></tr><tr><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10159" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>=</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container></td><td>&gt; 1</td><td>-</td><td>≠</td><td>-</td><td>≠</td></tr><tr><td>Supervised Learning</td><td>✓</td><td></td><td>✓</td><td></td><td>✓</td><td></td><td></td></tr><tr><td>Multi-Task Learning</td><td></td><td>✓</td><td>✓</td><td></td><td>✓</td><td></td><td></td></tr><tr><td>Transfer Learning</td><td>✓</td><td>✓</td><td></td><td>✓</td><td></td><td>✓</td><td>✓</td></tr><tr><td>Zero-Shot Learning</td><td>✓</td><td></td><td></td><td>✓</td><td></td><td>✓</td><td></td></tr><tr><td>Domain Adaptation</td><td>✓</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Test-Time Training</td><td>✓</td><td>✓</td><td></td><td>✓</td><td>✓</td><td></td><td>✓</td></tr><tr><td>Domain Generalization</td><td>✓</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td></td></tr></tbody></table></div><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><div class="table-container"><table class="fixed-table"><tbody><tr><td rowspan="2"></td><td colspan="2"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10160" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></mjx-assistive-mml></mjx-container></td><td colspan="2"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10161" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container> 与 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10162" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container> 对比</td><td colspan="2"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10163" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.046em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>S</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> 与 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10164" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.046em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>T</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> 对比</td><td rowspan="2">能否访问 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10165" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container> ？</td></tr><tr><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10166" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>=</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container></td><td>&gt; 1</td><td>-</td><td>≠</td><td>-</td><td>≠</td></tr><tr><td>监督学习（Supervised Learning）</td><td>✓</td><td></td><td>✓</td><td></td><td>✓</td><td></td><td></td></tr><tr><td>多任务学习（Multi-Task Learning）</td><td></td><td>✓</td><td>✓</td><td></td><td>✓</td><td></td><td></td></tr><tr><td>迁移学习（Transfer Learning）</td><td>✓</td><td>✓</td><td></td><td>✓</td><td></td><td>✓</td><td>✓</td></tr><tr><td>零样本学习（Zero-Shot Learning）</td><td>✓</td><td></td><td></td><td>✓</td><td></td><td>✓</td><td></td></tr><tr><td>领域自适应（Domain Adaptation）</td><td>✓</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>测试时训练（Test-Time Training）</td><td>✓</td><td>✓</td><td></td><td>✓</td><td>✓</td><td></td><td>✓</td></tr><tr><td>领域泛化（Domain Generalization）</td><td>✓</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td></td></tr></tbody></table></div></div><br></div><div><div><div><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10167" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></mjx-assistive-mml></mjx-container> : number of source domains/tasks. <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10168" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>V</mi></mrow><mrow data-mjx-texclass="ORD"><mi>S</mi><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mi>T</mi></mrow></msubsup></math></mjx-assistive-mml></mjx-container> : source/target joint distribution. <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10169" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.177em; margin-left: -0.046em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>S</mi><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mi>T</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> : source/target label space. <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10170" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.3em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi></mrow><mrow data-mjx-texclass="ORD"><mi>T</mi></mrow></msubsup></math></mjx-assistive-mml></mjx-container> : target marginal. <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10171" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2020"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>†</mo></math></mjx-assistive-mml></mjx-container> : Limited in quantities. like a single example or mini-batch.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10172" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></mjx-assistive-mml></mjx-container> ：源域/任务的数量。<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10173" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>V</mi></mrow><mrow data-mjx-texclass="ORD"><mi>S</mi><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mi>T</mi></mrow></msubsup></math></mjx-assistive-mml></mjx-container> ：源/目标联合分布。<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10174" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.177em; margin-left: -0.046em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>S</mi><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mi>T</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> ：源/目标标签空间。<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10175" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.3em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi></mrow><mrow data-mjx-texclass="ORD"><mi>T</mi></mrow></msubsup></math></mjx-assistive-mml></mjx-container> ：目标边缘分布。<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10176" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2020"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>†</mo></math></mjx-assistive-mml></mjx-container> ：数量有限，例如单个示例或小批量。</div></div></div></div><div><br><!-- Media --><br></div><div><div><div>Evaluation Metrics Two metrics have been commonly adopted, namely average and worst-case performance. The former concerns about the average performance in held-out domains, which is used in most domain shift scenarios. In contrast, the latter focuses on the worst performance among held-out domains, which is often used in the case of subpopulation shift [126] and has been widely adopted by the causal inference community [127] as well as some datasets in the WILDS benchmark [85].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">评估指标 通常采用两种指标，即平均性能和最坏情况性能。前者关注在保留域中的平均性能，这在大多数域偏移场景中使用。相比之下，后者关注保留域中的最差性能，这常用于子群体偏移的情况 [126]，并且也被因果推理界 [127] 以及 WILDS 基准测试中的一些数据集 [85] 广泛采用。</div></div></div></div><div><br></div><div><div><div>Model Selection concerns about which model (checkpoint), architecture or hyper-parameters to choose for evaluation, which has recently been identified by [128] as a crucial step in the evaluation pipeline. As summarized in [128], there are three model selection criteria: i) Training-domain validation, which holds out a subset of training data for model selection; ii) Leave-one-domain-out validation, which keeps one source domain for model selection; iii) Test-domain validation (oracle), which performs model selection using a random subset of test domain data. As suggested by [128], the last criterion would lead to overly optimistic or pessimistic results and thus should be used with care. Another important lesson from [128] is that specially designed DG methods often perform similarly with the plain model (known as Empirical Risk Minimization) when using larger neural networks and an extensive search of hyper-parameters. Therefore, it is suggested that future evaluation should cover different neural network architectures and ensure comparison is made using the same model selection criterion.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">模型选择 关注选择哪个模型（检查点）、架构或超参数进行评估，最近 [128] 已将其确定为评估流程中的关键步骤。正如 [128] 所总结的，有三种模型选择标准：i) 训练域验证，即留出一部分训练数据用于模型选择；ii) 留一域验证，即保留一个源域用于模型选择；iii) 测试域验证（神谕），即使用测试域数据的随机子集进行模型选择。正如 [128] 所建议的，最后一种标准会导致过于乐观或悲观的结果，因此应谨慎使用。从 [128] 中得到的另一个重要经验是，当使用更大的神经网络并广泛搜索超参数时，专门设计的域泛化（DG）方法通常与普通模型（即经验风险最小化）表现相似。因此，建议未来的评估应涵盖不同的神经网络架构，并确保使用相同的模型选择标准进行比较。</div></div></div></div><div><br></div><h3><div><div>2.5 Related Topics<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2.5 相关主题</div></div></div></h3><div><br></div><div><div><div>In this section, we discuss the relations between DG and its related topics, and clarify their differences. See Table 2 for an overview.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在本节中，我们讨论域泛化（DG）与其相关主题之间的关系，并阐明它们的差异。概述见表 2。</div></div></div></div><div><br></div><div><div><div>Supervised Learning generally aims to learn an input-output mapping by minimizing the following risk: <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10177" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-ds mjx-b"><mjx-c class="mjx-c1D53C TEX-A"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.411em;"><mjx-texatom size="s" texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c223C"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.105em; padding-left: 0.486em; margin-bottom: -0.551em;"><mjx-mo class="mjx-sop" style="width: 0px; margin-left: -0.278em;"><mjx-c class="mjx-c2C6 TEX-S1"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom texclass="ORD" style="font-size: 71.4%;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-texatom></mjx-script></mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi mathvariant="double-struck">E</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>∼</mo><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mover><mi>P</mi><mo>^</mo></mover></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></mrow></msub><mi>ℓ</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>f</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>x</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>,</mo><mi>y</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> ,where <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10178" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.105em; padding-left: 0.486em; margin-bottom: -0.551em;"><mjx-mo class="mjx-sop" style="width: 0px; margin-left: -0.278em;"><mjx-c class="mjx-c2C6 TEX-S1"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mover><mi>P</mi><mo>^</mo></mover></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> denotes the empirical distribution rather than the real data distribution <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10179" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> ,which is inaccessible. The hope is that once the loss is minimized, the learned model can work well on data generated from <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10180" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> ,which heavily relies on the i.i.d. assumption. The crucial difference between SL and DG is that in the latter training and test data is drawn from different distributions, thus violating the i.i.d. assumption. DG is arguably a more practical setting in real-world applications [43].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">监督学习 通常旨在通过最小化以下风险来学习输入 - 输出映射：<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10181" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-ds mjx-b"><mjx-c class="mjx-c1D53C TEX-A"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.411em;"><mjx-texatom size="s" texclass="ORD"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c223C"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.105em; padding-left: 0.486em; margin-bottom: -0.551em;"><mjx-mo class="mjx-sop" style="width: 0px; margin-left: -0.278em;"><mjx-c class="mjx-c2C6 TEX-S1"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom texclass="ORD" style="font-size: 71.4%;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-texatom></mjx-script></mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi mathvariant="double-struck">E</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>∼</mo><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mover><mi>P</mi><mo>^</mo></mover></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></mrow></msub><mi>ℓ</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>f</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>x</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>,</mo><mi>y</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> ，其中 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10182" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.105em; padding-left: 0.486em; margin-bottom: -0.551em;"><mjx-mo class="mjx-sop" style="width: 0px; margin-left: -0.278em;"><mjx-c class="mjx-c2C6 TEX-S1"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mover><mi>P</mi><mo>^</mo></mover></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> 表示经验分布，而非无法获取的真实数据分布 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10183" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> 。希望一旦损失最小化，所学习的模型就能在从 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10184" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> 生成的数据上表现良好，这在很大程度上依赖于独立同分布（i.i.d.）假设。监督学习（SL）和域泛化（DG）的关键区别在于，在后者中，训练数据和测试数据来自不同的分布，从而违反了独立同分布假设。可以说，域泛化在现实世界应用中是一种更实际的设置 [43]。</div></div></div></div><div><br></div><div><div><div>Multi-Task Learning (MTL) The goal of MTL is to simultaneously learn multiple related tasks <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10185" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>K</mi><mo>&gt;</mo><mn>1</mn></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> using a single model [129], [130], [131], [132], [133]. As shown in Table 2, MTL aims to make a model perform well on the same set of tasks that the model was trained on <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10186" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.046em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.046em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>S</mi></mrow></msub><mo>=</mo><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>T</mi></mrow></msub></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> ,whereas DG aims to generalize a model to unseen data distributions <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10187" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-texatom><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></mrow></msubsup><mo>≠</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> . Though being different in terms of the problem setup, the MTL paradigm has been exploited in some DG methods, notably for those based on self-supervised learning [49], [134], [135]. Intuitively, MTL benefits from the effect of regularization brought by parameter sharing [129], which may in part explain why the MTL paradigm works for DG.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">多任务学习（MTL） 多任务学习的目标是使用单个模型同时学习多个相关任务 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10188" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>K</mi><mo>&gt;</mo><mn>1</mn></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> [129]、[130]、[131]、[132]、[133]。如表 2 所示，多任务学习旨在使模型在其训练的同一组任务 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10189" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msub><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.046em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.046em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>S</mi></mrow></msub><mo>=</mo><msub><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></mrow><mrow data-mjx-texclass="ORD"><mi>T</mi></mrow></msub></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 上表现良好，而域泛化旨在将模型推广到未见的数据分布 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10190" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-texatom><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></mrow></msubsup><mo>≠</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 。尽管在问题设置方面有所不同，但多任务学习范式已在一些域泛化方法中得到应用，特别是那些基于自监督学习的方法 [49]、[134]、[135]。直观地说，多任务学习受益于参数共享带来的正则化效果 [129]，这在一定程度上可以解释为什么多任务学习范式适用于域泛化。</div></div></div></div><div><br></div><div><div><div>Transfer Learning (TL) aims to transfer the knowledge learned from one (or multiple) problem/domain/task to a different but related one [136]. A well-known TL example in contemporary deep learning is fine-tuning: first pretrain deep neural networks on large-scale datasets, such as ImageNet [11] for vision models or BooksCorpus [137] for language models; then fine-tune them on downstream tasks [138]. Given that pre-trained deep features are highly transferable, as shown in several studies [139], [140], a couple of recent DG works [141], [142] have researched how to preserve the transferable features learned via large-scale pre-training when learning new knowledge from source synthetic data for synthetic-to-real applications. As shown in Table 2, a key difference between TL and DG lies in whether the target data is used. In TL, the target data is required for model fine-tuning for new downstream tasks, whereas in DG we assume to have no access to the target data, thus focusing more on model generalization. Nonetheless, TL and DG share some similarities: the target distribution in both TL and DG is different from the source distribution; in terms of label space, TL mainly concerns disjoint label space, whereas DG considers both cases, i.e., same label space for homogeneous DG and disjoint label space for heterogeneous DG.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">迁移学习（Transfer Learning，TL）旨在将从一个（或多个）问题/领域/任务中学到的知识迁移到另一个不同但相关的问题/领域/任务中 [136]。当代深度学习中一个著名的迁移学习示例是微调：首先在大规模数据集上预训练深度神经网络，例如用于视觉模型的 ImageNet 数据集 [11] 或用于语言模型的 BooksCorpus 语料库 [137]；然后在下游任务上对其进行微调 [138]。正如多项研究 [139]、[140] 所示，预训练的深度特征具有高度可迁移性，因此近期有几项领域泛化（Domain Generalization，DG）工作 [141]、[142] 研究了在从源合成数据中学习新知识以实现从合成到真实的应用时，如何保留通过大规模预训练学到的可迁移特征。如表 2 所示，迁移学习和领域泛化的一个关键区别在于是否使用目标数据。在迁移学习中，模型针对新的下游任务进行微调时需要目标数据，而在领域泛化中，我们假设无法获取目标数据，因此更侧重于模型的泛化能力。尽管如此，迁移学习和领域泛化仍有一些相似之处：两者的目标分布都与源分布不同；在标签空间方面，迁移学习主要关注不相交的标签空间，而领域泛化则考虑两种情况，即同质领域泛化的相同标签空间和异质领域泛化的不相交标签空间。</div></div></div></div><div><br></div><div><div><div>Zero-Shot Learning (ZSL) is related to DG in the sense that the goal in both problems is to deal with unseen distributions. Differently, distribution shift in ZSL is mainly caused by label space changes [143],[144],[145],i.e., <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10191" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup><mo>≠</mo></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10192" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container> ,since the task is to recognize new classes,except for generalized ZSL [146] which considers both new and old classes at test time; while in DG, domain shift mostly results from covariate shift [19], i.e., only the marginal distribution changes <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10193" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-texatom><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup><mo>≠</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></mrow></msubsup></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>⋅</mo><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msup></math></mjx-assistive-mml></mjx-container> To recognize unseen classes in ZSL,a common practice is to learn a mapping between the input image space and the attribute space [148] since the label space is disjoint between training and test data. Interestingly, attributes have also been exploited in DG for learning domain-generalizable representations [149].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">零样本学习（Zero-Shot Learning，ZSL）与领域泛化相关，因为这两个问题的目标都是处理未见分布。不同的是，零样本学习中的分布偏移主要由标签空间变化引起 [143]、[144]、[145]，即 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10194" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup><mo>≠</mo></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10195" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>Y</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></mrow></msubsup></math></mjx-assistive-mml></mjx-container>，因为该任务是识别新类别，不过广义零样本学习 [146] 在测试时会同时考虑新类别和旧类别；而在领域泛化中，领域偏移主要由协变量偏移导致 [19]，即仅边缘分布发生变化 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10196" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c54 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.233em;"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c53 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-texatom><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">T</mi></mrow></mrow></msubsup><mo>≠</mo><msubsup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi>X</mi></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">S</mi></mrow></mrow></msubsup></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>⋅</mo><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msup></math></mjx-assistive-mml></mjx-container>。为了在零样本学习中识别未见类别，常见的做法是学习输入图像空间和属性空间之间的映射 [148]，因为训练数据和测试数据的标签空间不相交。有趣的是，属性也被用于领域泛化中以学习领域可泛化的表示 [149]。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-47913b15-0291-4df6-83b8-adb8f7e03fd5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-5="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-df9d757f-22e2-4c3f-b8e3-d50ff1de465e" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-6="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-a440ff7f-1a23-44c7-9121-51ea58146522" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-7="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-7="0,0"></paragraphpositioning></div></div></div><div><div><div>Minimizing the KL Divergence As a commonly used distribution divergence measure, the KL divergence has also been employed for domain alignment [172], [173]. In [172], domain-agnostic posteriors within each class are aligned via the KL divergence. In [173], the KL divergence is used to force all source domain features to be aligned with a Gaussian distribution.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">最小化 KL 散度 作为一种常用的分布散度度量，KL 散度也被用于领域对齐 [172]、[173]。在 [172] 中，通过 KL 散度对齐每个类内与领域无关的后验。在 [173] 中，使用 KL 散度迫使所有源领域特征与高斯分布对齐。</div></div></div></div><div><br></div><div><div><div>Minimizing Maximum Mean Discrepancy (MMD) The MMD distance [219] measures the divergence between two probability distributions by first mapping instances to a reproducing kernel Hilbert space (RKHS) and then computing the distance based on their mean. Using the autoencoder architecture, Li et al. [31] minimized the MMD distance between source domain distributions on the hidden-layer features, and meanwhile, forced the feature distributions to be similar to a prior distribution via adversarial learning [220].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">最小化最大均值差异（MMD） 最大均值差异（MMD）距离 [219] 通过首先将实例映射到再生核希尔伯特空间（RKHS），然后基于它们的均值计算距离来衡量两个概率分布之间的差异。使用自编码器架构，Li 等人 [31] 最小化了隐藏层特征上源领域分布之间的 MMD 距离，同时，通过对抗学习 [220] 迫使特征分布与先验分布相似。</div></div></div></div><div><br></div><div><div><div>Domain-Adversarial Learning Different from explicit distance measures like the MMD, adversarial learning [220] formulates the distribution minimization problem through a minimax two-player game. Initially proposed by Goodfel-low et al. [220], adversarial learning was used to train a generative model, which takes as input random noises and generates photorealistic images. This is achieved by learning a discriminator to distinguish between real and the generated fake images (i.e., minimizing the binary classification loss), while encouraging the generator to fool the discriminator (i.e., maximizing the binary classification loss). In particular, the authors in [220] theoretically justified that generative adversarial learning is equivalent to minimizing the Jensen-Shannon divergence between the real distribution and the generated distribution. Therefore, it is natural to use adversarial learning for distribution alignment, which has already been extensively studied in the domain adaptation area for aligning the source-target distributions [15], [221], [222], [223].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">领域对抗学习 与最大均值差异（MMD）等显式距离度量不同，对抗学习 [220] 通过一个极小极大的二人博弈来表述分布最小化问题。对抗学习最初由古德费洛（Goodfellow）等人 [220] 提出，用于训练生成模型，该模型以随机噪声为输入，生成逼真的图像。这是通过学习一个判别器来区分真实图像和生成的虚假图像（即最小化二元分类损失），同时鼓励生成器欺骗判别器（即最大化二元分类损失）来实现的。特别地，文献 [220] 的作者从理论上证明了生成对抗学习等价于最小化真实分布和生成分布之间的詹森 - 香农散度（Jensen - Shannon divergence）。因此，自然可以使用对抗学习进行分布对齐，这在领域自适应领域已经被广泛研究，用于对齐源域和目标域的分布 [15]、[221]、[222]、[223]。</div></div></div></div><div><br></div><div><div><div>In DG, adversarial learning is performed between source domains to learn source domain-agnostic features that are expected to work in novel domains [32], [117], [174], [175], [176]. Simply speaking, the learning objective is to make features confuse a domain discriminator, which can be implemented as a multi-class domain discriminator [177], [179], [180], or a binary domain discriminator in a per-domain basis [32], [117]. Typically, the learning steps alternate between the feature generator and the domain discriminator(s) [32]. However, one can simplify the process to achieve singlestep update by using the gradient-reversal layer [15] to flip the sign of the gradients back-propagated from the domain discriminator(s) [178].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在领域泛化（DG）中，在源域之间进行对抗学习，以学习期望在新领域中有效的源域无关特征 [32]、[117]、[174]、[175]、[176]。简单来说，学习目标是让特征使领域判别器产生混淆，领域判别器可以实现为多类领域判别器 [177]、[179]、[180]，或者基于每个领域的二元领域判别器 [32]、[117]。通常，学习步骤在特征生成器和领域判别器之间交替进行 [32]。然而，通过使用梯度反转层 [15] 翻转从领域判别器反向传播的梯度符号，可以简化过程以实现单步更新 [178]。</div></div></div></div><div><br></div><div><div><div>To enhance domain alignment, researchers have also combined domain-adversarial learning with explicit distance measures like moments minimization [174], or with some regularization constraints such as entropy [181].<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">为了增强领域对齐，研究人员还将领域对抗学习与显式距离度量（如矩最小化 [174]）或一些正则化约束（如熵 [181]）相结合。</div></div></div></div><div><br></div><div><div><div>Multi-Task Learning has also been explored for domain alignment [53], [206]. Different from directly minimizing the distribution divergence, MTL facilitates the learning of generic features by parameter sharing [129]. This is easy to understand: in order to simultaneously deal with different tasks the features have to be generic enough. In [53], the authors proposed a denoising autoencoder architecture (later employed in [206]) where the encoder is shared but the decoder is split into domain-specific branches, each connected to a reconstruction task. The model was trained with two objectives, one being self-domain reconstruction while the other being cross-domain reconstruction, which aim to force the hidden representations to be as generic as possible.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">多任务学习（MTL）也被用于领域对齐 [53]、[206]。与直接最小化分布差异不同，多任务学习通过参数共享促进通用特征的学习 [129]。这很容易理解：为了同时处理不同的任务，特征必须足够通用。在文献 [53] 中，作者提出了一种去噪自动编码器架构（后来在文献 [206] 中被采用），其中编码器是共享的，但解码器被拆分为特定领域的分支，每个分支连接到一个重建任务。该模型以两个目标进行训练，一个是自领域重建，另一个是跨领域重建，旨在迫使隐藏表示尽可能通用。</div></div></div></div><div><br><!-- Media --><br><!-- figureText: meta-source \( \widehat{\theta } = \theta  - \eta {\nabla }_{\theta }{\ell }_{\text{outer }} \) outer update \( {f}_{\theta } \) \( {\ell }_{\text{inner }}\left( {{f}_{\theta }\left( x\right) ,y}\right) \) \( {\theta }^{ * } = \theta  - \eta {\nabla }_{\theta }{\ell }_{\text{inner }} \) inner update \( {f}_{{\theta }^{ * }} \) \( {\ell }_{\text{outer }}\left( {{f}_{{\theta }^{ * }}\left( {x}^{\prime }\right) ,{y}^{\prime }}\right) \) art photo meta-target cartoon --><br></div><img src="https://cdn.noedgeai.com/0195d149-280f-7e81-bc6e-e908e6b9148e_7.jpg?x=921&amp;y=122&amp;w=741&amp;h=408&amp;r=0" alt="https://cdn.noedgeai.com/0195d149-280f-7e81-bc6e-e908e6b9148e_7.jpg?x=921&amp;y=122&amp;w=741&amp;h=408&amp;r=0"><div><br></div><div><div><div>Fig. 3. A commonly used meta-learning paradigm [33] in domain generalization. The source domains (i.e., art, photo and cartoon from PACS [37]) are divided into disjoint meta-source and meta-target domains. The outer learning, which simulates domain shift using the meta-target data, back-propagates the gradients all the way back to the base parameters such that the model learned by the inner algorithm with the meta-source data improves the outer objective. The red arrows in this figure denote the gradient flow through the second-order differentiation.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">图 3. 领域泛化中常用的元学习范式 [33]。源域（即来自 PACS [37] 的艺术、照片和卡通）被划分为不相交的元源域和元目标域。外部学习使用元目标数据模拟领域偏移，将梯度一直反向传播到基础参数，使得内部算法使用元源数据学习的模型能够改善外部目标。图中的红色箭头表示通过二阶微分的梯度流。</div></div></div></div><div><br><!-- Media --><br></div><div><div><div>Domain alignment is still a popular research direction in DG. This idea has also been extensively studied in the domain adaptation (DA) literature [15], [16], [151], [224], [225], but with a rigorous theoretical support [3]. In particular, the DA theory introduced in [3] suggested that minimizing the distribution divergence between source and target has a huge impact on lowering the upper-bound of the target error. However, in DG we cannot access the target data and therefore, the alignment is performed only among source domains. This inevitably raises a question of whether a representation learned to be invariant to source domain shift is guaranteed to generalize to an unseen domain shift in the target data. To solve this concern, one can focus on developing novel theories to explain how alignment in source domains improves generalization in unseen domains.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">领域对齐仍然是领域泛化中的一个热门研究方向。这个想法在领域自适应（DA）文献 [15]、[16]、[151]、[224]、[225] 中也得到了广泛研究，并且有严格的理论支持 [3]。特别地，文献 [3] 中引入的领域自适应理论表明，最小化源域和目标域之间的分布差异对降低目标误差的上界有巨大影响。然而，在领域泛化中，我们无法访问目标数据，因此，对齐仅在源域之间进行。这不可避免地引发了一个问题：学习到的对源域偏移不变的表示是否能保证泛化到目标数据中未见的领域偏移。为了解决这个问题，可以专注于开发新的理论来解释源域中的对齐如何提高在未见领域中的泛化能力。</div></div></div></div><div><br></div><h3><div><div>3.2 Meta-Learning<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.2 元学习</div></div></div></h3><div><br></div><div><div><div>Meta-learning has been a fast growing area with applications to many machine learning and computer vision problems [33], [42], [94], [103], [226]. Also known as learning-to-learning, meta-learning aims to learn from episodes sampled from related tasks to benefit future learning (see [227] for a comprehensive survey on meta-learning). The meta-learning paper most related to DG is MAML [226], which divides training data into meta-train and meta-test sets, and trains a model using the meta-train set in such a way to improve the performance on the meta-test set. The MAML-style training usually involves a second-order differentiation through the update of the base model, thus posing issues on efficiency and memory consumption for large neural network models [227]. In [226], MAML was used for parameter initialization, i.e., to learn an initialization state that is only a few gradient steps away from the solution to the target task.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">元学习是一个快速发展的领域，应用于许多机器学习和计算机视觉问题 [33]、[42]、[94]、[103]、[226]。元学习也被称为“学习如何学习”，旨在从相关任务中采样的情节中学习，以利于未来的学习（有关元学习的全面综述，请参阅 [227]）。与领域泛化最相关的元学习论文是模型无关元学习（MAML） [226]，它将训练数据分为元训练集和元测试集，并使用元训练集训练模型，以提高在元测试集上的性能。MAML 风格的训练通常涉及通过基础模型的更新进行二阶微分，因此对于大型神经网络模型会带来效率和内存消耗方面的问题 [227]。在文献 [226] 中，MAML 用于参数初始化，即学习一个初始化状态，该状态与目标任务的解仅相差几个梯度步骤。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-20b86a1e-8bb3-4cd5-84fe-dc5ce6aa54dc" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-8="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-9502ed98-a7c0-4266-9e63-e7694deb0578" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-3429406f-4cbf-4790-9f90-23a9d55a78e3" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-10="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="12" id="mark-f82f9d19-f7bd-46ab-abee-39a5f317622f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-11="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="13" id="mark-3da78524-8ee4-4fdf-9faa-49c71f087322" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-12="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="14" id="mark-9d8e3da1-2caf-48bf-8f8e-756848a28403" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-13="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"></div><div><div data-page="15" id="mark-4a98bb10-ed82-4e57-8e7a-7892a9437566" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate alive_postion_page_md" data-positiontag-14="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-912c0603-6019-4df5-ad65-928d7b38172f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-15="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-dbf56d44-e6a0-43ff-8143-64e8767e170e" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-16="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-0708dab8-26e7-494a-9109-850b54d2f256" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-17="0,0"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-17="0,0">[163] Y. Sun, X. Wang, Z. Liu, J. Miller, A. Efros, and M. Hardt, "Test-time training with self-supervision for generalization under distribution shifts," in ICML, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[163] 孙（Y. Sun）、王（X. Wang）、刘（Z. Liu）、J. 米勒（J. Miller）、A. 埃弗罗斯（A. Efros）和 M. 哈特（M. Hardt），《在分布偏移下通过自监督进行测试时训练以实现泛化》，发表于国际机器学习会议（ICML），2020 年。</div></paragraphpositioning></div></div></div><div><br></div><div><div><div>[164] S. Erfani, M. Baktashmotlagh, M. Moshtaghi, X. Nguyen, C. Leckie, J. Bailey, and R. Kotagiri, "Robust domain generali-<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[164] S. 埃尔法尼（S. Erfani）、M. 巴克塔什莫特拉格（M. Baktashmotlagh）、M. 莫什塔吉（M. Moshtaghi）、阮（X. Nguyen）、C. 莱基（C. Leckie）、J. 贝利（J. Bailey）和 R. 科塔吉里（R. Kotagiri），《通过强制分布不变性实现鲁棒领域泛化</div></div></div></div><div><br></div><div><div><div>sation by enforcing distribution invariance," in IJCAI, 2016.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">》，发表于国际人工智能联合会议（IJCAI），2016 年。</div></div></div></div><div><br></div><div><div><div>[165] M. Ghifary, D. Balduzzi, W. B. Kleijn, and M. Zhang, "Scatter component analysis: A unified framework for domain adaptation and domain generalization," TPAMI, 2017.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[165] M. 吉法里（M. Ghifary）、D. 巴尔杜齐（D. Balduzzi）、W. B. 克莱因（W. B. Kleijn）和张（M. Zhang），《散度分量分析：领域自适应和领域泛化的统一框架》，《模式分析与机器智能汇刊》（TPAMI），2017 年。</div></div></div></div><div><br></div><div><div><div>[166] Y. Li, M. Gong, X. Tian, T. Liu, and D. Tao, "Domain generalization via conditional invariant representations," in AAAI, 2018.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[166] 李（Y. Li）、龚（M. Gong）、田（X. Tian）、刘（T. Liu）和陶（D. Tao），《通过条件不变表示实现领域泛化》，发表于2018年的AAAI会议。</div></div></div></div><div><br></div><div><div><div>[167] X. Jin, C. Lan, W. Zeng, and Z. Chen, "Feature alignment and restoration for domain generalization and adaptation," arXiv preprint arXiv:2006.12009, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[167] 金（X. Jin）、兰（C. Lan）、曾（W. Zeng）和陈（Z. Chen），《用于领域泛化和适应的特征对齐与恢复》，预印本arXiv:2006.12009，2020年。</div></div></div></div><div><br></div><div><div><div>[168] S. Hu, K. Zhang, Z. Chen, and L. Chan, "Domain generalization via multidomain discriminant analysis," in UAI, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[168] 胡（S. Hu）、张（K. Zhang）、陈（Z. Chen）和陈（L. Chan），《通过多领域判别分析实现领域泛化》，发表于2020年的UAI会议。</div></div></div></div><div><br></div><div><div><div>[169] S. Motiian, M. Piccirilli, D. A. Adjeroh, and G. Doretto, "Unified deep supervised domain adaptation and generalization," in ICCV, 2017.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[169] 莫蒂安（S. Motiian）、皮西里利（M. Piccirilli）、阿杰罗（D. A. Adjeroh）和多雷托（G. Doretto），《统一的深度监督领域适应与泛化》，发表于2017年的ICCV会议。</div></div></div></div><div><br></div><div><div><div>[170] C. Yoon, G. Hamarneh, and R. Garbi, "Generalizable feature learning in the presence of data bias and domain class imbalance with application to skin lesion classification," in MICCAI, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[170] 尹（C. Yoon）、哈马内（G. Hamarneh）和加尔比（R. Garbi），《存在数据偏差和领域类别不平衡情况下的可泛化特征学习及其在皮肤病变分类中的应用》，发表于2019年的MICCAI会议。</div></div></div></div><div><br></div><div><div><div>[171] D. Mahajan, S. Tople, and A. Sharma, "Domain generalization using causal matching," arXiv preprint arXiv:2006.07500, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[171] 马哈詹（D. Mahajan）、托普尔（S. Tople）和夏尔马（A. Sharma），《使用因果匹配实现领域泛化》，预印本arXiv:2006.07500，2020年。</div></div></div></div><div><br></div><div><div><div>[172] Z. Wang, M. Loog, and J. van Gemert, "Respecting domain relations: Hypothesis invariance for domain generalization," arXiv preprint arXiv:2010.07591, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[172] 王（Z. Wang）、洛格（M. Loog）和范格默特（J. van Gemert），《尊重领域关系：领域泛化的假设不变性》，预印本arXiv:2010.07591，2020年。</div></div></div></div><div><br></div><div><div><div>[173] H. Li, Y. Wang, R. Wan, S. Wang, T.-Q. Li, and A. C. Kot, "Domain generalization for medical imaging classification with linear-dependency regularization," in NeurIPS, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[173] 李（H. Li）、王（Y. Wang）、万（R. Wan）、王（S. Wang）、李（T.-Q. Li）和科特（A. C. Kot），《通过线性依赖正则化实现医学图像分类的领域泛化》，发表于2020年的NeurIPS会议。</div></div></div></div><div><br></div><div><div><div>[174] M. M. Rahman, C. Fookes, M. Baktashmotlagh, and S. Sridharan, "Correlation-aware adversarial domain adaptation and generalization," PR, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[174] 拉赫曼（M. M. Rahman）、富克斯（C. Fookes）、巴克塔什莫特拉格（M. Baktashmotlagh）和斯里达尔南（S. Sridharan），《相关感知对抗领域适应与泛化》，发表于2020年的PR期刊。</div></div></div></div><div><br></div><div><div><div>[175] I. Albuquerque, J. Monteiro, M. Darvishi, T. H. Falk, and I. Mitliagkas, "Generalizing to unseen domains via distribution matching," arXiv preprint arXiv:1911.00804, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[175] 阿尔布克尔克（I. Albuquerque）、蒙泰罗（J. Monteiro）、达维希（M. Darvishi）、福尔克（T. H. Falk）和米特利亚加斯（I. Mitliagkas），《通过分布匹配泛化到未见领域》，预印本arXiv:1911.00804，2019年。</div></div></div></div><div><br></div><div><div><div>[176] Z. Deng, F. Ding, C. Dwork, R. Hong, G. Parmigiani, P. Patil, and P. Sur, "Representation via representations: Domain generalization via adversarially learned invariant representations," arXiv preprint arXiv:2006.11478, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[176] 邓（Z. Deng）、丁（F. Ding）、德沃克（C. Dwork）、洪（R. Hong）、帕尔米贾尼（G. Parmigiani）、帕蒂尔（P. Patil）和苏尔（P. Sur），《通过表示实现表示：通过对抗学习的不变表示实现领域泛化》，预印本arXiv:2006.11478，2020年。</div></div></div></div><div><br></div><div><div><div>[177] T. Matsuura and T. Harada, "Domain generalization using a mixture of multiple latent domains," in AAAI, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[177] 松浦（T. Matsuura）和原田（T. Harada），《使用多个潜在领域的混合实现领域泛化》，发表于2020年的AAAI会议。</div></div></div></div><div><br></div><div><div><div>[178] Y. Jia, J. Zhang, S. Shan, and X. Chen, "Single-side domain generalization for face anti-spoofing," in CVPR, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[178] 贾（Y. Jia）、张（J. Zhang）、单（S. Shan）和陈（X. Chen），《用于人脸反欺骗的单边领域泛化》，发表于2020年的CVPR会议。</div></div></div></div><div><br></div><div><div><div>[179] K. Akuzawa, Y. Iwasawa, and Y. Matsuo, "Adversarial invariant feature learning with accuracy constraint for domain generalization," in ECMLPKDD, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[179] 阿久泽（K. Akuzawa）、岩泽（Y. Iwasawa）和松尾（Y. Matsuo），《具有精度约束的对抗不变特征学习用于领域泛化》，发表于2019年的ECMLPKDD会议。</div></div></div></div><div><br></div><div><div><div>[180] S. Aslani, V. Murino, M. Dayan, R. Tam, D. Sona, and G. Hamarneh, "Scanner invariant multiple sclerosis lesion segmentation from mri," in ISBI, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[180] 阿斯兰尼（S. Aslani）、穆里诺（V. Murino）、戴扬（M. Dayan）、谭（R. Tam）、索纳（D. Sona）和哈马内（G. Hamarneh），《从MRI中进行扫描仪不变的多发性硬化病变分割》，发表于2020年的ISBI会议。</div></div></div></div><div><br></div><div><div><div>[181] S. Zhao, M. Gong, T. Liu, H. Fu, and D. Tao, "Domain generalization via entropy regularization," in NeurIPS, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[181] 赵（S. Zhao）、龚（M. Gong）、刘（T. Liu）、傅（H. Fu）和陶（D. Tao），《通过熵正则化实现领域泛化》，发表于2020年的NeurIPS会议。</div></div></div></div><div><br></div><div><div><div>[182] D. Li, Y. Yang, Y.-Z. Song, and T. Hospedales, "Sequential learning for domain generalization," in ECCV-W, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[182] 李（D. Li）、杨（Y. Yang）、宋（Y.-Z. Song）和霍斯佩代尔斯（T. Hospedales），《用于领域泛化的序列学习》，发表于2020年欧洲计算机视觉大会研讨会（ECCV-W）。</div></div></div></div><div><br></div><div><div><div>[183] Y. Du, J. Xu, H. Xiong, Q. Qiu, X. Zhen, C. G. Snoek, and L. Shao, "Learning to learn with variational information bottleneck for domain generalization," in ECCV, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[183] 杜（Y. Du）、徐（J. Xu）、熊（H. Xiong）、邱（Q. Qiu）、甄（X. Zhen）、斯诺克（C. G. Snoek）和邵（L. Shao），《利用变分信息瓶颈进行领域泛化的元学习》，发表于2020年欧洲计算机视觉大会（ECCV）。</div></div></div></div><div><br></div><div><div><div>[184] Y. Du, X. Zhen, L. Shao, and C. G. M. Snoek, "Metanorm: Learning to normalize few-shot batches across domains," in ICLR, 2021.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[184] 杜（Y. Du）、甄（X. Zhen）、邵（L. Shao）和斯诺克（C. G. M. Snoek），《元归一化：学习跨领域对少样本批次进行归一化》，发表于2021年国际学习表征会议（ICLR）。</div></div></div></div><div><br></div><div><div><div>[185] B. Wang, M. Lapata, and I. Titov, "Meta-learning for domain generalization in semantic parsing," arXiv preprint arXiv:2010.11988, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[185] 王（B. Wang）、拉帕塔（M. Lapata）和季托夫（I. Titov），《语义解析中用于领域泛化的元学习》，预印本arXiv:2010.11988，2020年。</div></div></div></div><div><br></div><div><div><div>[186] S. Otálora, M. Atzori, V. Andrearczyk, A. Khan, and H. Müller, "Staining invariant features for improving generalization of deep convolutional neural networks in computational pathology," Frontiers in bioengineering and biotechnology, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[186] 奥塔洛拉（S. Otálora）、阿佐里（M. Atzori）、安德烈亚尔齐克（V. Andrearczyk）、汗（A. Khan）和米勒（H. Müller），《用于提高计算病理学中深度卷积神经网络泛化能力的染色不变特征》，发表于《生物工程与生物技术前沿》（Frontiers in bioengineering and biotechnology），2019年。</div></div></div></div><div><br></div><div><div><div>[187] C. Chen, W. Bai, R. H. Davies, A. N. Bhuva, C. H. Manisty, J. B. Augusto, J. C. Moon, N. Aung, A. M. Lee, M. M. Sanghvi et al., "Improving the generalizability of convolutional neural network-based segmentation on cmr images," Frontiers in cardiovascular medicine, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[187] 陈（C. Chen）、白（W. Bai）、戴维斯（R. H. Davies）、布瓦（A. N. Bhuva）、马尼斯特（C. H. Manisty）、奥古斯托（J. B. Augusto）、穆恩（J. C. Moon）、昂（N. Aung）、李（A. M. Lee）、桑格维（M. M. Sanghvi）等，《提高基于卷积神经网络的心脏磁共振图像分割的泛化能力》，发表于《心血管医学前沿》（Frontiers in cardiovascular medicine），2020年。</div></div></div></div><div><br></div><div><div><div>[188] L. Zhang, X. Wang, D. Yang, T. Sanford, S. Harmon, B. Turkbey, B. J. Wood, H. Roth, A. Myronenko, D. Xu et al., "Generalizing deep learning for medical image segmentation to unseen domains via deep stacked transformation," TMI, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[188] 张（L. Zhang）、王（X. Wang）、杨（D. Yang）、桑福德（T. Sanford）、哈蒙（S. Harmon）、特克贝（B. Turkbey）、伍德（B. J. Wood）、罗斯（H. Roth）、米罗年科（A. Myronenko）、徐（D. Xu）等，《通过深度堆叠变换将医学图像分割的深度学习泛化到未见领域》，发表于《医学成像汇刊》（TMI），2020年。</div></div></div></div><div><br></div><div><div><div>[189] F. Qiao, L. Zhao, and X. Peng, "Learning to learn single domain generalization," in CVPR, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[189] 乔（F. Qiao）、赵（L. Zhao）和彭（X. Peng），《学习单领域泛化》，发表于2020年计算机视觉与模式识别会议（CVPR）。</div></div></div></div><div><br></div><div><div><div>[190] A. Sinha, H. Namkoong, R. Volpi, and J. Duchi, "Certifying some distributional robustness with principled adversarial training," arXiv preprint arXiv:1710.10571, 2017.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[190] 辛哈（A. Sinha）、南孔（H. Namkoong）、沃尔皮（R. Volpi）和杜奇（J. Duchi），《通过原则性对抗训练证明某些分布鲁棒性》，预印本arXiv:1710.10571，2017年。</div></div></div></div><div><br></div><div><div><div>[191] Z. Xu, D. Liu, J. Yang, C. Raffel, and M. Niethammer, "Robust and generalizable visual representation learning via random convolutions," in ICLR, 2021.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[191] 徐（Z. Xu）、刘（D. Liu）、杨（J. Yang）、拉菲尔（C. Raffel）和尼瑟默（M. Niethammer），《通过随机卷积进行鲁棒且可泛化的视觉表征学习》，发表于2021年国际学习表征会议（ICLR）。</div></div></div></div><div><br></div><div><div><div>[192] N. Somavarapu, C.-Y. Ma, and Z. Kira, "Frustratingly simple domain generalization via image stylization," arXiv preprint arXiv:2006.11207, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[192] 索马瓦拉普（N. Somavarapu）、马（C.-Y. Ma）和基拉（Z. Kira），《通过图像风格化实现令人沮丧的简单领域泛化》，预印本arXiv:2006.11207，2020年。</div></div></div></div><div><br></div><div><div><div>[193] F. C. Borlino, A. D'Innocente, and T. Tommasi, "Rethinking domain generalization baselines," arXiv preprint arXiv:2101.09060, 2021.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[193] 博利诺（F. C. Borlino）、迪诺森特（A. D'Innocente）和托马西（T. Tommasi），《重新思考领域泛化基线》，预印本arXiv:2101.09060，2021年。</div></div></div></div><div><br></div><div><div><div>[194] F. M. Carlucci, P. Russo, T. Tommasi, and B. Caputo, "Hallucinating agnostic images to generalize across domains." in ICCV-W, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[194] 卡尔卢奇（F. M. Carlucci）、鲁索（P. Russo）、托马西（T. Tommasi）和卡普托（B. Caputo），《生成不可知图像以实现跨领域泛化》，发表于2019年国际计算机视觉大会研讨会（ICCV-W）。</div></div></div></div><div><br></div><div><div><div>[195] Z. Xu, W. Li, L. Niu, and D. Xu, "Exploiting low-rank structure from latent domains for domain generalization," in ECCV,2014.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[195] 徐（Z. Xu）、李（W. Li）、牛（L. Niu）和徐（D. Xu），《从潜在领域中挖掘低秩结构以实现领域泛化》，发表于2014年欧洲计算机视觉大会（ECCV）。</div></div></div></div><div><br></div><div><div><div>[196] L. Niu, W. Li, and D. Xu, "Multi-view domain generalization for visual recognition," in ICCV, 2015.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[196] 牛（L. Niu）、李（W. Li）和徐（D. Xu），《用于视觉识别的多视图领域泛化》，发表于2015年国际计算机视觉大会（ICCV）。</div></div></div></div><div><br></div><div><div><div>[197] —, "Visual recognition by learning from web data: A weakly supervised domain generalization approach," in CVPR, 2015.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[197] —，《通过从网络数据中学习进行视觉识别：一种弱监督领域泛化方法》，发表于2015年计算机视觉与模式识别会议（CVPR）。</div></div></div></div><div><br></div><div><div><div>[198] Z. Ding and Y. Fu, "Deep domain generalization with structured low-rank constraint," TIP, 2017.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[198] 丁泽（Z. Ding）和傅宇（Y. Fu），“具有结构化低秩约束的深度领域泛化”，《IEEE 图像处理汇刊》（TIP），2017 年。</div></div></div></div><div><br></div><div><div><div>[199] A. D'Innocente and B. Caputo, "Domain generalization with domain-specific aggregation modules," in GCPR, 2018.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[199] A. D'Innocente 和 B. 卡普托（B. Caputo），“使用特定领域聚合模块的领域泛化”，发表于 2018 年德国模式识别会议（GCPR）。</div></div></div></div><div><br></div><div><div><div>[200] M. Mancini, S. R. Bulo, B. Caputo, and E. Ricci, "Best sources forward: domain generalization through source-specific nets," in ICIP, 2018.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[200] M. 曼奇尼（M. Mancini）、S. R. 布洛（S. R. Bulo）、B. 卡普托（B. Caputo）和 E. 里奇（E. Ricci），“最佳源向前：通过特定源网络实现领域泛化”，发表于 2018 年国际图像处理会议（ICIP）。</div></div></div></div><div><br></div><div><div><div>[201] S. Wang, L. Yu, K. Li, X. Yang, C.-W. Fu, and P.-A. Heng, "Dofe: Domain-oriented feature embedding for generalizable fundus image segmentation on unseen datasets," TMI, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[201] 王硕（S. Wang）、于磊（L. Yu）、李凯（K. Li）、杨晓（X. Yang）、傅传伟（C.-W. Fu）和彭安恒（P.-A. Heng），“DOFE：用于在未见数据集上进行可泛化眼底图像分割的面向领域特征嵌入”，《IEEE 医学成像汇刊》（TMI），2020 年。</div></div></div></div><div><br></div><div><div><div>[202] S. Seo, Y. Suh, D. Kim, J. Han, and B. Han, "Learning to optimize domain specific normalization for domain generalization," in ECCV, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[202] S. 徐（S. Seo）、Y. 徐（Y. Suh）、D. 金（D. Kim）、J. 韩（J. Han）和 B. 韩（B. Han），“学习优化特定领域归一化以实现领域泛化”，发表于 2020 年欧洲计算机视觉会议（ECCV）。</div></div></div></div><div><br></div><div><div><div>[203] M. Segù, A. Tonioni, and F. Tombari, "Batch normalization embeddings for deep domain generalization," arXiv preprint arXiv:2011.12672, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[203] M. 塞古（M. Segù）、A. 托尼奥尼（A. Tonioni）和 F. 通巴里（F. Tombari），“用于深度领域泛化的批量归一化嵌入”，预印本 arXiv:2011.12672，2020 年。</div></div></div></div><div><br></div><div><div><div>[204] M. Mancini, S. R. Bulo, B. Caputo, and E. Ricci, "Robust place categorization with deep domain generalization," RA-L, 2018.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[204] M. 曼奇尼（M. Mancini）、S. R. 布洛（S. R. Bulo）、B. 卡普托（B. Caputo）和 E. 里奇（E. Ricci），“基于深度领域泛化的鲁棒场所分类”，《IEEE 机器人与自动化快报》（RA - L），2018 年。</div></div></div></div><div><br></div><div><div><div>[205] J. Cha, H. Cho, K. Lee, S. Park, Y. Lee, and S. Park, "Domain generalization needs stochastic weight averaging for robustness on domain shifts," arXiv preprint arXiv:2102.08604, 2021.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[205] J. 查（J. Cha）、H. 赵（H. Cho）、K. 李（K. Lee）、S. 朴（S. Park）、Y. 李（Y. Lee）和 S. 朴（S. Park），“领域泛化需要随机权重平均以应对领域偏移的鲁棒性”，预印本 arXiv:2102.08604，2021 年。</div></div></div></div><div><br></div><div><div><div>[206] U. Maniyar, A. A. Deshmukh, U. Dogan, and V. N. Balasubrama-nian, "Zero shot domain generalization," in BMVC, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[206] U. 马尼耶尔（U. Maniyar）、A. A. 德什穆克（A. A. Deshmukh）、U. 多根（U. Dogan）和 V. N. 巴拉苏布拉马尼亚姆（V. N. Balasubrama - nian），“零样本领域泛化”，发表于 2020 年英国机器视觉会议（BMVC）。</div></div></div></div><div><br></div><div><div><div>[207] P. Chattopadhyay, Y. Balaji, and J. Hoffman, "Learning to balance specificity and invariance for in and out of domain generalization," in ECCV, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[207] P. 查托帕德亚（P. Chattopadhyay）、Y. 巴拉吉（Y. Balaji）和 J. 霍夫曼（J. Hoffman），“学习平衡特异性和不变性以实现领域内和领域外泛化”，发表于 2020 年欧洲计算机视觉会议（ECCV）。</div></div></div></div><div><br></div><div><div><div>[208] V. Piratla, P. Netrapalli, and S. Sarawagi, "Efficient domain generalization via common-specific low-rank decomposition," in ICML, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[208] V. 皮拉特（V. Piratla）、P. 内特拉帕利（P. Netrapalli）和 S. 萨拉瓦吉（S. Sarawagi），“通过通用 - 特定低秩分解实现高效领域泛化”，发表于 2020 年国际机器学习会议（ICML）。</div></div></div></div><div><br></div><div><div><div>[209] M. Ilse, J. M. Tomczak, C. Louizos, and M. Welling, "Diva: Domain invariant variational autoencoder," in ICLR-W, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[209] M. 伊尔塞（M. Ilse）、J. M. 托姆恰克（J. M. Tomczak）、C. 路易佐斯（C. Louizos）和 M. 韦林（M. Welling），“DIVA：领域不变变分自编码器”，发表于 2019 年国际学习表征会议研讨会（ICLR - W）。</div></div></div></div><div><br></div><div><div><div>[210] G. Wang, H. Han, S. Shan, and X. Chen, "Cross-domain face presentation attack detection via multi-domain disentangled representation learning," in CVPR, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[210] 王戈（G. Wang）、韩浩（H. Han）、单珊（S. Shan）和陈曦（X. Chen），“通过多领域解纠缠表示学习进行跨领域人脸呈现攻击检测”，发表于 2020 年计算机视觉与模式识别会议（CVPR）。</div></div></div></div><div><br></div><div><div><div>[211] M. Laskin, K. Lee, A. Stooke, L. Pinto, P. Abbeel, and A. Srinivas, "Reinforcement learning with augmented data," NeurIPS, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[211] M. 拉斯金（M. Laskin）、K. 李（K. Lee）、A. 斯托克（A. Stooke）、L. 平托（L. Pinto）、P. 阿贝贝尔（P. Abbeel）和 A. 斯里尼瓦斯（A. Srinivas），“使用增强数据的强化学习”，神经信息处理系统大会（NeurIPS），2020 年。</div></div></div></div><div><br></div><div><div><div>[212] I. Kostrikov, D. Yarats, and R. Fergus, "Image augmentation is all you need: Regularizing deep reinforcement learning from pixels," arXiv preprint arXiv:2004.13649, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[212] I. 科斯德里科夫（I. Kostrikov）、D. 亚拉茨（D. Yarats）和 R. 弗格斯（R. Fergus），“图像增强就是你所需要的：从像素正则化深度强化学习”，预印本 arXiv:2004.13649，2020 年。</div></div></div></div><div><br></div><div><div><div>[213] J. Tobin, R. Fong, A. Ray, J. Schneider, W. Zaremba, and P. Abbeel, "Domain randomization for transferring deep neural networks from simulation to the real world," in IROS, 2017.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[213] J. 托宾（J. Tobin）、R. 方（R. Fong）、A. 雷（A. Ray）、J. 施耐德（J. Schneider）、W. 扎雷巴（W. Zaremba）和 P. 阿贝贝尔（P. Abbeel），“用于将深度神经网络从模拟转移到现实世界的领域随机化”，发表于 2017 年智能机器人与系统国际会议（IROS）。</div></div></div></div><div><br></div><div><div><div>[214] K. Lee, K. Lee, J. Shin, and H. Lee, "Network randomization: A simple technique for generalization in deep reinforcement learning," arXiv preprint arXiv:1910.05396, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[214] 李（K. Lee）、李（K. Lee）、申（J. Shin）和李（H. Lee），《网络随机化：深度强化学习中一种简单的泛化技术》，预印本 arXiv:1910.05396，2019年。</div></div></div></div><div><br></div><div><div><div>[215] D. Yarats, A. Zhang, I. Kostrikov, B. Amos, J. Pineau, and R. Fergus, "Improving sample efficiency in model-free reinforcement learning from images," in AAAI, 2021.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[215] 亚拉茨（D. Yarats）、张（A. Zhang）、科斯德里科夫（I. Kostrikov）、阿莫斯（B. Amos）、皮诺（J. Pineau）和弗格斯（R. Fergus），《提高基于图像的无模型强化学习的样本效率》，发表于AAAI会议，2021年。</div></div></div></div><div><br></div><div><div><div>[216] M. Laskin, A. Srinivas, and P. Abbeel, "Curl: Contrastive unsupervised representations for reinforcement learning," in ICML, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[216] 拉斯金（M. Laskin）、斯里尼瓦斯（A. Srinivas）和阿比尔（P. Abbeel），《Curl：用于强化学习的对比无监督表示》，发表于ICML会议，2020年。</div></div></div></div><div><br></div><div><div><div>[217] C. Villani, Optimal transport: old and new. Springer Science &amp; Business Media, 2008.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[217] 维拉尼（C. Villani），《最优传输：旧与新》，施普林格科学与商业媒体出版社，2008年。</div></div></div></div><div><br></div><div><div><div>[218] B. Schölkopf, D. Janzing, J. Peters, E. Sgouritsa, K. Zhang, and J. Mooij, "On causal and anticausal learning," in ICML, 2012.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[218] 肖尔科普夫（B. Schölkopf）、扬津（D. Janzing）、彼得斯（J. Peters）、斯古里察（E. Sgouritsa）、张（K. Zhang）和莫伊（J. Mooij），《关于因果和反因果学习》，发表于ICML会议，2012年。</div></div></div></div><div><br></div><div><div><div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-a8cb9d16-b09e-4c0a-b160-acc7887a8a54" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-18="0,0"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-18="0,0">[219] A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Schölkopf, and A. Smola, "A kernel two-sample test," JMLR, 2012.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[219] 格雷顿（A. Gretton）、博格瓦尔特（K. M. Borgwardt）、拉施（M. J. Rasch）、肖尔科普夫（B. Schölkopf）和斯莫拉（A. Smola），《核双样本检验》，《机器学习研究杂志》（JMLR），2012年。</div></paragraphpositioning></div></div></div><div><br></div><div><div><div>[220] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, "Generative adversarial nets," in NeurIPS, 2014.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[220] 古德费洛（I. Goodfellow）、普热-阿巴迪（J. Pouget - Abadie）、米尔扎（M. Mirza）、徐（B. Xu）、沃德 - 法利（D. Warde - Farley）、奥扎尔（S. Ozair）、库尔维尔（A. Courville）和本吉奥（Y. Bengio），《生成对抗网络》，发表于NeurIPS会议，2014年。</div></div></div></div><div><br></div><div><div><div>[221] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell, "Adversarial discriminative domain adaptation," in CVPR, 2017.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[221] 曾（E. Tzeng）、霍夫曼（J. Hoffman）、塞内科（K. Saenko）和达雷尔（T. Darrell），《对抗性判别域适应》，发表于CVPR会议，2017年。</div></div></div></div><div><br></div><div><div><div>[222] W. Zhang, W. Ouyang, W. Li, and D. Xu, "Collaborative and adversarial network for unsupervised domain adaptation," in CVPR, 2018.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[222] 张（W. Zhang）、欧阳（W. Ouyang）、李（W. Li）和徐（D. Xu），《用于无监督域适应的协作与对抗网络》，发表于CVPR会议，2018年。</div></div></div></div><div><br></div><div><div><div>[223] M. Long, Z. Cao, J. Wang, and M. I. Jordan, "Conditional adversarial domain adaptation," in NeurIPS, 2018.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[223] 龙（M. Long）、曹（Z. Cao）、王（J. Wang）和乔丹（M. I. Jordan），《条件对抗域适应》，发表于NeurIPS会议，2018年。</div></div></div></div><div><br></div><div><div><div>[224] C.-Y. Lee, T. Batra, M. H. Baig, and D. Ulbricht, "Sliced wasser-stein discrepancy for unsupervised domain adaptation," in CVPR, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[224] 李（C. - Y. Lee）、巴特拉（T. Batra）、拜格（M. H. Baig）和乌尔布里希特（D. Ulbricht），《用于无监督域适应的切片瓦瑟斯坦差异》，发表于CVPR会议，2019年。</div></div></div></div><div><br></div><div><div><div>[225] Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. Marchand, and V. Lempitsky, "Domain-adversarial training of neural networks," JMLR, 2016.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[225] 加宁（Y. Ganin）、乌斯蒂诺娃（E. Ustinova）、阿贾坎（H. Ajakan）、热尔曼（P. Germain）、拉罗谢尔（H. Larochelle）、拉维奥莱特（F. Laviolette）、马尔尚（M. Marchand）和伦皮茨基（V. Lempitsky），《神经网络的域对抗训练》，《机器学习研究杂志》（JMLR），2016年。</div></div></div></div><div><br></div><div><div><div>[226] C. Finn, P. Abbeel, and S. Levine, "Model-agnostic meta-learning for fast adaptation of deep networks," in ICML, 2017.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[226] 芬恩（C. Finn）、阿比尔（P. Abbeel）和莱文（S. Levine），《用于深度网络快速适应的模型无关元学习》，发表于ICML会议，2017年。</div></div></div></div><div><br></div><div><div><div>[227] T. Hospedales, A. Antoniou, P. Micaelli, and A. Storkey, "Meta-learning in neural networks: A survey," arXiv preprint arXiv:2004.05439, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[227] 霍斯佩代尔斯（T. Hospedales）、安东尼奥（A. Antoniou）、米卡埃利（P. Micaelli）和斯托基（A. Storkey），《神经网络中的元学习：综述》，预印本 arXiv:2004.05439，2020年。</div></div></div></div><div><br></div><div><div><div>[228] J.-M. Perez-Rua, X. Zhu, T. M. Hospedales, and T. Xiang, "Incremental few-shot object detection," in CVPR, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[228] 佩雷斯 - 鲁阿（J. - M. Perez - Rua）、朱（X. Zhu）、霍斯佩代尔斯（T. M. Hospedales）和向（T. Xiang），《增量式少样本目标检测》，发表于CVPR会议，2020年。</div></div></div></div><div><br></div><div><div><div>[229] J. Gordon, J. Bronskill, M. Bauer, S. Nowozin, and R. E. Turner, "Meta-learning probabilistic inference for prediction," in ICLR, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[229] 戈登（J. Gordon）、布龙斯基尔（J. Bronskill）、鲍尔（M. Bauer）、诺沃津（S. Nowozin）和特纳（R. E. Turner），《用于预测的元学习概率推理》，发表于ICLR会议，2019年。</div></div></div></div><div><br></div><div><div><div>[230] I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning. MIT Press, 2016.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[230] I. 古德费洛（I. Goodfellow）、Y. 本吉奥（Y. Bengio）和 A. 库尔维尔（A. Courville），《深度学习》（Deep Learning）。麻省理工学院出版社（MIT Press），2016 年。</div></div></div></div><div><br></div><div><div><div>[231] I. J. Goodfellow, J. Shlens, and C. Szegedy, "Explaining and harnessing adversarial examples," in ICLR, 2015.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[231] I. J. 古德费洛（I. J. Goodfellow）、J. 什伦斯（J. Shlens）和 C. 塞格迪（C. Szegedy），“解释和利用对抗样本”（"Explaining and harnessing adversarial examples"），发表于 2015 年国际学习表征会议（ICLR）。</div></div></div></div><div><br></div><div><div><div>[232] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. J. Goodfellow, and R. Fergus, "Intriguing properties of neural networks," in ICLR, 2014.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[232] C. 塞格迪（C. Szegedy）、W. 扎雷巴（W. Zaremba）、I. 苏茨克维（I. Sutskever）、J. 布鲁纳（J. Bruna）、D. 埃尔汉（D. Erhan）、I. J. 古德费洛（I. J. Goodfellow）和 R. 费格斯（R. Fergus），“神经网络的有趣特性”（"Intriguing properties of neural networks"），发表于 2014 年国际学习表征会议（ICLR）。</div></div></div></div><div><br></div><div><div><div>[233] X. Huang and S. Belongie, "Arbitrary style transfer in real-time with adaptive instance normalization," in ICCV, 2017.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[233] X. 黄（X. Huang）和 S. 贝隆吉（S. Belongie），“基于自适应实例归一化的实时任意风格迁移”（"Arbitrary style transfer in real - time with adaptive instance normalization"），发表于 2017 年国际计算机视觉大会（ICCV）。</div></div></div></div><div><br></div><div><div><div>[234] H. Zhang, M. Cisse, Y. N. Dauphin, and D. Lopez-Paz, "mixup: Beyond empirical risk minimization," in ICLR, 2018.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[234] H. 张（H. Zhang）、M. 西塞（M. Cisse）、Y. N. 多芬（Y. N. Dauphin）和 D. 洛佩斯 - 帕斯（D. Lopez - Paz），“mixup：超越经验风险最小化”（"mixup: Beyond empirical risk minimization"），发表于 2018 年国际学习表征会议（ICLR）。</div></div></div></div><div><br></div><div><div><div>[235] Z.-H. Zhou, Ensemble methods: foundations and algorithms. Chapman and Hall/CRC, 2012.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[235] 周志华（Z.-H. Zhou），《集成学习方法：基础与算法》（Ensemble methods: foundations and algorithms）。查普曼与霍尔出版社/CRC 出版社（Chapman and Hall/CRC），2012 年。</div></div></div></div><div><br></div><div><div><div>[236] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich, "Going deeper with convolutions," in CVPR, 2015.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[236] C. 塞格迪（C. Szegedy）、W. 刘（W. Liu）、Y. 贾（Y. Jia）、P. 塞尔马内特（P. Sermanet）、S. 里德（S. Reed）、D. 安古洛夫（D. Anguelov）、D. 埃尔汉（D. Erhan）、V. 范霍克（V. Vanhoucke）和 A. 拉宾诺维奇（A. Rabinovich），“卷积神经网络的深度探索”（"Going deeper with convolutions"），发表于 2015 年计算机视觉与模式识别会议（CVPR）。</div></div></div></div><div><br></div><div><div><div>[237] T. Malisiewicz, A. Gupta, and A. A. Efros, "Ensemble of exemplar-svms for object detection and beyond," in ICCV,2011.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[237] T. 马利塞维奇（T. Malisiewicz）、A. 古普塔（A. Gupta）和 A. A. 埃弗罗斯（A. A. Efros），“用于目标检测及其他任务的样本支持向量机集成”（"Ensemble of exemplar - svms for object detection and beyond"），发表于 2011 年国际计算机视觉大会（ICCV）。</div></div></div></div><div><br></div><div><div><div>[238] S. Ioffe and C. Szegedy, "Batch normalization: Accelerating deep network training by reducing internal covariate shift," in ICML, 2015.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[238] S. 伊夫（S. Ioffe）和 C. 塞格迪（C. Szegedy），“批量归一化：通过减少内部协变量偏移加速深度网络训练”（"Batch normalization: Accelerating deep network training by reducing internal covariate shift"），发表于 2015 年国际机器学习会议（ICML）。</div></div></div></div><div><br></div><div><div><div>[239] P. Izmailov, D. Podoprikhin, T. Garipov, D. Vetrov, and A. G. Wilson, "Averaging weights leads to wider optima and better generalization," in UAI, 2018.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[239] P. 伊兹马伊洛夫（P. Izmailov）、D. 波多普里欣（D. Podoprikhin）、T. 加里波夫（T. Garipov）、D. 维特罗夫（D. Vetrov）和 A. G. 威尔逊（A. G. Wilson），“权重平均导致更宽的最优解和更好的泛化能力”（"Averaging weights leads to wider optima and better generalization"），发表于 2018 年人工智能不确定性会议（UAI）。</div></div></div></div><div><br></div><div><div><div>[240] M. Noroozi and P. Favaro, "Unsupervised learning of visual representations by solving jigsaw puzzles," in ECCV,2016.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[240] M. 诺鲁齐（M. Noroozi）和 P. 法瓦罗（P. Favaro），“通过解决拼图游戏进行视觉表征的无监督学习”（"Unsupervised learning of visual representations by solving jigsaw puzzles"），发表于 2016 年欧洲计算机视觉大会（ECCV）。</div></div></div></div><div><br></div><div><div><div>[241] S. Gidaris, P. Singh, and N. Komodakis, "Unsupervised representation learning by predicting image rotations," in ICLR, 2018.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[241] S. 吉达里斯（S. Gidaris）、P. 辛格（P. Singh）和 N. 科莫达基斯（N. Komodakis），“通过预测图像旋转进行无监督表征学习”（"Unsupervised representation learning by predicting image rotations"），发表于 2018 年国际学习表征会议（ICLR）。</div></div></div></div><div><br></div><div><div><div>[242] L. Jing and Y. Tian, "Self-supervised visual feature learning with deep neural networks: A survey," TPAMI, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[242] 荆琳（L. Jing）和田永红（Y. Tian），“基于深度神经网络的自监督视觉特征学习综述”（"Self - supervised visual feature learning with deep neural networks: A survey"），发表于《模式分析与机器智能汇刊》（TPAMI），2020 年。</div></div></div></div><div><br></div><div><div><div>[243] M. Caron, P. Bojanowski, A. Joulin, and M. Douze, "Deep clustering for unsupervised learning of visual features," in ECCV, 2018.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[243] M. 卡龙（M. Caron）、P. 博亚诺夫斯基（P. Bojanowski）、A. 茹林（A. Joulin）和 M. 杜泽（M. Douze），“用于视觉特征无监督学习的深度聚类”（"Deep clustering for unsupervised learning of visual features"），发表于 2018 年欧洲计算机视觉大会（ECCV）。</div></div></div></div><div><br></div><div><div><div>[244] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick, "Momentum contrast for unsupervised visual representation learning," in CVPR, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[244] 何恺明（K. He）、范浩强（H. Fan）、吴育昕（Y. Wu）、谢赛宁（S. Xie）和 Ross Girshick（R. Girshick），“用于无监督视觉表征学习的动量对比”（"Momentum contrast for unsupervised visual representation learning"），发表于 2020 年计算机视觉与模式识别会议（CVPR）。</div></div></div></div><div><br></div><div><div><div>[245] J.-B. Grill, F. Strub, F. Altché, C. Tallec, P. H. Richemond, E. Buchatskaya, C. Doersch, B. A. Pires, Z. D. Guo, M. G. Azar et al., "Bootstrap your own latent: A new approach to self-supervised learning," in NeurIPS, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[245] J.-B. 格里尔（J.-B. Grill）、F. 斯特鲁布（F. Strub）、F. 阿尔切（F. Altché）、C. 塔莱克（C. Tallec）、P. H. 里什蒙（P. H. Richemond）、E. 布查茨卡娅（E. Buchatskaya）、C. 多尔施（C. Doersch）、B. A. 皮雷斯（B. A. Pires）、Z. D. 郭（Z. D. Guo）、M. G. 阿扎尔（M. G. Azar）等人，“自举自身潜在表征：一种自监督学习的新方法”（"Bootstrap your own latent: A new approach to self - supervised learning"），发表于 2020 年神经信息处理系统大会（NeurIPS）。</div></div></div></div><div><br></div><div><div><div>[246] X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever, and P. Abbeel, "Infogan: Interpretable representation learning by information maximizing generative adversarial nets," in NeurIPS, 2016.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[246] 陈X（X. Chen）、段Y（Y. Duan）、胡特霍夫特R（R. Houthooft）、舒尔曼J（J. Schulman）、苏茨克维I（I. Sutskever）和阿比尔P（P. Abbeel），《信息生成对抗网络（InfoGAN）：通过信息最大化生成对抗网络进行可解释的表征学习》，发表于神经信息处理系统大会（NeurIPS），2016年。</div></div></div></div><div><br></div><div><div><div>[247] T. DeVries and G. W. Taylor, "Improved regularization of convolutional neural networks with cutout," arXiv preprint arXiv:1708.04552, 2017.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[247] 德弗里斯T（T. DeVries）和泰勒G. W（G. W. Taylor），《使用Cutout改进卷积神经网络的正则化》，预印本arXiv:1708.04552，2017年。</div></div></div></div><div><br></div><div><div><div>[248] I. Redko, E. Morvant, A. Habrard, M. Sebban, and Y. Bennani, "A survey on domain adaptation theory: learning bounds and theoretical guarantees," arXiv preprint arXiv:2004.11829, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[248] 雷德科I（I. Redko）、莫尔万特E（E. Morvant）、哈布拉德A（A. Habrard）、塞班M（M. Sebban）和贝纳尼Y（Y. Bennani），《领域自适应理论综述：学习边界和理论保证》，预印本arXiv:2004.11829，2020年。</div></div></div></div><div><br></div><div><div><div>[249] A. A. Deshmukh, Y. Lei, S. Sharma, U. Dogan, J. W. Cutler, and C. Scott, "A generalization error bound for multi-class domain generalization," arXiv preprint arXiv:1905.10392, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[249] 德什穆克A. A（A. A. Deshmukh）、雷Y（Y. Lei）、夏尔马S（S. Sharma）、多根U（U. Dogan）、卡特勒J. W（J. W. Cutler）和斯科特C（C. Scott），《多类领域泛化的泛化误差界》，预印本arXiv:1905.10392，2019年。</div></div></div></div><div><br></div><div><div><div>[250] E. Rosenfeld, P. Ravikumar, and A. Risteski, "An online learning approach to interpolation and extrapolation in domain generalization," in AISTATS, 2022.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[250] 罗森菲尔德E（E. Rosenfeld）、拉维库马尔P（P. Ravikumar）和里斯泰斯基A（A. Risteski），《领域泛化中插值和外推的在线学习方法》，发表于人工智能与统计会议（AISTATS），2022年。</div></div></div></div><div><br></div><div><div><div>[251] R. Vedantam, D. Lopez-Paz, and D. J. Schwab, "An empirical investigation of domain generalization with empirical risk minimizers," NeurIPS, 2021.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[251] 维丹塔姆R（R. Vedantam）、洛佩斯 - 帕斯D（D. Lopez - Paz）和施瓦布D. J（D. J. Schwab），《基于经验风险最小化器的领域泛化的实证研究》，神经信息处理系统大会（NeurIPS），2021年。</div></div></div></div><div><br></div><div><div><div>[252] H. Ye, C. Xie, T. Cai, R. Li, Z. Li, and L. Wang, "Towards a theoretical framework of out-of-distribution generalization," NeurIPS, 2021.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[252] 叶H（H. Ye）、谢C（C. Xie）、蔡T（T. Cai）、李R（R. Li）、李Z（Z. Li）和王L（L. Wang），《迈向分布外泛化的理论框架》，神经信息处理系统大会（NeurIPS），2021年。</div></div></div></div><div><br></div><div><div><div>[253] D. Li, H. Gouk, and T. Hospedales, "Finding lost dg: Explaining domain generalization via model complexity," arXiv preprint arXiv:2202.00563, 2022.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[253] 李D（D. Li）、古克H（H. Gouk）和霍斯佩代尔斯T（T. Hospedales），《寻找失落的领域泛化（DG）：通过模型复杂度解释领域泛化》，预印本arXiv:2202.00563，2022年。</div></div></div></div><div><br></div><div><div><div>[254] Y. Han, G. Huang, S. Song, L. Yang, H. Wang, and Y. Wang, "Dynamic neural networks: A survey," arXiv preprint arXiv:2102.04906, 2021.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[254] 韩Y（Y. Han）、黄G（G. Huang）、宋S（S. Song）、杨L（L. Yang）、王H（H. Wang）和王Y（Y. Wang），《动态神经网络综述》，预印本arXiv:2102.04906，2021年。</div></div></div></div><div><br></div><div><div><div>[255] X. Jia, B. De Brabandere, T. Tuytelaars, and L. Van Gool, "Dynamic filter networks," in NeurIPS, 2016.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[255] 贾X（X. Jia）、德布拉班德雷B（B. De Brabandere）、蒂特拉尔斯T（T. Tuytelaars）和范古尔L（L. Van Gool），《动态滤波器网络》，发表于神经信息处理系统大会（NeurIPS），2016年。</div></div></div></div><div><br></div><div><div><div>[256] B. Yang, G. Bender, Q. V. Le, and J. Ngiam, "Condconv: Conditionally parameterized convolutions for efficient inference," in NeurIPS, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[256] 杨B（B. Yang）、本德G（G. Bender）、勒Q. V（Q. V. Le）和尼亚姆J（J. Ngiam），《条件卷积（CondConv）：用于高效推理的条件参数化卷积》，发表于神经信息处理系统大会（NeurIPS），2019年。</div></div></div></div><div><br></div><div><div><div>[257] D. Ulyanov, A. Vedaldi, and V. Lempitsky, "Instance normalization: The missing ingredient for fast stylization," arXiv:1607.08022, 2016.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[257] 乌利亚诺夫D（D. Ulyanov）、韦尔迪耶A（A. Vedaldi）和伦皮茨基V（V. Lempitsky），《实例归一化：快速风格化缺失的要素》，预印本arXiv:1607.08022，2016年。</div></div></div></div><div><br></div><div><div><div>[258] J. L. Ba, J. R. Kiros, and G. E. Hinton, "Layer normalization," arXiv preprint arXiv:1607.06450, 2016.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[258] 巴J. L（J. L. Ba）、基罗斯J. R（J. R. Kiros）和辛顿G. E（G. E. Hinton），《层归一化》，预印本arXiv:1607.06450，2016年。</div></div></div></div><div><br></div><div><div><div>[259] P. Luo, J. Ren, Z. Peng, R. Zhang, and J. Li, "Differentiable learning-to-normalize via switchable normalization," in ICLR, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[259] 罗P（P. Luo）、任J（J. Ren）、彭Z（Z. Peng）、张R（R. Zhang）和李J（J. Li），《通过可切换归一化进行可微的归一化学习》，发表于国际学习表征会议（ICLR），2019年。</div></div></div></div><div><br></div><div><div><div>[260] T. Park, M.-Y. Liu, T.-C. Wang, and J.-Y. Zhu, "Semantic image synthesis with spatially-adaptive normalization," in CVPR, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[260] 朴T（T. Park）、刘M - Y（M. - Y. Liu）、王T - C（T. - C. Wang）和朱J - Y（J. - Y. Zhu），《基于空间自适应归一化的语义图像合成》，发表于计算机视觉与模式识别会议（CVPR），2019年。</div></div></div></div><div><br></div><div><div><div>[261] L. Deecke, T. Hospedales, and H. Bilen, "Latent domain learning with dynamic residual adapters," arXiv preprint arXiv:2006.00996, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[261] 德克L（L. Deecke）、霍斯佩代尔斯T（T. Hospedales）和比伦H（H. Bilen），《使用动态残差适配器的潜在领域学习》，预印本arXiv:2006.00996，2020年。</div></div></div></div><div><br></div><div><div><div>[262] K. Xu, M. Zhang, J. Li, S. S. Du, K.-I. Kawarabayashi, and S. Jegelka, "How neural networks extrapolate: From feedforward to graph neural networks," in ICLR, 2021.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[262] 徐（Xu）、张（Zhang）、李（Li）、杜（Du）、河原林（Kawarabayashi）和杰格尔卡（Jegelka），“神经网络如何外推：从前馈网络到图神经网络”，发表于《国际学习表征会议》（ICLR），2021年。</div></div></div></div><div><br></div><div><div><div>[263] R. Geirhos, J.-H. Jacobsen, C. Michaelis, R. Zemel, W. Brendel, M. Bethge, and F. A. Wichmann, "Shortcut learning in deep neural networks," Nature Machine Intelligence, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[263] 盖尔霍斯（Geirhos）、雅各布森（Jacobsen）、米夏埃利斯（Michaelis）、泽梅尔（Zemel）、布伦德尔（Brendel）、贝格（Bethge）和维希曼（Wichmann），“深度神经网络中的捷径学习”，发表于《自然机器智能》（Nature Machine Intelligence），2020年。</div></div></div></div><div><br></div><div><div><div>[264] B. Kim, H. Kim, K. Kim, S. Kim, and J. Kim, "Learning not to learn: Training deep neural networks with biased data," in CVPR, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[264] 金（Kim）、金（Kim）、金（Kim）、金（Kim）和金（Kim），“学习不学习：用有偏差的数据训练深度神经网络”，发表于《计算机视觉与模式识别会议》（CVPR），2019年。</div></div></div></div><div><br></div><div><div><div>[265] Y. Bengio, T. Deleu, N. Rahaman, R. Ke, S. Lachapelle, O. Bi-laniuk, A. Goyal, and C. Pal, "A meta-transfer objective for learning to disentangle causal mechanisms," arXiv preprint arXiv:1901.10912, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[265] 本吉奥（Bengio）、德勒（Deleu）、拉哈曼（Rahaman）、柯（Ke）、拉夏佩勒（Lachapelle）、比拉纽克（Bilaniuk）、戈亚尔（Goyal）和帕尔（Pal），“用于学习解开因果机制的元转移目标”，预印本发表于arXiv:1901.10912，2019年。</div></div></div></div><div><br></div><div><div><div>[266] B. Scholkopf, F. Locatello, S. Bauer, N. R. Ke, N. Kalchbrenner, A. Goyal, and Y. Bengio, "Towards causal representation learning," arXiv preprint arXiv:2102.11107, 2021.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[266] 肖尔科普夫（Scholkopf）、洛卡特洛（Locatello）、鲍尔（Bauer）、柯（Ke）、卡尔克布伦纳（Kalchbrenner）、戈亚尔（Goyal）和本吉奥（Bengio），“迈向因果表征学习”，预印本发表于arXiv:2102.11107，2021年。</div></div></div></div><div><br></div><div><div><div>[267] J. Hoffman, S. Gupta, and T. Darrell, "Learning with side information through modality hallucination," in CVPR, 2016.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[267] 霍夫曼（Hoffman）、古普塔（Gupta）和达雷尔（Darrell），“通过模态幻觉利用侧面信息进行学习”，发表于《计算机视觉与模式识别会议》（CVPR），2016年。</div></div></div></div><div><br></div><div><div><div>[268] K. Zhou, A. Paiement, and M. Mirmehdi, "Detecting humans in rgb-d data with cnns," in MVA, 2017.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[268] 周（Zhou）、帕耶芒（Paiement）和米尔梅赫迪（Mirmehdi），“用卷积神经网络（CNN）在RGB - D数据中检测人体”，发表于《机器视觉应用会议》（MVA），2017年。</div></div></div></div><div><br></div><div><div><div>[269] A. Zunino, S. A. Bargal, R. Volpi, M. Sameki, J. Zhang, S. Sclaroff, V. Murino, and K. Saenko, "Explainable deep classification models for domain generalization," arXiv preprint arXiv:2003.06498, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[269] 祖尼诺（Zunino）、巴尔加尔（Bargal）、沃尔皮（Volpi）、萨梅基（Sameki）、张（Zhang）、斯克拉罗夫（Sclaroff）、穆里诺（Murino）和塞内科（Saenko），“用于领域泛化的可解释深度分类模型”，预印本发表于arXiv:2003.06498，2020年。</div></div></div></div><div><br></div><div><div><div>[270] M. D. Zeiler and R. Fergus, "Visualizing and understanding convolutional networks," in ECCV, 2014.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[270] 齐勒（Zeiler）和弗格斯（Fergus），“可视化和理解卷积网络”，发表于《欧洲计算机视觉会议》（ECCV），2014年。</div></div></div></div><div><br></div><div><div><div>[271] Z. Li and D. Hoiem, "Learning without forgetting," TPAMI, 2017.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[271] 李（Li）和霍耶姆（Hoiem），“学习而不忘却”，发表于《模式分析与机器智能汇刊》（TPAMI），2017年。</div></div></div></div><div><br></div><div><div><div>[272] H. Sharifi-Noghabi, H. Asghari, N. Mehrasa, and M. Ester, "Domain generalization via semi-supervised meta learning," arXiv preprint arXiv:2009.12658, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[272] 沙里菲 - 诺加比（Sharifi - Noghabi）、阿斯加里（Asghari）、梅拉萨（Mehrasa）和埃斯特（Ester），“通过半监督元学习实现领域泛化”，预印本发表于arXiv:2009.12658，2020年。</div></div></div></div><div><br></div><div><div><div>[273] X. Liu, S. Thermos, A. O'Neil, and S. A. Tsaftaris, "Semi-supervised meta-learning with disentanglement for domain-generalised medical image segmentation," in MICCAI, 2021.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[273] 刘（Liu）、塞尔莫斯（Thermos）、奥尼尔（O'Neil）和察夫塔里斯（Tsaftaris），“用于领域泛化医学图像分割的带解缠的半监督元学习”，发表于《医学图像计算与计算机辅助干预会议》（MICCAI），2021年。</div></div></div></div><div><br></div><div><div><div>[274] X. Liu, S. Thermos, P. Sanchez, A. Q. O'Neil, and S. A. Tsaftaris, "vmfnet: Compositionality meets domain-generalised segmentation," in MICCAI, 2022.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[274] 刘（Liu）、塞尔莫斯（Thermos）、桑切斯（Sanchez）、奥尼尔（O'Neil）和察夫塔里斯（Tsaftaris），“vmfnet：组合性与领域泛化分割的结合”，发表于《医学图像计算与计算机辅助干预会议》（MICCAI），2022年。</div></div></div></div><div><br></div><div><div><div>[275] C. Geng, S.-j. Huang, and S. Chen, "Recent advances in open set recognition: A survey," TPAMI, 2020.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[275] 耿（Geng）、黄（Huang）和陈（Chen），“开放集识别的最新进展：综述”，发表于《模式分析与机器智能汇刊》（TPAMI），2020年。</div></div></div></div><div><br></div><div><div><div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="20" id="mark-5a9fbbe1-7652-461f-b138-84abdbc2776c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-19="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-19="0,0">[276] Y. Wu, Y. Chen, L. Wang, Y. Ye, Z. Liu, Y. Guo, and Y. Fu, "Large scale incremental learning," in CVPR, 2019.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[276] 吴（Wu）、陈（Chen）、王（Wang）、叶（Ye）、刘（Liu）、郭（Guo）和傅（Fu），“大规模增量学习”，发表于《计算机视觉与模式识别会议》（CVPR），2019年。</div></paragraphpositioning></div></div></div><div><br></div><div><div><div>[277] W. Li, R. Zhao, T. Xiao, and X. Wang, "Deepreid: Deep filter pairing neural network for person re-identification," in CVPR, 2014.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">[277] 李（Li）、赵（Zhao）、肖（Xiao）和王（Wang），“Deepreid：用于行人重识别的深度滤波器配对神经网络”，发表于《计算机视觉与模式识别会议》（CVPR），2014年。</div></div></div></div><div><br><!-- Media --><br></div><div style="position: relative; display: block;"><img draggable="false" src="https://cdn.noedgeai.com/0195d149-280f-7e81-bc6e-e908e6b9148e_19.jpg?x=139&amp;y=373&amp;w=215&amp;h=276&amp;r=0" alt="" style="display: block;"></div><div><br><!-- Media --><br></div><div><div><div>Kaiyang Zhou received the PhD degree in Computer Science from the University of Surrey, UK, in 2020. He is currently a Research Fellow at Nanyang Technological University, Singapore. His research lies at the intersection of machine learning and computer vision. His papers have been published at major journals and conferences in relevant fields, such as TPAMI, IJCV, ICLR, AAAI, CVPR, ICCV, and ECCV. According to Google Scholar, his papers have been cited more than 1,600 times,with h-index at 14 . He serves/served as an Area Chair/Senior Program Committee Member for BMVC (2022) and AAAI (2023), and a reviewer for top-tier journals and conferences including TPAMI, ICLR, NeurIPS, ICML, CVPR, ICCV, ECCV, etc.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">周开阳于2020年从英国萨里大学（University of Surrey）获得计算机科学博士学位。他目前是新加坡南洋理工大学的研究员。他的研究领域处于机器学习和计算机视觉的交叉点。他的论文已发表在相关领域的主要期刊和会议上，如《模式分析与机器智能汇刊》（TPAMI）、《国际计算机视觉杂志》（IJCV）、国际学习表征会议（ICLR）、美国人工智能协会会议（AAAI）、计算机视觉与模式识别会议（CVPR）、国际计算机视觉会议（ICCV）和欧洲计算机视觉会议（ECCV）等。根据谷歌学术，他的论文被引用超过1600次，h指数为14。他担任过英国机器视觉会议（BMVC，2022年）和美国人工智能协会会议（AAAI，2023年）的领域主席/高级程序委员会成员，也是包括《模式分析与机器智能汇刊》（TPAMI）、国际学习表征会议（ICLR）、神经信息处理系统大会（NeurIPS）、国际机器学习会议（ICML）、计算机视觉与模式识别会议（CVPR）、国际计算机视觉会议（ICCV）、欧洲计算机视觉会议（ECCV）等顶级期刊和会议的审稿人。</div></div></div></div><div><br><!-- Media --><br></div><div style="position: relative; display: block;"><img draggable="false" src="https://cdn.noedgeai.com/0195d149-280f-7e81-bc6e-e908e6b9148e_19.jpg?x=135&amp;y=898&amp;w=223&amp;h=249&amp;r=0" alt="" style="display: block;"></div><div><br><!-- Media --><br></div><div><div><div>Ziwei Liu is currently an Assistant Professor at Nanyang Technological University, Singapore. Previously, he was a senior research fellow at the Chinese University of Hong Kong and a postdoctoral researcher at University of California, Berkeley. Ziwei received his PhD from the Chinese University of Hong Kong. His research revolves around computer vision, machine learning and computer graphics. He has published extensively on top-tier conferences and journals in relevant fields, including CVPR, ICCV, ECCV, NeurIPS, ICLR, ICML, TPAMI, TOG and Nature - Machine Intelligence. He is the recipient of Microsoft Young Fellowship, Hong Kong PhD Fellowship, ICCV Young Researcher Award and HKSTP Best Paper Award. He also serves as an Area Chair of ICCV, NeurIPS and AAAI.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">刘子微目前是新加坡南洋理工大学的助理教授。此前，他是香港中文大学的高级研究员，也是加州大学伯克利分校的博士后研究员。刘子微从香港中文大学获得博士学位。他的研究围绕计算机视觉、机器学习和计算机图形学展开。他在相关领域的顶级会议和期刊上发表了大量论文，包括计算机视觉与模式识别会议（CVPR）、国际计算机视觉会议（ICCV）、欧洲计算机视觉会议（ECCV）、神经信息处理系统大会（NeurIPS）、国际学习表征会议（ICLR）、国际机器学习会议（ICML）、《模式分析与机器智能汇刊》（TPAMI）、《计算机图形学汇刊》（TOG）和《自然 - 机器智能》（Nature - Machine Intelligence）。他获得过微软青年学者奖学金、香港博士研究生奖学金、国际计算机视觉会议青年研究者奖和香港科技园最佳论文奖。他还担任国际计算机视觉会议（ICCV）、神经信息处理系统大会（NeurIPS）和美国人工智能协会会议（AAAI）的领域主席。</div></div></div></div><div><br><!-- Media --><br></div><div style="position: relative; display: block;"><img draggable="false" src="https://cdn.noedgeai.com/0195d149-280f-7e81-bc6e-e908e6b9148e_19.jpg?x=148&amp;y=1398&amp;w=194&amp;h=269&amp;r=0" alt="" style="display: block;"></div><div><br><!-- Media --><br></div><div><div><div>Yu Qiao is a professor with Shanghai Al Laboratory and the Shenzhen Institutes of Advanced Technology (SIAT), the Chinese Academy of Sciences. His research interests include computer vision, deep learning, and bioinformation. He has published more than 300 papers in international journals and conferences, including T-PAMI, IJCV, T-IP, T-SP, CVPR, ICCV, etc. His H-index is 72 , with 35,000 citations in Google scholar. He is the recipient of the distinguished paper award in AAAI 2021. His group achieved the first runner-up at the ImageNet Large Scale Visual Recognition Challenge 2015 in scene recognition, and was the winner at the ActivityNet Large Scale Activity Recognition Challenge 2016 in video classification. He served as the program chair of IEEE ICIST 2014.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">乔宇是上海人工智能实验室和中国科学院深圳先进技术研究院（SIAT）的教授。他的研究兴趣包括计算机视觉、深度学习和生物信息学。他在国际期刊和会议上发表了300多篇论文，包括《模式分析与机器智能汇刊》（T - PAMI）、《国际计算机视觉杂志》（IJCV）、《图像处理汇刊》（T - IP）、《信号处理汇刊》（T - SP）、计算机视觉与模式识别会议（CVPR）、国际计算机视觉会议（ICCV）等。他的h指数为72，谷歌学术引用次数达35000次。他获得过2021年美国人工智能协会会议杰出论文奖。他的团队在2015年ImageNet大规模视觉识别挑战赛的场景识别任务中获得亚军，并在2016年ActivityNet大规模活动识别挑战赛的视频分类任务中获胜。他曾担任2014年IEEE智能科学与技术国际会议（ICIST）的程序主席。</div></div></div></div><div><br><!-- Media --><br></div><div style="position: relative; display: block;"><img draggable="false" src="https://cdn.noedgeai.com/0195d149-280f-7e81-bc6e-e908e6b9148e_19.jpg?x=133&amp;y=1898&amp;w=226&amp;h=272&amp;r=0" alt="" style="display: block;"></div><div><br><!-- Media --><br></div><div><div><div>Tao Xiang received the Ph.D. degree in electrical and computer engineering from the National University of Singapore in 2002. He is currently a full professor in the Department of Electrical and Electronic Engineering, University of Surrey and a Research Scientist Manager at Meta AI. His research interests include computer vision and machine learning. He has published over 200 papers in international journals and conferences with over <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10039" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mstyle><mjx-mspace style="width: 0.278em;"></mjx-mspace></mjx-mstyle><mjx-mi class="mjx-n"><mjx-c class="mjx-c4B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>28</mn></mrow><mrow data-mjx-texclass="ORD"><mstyle scriptlevel="0"><mspace width="0.278em"></mspace></mstyle><mi mathvariant="normal">K</mi></mrow></math></mjx-assistive-mml></mjx-container> citations.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">向涛于2002年从新加坡国立大学获得电气与计算机工程博士学位。他目前是萨里大学电气与电子工程系的正教授，也是Meta AI的研究科学家经理。他的研究兴趣包括计算机视觉和机器学习。他在国际期刊和会议上发表了200多篇论文，引用次数超过<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10040" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mstyle><mjx-mspace style="width: 0.278em;"></mjx-mspace></mjx-mstyle><mjx-mi class="mjx-n"><mjx-c class="mjx-c4B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>28</mn></mrow><mrow data-mjx-texclass="ORD"><mstyle scriptlevel="0"><mspace width="0.278em"></mspace></mstyle><mi mathvariant="normal">K</mi></mrow></math></mjx-assistive-mml></mjx-container>次。</div></div></div></div><div><br><!-- Media --><br></div><div style="position: relative; display: block;"><img draggable="false" src="https://cdn.noedgeai.com/0195d149-280f-7e81-bc6e-e908e6b9148e_19.jpg?x=910&amp;y=131&amp;w=224&amp;h=267&amp;r=0" alt="" style="display: block;"></div><div><br><!-- Media --><br></div><div><div><div>Chen Change Loy (Senior Member, IEEE) received the PhD degree in computer science from the Queen Mary University of London, in 2010. He is an associate professor with the School of Computer Science and Engineering, Nanyang Technological University. Prior to joining NTU, he served as a research assistant professor with the Department of Information Engineering, The Chinese University of Hong Kong, from 2013 to 2018. His research interests include computer vision and deep learning with a focus on image/video restoration and enhancement, generative tasks, and representation learning. He serves as an Associate Editor of the International Journal of Computer Vision (IJCV) and IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). He also serves/served as an Area Chair of ICCV 2021, CVPR (2021, 2019), ECCV (2022, 2018), AAAI (2021-2023), and BMVC (2018-2021).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">罗智泉（IEEE高级会员）于2010年从伦敦玛丽女王大学获得计算机科学博士学位。他是南洋理工大学计算机科学与工程学院的副教授。在加入南洋理工大学之前，他于2013年至2018年担任香港中文大学信息工程系的研究助理教授。他的研究兴趣包括计算机视觉和深度学习，重点是图像/视频恢复与增强、生成任务和表征学习。他担任《国际计算机视觉杂志》（IJCV）和《IEEE模式分析与机器智能汇刊》（TPAMI）的副主编。他还担任过2021年国际计算机视觉会议（ICCV）、计算机视觉与模式识别会议（CVPR，2021年、2019年）、欧洲计算机视觉会议（ECCV，2022年、2018年）、美国人工智能协会会议（AAAI，2021 - 2023年）和英国机器视觉会议（BMVC，2018 - 2021年）的领域主席。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div>
      </body>
    </html>
  