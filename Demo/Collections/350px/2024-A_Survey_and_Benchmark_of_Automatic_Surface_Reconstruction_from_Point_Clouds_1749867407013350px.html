
    <!DOCTYPE html>
    <html lang="en">
      <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Doc2x-Export-Html-Result</title>
        <style>
            * {
              padding: 0;
              margin: 0;
              box-sizing: border-box;
            }
             html {
              line-height: 1.15; /* 1 */
              -webkit-text-size-adjust: 100%; /* 2 */
            }
            body {
              padding: 20px 350px;
              margin: 0;
            }
            main {
              display: block;
            }
            h1 {
              font-size: 2em;
              margin: 0.67em 0;
            }
            hr {
              box-sizing: content-box; /* 1 */
              height: 0; /* 1 */
              overflow: visible; /* 2 */
            }
            pre {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            a {
              background-color: transparent;
            }
            abbr[title] {
              border-bottom: none; /* 1 */
              text-decoration: underline; /* 2 */
              text-decoration: underline dotted; /* 2 */
            }
            b,
            strong {
              font-weight: bolder;
            }
            code,
            kbd,
            samp {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            small {
              font-size: 80%;
            }
            sub,
            sup {
              font-size: 75%;
              line-height: 0;
              position: relative;
              vertical-align: baseline;
            }
            sub {
              bottom: -0.25em;
            }
            sup {
              top: -0.5em;
            }
            img {
              border-style: none;
            }
            button,
            input,
            optgroup,
            select,
            textarea {
              font-family: inherit; /* 1 */
              font-size: 100%; /* 1 */
              line-height: 1.15; /* 1 */
              margin: 0; /* 2 */
            }
            button,
            input { /* 1 */
              overflow: visible;
            }
            button,
            select { /* 1 */
              text-transform: none;
            }
            button,
            [type="button"],
            [type="reset"],
            [type="submit"] {
              -webkit-appearance: button;
            }
            button::-moz-focus-inner,
            [type="button"]::-moz-focus-inner,
            [type="reset"]::-moz-focus-inner,
            [type="submit"]::-moz-focus-inner {
              border-style: none;
              padding: 0;
            }
            button:-moz-focusring,
            [type="button"]:-moz-focusring,
            [type="reset"]:-moz-focusring,
            [type="submit"]:-moz-focusring {
              outline: 1px dotted ButtonText;
            }
            fieldset {
              padding: 0.35em 0.75em 0.625em;
            }
            legend {
              box-sizing: border-box; /* 1 */
              color: inherit; /* 2 */
              display: table; /* 1 */
              max-width: 100%; /* 1 */
              padding: 0; /* 3 */
              white-space: normal; /* 1 */
            }
            progress {
              vertical-align: baseline;
            }
            textarea {
              overflow: auto;
            }
            [type="checkbox"],
            [type="radio"] {
              box-sizing: border-box; /* 1 */
              padding: 0; /* 2 */
            }
            [type="number"]::-webkit-inner-spin-button,
            [type="number"]::-webkit-outer-spin-button {
              height: auto;
            }
            [type="search"] {
              -webkit-appearance: textfield; /* 1 */
              outline-offset: -2px; /* 2 */
            }
            [type="search"]::-webkit-search-decoration {
              -webkit-appearance: none;
            }
            ::-webkit-file-upload-button {
              -webkit-appearance: button; /* 1 */
              font: inherit; /* 2 */
            }
            details {
              display: block;
            }
            summary {
              display: list-item;
            }
            [hidden] {
              display: none;
            }
             table {
                border-collapse: collapse;
                width: 100%;
                margin-top: 20px;
                margin-bottom: 20px;
              }
              table thead {
                background-color: #e5e5e5;
              }
              table td {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              table th {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              h1, h2, h3, h4, h5, h6 {
                margin-bottom: 20px;
              }
              p {
                margin-top: 20px;
                text-indent: 2em;
                margin-bottom: 20px;
              }
        </style>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <style>

</style>
      </head>
      <body style="padding: 40px;">
        <h1>A Survey and Benchmark of Automatic Surface Reconstruction from Point Clouds</h1><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h1>点云自动表面重建的调查与基准</h1></div><p>Raphael Sulzer, Renaud Marlet, Bruno Vallet and Loic Landrieu</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>拉斐尔·苏尔泽、雷诺·马尔莱、布鲁诺·瓦莱特和洛伊克·朗德里厄</p></div><p>Abstract-We present a comprehensive survey and benchmark of both traditional and learning-based methods for surface reconstruction from point clouds. This task is particularly challenging for real-world acquisitions due to factors such as noise, outliers, non-uniform sampling, and missing data. Traditional approaches often simplify the problem by imposing handcrafted priors on either the input point clouds or the resulting surface, a process that can require tedious hyperparameter tuning. In contrast, deep learning models have the capability to directly learn the properties of input point clouds and desired surfaces from data. We study the influence of handcrafted and learned priors on the precision and robustness of surface reconstruction techniques. We evaluate various time-tested and contemporary methods in a standardized manner. When both trained and evaluated on point clouds with identical characteristics, the learning-based models consistently produce higher-quality surfaces compared to their traditional counterparts—even in scenarios involving novel shape categories. However, traditional methods demonstrate greater resilience to the diverse anomalies commonly found in real-world 3D acquisitions. For the benefit of the research community, we make our code and datasets available, inviting further enhancements to learning-based surface reconstruction. This can be accessed at <a href="https://github.com/raphaelsulzer/dsr-benchmark">https://github.com/raphaelsulzer/dsr-benchmark</a>.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>摘要-我们提供了一个全面的调查和基准，涵盖了传统和基于学习的点云表面重建方法。由于噪声、离群点、不均匀采样和缺失数据等因素，这项任务在现实世界的获取中尤其具有挑战性。传统方法通常通过对输入点云或生成表面施加手工先验来简化问题，这一过程可能需要繁琐的超参数调整。相比之下，深度学习模型能够直接从数据中学习输入点云和期望表面的属性。我们研究了手工先验和学习先验对表面重建技术的精度和鲁棒性的影响。我们以标准化的方式评估各种经过时间考验和当代的方法。当在具有相同特征的点云上进行训练和评估时，基于学习的模型始终产生比传统模型更高质量的表面——即使在涉及新形状类别的场景中。然而，传统方法对现实世界3D获取中常见的各种异常表现出更强的韧性。为了研究社区的利益，我们提供了我们的代码和数据集，邀请进一步改进基于学习的表面重建。可以访问 <a href="https://github.com/raphaelsulzer/dsr-benchmark%E3%80%82">https://github.com/raphaelsulzer/dsr-benchmark。</a></p></div><p>Index Terms-surface reconstruction, point clouds, deep learning, mesh generation, survey, benchmark</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>索引词-表面重建、点云、深度学习、网格生成、调查、基准</p></div><h2>1 INTRODUCTION</h2><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h2>1 引言</h2></div><p>MODERN three-dimensional (3D) acquisition technol- ogy, such as range scanning or multi-view stereo (MVS) allows us to capture detailed geometric information of real scenes in the form of point clouds. However, sets of 3D points are usually not sufficient for modeling complex physical processes, such as fluid dynamics or environmental phenomena. A variety of applications in science and engineering require a continuous surface representation of objects or scenes. As a result, transforming point clouds into surface models-a process known as surface reconstruction-is a central problem in digital geometry processing. In this paper, we offer a comprehensive survey and benchmark of traditional and learning-based methods designed to address this problem.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>现代三维（3D）获取技术，如范围扫描或多视角立体（MVS），使我们能够以点云的形式捕捉真实场景的详细几何信息。然而，3D点集通常不足以建模复杂的物理过程，如流体动力学或环境现象。科学和工程中的多种应用需要对象或场景的连续表面表示。因此，将点云转换为表面模型——这一过程称为表面重建——是数字几何处理中的一个核心问题。在本文中，我们提供了针对这一问题的传统和基于学习的方法的全面调查和基准。</p></div><p>Without prior information about the sought surface, the task of surface reconstruction from point clouds becomes ill-posed: there are infinitely many surfaces that can potentially fit the given points. As illustrated in Fig. 1, acquisition defects such as non-uniform sampling, noise, outliers, or missing data further complicate the reconstruction of a geometrically and topologically accurate surface [1].</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在没有关于所需表面的先验信息的情况下，从点云进行表面重建的任务变得不适定：有无数个表面可能适合给定的点。如图1所示，获取缺陷如不均匀采样、噪声、离群点或缺失数据进一步复杂化了几何和拓扑准确表面的重建[1]。</p></div><p>Traditional surface reconstruction techniques often simplify this problem with handcrafted priors on the input cloud: point density, noise and outlier levels, or the output surface: smoothness, topological properties, or semantics. However, adapting priors to different acquisitions often requires tedious hyperparameter tuning. In contrast, contemporary deep learning methods learn point cloud defects and shape properties directly from training data. In consequence, they can reconstruct accurate surfaces without manual parameter tuning. However, neural surface reconstruction (NSR) methods have mainly been tested on artificial data sets with a limited number of object categories. Such datasets may not be representative of the endless variety of shapes in real-world scenarios. Moreover, NSR methods are typically applied on uniformly sampled point clouds. These do not reflect the irregularities of real-world acquisitions such as non-uniformity, missing data from occlusions, or transparent regions. The ability of NSR models to reconstruct shapes in unseen shape categories and from point clouds with unseen defects has rarely been rigorously and systematically evaluated.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>传统的表面重建技术通常通过对输入点云施加手工先验来简化这个问题：点密度、噪声和离群点水平，或输出表面：光滑度、拓扑属性或语义。然而，适应不同获取的先验通常需要繁琐的超参数调整。相比之下，当代深度学习方法直接从训练数据中学习点云缺陷和形状属性。因此，它们可以在没有手动参数调整的情况下重建准确的表面。然而，神经表面重建（NSR）方法主要在有限数量的对象类别的人工数据集上进行了测试。这些数据集可能无法代表现实世界场景中形状的无尽多样性。此外，NSR方法通常应用于均匀采样的点云。这些并不反映现实世界获取中的不规则性，如不均匀性、由于遮挡而缺失的数据或透明区域。NSR模型在未见形状类别和具有未见缺陷的点云中重建形状的能力很少经过严格和系统的评估。</p></div><p>In this paper, we propose a series of experiments designed to benchmark surface reconstruction algorithms from point clouds. We use a diverse range of publicly available shape datasets with objects of varying complexities and for which we know the true surface. To emulate real-world scenarios, we synthetically scan the objects to generate point clouds with realistic characteristics. Working with objects with known surfaces allows us to measure the geometric and topological quality of the reconstructed surfaces. We also consider point clouds from real acquisitions for which the true surface is typically unknown. By comparing novel learning-based algorithms to traditional test-of-time methods, we specifically study the impact of learned v.s. handcrafted priors in the reconstruction process. Throughout our study, the generalizability of these methods remains a focal point. Our main contributions are as follows:</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在本文中，我们提出了一系列实验，旨在基准测试点云的表面重建算法。我们使用多种公开可用的形状数据集，这些数据集包含不同复杂度的对象，并且我们知道真实表面。为了模拟现实世界场景，我们对对象进行合成扫描，以生成具有真实特征的点云。处理已知表面的对象使我们能够测量重建表面的几何和拓扑质量。我们还考虑来自真实获取的点云，其真实表面通常是未知的。通过将新颖的基于学习的算法与传统的时间考验方法进行比较，我们特别研究了学习先验与手工先验在重建过程中的影响。在我们的研究中，这些方法的可推广性始终是一个重点。我们的主要贡献如下：</p></div><ul>
<li>We provide a comprehensive literature review of surface reconstruction methods from point clouds, tracing developments over three decades up to the latest learning-based approaches. We contrast popular test-of-time traditional models with novel NSR models. Additionally, we discuss their relation to the new emerging field of rendering-based surface reconstruction.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>我们提供了一个全面的文献综述，回顾了点云表面重建方法的发展历程，追溯到最新的基于学习的方法。我们对比了流行的时间考验传统模型与新颖的NSR模型。此外，我们讨论了它们与新兴的基于渲染的表面重建领域的关系。</li>
</ul></div><hr>
<!-- Footnote --><ul>
<li>R. Sulzer is affiliated with Centre INRIA d'Université Côte d'Azur, Sophia Antipolis, France. E-mail: <a href="mailto:raphaelsulzer@gmx.de">raphaelsulzer@gmx.de</a>.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>R. Sulzer隶属于法国阿尔卑斯大学INRIA中心，索非亚·安提波利斯。电子邮件：<a href="mailto:raphaelsulzer@gmx.de">raphaelsulzer@gmx.de</a>。</li>
</ul></div><ul>
<li>R. Marlet is affiliated with LIGM, Ecole des Ponts, Univ Gustave Eiffel, CNRS, Marne-la-Vallée, France and Valeo.ai, Paris, France.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>R. Marlet隶属于法国马恩河谷的桥梁学校LIGM、古斯塔夫·埃菲尔大学、法国国家科学研究中心（CNRS）和法国巴黎的Valeo.ai。</li>
</ul></div><ul>
<li>B. Vallet is affiliated with LASTIG, Univ Gustave Eiffel, IGN-ENSG, F-94160 Saint-Mandé, France.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>B. Vallet 隶属于 LASTIG，居斯塔夫·艾菲尔大学，IGN-ENSG，法国圣曼德 F-94160。</li>
</ul></div><ul>
<li>L. Landrieu is affiliated with LIGM and LASTIG. Corresponding author: R. Sulzer</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>L. Landrieu 隶属于 LIGM 和 LASTIG。通讯作者：R. Sulzer</li>
</ul></div><!-- Footnote -->
<hr><ul>
<li>We benchmark both traditional and learning-based methods under consistent conditions. We perform several experiments to assess their geometric precision, topological consistency, and robustness using openly available shape datasets and point clouds from both synthetic and real scans.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>我们在一致的条件下对传统方法和基于学习的方法进行基准测试。我们进行多个实验，以评估它们的几何精度、拓扑一致性和鲁棒性，使用公开可用的形状数据集和来自合成和真实扫描的点云。</li>
</ul></div><h2>2 RELATED WORK</h2><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h2>2 相关工作</h2></div><p>In this section, we provide an overview of the existing surveys and benchmark studies of NSR methods.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在本节中，我们提供现有的 NSR 方法的调查和基准研究的概述。</p></div><h3>2.1 Surveys</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>2.1 调查</h3></div><p>Although several works survey the broad field of surface reconstruction from point clouds [1], [2], [3], [4], [5], [6], the majority predate the rise of learning-based reconstruction. Surface reconstruction methods are often grouped as interpolation-based [2] or approximation-based techniques [1]. Interpolation methods "connect" points of the input point cloud, usually by linear interpolation between pairs of points. Approximation methods use smooth functions to represent the point cloud globally or locally [7]. In our review, we consider both interpolating and approximating methods and focus on novel ideas in learning-based surface reconstruction. While many reconstruction methods can be distinguished by their surface priors [1], [5], we argue that several successful approaches combine different priors, complicating classification solely based on priors. We thus organize the methods into two groups: surface-based and volume-based approaches. This breakdown mirrors the primary mathematical surface representations: parametric [8] and implicit [9]. To the best of our knowledge, only two surveys include recent learning-based methods [5], [10]. The work of You et al. [3] predates important developments for learning-based methods, such as the incorporation of local information [11], [12], [13], [14], [15], [16], [17].</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>尽管有几项工作调查了从点云进行表面重建的广泛领域 [1]，[2]，[3]，[4]，[5]，[6]，但大多数都早于基于学习的重建的兴起。表面重建方法通常被分为基于插值 [2] 或基于近似的技术 [1]。插值方法通过线性插值连接输入点云的点，通常是成对的点之间。近似方法使用平滑函数来全局或局部表示点云 [7]。在我们的回顾中，我们考虑了插值和近似方法，并专注于基于学习的表面重建中的新想法。虽然许多重建方法可以通过其表面先验 [1]，[5] 来区分，但我们认为几种成功的方法结合了不同的先验，这使得仅基于先验的分类变得复杂。因此，我们将这些方法分为两组：基于表面的方法和基于体积的方法。这种划分反映了主要的数学表面表示：参数化 [8] 和隐式 [9]。据我们所知，只有两项调查包括最近的基于学习的方法 [5]，[10]。You 等人的工作 [3] 早于基于学习的方法的重要发展，例如局部信息的纳入 [11]，[12]，[13]，[14]，[15]，[16]，[17]。</p></div><h3>2.2 Benchmarks</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>2.2 基准</h3></div><p>Historically, very few benchmarks for surface reconstruction from point clouds have been proposed. Numerous methods use bespoke datasets to evaluate their approach, typically by uniformly sampling point clouds from the ground truth surface from existing shape collections [11], [12], [13], [16], [17], [18]. However, the characteristics of these sampled point clouds often differ between studies, complicating the comparison of their results. Moreover, these point clouds typically lack common defects seen in real acquisitions, such as missing data from occlusion.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>历史上，提出的用于从点云进行表面重建的基准非常少。许多方法使用定制的数据集来评估其方法，通常通过从现有形状集合中均匀采样点云来实现 [11]，[12]，[13]，[16]，[17]，[18]。然而，这些采样的点云的特征在不同研究之间往往有所不同，复杂了结果的比较。此外，这些点云通常缺乏在真实采集中看到的常见缺陷，例如由于遮挡而缺失的数据。</p></div><p>Two notable exceptions are the benchmarks of Berger et al. [19] and Huang et al. [5]. Both teams develop synthetic range scanning procedures to produce point clouds with realistic artifacts such as noise, non-uniformity, and misaligned scans. They also use shapes with non-trivial topology and details of various sizes. While providing interesting results, Berger et al.'s benchmark predates learning-based surface reconstruction and only considers traditional approximation techniques. Huang et al.'s benchmark considers learning-based methods, but does not specifically study their generalization capabilities.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>两个显著的例外是 Berger 等人的基准 [19] 和 Huang 等人的基准 [5]。这两个团队开发了合成范围扫描程序，以生成具有现实伪影的点云，例如噪声、不均匀性和错位扫描。他们还使用具有非平凡拓扑和各种大小细节的形状。虽然提供了有趣的结果，但 Berger 等人的基准早于基于学习的表面重建，并且仅考虑传统的近似技术。Huang 等人的基准考虑了基于学习的方法，但并未专门研究它们的泛化能力。</p></div><p>In our benchmark, we use the synthetic range scanning procedure of Berger et al. and their test shapes as they provide a realistic challenge for both learning-based and traditional algorithms. We also implement our own synthetic scanning procedure to produce MVS-like point clouds. We use synthetic scanning on existing large shape datasets to create training datasets with true surfaces and point clouds with realistic characteristics (see Fig. 5). Furthermore, we specifically study the generalization capabilities of methods by using train and test sets with different characteristics in terms of shape categories and acquisition defects.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在我们的基准中，我们使用 Berger 等人的合成范围扫描程序及其测试形状，因为它们为基于学习和传统算法提供了现实的挑战。我们还实现了自己的合成扫描程序，以生成类似 MVS 的点云。我们在现有的大型形状数据集上使用合成扫描，以创建具有真实表面和具有现实特征的点云的训练数据集（见图 5）。此外，我们特别研究了方法的泛化能力，通过使用在形状类别和采集缺陷方面具有不同特征的训练和测试集。</p></div><p>MVS benchmarks. The generation of point clouds from 2D information such as overlapping images is an integral problem of surface reconstruction. There exists a variety of benchmarks using data captured in a laboratory environment [20], [21] or in the wild [22], [23], [24]. These benchmarks often use low-quality image acquisitions as input, and use a higher-quality acquisition, e.g., from LiDAR scans, to produce precise and dense point clouds that serve as reference. However, even with advanced sensors, producing a complete and precise point cloud remains difficult. As a result, the evaluation of the reconstructed surfaces can be flawed. A common workaround is to restrict the evaluation to specific "trustworthy" areas [21], [23]. However, in contrast to true and complete surfaces, this approach prevents the computation of topological metrics such as component count, or differential metrics such as surface normals. Furthermore, many learning-based methods require a large dataset of closed reference surfaces and not just a small set of precise point clouds.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>MVS 基准。从 2D 信息（如重叠图像）生成点云是表面重建的一个重要问题。存在多种基准，使用在实验室环境 [20]，[21] 或野外 [22]，[23]，[24] 捕获的数据。这些基准通常使用低质量的图像采集作为输入，并使用更高质量的采集，例如来自 LiDAR 扫描，以生成作为参考的精确和密集的点云。然而，即使使用先进的传感器，生成完整和精确的点云仍然很困难。因此，重建表面的评估可能存在缺陷。一个常见的解决方法是将评估限制在特定的“可信”区域 [21]，[23]。然而，与真实和完整的表面相比，这种方法阻止了拓扑度量（如组件计数）或微分度量（如表面法线）的计算。此外，许多基于学习的方法需要大量的闭合参考表面数据集，而不仅仅是一小部分精确的点云。</p></div><h2>3 REPRESENTATIONS, PROPERTIES, AND RECON- STRUCTION OF SURFACES</h2><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h2>3 表面表示、属性和重建</h2></div><p>In this section, we first define the notion of surface and its mathematical and digital representations. We then discuss the most critical properties of reconstructed surfaces. Finally, we propose a grouping of surface reconstruction algorithms featured in our survey based on the mathematical representations of surfaces: parametric or implicit.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在本节中，我们首先定义表面的概念及其数学和数字表示。然后，我们讨论重建表面的最关键属性。最后，我们根据表面的数学表示（参数化或隐式）提出我们调查中所涉及的表面重建算法的分组。</p></div><p>Throughout this article,we denote by \(\mathcal{P}\) the input point cloud, \({\mathcal{S}}^{r}\) the reconstructed surface,and \({\mathcal{S}}^{g}\) the real surface from which \(\mathcal{P}\) is sampled.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在本文中，我们用 \(\mathcal{P}\) 表示输入点云，\({\mathcal{S}}^{r}\) 表示重建的表面，\({\mathcal{S}}^{g}\) 表示从中采样 \(\mathcal{P}\) 的真实表面。</p></div><h3>3.1 Representations</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>3.1 表示</h3></div><p>A surface is defined as an orientable, continuous 2-manifold within \({\mathbb{R}}^{3}\) ,which may or may not have boundaries [7], [25], [26]. These properties hold significance for surface visualization and processing, which we will elaborate on in subsequent sections. From a mathematical perspective, surface representations fall primarily into two categories: parametric and implicit.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>表面被定义为在 \({\mathbb{R}}^{3}\) 中的可定向、连续的二维流形，可能有也可能没有边界 [7]，[25]，[26]。这些属性对表面可视化和处理具有重要意义，我们将在后续部分详细阐述。从数学角度来看，表面表示主要分为两类：参数化和隐式。</p></div><p>Parametric surfaces. These surfaces are represented by a continuous and bijective function \(\mathbf{f} : \Omega  \mapsto  {\mathcal{S}}^{g}\) that maps a parameter domain \(\Omega  \in  {\mathbb{R}}^{2}\) (e.g., \({\left\lbrack  -1,1\right\rbrack  }^{2}\) ) to a 3D surface \({\mathcal{S}}^{g} = \mathbf{f}\left( \Omega \right)  \in  {\mathbb{R}}^{3}\) . However,it may be impractical to devise a single function to parameterize complex surfaces. Therefore, the parameter domain \(\Omega\) is usually divided into smaller subregions, each equipped with its own function [7]. Typically, \(\Omega\) is partitioned into triangles. A set of triangles approximating \({\mathcal{S}}^{g}\) can be efficiently stored and processed as a triangle surface mesh \(\mathcal{M} = \left( {\mathcal{V},\mathcal{E},\mathcal{F}}\right)\) ,where \(\mathcal{V}\) denotes the vertices of the triangles, \(\mathcal{E}\) their edges and \(\mathcal{F}\) their facets.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>参数化表面。这些表面由一个连续且双射的函数 \(\mathbf{f} : \Omega  \mapsto  {\mathcal{S}}^{g}\) 表示，该函数将参数域 \(\Omega  \in  {\mathbb{R}}^{2}\)（例如，\({\left\lbrack  -1,1\right\rbrack  }^{2}\)）映射到三维表面 \({\mathcal{S}}^{g} = \mathbf{f}\left( \Omega \right)  \in  {\mathbb{R}}^{3}\)。然而，设计一个单一的函数来参数化复杂表面可能不切实际。因此，参数域 \(\Omega\) 通常被划分为更小的子区域，每个子区域都有其自己的函数 [7]。通常，\(\Omega\) 被划分为三角形。可以高效地将一组近似 \({\mathcal{S}}^{g}\) 的三角形存储和处理为三角形表面网格 \(\mathcal{M} = \left( {\mathcal{V},\mathcal{E},\mathcal{F}}\right)\)，其中 \(\mathcal{V}\) 表示三角形的顶点，\(\mathcal{E}\) 表示它们的边，\(\mathcal{F}\) 表示它们的面。</p></div><!-- Media --><!-- figureText: (a) Unknown Topology (b) Unknown Geometry (c) Acquisition Defects --><img src="https://cdn.noedgeai.com/bo_d163rvn7aajc7388jqb0_2.jpg?x=231&#x26;y=119&#x26;w=1342&#x26;h=361&#x26;r=0"><p>Figure 1: Difficulties in surface reconstruction from point clouds: In each plot, we show the real surface —, point samples \(\bullet\) ,and possible reconstructions —. The correct topology and geometry of the real surface are not known from the point samples(a,b). The point samples may also include acquisition defects such as noise(c). The goal of any surface reconstruction algorithm is finding a good approximation of the real surface, in terms of its geometry and topology. Learning-based surface reconstruction can learn shape patterns or sampling errors such as the one exemplified here, and use the learned knowledge during reconstruction for a better approximation.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>图1：从点云重建表面中的困难：在每个图中，我们展示了真实表面——、点样本 \(\bullet\) 和可能的重建——。从点样本（a，b）中无法得知真实表面的正确拓扑和几何形状。点样本可能还包括获取缺陷，如噪声（c）。任何表面重建算法的目标是找到真实表面的良好近似，无论是在几何形状还是拓扑方面。基于学习的表面重建可以学习形状模式或采样误差，例如这里所示的例子，并在重建过程中利用所学知识以获得更好的近似。</p></div><!-- Media --><p>Implicit surfaces. These surfaces are defined by the level-set \(c\) of a scalar-valued function \(F : {\mathbb{R}}^{3} \mapsto  \mathbb{R}\) :</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>隐式表面。这些表面由标量值函数 \(F : {\mathbb{R}}^{3} \mapsto  \mathbb{R}\) 的水平集 \(c\) 定义：</p></div><p></p>\[{\mathcal{S}}_{c}^{g} = \left\{  {\mathbf{x} \in  {\mathbb{R}}^{3} \mid  F\left( \mathbf{x}\right)  = c}\right\}  . \tag{1}\]<p></p><p>The most common choice for \(F\) are signed distance function (SDF) or occupancy function (OF). An SDF gives the distance from a 3D point \(\mathbf{x}\) to the closest part of the surface. Points within the interior of the surface are assigned negative values, while those outside are given positive values. An OF typically has a value of 1 inside the surface and 0 outside. The \(c\) -level-set of \(F\) represent the surface \({\mathcal{S}}^{g}\) with \(c = 0\) for SDFs and \(c = {0.5}\) for OFs. Similar to the parametric case, the domains of implicit functions are often split into sub-regions, such as voxels [11], OcTree-nodes [27], or tetrahedra [28]. In practice, once computed, implicit surfaces are often converted into a parametric mesh, which is easier to handle for downstream applications.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>最常见的 \(F\) 选择是有符号距离函数（SDF）或占用函数（OF）。SDF 给出从三维点 \(\mathbf{x}\) 到表面最近部分的距离。表面内部的点被赋予负值，而外部的点则赋予正值。OF 通常在表面内部的值为 1，外部为 0。\(c\) -水平集的 \(F\) 表示表面 \({\mathcal{S}}^{g}\)，对于 SDF 为 \(c = 0\)，对于 OF 为 \(c = {0.5}\)。与参数化情况类似，隐式函数的域通常被划分为子区域，如体素 [11]、八叉树节点 [27] 或四面体 [28]。在实践中，一旦计算完成，隐式表面通常会被转换为参数化网格，这样更易于处理后续应用。</p></div><h3>3.2 Properties</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>3.2 属性</h3></div><p>We want the reconstructed surface \({\mathcal{S}}^{r}\) to be close in terms of geometry and topology to the real surface \({\mathcal{S}}^{g}\) from which the point cloud \(\mathcal{P}\) is sampled. Real surfaces exhibit certain intrinsic properties, such as watertightness, manifoldness, and orientability, which are crucial for a variety of downstream applications. Therefore, it is essential that the reconstructed surface \({\mathcal{S}}^{r}\) also possess these properties. In this section, we define these properties in the context of mesh representations. For a visual interpretation of these concepts, the reader is directed to Fig. 2.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>我们希望重建的表面 \({\mathcal{S}}^{r}\) 在几何形状和拓扑上接近从中采样的真实表面 \({\mathcal{S}}^{g}\)。真实表面表现出某些内在属性，如防水性、流形性和可定向性，这些对于各种后续应用至关重要。因此，重建的表面 \({\mathcal{S}}^{r}\) 也必须具备这些属性。在本节中，我们在网格表示的背景下定义这些属性。有关这些概念的视觉解释，请参见图 2。</p></div><ul>
<li>Watertightness: A geometric surface is considered watertight, or closed, when it is boundary-free. This implies that it forms a continuous and uninterrupted surface that encloses a finite volume without gaps or openings. For example, a sphere is a closed surface as one can move anywhere along its surface without ever encountering any boundaries. A mesh \(\mathcal{M}\) is boundary-free (or closed) if no edge is incident to only one facet: every edge should be shared between two facets to avoid gaps. In practice, surfaces reconstructed from real-world scenes will necessarily have boundaries due to the finite nature of the scanning coverage. Thus, we define a surface as watertight if it is boundary-free, except for any intersections with its domain boundary. Fig. 2a illustrates a non-watertight surface.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>防水性：当几何表面是无边界的时，它被认为是防水的或封闭的。这意味着它形成一个连续且不间断的表面，包围一个有限的体积，没有缝隙或开口。例如，球体是一个封闭的表面，因为人们可以在其表面上任意移动，而不会遇到任何边界。一个网格\(\mathcal{M}\)是无边界的（或封闭的），如果没有边只与一个面相接：每条边应该在两个面之间共享，以避免缝隙。在实际操作中，从现实场景重建的表面必然会有边界，因为扫描覆盖的有限性。因此，我们定义一个表面为防水的，如果它是无边界的，除了与其域边界的任何交点。图2a展示了一个非防水表面。</li>
</ul></div><ul>
<li>Manifoldness: Real and geometric surfaces are 2- manifold if and only if any of its point has a local neighborhood that is homeomorphic to an open subset of the Euclidean plane. In other words, every small enough region of the surface, irrespective of its curvature, can be continuously deformed into a 2D plane. A mesh \(\mathcal{M}\) is manifold if it has the following attributes:</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>多重性：真实和几何表面是2-多重的，当且仅当其任何点的局部邻域同胚于欧几里得平面的开子集。换句话说，表面的每个足够小的区域，无论其曲率如何，都可以连续变形为二维平面。一个网格\(\mathcal{M}\)是多重的，如果它具有以下属性：</li>
</ul></div><ul>
<li>Edge-manifold: For each edge in \(\mathcal{E}\) ,the set of facets that share this edge form a topological half-disk. This means that no edge can be incident to more than two facets. See Fig. 2b for an illustration of a mesh violating the edge-manifoldness property.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>边多重性：对于\(\mathcal{E}\)中的每条边，共享该边的面集合形成一个拓扑半圆盘。这意味着没有边可以与超过两个面相接。请参见图2b，了解违反边多重性属性的网格示例。</li>
</ul></div><ul>
<li>Vertex-manifold: For each vertex in \(\mathcal{V}\) ,the set of facets that share this vertex forms a topological half-disk. This implies that facets that share a common vertex are organized in an open or closed fan. In other words, each vertex is part of at least two edges and each edge is part of two facets.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>顶点多重性：对于\(\mathcal{V}\)中的每个顶点，共享该顶点的面集合形成一个拓扑半圆盘。这意味着共享公共顶点的面以开放或封闭扇形排列。换句话说，每个顶点至少是两条边的一部分，每条边是两个面的部分。</li>
</ul></div><ul>
<li>Intersection-free: All pairs of facets not sharing an edge or vertex do not intersect. In Fig. 2c, we represent a mesh that self-intersect outside of an edge.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>无交集：所有不共享边或顶点的面对不相交。在图2c中，我们表示一个在边外自交的网格。</li>
</ul></div><ul>
<li>Orientability: A mesh \(\mathcal{M}\) is orientable if and only if one can consistently assign a direction (or "side") to its facets such that adjacent facets always share the same orientation. This allows us to distinguish between "inside" and "outside" of the mesh. If the order of the vertices dictates the direction of the outward-facing normal with the right-hand rule, this has implications on the vertex ordering as well. Specifically, when two facets share a common edge, the ordering of the shared vertices should be reversed for the two facets. See Fig. 2d for an illustration of a non-orientable surface.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>可定向性：一个网格\(\mathcal{M}\)是可定向的，当且仅当可以一致地为其面分配一个方向（或“侧面”），使得相邻的面始终共享相同的方向。这使我们能够区分网格的“内部”和“外部”。如果顶点的顺序决定了外向法线的方向（使用右手法则），这对顶点的排序也有影响。具体来说，当两个面共享一个公共边时，两个面的共享顶点的顺序应该反转。请参见图2d，了解非可定向表面的示例。</li>
</ul></div><!-- Media --><!-- figureText: (a) Non-watertight (b) Non-manifold (c) Intersecting (d) Non-orientable --><img src="https://cdn.noedgeai.com/bo_d163rvn7aajc7388jqb0_3.jpg?x=152&#x26;y=146&#x26;w=1525&#x26;h=273&#x26;r=0"><p>Figure 2: Properties of surface meshes: In (a), we show a surface mesh that is non-watertight due to the hole in the center marked with red vertices and edges. The green vertices and edges mark the intersection with the domain boundary. In (b), we show a surface mesh with non-manifold edges and non-manifold vertices marked in red. In (c), we show a non-manifold and intersecting surface mesh. Here, the non-manifoldness is harder to detect, because it does not happen along edges of the mesh. In (d), we show a non-orientable surface.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>图2：表面网格的属性：在（a）中，我们展示了一个由于中心的孔而非防水的表面网格，孔用红色顶点和边标记。绿色的顶点和边标记与域边界的交点。在（b）中，我们展示了一个具有非多重边和非多重顶点的表面网格，标记为红色。在（c）中，我们展示了一个非多重且相交的表面网格。在这里，非多重性更难以检测，因为它并不发生在网格的边上。在（d）中，我们展示了一个非可定向的表面。</p></div><!-- Media --><p>The watertightness property is crucial for physical simulations such as fluid dynamics. Both manifoldness and orientability are prerequisites for certain mesh data structures, such as the widely used half-edge structure [29], [30]. These structures ensure consistent and predictable behavior during geometric transformations, topological modifications, and various mesh optimization and query operations, and many mesh processing algorithms require a manifold mesh. Lastly, intersection-free and orientable surfaces lead to a well-defined notion of inside and outside, which is important for mesh visualization and various geometric operations and metrics.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>防水性属性对于物理模拟（如流体动力学）至关重要。多重性和可定向性是某些网格数据结构的前提条件，例如广泛使用的半边结构[29]，[30]。这些结构确保在几何变换、拓扑修改以及各种网格优化和查询操作中具有一致和可预测的行为，许多网格处理算法需要一个多重网格。最后，无交集和可定向的表面导致了内部和外部的明确概念，这对于网格可视化以及各种几何操作和度量非常重要。</p></div><h3>3.3 Reconstruction</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>3.3 重建</h3></div><p>Surface reconstruction from point clouds consists in creating a continuous surface approximating the original surface from which the \(3\mathrm{D}\) points were sampled. In our survey, we group the methods for surface reconstruction from point clouds into two groups: surface-based and volume-based.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>从点云进行表面重建的过程是创建一个连续的表面，以近似原始表面，从中采样了\(3\mathrm{D}\)点。在我们的调查中，我们将从点云进行表面重建的方法分为两组：基于表面的方法和基于体积的方法。</p></div><p>Surface-based methods. These approaches focus on finding one or several parametric surfaces \({\mathcal{S}}^{r}\) approximating the input point cloud \(\mathcal{P}\) ,either in the form of triangles or two-dimensional (2D) patches, or by deforming parameterized enclosing envelops such as meshed spheres. The main limitation of surface-based methods with a single function \(\mathbf{f}\) is that the topology of the parameter domain \(\Omega\) must be equivalent to the topology of the true surface \(S\) ,which is usually unknown. Conversely, the main challenge for surface-based methods that define \({\mathcal{S}}^{r}\) with multiple functions for different regions is to guarantee consistent transitions between subsurfaces. In particular, it is difficult to keep the final surface intersection-free, manifold, and watertight.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>基于表面的方法。这些方法专注于寻找一个或多个参数化表面\({\mathcal{S}}^{r}\)，以近似输入点云\(\mathcal{P}\)，可以是三角形或二维（2D）补丁的形式，或者通过变形参数化的包围体，如网格球体。基于表面的方法的主要限制在于单一函数\(\mathbf{f}\)，即参数域\(\Omega\)的拓扑必须与真实表面\(S\)的拓扑相等，而真实表面通常是未知的。相反，基于表面的方法在为不同区域定义\({\mathcal{S}}^{r}\)的多个函数时，主要挑战在于确保子表面之间的一致过渡。特别是，保持最终表面无交集、流形且密封是困难的。</p></div><p>Volume-based methods. These methods segment a subset of \({\mathbb{R}}^{3}\) into interior (inside) and exterior (outside) subspaces. The surface is implicitly defined as the interface between the two subspaces. Most, but not all algorithms in this class formulate the problem as finding an implicit function indicating where a point in space is full (inside) or empty (outside). Surfaces reconstructed with volume-based methods are guaranteed to be watertight and intersection-free, but not necessarily manifold [2].</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>基于体积的方法。这些方法将\({\mathbb{R}}^{3}\)的一个子集分割为内部（内）和外部（外）子空间。表面隐式定义为两个子空间之间的接口。大多数，但并非所有此类算法将问题表述为寻找一个隐式函数，指示空间中的一个点是充满（内部）还是空的（外部）。使用基于体积的方法重建的表面保证是密封且无交集的，但不一定是流形[2]。</p></div><p>Mesh extraction. Surface-based methods typically directly yield a mesh,e.g.,by triangulating \(\Omega\) . In contrast,volume-based methods usually require an additional processing step. If the implicit field is discretized with tetrahedra using 3D Delaunay tetrahedralisation (3DT), a mesh can then be built from all triangles that are adjacent to one inside-tetrahedra and one outside-tetrahedra. Another option is the algorithm of Boissonnat and Oudot [59] that iteratively samples the implicit function \(F\) by drawing lines traversing the volume and building a triangle mesh from their intersection with the underlying surface \(S\) . One of the most popular methods for extracting a mesh from an implicit field is Marching Cubes [60], which discretizes the implicit function into voxels, constructs triangles inside each voxel that have at least one inside and one outside vertex, and extracts a triangulation as the union of all triangles. Recently, mesh extraction has also been addressed with deep learning methods [61], [62], [63], [64]. Neural meshing [64] specifically addresses the case where an implicit function is encoded in the weights of a neural network and aims to extract meshes with fewer triangles compared to Marching Cubes. A novel interesting approach in the direction of mesh extraction is the use of Voronoi diagrams to extract concise polygon meshes from an implicit function [61].</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>网格提取。基于表面的方法通常直接生成网格，例如，通过三角化\(\Omega\)。相比之下，基于体积的方法通常需要额外的处理步骤。如果隐式场使用三维德劳内四面体化（3DT）离散化为四面体，则可以从所有与一个内部四面体和一个外部四面体相邻的三角形构建网格。另一个选项是Boissonnat和Oudot的算法[59]，该算法通过绘制穿越体积的线来迭代采样隐式函数\(F\)，并从它们与基础表面\(S\)的交点构建三角网格。从隐式场提取网格的最流行的方法之一是Marching Cubes[60]，它将隐式函数离散化为体素，在每个体素内部构建至少有一个内部和一个外部顶点的三角形，并提取所有三角形的并集作为三角剖分。最近，网格提取也通过深度学习方法得到了关注[61]，[62]，[63]，[64]。神经网格化[64]特别解决了隐式函数编码在神经网络权重中的情况，并旨在提取比Marching Cubes更少三角形的网格。在网格提取方向上，一个新颖有趣的方法是使用Voronoi图从隐式函数中提取简洁的多边形网格[61]。</p></div><p>Robustness. When the point cloud \(\mathcal{P}\) is sampled densely and without noise, both surface-based and volume-based methods can provide theoretical guarantees about the topology and geometry of the reconstructed surface [2]. However, in this paper, we focus on the robustness of various methods to defect-laden input point clouds from 3D scanning.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>鲁棒性。当点云\(\mathcal{P}\)被密集且无噪声地采样时，基于表面和基于体积的方法都可以提供关于重建表面的拓扑和几何的理论保证[2]。然而，在本文中，我们关注各种方法对来自3D扫描的缺陷点云的鲁棒性。</p></div><p>Input. The characteristics of the input point cloud mainly depend on the sensor used for their acquisition.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>输入。输入点云的特征主要取决于用于获取它们的传感器。</p></div><p>LiDAR point clouds typically offer high precision and accuracy without a significant amount of noise or outliers due to the robustness of the active sensor to challenging conditions. However, LiDAR point clouds commonly suffer from occlusion due to the sensor's limited field of view.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>LiDAR点云通常提供高精度和准确性，且由于主动传感器对挑战条件的鲁棒性，噪声或异常值较少。然而，LiDAR点云通常由于传感器的有限视野而遭受遮挡。</p></div><p>Image-based point clouds are produced using a technique called multi-view stereo (MVS). Their quality heavily depends on the quality and quantity of input images. Pixels from overlapping images are matched which allows to compute their 3D location relative to the camera position. MVS can produce dense point clouds, especially in areas with abundant texture and features. However, poor lighting conditions or lack of texture can result in less accurate point clouds, and variations in image scales to strongly varying point densities [23].</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>基于图像的点云是使用称为多视角立体（MVS）的技术生成的。它们的质量在很大程度上取决于输入图像的质量和数量。重叠图像的像素被匹配，这使得可以计算它们相对于相机位置的三维位置。MVS可以生成密集的点云，特别是在纹理和特征丰富的区域。然而，较差的光照条件或缺乏纹理可能导致点云的准确性降低，并且图像尺度的变化会导致点密度的强烈变化[23]。</p></div><!-- Media --><!-- figureText: 4.1 Surface-based Surface reconstruction from point clouds 4.2 Volume-based 4.2.1 Interpolation 4.2.2 Approximation Mesh deformation \( \alpha \) -shapes I-O labeling Implicit func. (IF) Neural IF - Competing fronts [39] - \( \alpha \) -manifolds [41] - SSR [43] - SRUP [25] - ONet [53] - Point2Mesh [40] - \( \alpha \) -wrapping [42] - MVS via GC [44] - PSR [50] - DeepSDF [18 - High-res MVS [45] - MLS [51] - LIG [13] - SPSR [27] - DeepLS [12] - Scalable SR [47 - EPSR [52] - IGR [54] - WASURE [48] - ConvONet [11] - DeepDT [49] - P2S [14 - DGNN [15] - SAP [55] - POCO [17] - NKF 157 - NKSR [58] 4.1.1 Interpolation 4.1.2 Approximation Advancing front Selection-based Projection-based Patch fitting - Ball-pivoting [31] - PointTriNet [34] - Geometric struct. [36] - AtlasNet [37] - Regular interpolant [32] - IER-meshing [35] - DSE-meshing [16] - AtlasNetV2 [38] - Parallel ball-pivoting [33] --><img src="https://cdn.noedgeai.com/bo_d163rvn7aajc7388jqb0_4.jpg?x=130&#x26;y=119&#x26;w=1522&#x26;h=370&#x26;r=0"><p>Figure 3: Survey overview: Surface reconstruction algorithms can be categorized based on their primary representation approach: surface-based or volume-based. Within each category, methods are further classified as either interpolation-based or approximation-based. Subsequently, specific subgroups and various individual methods are identified under each classification, providing a comprehensive framework for understanding the landscape of surface reconstruction techniques.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>图3：调查概述：表面重建算法可以根据其主要表示方法分类：基于表面或基于体积。在每个类别中，方法进一步分类为插值型或近似型。随后，在每个分类下识别特定子组和各种单独方法，为理解表面重建技术的全景提供了一个全面的框架。</p></div><!-- Media --><h2>4 SURVEY</h2><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h2>4 调查</h2></div><p>In this section, we review important surface- and volume-based surface reconstruction methods and discuss their robustness against different types of point cloud defects. We also explore the numerous links between learning-based and traditional methods. Finally, we discuss recently emerging rendering-based methods for surface reconstruction.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在本节中，我们回顾重要的基于表面和基于体积的表面重建方法，并讨论它们对不同类型点云缺陷的鲁棒性。我们还探讨了基于学习的方法与传统方法之间的众多联系。最后，我们讨论了最近出现的基于渲染的表面重建方法。</p></div><h3>4.1 Surface-based reconstruction</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>4.1 基于表面的重建</h3></div><p>Surface-based approaches directly produce a surface, typically as a mesh,by connecting some of the points of \(\mathcal{P}\) or deforming a reference mesh.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>基于表面的方法直接生成表面，通常作为网格，通过连接一些点\(\mathcal{P}\)或变形参考网格。</p></div><h4>4.1.1 Surface-based interpolation</h4><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h4>4.1.1 基于表面的插值</h4></div><p>Most traditional surface-based approaches linearly interpolate between all or a selection of \(3\mathrm{D}\) points of \(\mathcal{P}\) . A critical aspect lies in how these points are connected into triangles, leading to a variety of algorithms.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>大多数传统的基于表面的算法在所有或部分\(3\mathrm{D}\)点之间进行线性插值。一个关键的方面在于这些点如何连接成三角形，从而导致各种算法的出现。</p></div><p>Advancing-front. Computing the 3DT of \(\mathcal{P}\) can be done by forming triangles for all triplets of points respecting the empty ball property, i.e., such that no other points lie within their circumsphere, which is the smallest sphere passing through three non-co-linear points. The Ball-pivoting algorithm [31] employs a greedy strategy to find such triplets and consists of several steps. First, it selects a seed triplet of points with the empty ball property such that their circumsphere has a radius close to a defined value related to the density of \(\mathcal{P}\) . This triplet defines the first triangle of the mesh, and its circumsphere forms a ball used for the rest of the algorithm. This ball is then pivoted around each edge of the triangle until it touches a new point, forming a new triplet, and hence a new triangle. Once all possible edges have been processed, the algorithm starts over with a new seed triangle until all points of \(\mathcal{P}\) have been considered.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>前进前沿。计算\(\mathcal{P}\)的3DT可以通过为所有满足空球性质的点三元组形成三角形来完成，即没有其他点位于它们的外接球内，该外接球是通过三个不共线点的最小球。Ball-pivoting算法[31]采用贪婪策略来寻找这样的三元组，并由几个步骤组成。首先，它选择一个具有空球性质的种子三元组，使得它们的外接球半径接近与\(\mathcal{P}\)的密度相关的定义值。这个三元组定义了网格的第一个三角形，其外接球形成了用于算法其余部分的球。然后，这个球围绕三角形的每条边进行旋转，直到接触到一个新点，形成一个新的三元组，从而形成一个新的三角形。一旦所有可能的边都被处理，算法将以新的种子三角形重新开始，直到考虑了所有\(\mathcal{P}\)点。</p></div><p>A similar approach to the Ball-pivoting algorithm, avoiding the fixed ball size, is the regular interpolant method [32]. It also starts by triangulating a seed triplet of points that adheres to the empty ball property. Then, for each existing edge \({p}_{i},{p}_{j}\) a new triangle \({p}_{i},{p}_{j},{p}_{k}\) is added to the triangulation. The point \({p}_{k}\) is chosen such that the new triangle has the smallest radius circumsphere for all \(p \in  \mathcal{P} \smallsetminus  \left\{  {{p}_{i},{p}_{j}}\right\}\) .</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>一种类似于Ball-pivoting算法的方法，避免了固定球大小，是规则插值法[32]。它同样从一个遵循空球性质的种子三元组开始进行三角剖分。然后，对于每个现有边\({p}_{i},{p}_{j}\)，向三角剖分中添加一个新的三角形\({p}_{i},{p}_{j},{p}_{k}\)。选择点\({p}_{k}\)，使得新三角形对于所有\(p \in  \mathcal{P} \smallsetminus  \left\{  {{p}_{i},{p}_{j}}\right\}\)具有最小的外接球半径。</p></div><p>A refinement of the Ball-pivoting algorithm [33] also use a ball of varying size, and additionally proposes a parallel implementation. Both follow-up works have enhanced the Ball-pivoting algorithm's robustness against nonuniform sampling. However, these methods remain sensitive to point cloud defects such as noise or large occlusions.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>Ball-pivoting算法[33]的一个改进也使用了可变大小的球，并额外提出了并行实现。这两个后续工作增强了Ball-pivoting算法对非均匀采样的鲁棒性。然而，这些方法仍然对点云缺陷（如噪声或大遮挡）敏感。</p></div><p>Selection-based. Similar to advancing-front techniques, some learning-based methods [34], [35] also iteratively build the triangulation from an initial set of candidate triangles. PointTriNet [34] computes the \(k\) -nearest neighbor graph of \(\mathcal{P}\) and creates seed triangles. Then,a first network selects some of these triangles based on their probability of being part of the final surface, which is obtained by considering their neighbouring points and already-formed triangles. Finally, a second network proposes new candidate triangles formed by points adjacent to selected triangles. The new candidates are processed by the first network and the algorithm continues for a user-defined number of iterations. As the loss function is the Chamfer distance between the input points and the reconstructed surface, this method can be trained without ground-truth meshes.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>基于选择。与前进前沿技术类似，一些基于学习的方法[34]，[35]也通过从初始候选三角形集迭代构建三角剖分。PointTriNet[34]计算\(k\)的最近邻图，并创建种子三角形。然后，第一个网络根据这些三角形成为最终表面一部分的概率进行选择，这个概率是通过考虑它们的邻近点和已形成的三角形获得的。最后，第二个网络提出由与选定三角形相邻的点形成的新候选三角形。新候选三角形由第一个网络处理，算法继续进行用户定义的迭代次数。由于损失函数是输入点与重建表面之间的Chamfer距离，因此该方法可以在没有真实网格的情况下进行训练。</p></div><p>The intrinsic-extrinsic ratio (IER) between two points is the ratio of the Euclidean distance and the geodesic distance along the true surface. An IER value near 1 for a pair of points suggests that the edge connecting them is likely to be part of the surface. IER-meshing [35] starts with a large set of seed triangles generated from the \(k\) -nearest neighbor graph of the point cloud. They then estimate the IER for the vertices of these triangles using an multilayer perceptron (MLP) supervised from a ground-truth mesh. Triangles whose vertices exhibit IER values close to 1 are then selected for the mesh, as this indicates a high probability of their edges being part of the actual surface. While they are robust against minor noise to the input point clouds, the aforementioned methods typically result in reconstructed surfaces that are neither manifold nor watertight.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>两个点之间的内在-外在比率（IER）是欧几里得距离与沿真实表面的测地距离的比率。对于一对点，IER值接近1表明连接它们的边很可能是表面的一部分。IER网格化[35]从点云的\(k\)最近邻图生成的大量种子三角形开始。然后，他们使用从真实网格监督的多层感知器（MLP）估计这些三角形顶点的IER。那些顶点的IER值接近1的三角形被选入网格，因为这表明它们的边很可能是实际表面的一部分。尽管它们对输入点云的轻微噪声具有鲁棒性，但上述方法通常导致重建的表面既不是流形也不是密闭的。</p></div><p>Projection-based. A notable example of projection-based methods is the algorithm by Boissonnat [36], which may be the earliest surface reconstruction algorithm [2]. This method starts by computing the tangent plane of each point, projecting their neighboring points onto these planes, computing a 2D Delaunay triangulation of the projected 2D point clouds, and merging these local reconstructions.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>基于投影。基于投影方法的一个显著例子是Boissonnat的算法[36]，这可能是最早的表面重建算法[2]。该方法首先计算每个点的切平面，将其邻近点投影到这些平面上，计算投影的二维点云的二维Delaunay三角剖分，并合并这些局部重建。</p></div><!-- Media --><!-- figureText: (a) Surface-based interpolation (b) Surface-based approximation (c) Volume-based interpolation (d) Volume-based approximation --><img src="https://cdn.noedgeai.com/bo_d163rvn7aajc7388jqb0_5.jpg?x=131&#x26;y=166&#x26;w=1536&#x26;h=332&#x26;r=0"><p>Figure 4: Examples of surface reconstruction algorithms: In (a), we exemplify a reconstruction from a surface-based interpolation approach. Close by points are connected with triangles to reconstruct the surface. In (b), we show a reconstruction of a surface-based approximation approach. An initial mesh, e.g., a plane, is deformed to fit to the input points. In (c), we show a volume-based interpolation. Input points are connected using a 3D Delaunay tetrahedralization. The resulting tetrahedra are then labelled as inside (dark blue) or outside the surface (red) and the interface triangles constitute the final mesh. In (d), we show a volume-based approximation. The surface is represented as an appropriate level set of an occupancy function.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>图4：表面重建算法的示例：在(a)中，我们展示了一种基于表面的插值方法的重建。相近的点通过三角形连接以重建表面。在(b)中，我们展示了一种基于表面的近似方法的重建。初始网格，例如一个平面，被变形以适应输入点。在(c)中，我们展示了一种基于体积的插值。输入点通过3D德劳内四面体化连接。生成的四面体被标记为在表面内部（深蓝色）或外部（红色），接口三角形构成最终网格。在(d)中，我们展示了一种基于体积的近似。表面被表示为占用函数的适当水平集。</p></div><!-- Media --><p>The use of tangent planes is difficult in areas with high curvature or for reconstructing thin structures. DSE-meshing [16] addresses these challenges by employing logarithmic maps as an alternative. Logarithmic maps offer local surface parametrizations around a point \(p\) based on the geodesics from that point, providing a more adaptable approach for complex geometries. This method uses an MLP to obtain approximate logarithmic maps for each point. Finally, neighboring maps are aligned and triangulated. This approach leads to fewer non-manifold edges compared to methods that process triangles independently. However, the surface may still not be watertight.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在高曲率区域或重建薄结构时，使用切平面是困难的。DSE网格化[16]通过采用对数映射作为替代方案来解决这些挑战。对数映射提供了基于从该点出发的测地线的局部表面参数化，为复杂几何体提供了更灵活的方法。该方法使用多层感知器（MLP）为每个点获取近似的对数映射。最后，相邻的映射被对齐并三角化。与独立处理三角形的方法相比，这种方法导致较少的非流形边。然而，表面仍然可能不是密封的。</p></div><h4>4.1.2 Surface-based approximation</h4><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h4>4.1.2 基于表面的近似</h4></div><p>Patch fitting. AtlasNet [37], one of the pioneering learning-based methods in surface reconstruction, employs an original approach. It starts with a triangulated \(2\mathrm{D}\) patch and uses a neural network to adjust its vertices' positions. This network is trained by minimizing the distance between the deformed surface and the point cloud, eliminating the need for actual mesh data for training purposes. Similar to interpolating methods, AtlasNet does not inherently ensure that the reconstructed surface is both watertight and manifold.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>补丁拟合。AtlasNet [37]是表面重建领域的开创性学习方法之一，采用了一种独特的方法。它从一个三角化的\(2\mathrm{D}\)补丁开始，并使用神经网络调整其顶点的位置。该网络通过最小化变形表面与点云之间的距离进行训练，消除了训练过程中对实际网格数据的需求。与插值方法类似，AtlasNet并不固有地确保重建的表面既是密封的又是流形的。</p></div><p>Mesh deformation. A variation of the same idea is the mesh-fitting approach, which starts with an intial mesh based on some of the input points [39] or a low-resolution Poisson [27] reconstruction [40], and adjusts the position of the vertices to fit the point cloud. Such methods demonstrate robustness in scenarios with missing data, but they require meticulous parameter tuning to effectively manage noise or outliers. A notable limitation is the fixed topology of the initial mesh throughout the reconstruction process. Consequently, if the initial mesh does not accurately reflect the true topology of the target surface, this discrepancy cannot be corrected later in the process. For example, if the initial mesh is convex and the desired surface includes holes, it can not be reconstructed with consistent orientation. A significant advantage of mesh deformation methods compared to other surface-based approaches is that they guarantee a watertight surface.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>网格变形。相同思想的一个变体是网格拟合方法，它基于一些输入点[39]或低分辨率的泊松重建[27][40]开始，调整顶点的位置以适应点云。这些方法在缺失数据的情况下表现出鲁棒性，但需要细致的参数调整以有效管理噪声或异常值。一个显著的限制是初始网格在整个重建过程中的拓扑是固定的。因此，如果初始网格未能准确反映目标表面的真实拓扑，这种差异在后续过程中无法纠正。例如，如果初始网格是凸的，而所需表面包含孔洞，则无法以一致的方向重建。与其他基于表面的方法相比，网格变形方法的一个显著优势是它们保证了密封的表面。</p></div><h3>4.2 Volume-based reconstruction</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>4.2 基于体积的重建</h3></div><p>Instead of directly generating a surface mesh, volume-based approaches consider discrete or continuous 3D volumes from which a mesh can be extracted. These methods offer a different perspective on the reconstruction process, initially emphasizing volume over surface geometry.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>基于体积的方法并不直接生成表面网格，而是考虑可以提取网格的离散或连续3D体积。这些方法为重建过程提供了不同的视角，最初强调体积而非表面几何。</p></div><h4>4.2.1 Volume-based interpolation</h4><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h4>4.2.1 基于体积的插值</h4></div><p>Volume-based interpolating methods commonly start by constructing a 3DT of the the convex hull of the point cloud \(\mathcal{P}\) into tetrahedra (see Fig. 4c). This 3DT is formed such that no point in \(\mathcal{P}\) lies within the circumspheres of any of these tetrahedra. For point clouds that are well distributed, the 3DT can be efficiently constructed with a time complexity of \(O\left( {n\log n}\right)\) [65] where \(n\) is the number of vertices. While the Delaunay triangulation itself does not directly yield a surface mesh,a dense-enough sampling of \(\mathcal{P}\) from \({\mathcal{S}}^{g}\) ensures that a subcomplex of the 3DT will accurately approximate both the geometry and the topology of \({\mathcal{S}}^{g}\) [2].</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>基于体积的插值方法通常从构建点云\(\mathcal{P}\)的凸包的3D德劳内四面体（见图4c）开始。这个3D德劳内四面体的构建方式是确保\(\mathcal{P}\)中的任何点都不位于这些四面体的外接球内。对于分布良好的点云，可以高效地构建3D德劳内四面体，时间复杂度为\(O\left( {n\log n}\right)\)[65]，其中\(n\)是顶点的数量。虽然德劳内三角剖分本身并不直接产生表面网格，但从\({\mathcal{S}}^{g}\)中对\(\mathcal{P}\)进行足够密集的采样可以确保3D德劳内四面体的子复合体将准确近似\({\mathcal{S}}^{g}\)的几何和拓扑[2]。</p></div><p>\(\alpha\) -shapes. One straightforward way to extract such a sub-complex from a 3DT involves two key steps: discarding all tetrahedra whose circumspheres are larger than a predetermined radius \(\alpha\) ,and then retaining only the boundary triangles, i.e., triangles between tetrahedra that are discarded and tetrahedra that are kept, resulting in the point cloud's \(\alpha\) -shape [41]. Like the Ball Pivoting algorithm,the selection of \(\alpha\) depends on the density of points. For samplings that are error-free and dense, \(\alpha\) -shapes,along with other interpolation methods [2], [36], [66], can offer provable guarantees of topological accuracy of the reconstructed surface [2]. A recent approach constructs a 3DT that is greedily refined and carved with an empty ball of size \(\alpha\) to reconstruct a watertight 2-manifold surface [42]. The surface strictly encloses the input point set by a positive user-defined offset.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>\(\alpha\) -形状。从3DT中提取这样的子复合体的一种简单方法涉及两个关键步骤：丢弃所有外接球半径大于预定半径的四面体\(\alpha\)，然后仅保留边界三角形，即丢弃的四面体与保留的四面体之间的三角形，从而得到点云的\(\alpha\) -形状[41]。与球体旋转算法类似，\(\alpha\)的选择依赖于点的密度。对于无误差且密集的采样，\(\alpha\) -形状以及其他插值方法[2]，[36]，[66]可以提供重建表面的拓扑准确性证明保证[2]。一种最近的方法构建了一个贪婪细化并用大小为\(\alpha\)的空球雕刻的3DT，以重建一个密闭的2-流形表面[42]。该表面通过正的用户定义偏移严格包围输入点集。</p></div><p>Inside-outside labeling. An alternative method to derive a surface from a 3DT is by labeling each tetrahedron as being inside or outside [15], [28], [43], [44], [45], [46], [47], [48], [67], [68], [69]. In this approach, every tetrahedron in the 3DT of \(\mathcal{P}\) is labeled as either inside or outside relative to \({\mathcal{S}}^{r}\) (dark blue and red regions in Fig. 4c). The surface is then defined as the interface between tetrahedra with different labels. This technique guarantees that the resulting surfaces are both intersection-free and watertight. The problem of labeling tetrahedra is typically formulated with a global energy under a form that can be efficiently minimized by a graph cut [70]. Unary inside/outside potentials are determined based on visibility information. Meanwhile, binary terms incorporate priors related to the smoothness or area of the reconstructed surface. This approach is robust to various moderate acquisition defects [28], [46], [68] and can handle large-scale scenes [47], [71]. In particular, Robust and Efficient Surface Reconstruction (RESR) [46] has a specific treatment to prevent tiny elongated tetrahedra from being wrongly labeled. DeepDT [49] uses a graph neural network (GNN) operating on a 3DT to predict the global energy parameters. Delaunay-Graph Neural Network (DGNN) [15] improves on this idea by integrating visibility information and using a scalable graph formulation operating on small subgraphs, allowing it to scale to large point clouds.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>内外部标记。通过将每个四面体标记为内部或外部[15]，[28]，[43]，[44]，[45]，[46]，[47]，[48]，[67]，[68]，[69]，从3DT中推导表面的另一种方法。在这种方法中，3DT中的每个四面体相对于\({\mathcal{S}}^{r}\)（图4c中的深蓝色和红色区域）被标记为内部或外部。然后，表面被定义为具有不同标签的四面体之间的接口。这项技术保证了生成的表面既无交集又密闭。标记四面体的问题通常以全局能量的形式进行表述，可以通过图切割有效地最小化[70]。基于可见性信息确定单一的内部/外部势。与此同时，二元项结合了与重建表面的光滑性或面积相关的先验。这种方法对各种适度的获取缺陷[28]，[46]，[68]具有鲁棒性，并且可以处理大规模场景[47]，[71]。特别是，鲁棒高效表面重建（RESR）[46]对防止小的细长四面体被错误标记有特定处理。DeepDT [49]使用在3DT上运行的图神经网络（GNN）来预测全局能量参数。Delaunay-图神经网络（DGNN）[15]通过整合可见性信息并使用在小子图上运行的可扩展图表述改进了这一想法，使其能够扩展到大点云。</p></div><h4>4.2.2 Volume-based approximation</h4><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h4>4.2.2 基于体积的近似</h4></div><p>Implicit functions. Implicit functions form the cornerstone of many popular volume-based surface approximation techniques. The seminal work by Hoppe et al. [25] pioneered this approach by defining an SDF based on the local tangent planes at each point. However, the computation of these tangent planes proved costly and susceptible to noise, as well as to variations in point density [51]. Over the years, implicit function methods have been refined and improved to address these challenges.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>隐式函数。隐式函数是许多流行的基于体积的表面近似技术的基石。Hoppe等人[25]的开创性工作通过在每个点处定义基于局部切平面的SDF（签名距离函数）开创了这一方法。然而，这些切平面的计算成本高且易受噪声以及点密度变化的影响[51]。多年来，隐式函数方法已被改进以应对这些挑战。</p></div><p>Arguably the most well-known method for surface reconstruction, Poisson surface reconstruction was introduced in 2006 by Kazhdan et al. [50]. The method uses an indicator function \(F\) and a level set that defines the reconstructed surface \({\mathcal{S}}^{r}\) . The main idea of the approach is that the Laplacian of \(F\) should equate to the divergence of a vector field \(\overrightarrow{N}\) defined by the oriented normals of the points of \(\mathcal{P}\) :</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>可以说，最著名的表面重建方法是由Kazhdan等人于2006年提出的泊松表面重建[50]。该方法使用指示函数\(F\)和定义重建表面\({\mathcal{S}}^{r}\)的水平集。该方法的主要思想是\(F\)的拉普拉斯应等于由\(\mathcal{P}\)的定向法线定义的向量场\(\overrightarrow{N}\)的散度：</p></div><p></p>\[{\Delta F} = \nabla  \cdot  \overrightarrow{N}. \tag{2}\]<p></p><p>The reconstruction process starts by building an octree from \(\mathcal{P}\) and defines a system of hierarchical functions for each cell of the tree. The function coefficients are computed by solving a sparse linear system, making the method time and memory-efficient.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>重建过程首先从\(\mathcal{P}\)构建一个八叉树，并为树的每个单元定义一组层次函数。通过求解稀疏线性系统计算函数系数，使得该方法在时间和内存上都高效。</p></div><p>While Poisson reconstruction yields a closed and smooth surface, it tends to erase small details and structures. Screened Poisson Surface Reconstruction (SPSR) [27] addresses this problem by constraining the implicit function, and thus reconstructed surface, to pass through or near all points of \(\mathcal{P}\) . Moreover,this refined variant adds Neumann boundary conditions [72], which allow the reconstructed surface to intersect the boundary of the domain on which \(F\) is defined. This was further refined by adding Dirichlet boundary conditions around a tight envelope enclosing the point cloud \(\mathcal{P}\) and leading to better reconstructions in areas of missing data [52]. Poisson methods generate watertight meshes and are robust against a wide array of acquisition defects of moderate amplitude. However, a notable prerequisite is the need for well-oriented normals, which can be a significant challenge in real-world data acquisition.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>虽然泊松重建产生了一个封闭且光滑的表面，但它往往会抹去小细节和结构。筛选泊松表面重建（SPSR）[27]通过约束隐式函数，从而使重建的表面通过或接近所有点\(\mathcal{P}\)来解决这个问题。此外，这种改进的变体增加了诺依曼边界条件[72]，允许重建的表面与定义\(F\)的区域边界相交。这进一步通过在包围点云\(\mathcal{P}\)的紧密包络周围添加狄利克雷边界条件得到了改进，从而在缺失数据区域实现了更好的重建[52]。泊松方法生成密闭的网格，并且对中等幅度的各种采集缺陷具有鲁棒性。然而，一个显著的前提是需要良好定向的法线，这在实际数据采集中可能是一个重大挑战。</p></div><p>Rather than being characterized by its Laplacian and boundary conditions,the implicit function \(F\) can be represented as a neural field with a neural network [18], [53], [73]. This broad category of methods is further subdivided into three distinct subgroups based on the nature of the network employed: set-based, grid-based, or neighborhood-based. Each subgroup represents a unique approach to leveraging neural networks for the representation of implicit functions.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>隐式函数\(F\)可以被表示为一个神经场，使用神经网络，而不是通过其拉普拉斯算子和边界条件来表征[18]，[53]，[73]。这一广泛的方法类别进一步根据所使用网络的性质分为三种不同的子组：基于集合的、基于网格的或基于邻域的。每个子组代表了一种独特的方法，利用神经网络来表示隐式函数。</p></div><p>Set-based neural implicit functions (NIFs). This first class of approaches consider the input point cloud as an unordered set of points and compute a global embedding for its global structure. Occupancy Networks (ONet) [53] defines \(F\) as a fully-connected network (FCN) conditioned by the input point cloud \(\mathcal{P}\) . This network is trained to predict whether a set of preset points lie inside or outside the surface \({\mathcal{S}}^{g}\) . To accurately train the network,true watertight surfaces are required for reference, such as those found in some CAD-based object databases.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>基于集合的神经隐式函数（NIFs）。这一类方法将输入点云视为无序的点集，并计算其全局结构的全局嵌入。占用网络（ONet）[53]将\(F\)定义为一个完全连接的网络（FCN），以输入点云\(\mathcal{P}\)为条件。该网络经过训练以预测一组预设点是否位于表面\({\mathcal{S}}^{g}\)的内部或外部。为了准确训练网络，需要真实的密闭表面作为参考，例如在某些基于CAD的物体数据库中找到的表面。</p></div><p>DeepSDF [18] takes a different approach by conditioning \(F\) on a latent shape code optimized for a given input point cloud \(\mathcal{P}\) during inference. This optimization is facilitated by an auto-decoder network trained on a collection of shapes. However, the optimization process requires accurate signed distance values for the input point cloud, which can be challenging for complex or ambiguously oriented shapes.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>DeepSDF [18]采取了不同的方法，通过在推理过程中将\(F\)条件化为针对给定输入点云\(\mathcal{P}\)优化的潜在形状编码。这一优化是通过在一组形状上训练的自编码器网络来实现的。然而，优化过程需要输入点云的准确有符号距离值，这对于复杂或模糊定向的形状可能具有挑战性。</p></div><p>The Local Implicit Grid (LIG) [13] and DeepLS [12] approaches split the input point cloud \(\mathcal{P}\) into overlapping subregions and process them independently with weight-sharing networks. A benefit of this approach is that similar areas belonging to different objects, such as flat surfaces on tabletops or floors, are processed uniformly, thus reducing the risk of the network overfitting to specific training scenes. However, as DeepSDF, these techniques also require true values of the implicit function \(F\) for the shape during inference. Furthermore, the dimension of the subregions is a critical parameter that requires careful calibration to ensure successful reconstruction.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>局部隐式网格（LIG）[13]和DeepLS [12]方法将输入点云\(\mathcal{P}\)划分为重叠的子区域，并使用权重共享网络独立处理它们。这种方法的一个好处是，属于不同物体的相似区域，例如桌面或地板上的平面，能够统一处理，从而减少网络对特定训练场景的过拟合风险。然而，与DeepSDF一样，这些技术在推理过程中也需要隐式函数\(F\)的真实值。此外，子区域的维度是一个关键参数，需要仔细校准以确保成功重建。</p></div><p>Implicit Geometric Regularisation (IGR) [54] proposes a different approach in which a FCN is optimized during inference for each test shape such that the signed distance's 0 -level set goes through the points of \(\mathcal{P}\) and its Laplacian follows the points normal. As this approach is optimized for each shape independently, it does not require true meshes for supervision, but it also cannot learn shape priors.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>隐式几何正则化（IGR）[54]提出了一种不同的方法，其中在推理过程中为每个测试形状优化一个FCN，使得有符号距离的0级集通过点\(\mathcal{P}\)，其拉普拉斯遵循点的法线。由于这种方法是针对每个形状独立优化的，因此不需要真实网格进行监督，但它也无法学习形状先验。</p></div><p>Grid-based NIFs. As they rely on a single point cloud embedding to define the implicit function \(F\) ,set-based NIF methods tend to discard local point cloud information, which often results in oversmoothing [11]. To address this issue, the 3D space can be discretized into a voxel grid which can be used to learn local features.. Then, 2D or 3D U-Nets [74], [75] process the resulting maps to capture local and global shape information and, in turn, connect a fully-connected network predicting occupancy. Convolutional Occupancy Networks (ConvONet) [11] exemplifies this approach and also proposes a sliding-window strategy to scale to larger scans. However, since the content of the windows must be consistent with the scale of training shapes, this approach can be computationally expensive for large scenes.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>基于网格的NIFs。由于它们依赖于单一的点云嵌入来定义隐式函数\(F\)，基于集合的NIF方法往往会丢弃局部点云信息，这通常会导致过度平滑[11]。为了解决这个问题，可以将3D空间离散化为一个体素网格，以学习局部特征。然后，2D或3D U-Net [74]，[75]处理生成的地图，以捕捉局部和全局形状信息，并进而连接一个预测占用的完全连接网络。卷积占用网络（ConvONet）[11]就是这种方法的一个例子，并且还提出了一种滑动窗口策略，以扩展到更大的扫描。然而，由于窗口的内容必须与训练形状的规模一致，因此这种方法在处理大场景时可能计算开销较大。</p></div><p>Using a similar encoder architecture, Shape As Points (SAP) [55] merges neural implicit fields with Poisson reconstruction techniques. The process starts by densifying the input point cloud and estimating the point normals. This enhanced point cloud is then fed into a differentiable Poisson solver, which determines the occupancy for each cell of a regular grid (cf. the indicator function \(F\) of Poisson). These predicted values are then compared to true occupancies with the L2 loss, leading to a fully differentiable pipeline where point encoding, densification, and normal estimation are all learned end-to-end. Shape As Points actually comes in two flavors: a purely optimisation-based Shape As Points \(\left( {\mathrm{{SAP}}}^{ * }\right)\) ,which does not use any training,and a learning-based setting, for which we retain the name SAP.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>使用类似的编码器架构，Shape As Points (SAP) [55] 将神经隐式场与泊松重建技术相结合。该过程首先通过加密输入点云并估计点法线来开始。然后将增强的点云输入到可微分的泊松求解器中，该求解器确定规则网格中每个单元的占用情况（参见泊松的指示函数 \(F\)）。这些预测值与真实占用情况通过L2损失进行比较，从而形成一个完全可微分的管道，其中点编码、加密和法线估计都是端到端学习的。Shape As Points 实际上有两种形式：一种是纯优化基础的 Shape As Points \(\left( {\mathrm{{SAP}}}^{ * }\right)\)，不使用任何训练，另一种是基于学习的设置，我们保留名称 SAP。</p></div><p>Neural Kernel Fields (NKF) [57] also combine learned features with techniques of the classical Poisson surface reconstruction. Input points are encoded into a feature grid, which is then used to compute local kernel basis functions for every point. Similar to PSR, the function coefficients are computed by solving a sparse linear system and using occupancy information from oriented normals. Recently, NKF has been updated to make the method more scalable and robust to noise, by using hierarchical features from multiple voxel grids at different resolutions and aligning the implicit function gradients with the normal direction of the input points [56], [58]. In contrast to the original Poisson Surface Reconstruction, the aforementioned methods allow to incorporate learned priors into the implicit function computation. Additionally, for SAP the input point cloud does not need to be equipped with oriented normals.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>神经核场 (NKF) [57] 也将学习到的特征与经典的泊松表面重建技术相结合。输入点被编码为特征网格，然后用于计算每个点的局部核基函数。与PSR类似，函数系数是通过求解稀疏线性系统并使用来自定向法线的占用信息来计算的。最近，NKF 已经更新，使该方法在噪声下更具可扩展性和鲁棒性，通过使用来自不同分辨率的多个体素网格的层次特征，并将隐式函数梯度与输入点的法线方向对齐 [56]，[58]。与原始的泊松表面重建相比，上述方法允许将学习到的先验信息纳入隐式函数计算中。此外，对于SAP，输入点云不需要配备定向法线。</p></div><p>Neighborhood-based NIFs. The choice of the voxel size for 3D convolution-based methods is often critical: opting for small voxels increases computational and memory requirements, whereas coarse grids discard geometric details. Points2Surf (P2S) [14] proposes an alternative approach that predicts signed distance functions by encoding both the local neighborhood of each point (for unsigned distance prediction) and a downsampled representation of the entire shape (for orientation prediction). Leveraging \(k\) -nearest neighbor sampling, this method offers better adaptability to variations in point density. However, it may result in extended processing times since the local neighborhoods of each point needs to be processed individually during the inference stage. Point Convolution for Surface Reconstruction (POCO) [17] proposes instead to use a continuous convolution backbone [76] to learn point features without spatial discretization. The occupancy of each point is then determined by an attention-based scheme.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>基于邻域的NIFs。对于基于3D卷积的方法，体素大小的选择往往至关重要：选择小体素会增加计算和内存需求，而粗网格则会丢失几何细节。Points2Surf (P2S) [14] 提出了一种替代方法，通过编码每个点的局部邻域（用于无符号距离预测）和整个形状的下采样表示（用于方向预测）来预测带符号的距离函数。利用 \(k\) -最近邻采样，该方法提供了更好的适应点密度变化的能力。然而，由于在推理阶段需要单独处理每个点的局部邻域，这可能导致处理时间延长。表面重建的点卷积 (POCO) [17] 则建议使用连续卷积骨干 [76] 来学习点特征，而不进行空间离散化。然后通过基于注意力的方案确定每个点的占用情况。</p></div><h3>4.3 Rendering-based reconstruction</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>4.3 基于渲染的重建</h3></div><p>Our paper specifically addresses surface reconstruction methods from 3D point clouds. However, a new emerging field is the reconstruction of surfaces directly from images using rendering techniques from computer graphics. Originally, so-called novel view synthesis methods [77], [78] were specifically designed for generating new views of an object or scene starting from a set of given images with their accurate pose. These methods present many advantages, including the ability to generate photo-realistic content, to deal with complex lighting and transparencies [79], and the fact that they do not rely on complex sensors. Recently, more and more rendering-based methods have been designed specifically for surface reconstruction [80], [81], [82]. They can be divided into the two categories, neural radiance fields (NeRFs) and 3D Gaussian Splatting, and are closely related to the two corresponding, more general, principles from computer graphics, namely ray tracing and rasterization.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>我们的论文专门讨论从3D点云进行表面重建的方法。然而，一个新兴领域是直接从图像重建表面，使用计算机图形学中的渲染技术。最初，所谓的新视图合成方法 [77]，[78] 是专门为从一组给定图像及其准确姿态生成对象或场景的新视图而设计的。这些方法具有许多优点，包括生成照片真实内容的能力、处理复杂光照和透明度 [79] 的能力，以及它们不依赖于复杂传感器的事实。最近，越来越多的基于渲染的方法专门为表面重建而设计 [80]，[81]，[82]。它们可以分为两类，神经辐射场 (NeRFs) 和3D高斯溅射，与计算机图形学中的两种相应的更一般的原理密切相关，即光线追踪和光栅化。</p></div><h4>4.3.1 NeRF and Gaussian Splatting</h4><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h4>4.3.1 NeRF 和高斯溅射</h4></div><p>NeRF encode scenes within the weights of a neural network [77] by mapping 3D locations and viewing directions with a volume density and emitted color. Although initially designed for novel view synthesis, extensions such as NeuS [83] and VolSDF [84] reparameterize the volume density using signed distance functions, allowing explicit surface extraction from radiance fields. NeRF have also been extended from object-level to entire scenes, such as Urban Radiance Fields [85], which incorporate point clouds, and Neuralangelo [86], which employs instant neural graphics primitives to improve reconstruction speed.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>NeRF通过将3D位置和视角映射到体积密度和发射颜色，将场景编码到神经网络的权重中 [77]。尽管最初是为新视图合成设计的，但扩展如NeuS [83] 和 VolSDF [84] 使用带符号距离函数重新参数化体积密度，允许从辐射场中显式提取表面。NeRF还从对象级扩展到整个场景，例如城市辐射场 (Urban Radiance Fields) [85]，该场景结合了点云，以及Neuralangelo [86]，该场景采用即时神经图形原语以提高重建速度。</p></div><p>3D Gaussian Splatting [87] provides an efficient rendering technique based on differentiable rasterization of 3D Gaussians initialized from sparse point clouds. While primarily aimed at novel view synthesis, preliminary works like SuGaR [82] and Gaussian Frosting [88] explore efficient mesh reconstruction and real-time rendering within this framework. These methods highlight the potential of rasterization-based techniques for surface reconstruction, although they are still in the early stages.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>3D高斯溅射 [87] 提供了一种基于从稀疏点云初始化的3D高斯的可微光栅化的高效渲染技术。虽然主要针对新视图合成，但像SuGaR [82] 和 Gaussian Frosting [88] 这样的初步工作在此框架内探索高效的网格重建和实时渲染。这些方法突显了基于光栅化的技术在表面重建中的潜力，尽管它们仍处于早期阶段。</p></div><h2>5 BENCHMARK SETUP</h2><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h2>5 基准设置</h2></div><p>In this section, we propose a series of experiments to benchmark surface reconstruction algorithms discussed in the previous section. We first describe our approach to generate realistic point clouds (Sec. 5.1) and detail the different datasets that we use (Sec. 5.2). We then define the experimental setup (Sec. 5.3), the methods evaluated (Sec. 5.4) and finally the benchmark's metrics (Sec. 5.5).</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在本节中，我们提出了一系列实验，以基准测试前一节讨论的表面重建算法。我们首先描述生成真实点云的方法（第5.1节），并详细说明我们使用的不同数据集（第5.2节）。然后，我们定义实验设置（第5.3节）、评估的方法（第5.4节），最后是基准的指标（第5.5节）。</p></div><h3>5.1 Synthetic scanning for point cloud generation</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>5.1 合成扫描以生成点云</h3></div><p>In an ideal scenario, we would use real point cloud acquisitions and compare the reconstructed surfaces with the associated true surfaces. However, it is often impractical to obtain the true surfaces of real objects, as it requires high-density and error-free scans as well as substantial manual intervention. Many existing MVS benchmarks derive their point clouds from images, and the true surfaces are obtained with extensive acquisitions from multiple stationary Light Detection and Ranging (LiDAR) scans [20], [21], [22], [23], [24]. However, even these surfaces may be incomplete or not watertight due to occlusions. Additionally, these datasets are typically limited in scale, featuring only a few objects or scenes. As a result, while they are valuable for evaluation purposes, they are less suitable for training models. Instead, we propose to use synthetic surfaces from extensive shape collections for training, since they come with strong topological guarantees. In order to reproduce the defects commonly encountered during real scans, such as density variations and missing data from occlusion, we implement realistic artificial scanning procedures, illustrated in Fig. 6.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在理想情况下，我们将使用真实的点云采集，并将重建的表面与相关的真实表面进行比较。然而，获取真实物体的真实表面往往不切实际，因为这需要高密度和无误差的扫描以及大量的人工干预。许多现有的多视图立体（MVS）基准测试从图像中导出点云，真实表面是通过对多个静态光学探测和测距（LiDAR）扫描进行广泛采集获得的[20]，[21]，[22]，[23]，[24]。然而，即使这些表面也可能由于遮挡而不完整或不密封。此外，这些数据集通常在规模上有限，仅包含少数对象或场景。因此，尽管它们在评估方面很有价值，但不太适合用于训练模型。相反，我们建议使用来自广泛形状集合的合成表面进行训练，因为它们具有强大的拓扑保证。为了重现真实扫描中常见的缺陷，如密度变化和由于遮挡而缺失的数据，我们实施了现实的人工扫描程序，如图6所示。</p></div><!-- Media --><!-- figureText: (a) High Quality Mesh (b) Real MVS (c) Real range scan (f) Synthetic range scan (d) Uniform sampling (e) Synthetic MVS --><img src="https://cdn.noedgeai.com/bo_d163rvn7aajc7388jqb0_8.jpg?x=290&#x26;y=145&#x26;w=1244&#x26;h=880&#x26;r=0"><p>Figure 5: Synthetic and real point clouds: Real world point cloud acquisitions (b,c) have defects such as missing data from occlusion. However, surface reconstruction methods are often tested on point clouds that are produced by directly and uniformly sampling a ground truth surface (d). While this sampling strategy allows to add artificial noise, it cannot realistically model missing data from occlusion. Instead, we test methods on synthetic MVS (e) and synthetic range scans (f) which allows us to reproduce realistic sampling defects.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>图5：合成和真实点云：真实世界的点云采集（b,c）存在缺陷，如由于遮挡而缺失的数据。然而，表面重建方法通常在通过直接和均匀采样真实表面（d）生成的点云上进行测试。虽然这种采样策略允许添加人工噪声，但无法真实地模拟由于遮挡而缺失的数据。相反，我们在合成多视图立体（e）和合成范围扫描（f）上测试方法，这使我们能够重现真实的采样缺陷。</p></div><!-- Media --><h4>5.1.1 Synthetic MVS</h4><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h4>5.1.1 合成多视图立体</h4></div><p>We propose a procedure designed to replicate the typical characteristics of point clouds obtained from MVS techniques. While our approach doesn't follow an MVS pipeline, it aims to produce point clouds with similar defects as those found in MVS-generated point clouds. However, it does not model failure cases from MVS methods, such as the lack of points in areas with difficult lighting conditions or without texture, or strong variations in density and noise levels.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>我们提出了一种旨在复制从多视图立体技术获得的点云典型特征的程序。虽然我们的方法不遵循MVS管道，但它旨在生成具有与MVS生成的点云相似缺陷的点云。然而，它并不模拟MVS方法的失败案例，例如在光照条件困难或没有纹理的区域缺少点，或密度和噪声水平的强烈变化。</p></div><p>We randomly position virtual sensors around a sphere enclosing the object, and shoot rays towards random points on the object's circumsphere. A new 3D point is recorded at the first intersection of the ray with the object's surface. Further intersections are ignored, leading to similar occlusion patterns as in real world acquisitions. We create two types of scans using this methodology: (i) sparse point clouds, consisting of approximately 3,000 points per object; (ii) dense point clouds, comprising around 10,000 points per object, with 10% of these points being outliers. Consistent with the approach suggested by Peng et al. [11], we apply Gaussian noise to each point position, characterized by a zero mean and a standard deviation of \({0.5}\%\) of the bounding box diagonal. Both sparse and dense scans are conducted from 10 uniformly distributed sensor positions.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>我们随机将虚拟传感器放置在包围物体的球体周围，并向物体的外接球上的随机点发射光线。在光线与物体表面的第一次交点处记录一个新的3D点。进一步的交点被忽略，从而导致与真实世界采集相似的遮挡模式。我们使用这种方法创建两种类型的扫描：（i）稀疏点云，每个物体约包含3,000个点；（ii）密集点云，每个物体约包含10,000个点，其中10%的点为离群点。与Peng等人[11]建议的方法一致，我们对每个点的位置施加高斯噪声，其特征为零均值和边界框对角线的标准差\({0.5}\%\)。稀疏和密集扫描均从10个均匀分布的传感器位置进行。</p></div><h4>5.1.2 Synthetic range scanning</h4><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h4>5.1.2 合成范围扫描</h4></div><p>We use a modified version of the range scanning procedure from the surface reconstruction benchmark of Berger et al. [19]. We choose five distinct scanning settings, each presenting varying levels of difficulty, to scan each shape:</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>我们使用Berger等人[19]的表面重建基准的范围扫描程序的修改版本。我们选择五种不同的扫描设置，每种设置呈现不同的难度级别，以扫描每种形状：</p></div><ul>
<li>LR: Low resolution to replicates point clouds obtained from long-range scanning;</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>LR：低分辨率，复制从长距离扫描获得的点云；</li>
</ul></div><ul>
<li>HR: High resolution with close to no defects;</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>HR：高分辨率，几乎没有缺陷；</li>
</ul></div><ul>
<li>HRN: Noisy acquisition by adding random jitter on the point positions;</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>HRN：通过在点位置添加随机抖动进行噪声采集；</li>
</ul></div><ul>
<li>HRO: Outliers by adding points uniformly sampled the bounding box of the object;</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>HRO：通过在物体的边界框中均匀采样添加离群点；</li>
</ul></div><ul>
<li>HRNO: Noise and outliers combines the last two defects. See the supplementary material for the exact numbers and the original benchmark paper [19] for further details.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>HRNO：噪声和离群点结合了最后两个缺陷。有关确切数字，请参见补充材料，更多详细信息请参见原始基准论文[19]。</li>
</ul></div><h3>5.2 Datasets</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>5.2 数据集</h3></div><p>To train and evaluate various surface reconstruction algorithms from point clouds, we use a mix of synthetic and real shapes. See the supplementary material for visual examples.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>为了训练和评估各种从点云中重建表面的算法，我们使用合成和真实形状的混合。有关视觉示例，请参见补充材料。</p></div><p>Training sets. To have enough shapes to train deep networks, we use the synthetic and closed shapes from ShapeNet [89] and ModelNet [90]. Point clouds are generated using our MVS procedure, and the true surfaces are processed with ManifoldPlus [91] to make them watertight. We generate point clouds with 3000 and 10,000 points for ScanNet, and 3000 points for ModelNet as they are typically simpler models. Following the standard practice in this field, we use Choy et al.'s [92] 13-class subset of ShapeNet and the corresponding train/val/test split. We use the training sets to parametrize non-learning-based methods, ensuring a fair comparison across different algorithms.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>训练集。为了拥有足够的形状来训练深度网络，我们使用来自ShapeNet（原词）和ModelNet（原词）的合成和封闭形状。点云是使用我们的MVS程序生成的，真实表面经过ManifoldPlus（原词）处理，以确保其密闭性。我们为ScanNet生成3000和10000个点的点云，为ModelNet生成3000个点的点云，因为它们通常是更简单的模型。按照该领域的标准做法，我们使用Choy等人（原词）的ShapeNet的13类子集及其相应的训练/验证/测试划分。我们使用训练集来参数化非学习基础的方法，确保不同算法之间的公平比较。</p></div><p>Evaluation. We evaluate the methods using five shapes from the benchmark of Berger et al. [19] with challenging features, such as intricate details and complex topology. These shapes present a higher reconstruction difficulty compared to those in ModelNet. For each shape, we generate 4 point clouds: with 3000 and 10,000, and using synthetic MVS and range scanning procedures. For qualitative evaluation, we also consider real scans, including open surfaces. We select a range scan from Tanks and Temples [24] (Truck), and two MVS point clouds from DTU [21] (scan1) and from Middlebury [20] (Temple), each subsampled to 50,000 points.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>评估。我们使用Berger等人（原词）基准中的五个具有挑战性特征的形状来评估这些方法，例如复杂的细节和复杂的拓扑。这些形状的重建难度高于ModelNet中的形状。对于每个形状，我们生成4个点云：3000个和10000个点，使用合成MVS和范围扫描程序。对于定性评估，我们还考虑真实扫描，包括开放表面。我们从Tanks and Temples（原词）（卡车）中选择一个范围扫描，从DTU（原词）（扫描1）和Middlebury（原词）（寺庙）中选择两个MVS点云，每个点云都下采样到50000个点。</p></div><h3>5.3 Design of the experiments</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>5.3 实验设计</h3></div><p>We design a series of experiments (Tab. 1) to thoroughly evaluate surface reconstruction models.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>我们设计了一系列实验（表1）以全面评估表面重建模型。</p></div><p>Evaluation of methods with dataset-driven parameterization. We benchmark both learning-based methods and traditional optimization-based methods that have parameters that can be set according to a given dataset and which can be evaluated on a complete dataset.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>使用数据集驱动参数化的方法评估。我们基准测试了学习基础的方法和传统的基于优化的方法，这些方法的参数可以根据给定的数据集进行设置，并且可以在完整的数据集上进行评估。</p></div><ul>
<li>(E1) In-distribution. We trained models on the ShapeNet training set and test on its test set. All point clouds are generated using the same MVS scanning procedure, featuring 3000 points with Gaussian noise (zero mean, standard deviation of 0.5% of the bounding box diagonal). This experiment assesses the models' ability to handle sparse point clouds, to complete missing data, and to eliminate noise.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>(E1) 在分布内。我们在ShapeNet训练集上训练模型，并在其测试集上进行测试。所有点云都是使用相同的MVS扫描程序生成的，具有3000个点和高斯噪声（均值为零，标准差为边界框对角线的0.5%）。该实验评估模型处理稀疏点云、补全缺失数据和消除噪声的能力。</li>
</ul></div><ul>
<li>(E2) Out-of-distribution - unseen point cloud characteristics. We test models trained in E1 on denser point clouds with 10,000 points with the same 0.5% Gaussian noise, and with the addition of 10% outliers. 5 This tests the ability of the model to generalize to different point cloud characteristics.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>(E2) 超出分布 - 未见点云特征。我们在E1中训练的模型在更密集的点云上进行测试，具有10000个点，噪声同样为0.5%的高斯噪声，并增加了10%的离群点。5 这测试了模型对不同点云特征的泛化能力。</li>
</ul></div><ul>
<li>(E3) Out-of-distribution - unseen shape categories: less complex. We evaluate models from E1 on Mod-elNet categories not present in the ShapeNet training set, maintaining the same point cloud characteristics. This explores generalization to new shape categories in an easy setting.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>(E3) 超出分布 - 未见形状类别：较少复杂。我们在ShapeNet训练集中不存在的ModelNet类别上评估E1中的模型，保持相同的点云特征。这探讨了在简单设置中对新形状类别的泛化。</li>
</ul></div><ul>
<li>(E4) Out-of-distribution - unseen shape categories: more complex. We train the learning methods on the simpler shapes from ModelNet and evaluate them on the test set of ShapeNet. Here, we assess whether learning methods can generalize from simple shapes to more complex ones, a difficult out-of-distribution setting.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>(E4) 超出分布 - 未见形状类别：更复杂。我们在ModelNet的简单形状上训练学习方法，并在ShapeNet的测试集上进行评估。在这里，我们评估学习方法是否能够从简单形状泛化到更复杂的形状，这是一个困难的超出分布设置。</li>
</ul></div><p>Evaluation of methods without dataset-driven parameterization. As the tested neural optimization-based methods are significantly slower than learning-based and traditional optimization-based methods (several minutes v.s a few seconds for a single shape), we had to evaluate them separately, on a much smaller dataset than the ShapeNet or ModelNet test sets (which contain several thousands shapes).</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>没有数据集驱动参数化的方法评估。由于测试的神经优化基础方法显著慢于学习基础和传统优化基础方法（单个形状几分钟对比几秒），我们不得不在比ShapeNet或ModelNet测试集（包含几千个形状）小得多的数据集上单独评估它们。</p></div><!-- Media --><!-- figureText: (a) Synthetic MVS (b) Synthetic range scanning --><img src="https://cdn.noedgeai.com/bo_d163rvn7aajc7388jqb0_9.jpg?x=912&#x26;y=119&#x26;w=750&#x26;h=424&#x26;r=0"><p>Figure 6: Synthetic scanning: We randomly place sensors ( on bounding spheres with multiple radii around an object. To produce MVS-like point clouds, we consider rays (—) from sensors aiming at uniformly sampled points on the circumsphere of the object (a). This produces non-uniform point clouds with self-occlusions similar to real MVS point clouds. For synthetic range scanning, we use a modified version of Berger et al.'s [19] pipeline, which considers rays arranged on a uniform line grid aiming at the object (b). This produces point clouds with uniformity and self-occlusions similar to real range scanning point clouds.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>图6：合成扫描：我们随机放置传感器（在物体周围的多个半径的边界球上）。为了生成类似MVS的点云，我们考虑从传感器发出的光线（—），这些光线指向物体的外接球上均匀采样的点（a）。这产生了具有自遮挡的非均匀点云，类似于真实的MVS点云。对于合成范围扫描，我们使用Berger等人（原词）的方法的修改版本，该方法考虑在均匀线网格上排列的光线，指向物体（b）。这产生了具有均匀性和自遮挡的点云，类似于真实的范围扫描点云。</p></div><!-- Media --><ul>
<li>(E5) Shape variety with defects. We evaluate both neural and traditional optimization-based methods that do not require parameterization based on a training set on Berger et al.'s synthetic range-scanning dataset.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>(E5) 具有缺陷的形状多样性。我们评估不需要基于训练集参数化的神经和传统优化基础方法，使用Berger等人（原词）的合成范围扫描数据集。</li>
</ul></div><p>Evaluation of all methods on a common ground. Last, we evaluate all types of methods on the same, small-enough datasets, featuring both synthetic and real point clouds.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在共同基础上评估所有方法。最后，我们在相同的、足够小的数据集上评估所有类型的方法，包含合成和真实点云。</p></div><ul>
<li>(E6) Synthetic data with ground truth (quantitative evaluation). We compare learning- and optimization-based methods for the MVS-scanned version of five shapes from Berger et al.'s dataset, which do not correspond to any of ShapeNet's categories but are comparable in complexity. We use the models trained in E1.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>(E6) 具有真实值的合成数据（定量评估）。我们比较学习和优化基础方法在Berger等人（原词）数据集中五个形状的MVS扫描版本，这些形状不对应于ShapeNet的任何类别，但在复杂性上是可比的。我们使用在E1中训练的模型。</li>
</ul></div><ul>
<li>(E7) Real data without ground truth (qualitative evaluation). Finally, we compare the learning-based network trained in E1 to optimization-based methods on real point clouds obtained by MVS and range scanning. As these real shapes do not have a ground truth surface, we only perform qualitative evaluation.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>(E7) 没有真实值的真实数据（定性评估）。最后，我们将E1中训练的基于学习的网络与基于优化的方法在通过MVS和范围扫描获得的真实点云上进行比较。由于这些真实形状没有真实值表面，我们仅进行定性评估。</li>
</ul></div><h3>5.4 Evaluated surface reconstruction methods</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>5.4 评估的表面重建方法</h3></div><p>In this section, we offer a concise overview and some specifics regarding the implementation of the methods evaluated in our benchmark. For a more comprehensive analysis, please refer to our detailed survey presented in Sec. 4.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在本节中，我们提供了对我们基准中评估方法的简要概述和一些具体细节。有关更全面的分析，请参阅我们在第4节中提供的详细调查。</p></div><p>To ensure a fair evaluation of traditional methods, when running experiments with a training set (E1-E4), we perform a grid-search on the parameters and select the configuration with the best mean volumetric IoU on the training set. In the experiments E5-E7, we use default parameters for all optimization methods.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>为了确保对传统方法的公平评估，在使用训练集（E1-E4）进行实验时，我们对参数进行网格搜索，并选择在训练集上具有最佳平均体积IoU的配置。在实验E5-E7中，我们对所有优化方法使用默认参数。</p></div><p>Learning-based methods. The parameters of these methods are learned on a training set.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>基于学习的方法。这些方法的参数是在训练集上学习的。</p></div><p>Table 1: Benchmark setup: We propose several experiments to evaluate the robustness of surface reconstruction models. In E1 to E4, we train learning and traditional methods on a set of shapes and evaluate them on a test set with varying characteristics: identical (E1), with different point cloud defects (E2), with simpler (E3) or more complex (E4) shapes. We evaluate on ShapeNet and ModelNet, with synthetic MVS point clouds. In E5, we evaluate neural-based and traditional optimization methods that do not tune their parameters; we use the few but varied synthetic range scans of Berger et al.’s dataset. In E6 and E7, we compare all methods quantitatively and qualitatively on synthetic and real point clouds.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>表1：基准设置：我们提出了几个实验来评估表面重建模型的鲁棒性。在E1到E4中，我们在一组形状上训练学习和传统方法，并在具有不同特征的测试集上进行评估：相同（E1），具有不同点云缺陷（E2），具有更简单（E3）或更复杂（E4）形状。我们在ShapeNet和ModelNet上进行评估，使用合成的MVS点云。在E5中，我们评估不调整参数的基于神经网络和传统优化方法；我们使用Berger等人的数据集中少量但多样的合成范围扫描。在E6和E7中，我们在合成和真实点云上对所有方法进行定量和定性比较。</p></div><!-- Media --><!-- figureText: Experiment Training set Test set Evaluation of methods with dataset-driven parameterization ShapeNet (synthetic MVS) ShapeNet (synthetic MVS) ModelNet (synthetic MVS) ShapeNet (synthetic MVS) Evaluation of methods without dataset-driven parameterization Berger et al. (synthetic range scan) Evaluation of all methods on a common ground Berger et al. (synthetic MVS) Middlebury (MVS), DTU (MVS), T&T (range scan) E1 In-distribution ShapeNet (synthetic MVS) E2 Out-of-distribution unseen point cloud characteristics: density, outliers ShapeNet (synthetic MVS) E3 Out-of-distribution unseen shape categories: less complex shapes ShapeNet (synthetic MVS) E4 Out-of-distribution unseen shape categories: more complex shapes ModelNet (synthetic MVS) E5 Shape variety with defects shapes with varying complexities, density, noise and outliers E6 Synthetic data with ground truth (quantitative evaluation) ShapeNet (synthetic MVS) E7 Real data without ground truth (qualitative evaluation) ShapeNet (synthetic MVS) --><img src="https://cdn.noedgeai.com/bo_d163rvn7aajc7388jqb0_10.jpg?x=123&#x26;y=501&#x26;w=1544&#x26;h=1536&#x26;r=0"><!-- Media --><ul>
<li>ConvONet [11] first extracts point features and averages them on cells of three 2D grids (2D variant), or one 3D grid (3D variant). It then uses convolutions to capture the local geometry and predicts the occupancy of query points from interpolated grid features.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>ConvONet [11] 首先提取点特征，并在三个2D网格（2D变体）或一个3D网格（3D变体）的单元上进行平均。然后，它使用卷积捕捉局部几何形状，并从插值网格特征中预测查询点的占用情况。</li>
</ul></div><ul>
<li>SAP [55] estimates the oriented normals and \(k\) point offsets for each input point to densify the point cloud. The resulting point cloud of size \(k\left| \mathcal{P}\right|\) is then used by a differentiable Poisson solver [27] to predict a mesh. The entire pipeline is trained end-to-end.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>SAP [55] 为每个输入点估计定向法线和\(k\)点偏移，以密集点云。得到的大小为\(k\left| \mathcal{P}\right|\)的点云随后被可微分的泊松求解器[27]用于预测网格。整个流程是端到端训练的。</li>
</ul></div><ul>
<li>DGNN [15] uses a graph neural network to predict the occupancy of Delaunay cells.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>DGNN [15] 使用图神经网络预测德劳内单元的占用情况。</li>
</ul></div><ul>
<li>POCO [17] extracts point features using point cloud convolution [76], then estimates the occupancy of query points with a learning-based interpolation method.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>POCO [17] 使用点云卷积[76]提取点特征，然后使用基于学习的插值方法估计查询点的占用情况。</li>
</ul></div><p>Neural optimization-based methods. These methods are optimized for each input shape independently, and do not rely on any training set.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>基于神经优化的方法。这些方法针对每个输入形状独立优化，并不依赖于任何训练集。</p></div><ul>
<li>IGR [54] learns an implicit function for an input cloud based on its points' position and normals. We train the model for 100,000 iterations for each scan.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>IGR [54] 根据输入点云的点位置和法线学习隐式函数。我们为每个扫描训练模型100,000次迭代。</li>
</ul></div><ul>
<li>LIG [13] trains an autoencoder from ground truth signed distance function and only retains its decoder for inference. As the training code is unavailable, we use the available decoder pretrained on ShapeNet (without noise). The input point clouds are augmented with 10 new points along each point's jet-estimated normals [93], whose occupancy is determined by the normals orientation. We use the proposed post-processing to remove falsely enclosed volumes</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>LIG [13] 从真实值签名距离函数训练自编码器，并仅保留其解码器用于推理。由于训练代码不可用，我们使用在ShapeNet上预训练的可用解码器（没有噪声）。输入点云沿每个点的喷射估计法线[93]增加10个新点，其占用情况由法线方向决定。我们使用所提出的后处理来去除错误封闭的体积。</li>
</ul></div><ul>
<li>P2M [40] iteratively moves the vertices of an initial mesh to fit a point cloud.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>P2M [40] 迭代地移动初始网格的顶点以适应点云。</li>
</ul></div><ul>
<li>SAP* [55] is the variant of SAP that is purely optimization-based, rather than learning-based. It uses non-learned normals and densification.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>SAP* [55] 是SAP的变体，纯粹基于优化，而不是基于学习。它使用非学习的法线和密集化。</li>
</ul></div><p>Note that while LIG employs a pretrained network, it also involves optimizing a unique function for each new input point cloud. Consequently, for the purposes of our analysis and classification, we categorize LIG as an optimization-based method, acknowledging its hybrid nature.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>请注意，虽然LIG使用了预训练网络，但它还涉及为每个新的输入点云优化一个独特的函数。因此，出于我们的分析和分类目的，我们将LIG归类为基于优化的方法，同时承认其混合特性。</p></div><p>Traditional optimization-based methods. These test-of-time methods do not rely on neural networks or training, but nonetheless have a few parameters, which can be set according to default values or adjusted depending on given ground-truth data (akin to a train set).</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>传统的基于优化的方法。这些经受时间考验的方法不依赖于神经网络或训练，但仍然有一些参数，可以根据默认值设置或根据给定的真实数据（类似于训练集）进行调整。</p></div><ul>
<li>SPSR [27] is a classic traditional method which approximates the surface as a level-set of an implicit function estimated from point positions and normal information. We use the sensor position to orient jet-estimated normals [93]. In experiments E1-E4, we perform a grid-search on the train set with octree depths of \(\{ 6,8,{10},{12}\}\) ,and boundary conditions in {dirichlet, neumann, free}. In experiments E5-E7, we use an octree of depth 10 and Dirichlet boundary condition. We also experimented with post-processing the reconstructed surface with the trimming tool provided by the authors but could not find parameters that consistently improve the evaluation metrics.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>SPSR [27] 是一种经典的传统方法，它将表面近似为从点位置和法线信息估计的隐式函数的水平集。我们使用传感器位置来定向喷射估计的法线 [93]。在实验 E1-E4 中，我们对训练集进行网格搜索，八叉树深度为 \(\{ 6,8,{10},{12}\}\)，边界条件为 {dirichlet, neumann, free}。在实验 E5-E7 中，我们使用深度为 10 的八叉树和 Dirichlet 边界条件。我们还尝试使用作者提供的修剪工具对重建的表面进行后处理，但未能找到能持续改善评估指标的参数。</li>
</ul></div><ul>
<li>RESR [46] is a classical graph-cut-based method exploiting on visibility information. For experiments E1- E4, we perform a grid-search on the train set with point weights \(\alpha  = \{ {16},{32},{48}\}\) and \(\sigma  = \{ {0.001},{0.01},{0.1},1\}\) , and regularization strength \(\lambda  = \{ {1.5},{2.5},5,{10}\}\) . In the optimization setting, we use the parametrization suggested by the authors: point weights \({\alpha }_{vis} = {32}\) and \(\sigma  = {0.01}\) and regularization strength \(\lambda  = 5\) .</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>RESR [46] 是一种经典的基于图切割的方法，利用可见性信息。在实验 E1-E4 中，我们对训练集进行网格搜索，点权重为 \(\alpha  = \{ {16},{32},{48}\}\) 和 \(\sigma  = \{ {0.001},{0.01},{0.1},1\}\)，正则化强度为 \(\lambda  = \{ {1.5},{2.5},5,{10}\}\)。在优化设置中，我们使用作者建议的参数化：点权重 \({\alpha }_{vis} = {32}\) 和 \(\sigma  = {0.01}\) 以及正则化强度 \(\lambda  = 5\)。</li>
</ul></div><h3>5.5 Evaluation metrics</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>5.5 评估指标</h3></div><p>We want the reconstructed surface \({\mathcal{S}}^{r}\) to be as close as possible to the ground-truth surface \({\mathcal{S}}^{g}\) in terms of geometry and topology. To measure this closeness we use various metrics described below.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>我们希望重建的表面 \({\mathcal{S}}^{r}\) 在几何和拓扑上尽可能接近真实表面 \({\mathcal{S}}^{g}\)。为了衡量这种接近程度，我们使用下面描述的各种指标。</p></div><p>Geometric metrics. We evaluate reconstructions with the volumetric intersection over union (IoU), symmetric Chamfer distance (CD), and normal consistency (NC):</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>几何指标。我们使用体积交并比（IoU）、对称 Chamfer 距离（CD）和法线一致性（NC）来评估重建结果：</p></div><ul>
<li>Volumetric IoU: We denote by \({\mathcal{V}}^{g}\) the space inside the ground-truth surface \({\mathcal{S}}^{g}\) ,and \({\mathcal{V}}^{r}\) the space inside the reconstructed surface \({\mathcal{V}}^{r}\) . The volumetric IoU estimates the intersection over union between \({\mathcal{V}}^{g}\) and \({\mathcal{V}}^{r}\) . To approximate this value,we sample a set \(\mathcal{P}\) of100,000 points in the union of the bounding boxes of \({\mathcal{V}}^{g}\) and \({\mathcal{V}}^{r}\) and calculate the following:</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>体积 IoU：我们用 \({\mathcal{V}}^{g}\) 表示真实表面 \({\mathcal{S}}^{g}\) 内部的空间，用 \({\mathcal{V}}^{r}\) 表示重建表面 \({\mathcal{V}}^{r}\) 内部的空间。体积 IoU 估计 \({\mathcal{V}}^{g}\) 和 \({\mathcal{V}}^{r}\) 之间的交并比。为了近似这个值，我们在 \({\mathcal{V}}^{g}\) 和 \({\mathcal{V}}^{r}\) 的边界框的并集中采样一组 \(\mathcal{P}\) 100,000 个点，并计算如下：</li>
</ul></div><p></p>\[\operatorname{IoU}\left( {{\mathcal{S}}^{g},{\mathcal{S}}^{r}}\right)  = \frac{\left| \left\{  p \in  \mathcal{P} \cap  {\mathcal{V}}^{g} \cap  {\mathcal{V}}^{r}\right\}  \right| }{\left| \left\{  p \in  \mathcal{P} \cap  \left( {\mathcal{V}}^{r} \cup  {\mathcal{V}}^{g}\right) \right\}  \right| }.\]<p></p><ul>
<li>Chamfer distance: We sample a set of points \({\mathcal{P}}^{g}\) and \({\mathcal{P}}^{r}\) on the facets of the ground-truth mesh and the reconstructed mesh,respectively,with \(\left| {\mathcal{P}}^{g}\right|  = \left| {\mathcal{P}}^{r}\right|  =\) 100,000. We approximate the symmetric Chamfer distance between \({\mathcal{S}}^{g}\) and \({\mathcal{S}}^{r}\) as follows:</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>Chamfer 距离：我们在真实网格和重建网格的面上分别采样一组点 \({\mathcal{P}}^{g}\) 和 \({\mathcal{P}}^{r}\)，数量为 \(\left| {\mathcal{P}}^{g}\right|  = \left| {\mathcal{P}}^{r}\right|  =\) 100,000。我们将 \({\mathcal{S}}^{g}\) 和 \({\mathcal{S}}^{r}\) 之间的对称 Chamfer 距离近似为：</li>
</ul></div><p></p>\[\mathrm{{CD}}\left( {{\mathcal{S}}^{g},{\mathcal{S}}^{r}}\right)  = \frac{1}{2\left| {\mathcal{P}}^{g}\right| }\mathop{\sum }\limits_{{x \in  {\mathcal{P}}^{g}}}\mathop{\min }\limits_{{y \in  {\mathcal{P}}^{r}}}\parallel x - y{\parallel }_{2}\]<p></p><p></p>\[+ \frac{1}{2\left| {\mathcal{P}}^{r}\right| }\mathop{\sum }\limits_{{y \in  {\mathcal{P}}^{r}}}\mathop{\min }\limits_{{x \in  {\mathcal{P}}^{g}}}\parallel y - x{\parallel }_{2}.\]<p></p><ul>
<li>Normal consistency: Let \(n\left( x\right)\) be the unit normal of a point \(x\) on a mesh,and \(\langle  \cdot  , \cdot  \rangle\) the Euclidean scalar product in \({\mathbb{R}}^{3}\) . The normal consistency is estimated as:</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>法线一致性：设 \(n\left( x\right)\) 为网格上点 \(x\) 的单位法线，\(\langle  \cdot  , \cdot  \rangle\) 为 \({\mathbb{R}}^{3}\) 中的欧几里得标量积。法线一致性估计为：</li>
</ul></div><p></p>\[\mathrm{{NC}}\left( {{\mathcal{S}}^{g},{\mathcal{S}}^{r}}\right)  = \frac{1}{2\left| {\mathcal{P}}^{g}\right| }\mathop{\sum }\limits_{{x \in  {\mathcal{P}}^{g}}}\left\langle  {n\left( x\right) ,n\left( {\mathop{\operatorname{argmin}}\limits_{{y \in  {\mathcal{P}}^{r}}}\parallel x - y{\parallel }_{2}}\right) }\right\rangle\]<p></p><p></p>\[+ \frac{1}{2\left| {\mathcal{P}}^{r}\right| }\mathop{\sum }\limits_{{y \in  {\mathcal{P}}^{r}}}\left\langle  {n\left( y\right) ,n\left( {\mathop{\operatorname{argmin}}\limits_{{x \in  {\mathcal{P}}^{g}}}\parallel y - x{\parallel }_{2}}\right) }\right\rangle  .\]<p></p><p>Topologic metrics. All surfaces considered in our benchmark have a single component, and are closed and manifold. In consequence, we can measure the geometric quality of the reconstructed surfaces with the following indices:</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>拓扑指标。我们基准中考虑的所有表面都有一个单一的组件，并且是闭合和流形的。因此，我们可以用以下指标来测量重建表面的几何质量：</p></div><ul>
<li>Number of components: The reconstructed surfaces should also have one component.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>组件数量：重建的表面也应该只有一个组件。</li>
</ul></div><ul>
<li>Number of boundary edges: All reconstructed meshes should have no boundary edges, i.e., edges that belong to only one facet.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>边界边缘数量：所有重建的网格都不应有边界边缘，即仅属于一个面的边缘。</li>
</ul></div><ul>
<li>Number of non-manifold edges: All the edges of the reconstructed meshes should be manifold.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>非流形边缘数量：所有重建网格的边缘应为流形。</li>
</ul></div><h2>6 EXPERIMENTS</h2><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h2>6 实验</h2></div><p>We report here the results of the series of experiments presented in Sec. 5.3 and designed to assess the robustness and performance of various deep and non-deep surface reconstruction methods from point clouds (cf. Tab. 1). We start in Sec. 6.1, for methods with dataset-driven parameterization, by measuring the impact of various inconsistencies between train and test sets. We then evaluate in Sec. 6.2 the performance of optimization-based methods without dataset-driven parameterization. Finally, we compare in Sec. 6.3 all evaluated methods, both learning- and optimization-based, on synthetic and real point acquisitions.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>我们在此报告第5.3节中提出的一系列实验结果，旨在评估各种深度和非深度表面重建方法从点云中提取的鲁棒性和性能（参见表1）。我们在第6.1节开始，针对数据集驱动参数化的方法，测量训练集和测试集之间各种不一致性的影响。然后在第6.2节中评估基于优化的方法在没有数据集驱动参数化情况下的性能。最后，我们在第6.3节中比较所有评估的方法，包括基于学习和基于优化的方法，在合成和真实点采集上。</p></div><h3>6.1 Surface reconstruction with dataset-driven param- eterization (E1 - E4)</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>6.1 基于数据集驱动参数化的表面重建 (E1 - E4)</h3></div><p>We examine the precision and versatility of recent supervised learning-based methods, as well as two traditional optimization-based methods, whose parameters were trained or tuned on a training set. We report qualitative results in Fig. 7, and quantitative results in Tab. 2.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>我们考察了最近基于监督学习的方法的精度和多样性，以及两种传统的基于优化的方法，这些方法的参数是在训练集上训练或调整的。我们在图7中报告了定性结果，在表2中报告了定量结果。</p></div><p>E1: In distribution. In this simple setting, learning-based methods demonstrate superior performance compared to traditional approaches, achieving more than a 5% improvement in volumetric IoU over SPSR and RESR. Implicit field-based methods like POCO, SAP, and ConvONet show particularly strong results. However, DGNN underperforms relative to other learning methods, likely due to the sparsity of the point clouds in this experiment.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>E1: 在分布内。在这个简单的设置中，基于学习的方法相比传统方法表现出更优越的性能，在体积IoU上比SPSR和RESR提高了超过5%。基于隐式场的方法如POCO、SAP和ConvONet表现出特别强的结果。然而，DGNN相对于其他学习方法表现不佳，可能是由于本实验中点云的稀疏性。</p></div><p>E2: Out-of-distribution - unseen point characteristics. Learning-based methods exhibit a noticeable decline in performance when confronted with point characteristics (higher density, outliers) that were not seen during training. On the other hand, traditional methods, especially SPSR, display a robust response to outliers and take advantage of a higher point density. While SAP's reconstructions tend to be overly smooth, missing finer details, they are not as severely affected by defects as other learning-based approaches. The technique of RESR encounters issues due to its lower regularization weight, which was optimized for outlier-free point clouds. A higher regularization might be beneficial in minimizing erroneous components caused by outliers.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>E2: 超出分布 - 未见点特征。基于学习的方法在面对训练期间未见的点特征（更高的密度、离群点）时表现出明显的性能下降。另一方面，传统方法，特别是SPSR，对离群点表现出强大的响应，并利用更高的点密度。虽然SAP的重建往往过于平滑，缺失细节，但它们并没有像其他基于学习的方法那样受到缺陷的严重影响。RESR由于其较低的正则化权重而遇到问题，该权重是针对无离群点的点云优化的。更高的正则化可能有助于最小化由离群点引起的错误成分。</p></div><p>E3: Out-of-distribution - unseen classes (simpler). In the task of reconstructing simpler, out-of-category shapes from ModelNet (E3), neural implicit field methods stand out for their visually superior reconstructions. SAP and POCO lead in terms of quantitative performance. The interpolating approach DGNN outperforms ConvONet in this experiment, demonstrating its generalization capabilities.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>E3: 超出分布 - 未见类别（更简单）。在从ModelNet重建更简单的超出类别形状的任务中（E3），神经隐式场方法因其视觉上更优越的重建而脱颖而出。SAP和POCO在定量性能方面领先。插值方法DGNN在本实验中优于ConvONet，展示了其泛化能力。</p></div><p>E4: Out-of-distribution - unseen classes (more complex). In this experiment, most methods overfit the simpler training shapes from ModelNet shapes and subsequently struggle with reconstructing the more complex shapes from ShapeNet. The non-learning-based method SPSR is also affected as its parameters are tuned on ModelNet. Specifically, the optimalo octree depth for ModelNet reconstructions is \(d = 8\) ,as opposed to \(d = {10}\) for ShapeNet,resulting in a decrease in volumetric IoU from 77.1 in E1 to 74.6 in E4. In contrast, the parameter tuning for RESR remains consistent across both datasets. DGNN stands out as the only learning-based method that does not exhibit overfitting on the ModelNet dataset, leading to the most successful outcomes both quantitatively and qualitatively. In fact, its performance is on par with its results when directly trained on the ShapeNet dataset. We attribute this behavior to the local nature of DGNN, which only consider small subgraphs during training and inference.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>E4: 超出分布 - 未见类别（更复杂）。在本实验中，大多数方法对ModelNet的简单训练形状过拟合，随后在重建ShapeNet的更复杂形状时遇到困难。非学习方法SPSR也受到影响，因为其参数是在ModelNet上调整的。具体而言，ModelNet重建的最佳八叉树深度为\(d = 8\)，而ShapeNet为\(d = {10}\)，导致体积IoU从E1的77.1下降到E4的74.6。相比之下，RESR的参数调整在两个数据集之间保持一致。DGNN是唯一一个在ModelNet数据集上没有表现出过拟合的基于学习的方法，导致在定量和定性上都取得了最成功的结果。事实上，其性能与直接在ShapeNet数据集上训练时的结果相当。我们将这种行为归因于DGNN的局部特性，它在训练和推理过程中仅考虑小的子图。</p></div><p>Methods Performance. We propose an analysis of the performance of each model:</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>方法性能。我们提出对每个模型性能的分析：</p></div><ul>
<li>ConvONet perform best when both the training and test sets share identical point cloud characteristics and shape categories. On more complicated settings, this method performs below traditional approaches.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>当训练集和测试集共享相同的点云特征和形状类别时，ConvONet表现最佳。在更复杂的设置中，该方法的表现低于传统方法。</li>
</ul></div><ul>
<li>SAP stands out for its superior reconstructions and robustness against outliers, partly due to its unique capability of explicitly predicting normals. This feature contributes to SAP achieving the highest mean normal consistency across all experiments.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>SAP因其卓越的重建和对离群点的鲁棒性而脱颖而出，部分原因在于其独特的显式预测法线的能力。该特性使SAP在所有实验中实现了最高的平均法线一致性。</li>
</ul></div><ul>
<li>DGNN, with its blend of local learning and global regularization, consistently delivers competitive results in nearly all scenarios, with the notable exception of the outlier-rich environment in E2. Overall, it achieves the highest volumetric IoU amongst learning-based methods when averaged across all experiments.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>DGNN凭借其局部学习和全局正则化的结合，在几乎所有场景中始终提供竞争力的结果，唯一的例外是E2中的离群点丰富环境。总体而言，它在所有实验中平均实现了基于学习的方法中最高的体积IoU。</li>
</ul></div><ul>
<li>POCO's local attention-based learning mechanism yields optimal outcomes when reconstruction does not require adapting to unseen domains. It particularly excels in experiments where the point cloud characteristics remain consistent between training and testing (E1, E3, E4). However, POCO is significantly impacted by outliers, as evidenced in E2, and shows a tendency to overfit on simpler training shapes, as observed in E4. Notably, both POCO and SAP produce watertight reconstructions, with boundary edges only appearing where the reconstruction intersects the bounding box.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>POCO的基于局部注意力的学习机制在重建不需要适应未见领域时产生最佳结果。它在训练和测试之间点云特征保持一致的实验中表现尤为出色（E1、E3、E4）。然而，POCO受到离群点的显著影响，如E2所示，并且在E4中显示出对更简单训练形状的过拟合倾向。值得注意的是，POCO和SAP都产生了密闭的重建，边界边缘仅在重建与边界框相交的地方出现。</li>
</ul></div><ul>
<li>SPSR demonstrates a high degree of robustness to various defects and shape complexities, yielding consistently good results across different metrics. However, it tends to produce less compact reconstructions with a higher number of components.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>SPSR在各种缺陷和形状复杂性方面表现出高度的鲁棒性，在不同指标上始终产生良好的结果。然而，它往往生成的重建不够紧凑，组件数量较多。</li>
</ul></div><ul>
<li>RESR, while slightly less robust to outliers and now relatively old, achieves a mean volumetric IoU higher than any of the learning-based methods, and presents the most compact reconstructions with an average of 2.7 components only. However, this approach produces a significant number of non-manifold edges.</li>
</ul><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><ul>
<li>RESR虽然对离群点的鲁棒性稍逊，并且现在相对较旧，但其平均体积IoU高于任何基于学习的方法，并且仅以平均2.7个组件呈现出最紧凑的重建。然而，这种方法产生了大量非流形边缘。</li>
</ul></div><h3>6.2 Surface reconstruction without dataset-driven pa- rameterization (E5)</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>6.2 无数据集驱动参数化的表面重建 (E5)</h3></div><p>Setting. We now evaluate methods that do not learn or tune their parameters on a training set. We consider neural-network-based optimization approaches that learn a new function to fit each input point cloud. We also assess the performance of non-learning-based methods, using their default parameters for a fair evaluation. These methods are tested on the benchmark shapes from Berger et al. [19], which uses synthetic range scans with varying resolutions, noise levels, and outlier proportions.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>设置。我们现在评估不在训练集上学习或调整其参数的方法。我们考虑基于神经网络的优化方法，这些方法学习一个新函数以拟合每个输入点云。我们还评估非学习方法的性能，使用其默认参数进行公平评估。这些方法在Berger等人[19]的基准形状上进行测试，该基准使用具有不同分辨率、噪声水平和离群点比例的合成范围扫描。</p></div><p>Analysis. We report the results of this experience in Tab. 3. Interestingly, traditional methods such as SPSR and RESR consistently surpass network-based approaches in most metrics and scenarios. Their superior performance is particularly evident when dealing with outliers, where they exhibit over a 10-point advantage in volumetric IoU and normal consistency. SPSR provides accurate and robust normal estimation under various conditions. RESR achieves the highest mean IoU and mean Chamfer distance, and yields the most compact reconstructions. However, it also results in a significant number of non-manifold edges.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>分析。我们在表3中报告了这一实验的结果。有趣的是，传统方法如SPSR和RESR在大多数指标和场景中始终超越基于网络的方法。它们的优越性能在处理离群点时尤为明显，在体积IoU和法线一致性上表现出超过10点的优势。SPSR在各种条件下提供准确且鲁棒的法线估计。RESR实现了最高的平均IoU和平均Chamfer距离，并产生了最紧凑的重建。然而，它也导致了大量非流形边缘。</p></div><!-- Media --><!-- figureText: Input (E3) Out-of-category: (E4) Out-of-category: (E6) Out-of-category: less complex shapes more complex shapes similar complex shapes CONet2D [11] CONet3D [11] SAP [55] DGNN [15] POCO [17] †SPSR [27] \( {}^{ \dagger  } \) RESR [46] Ground truth (E1) In-distribution (E2) Out-of-distribution: higher density, outliers --><img src="https://cdn.noedgeai.com/bo_d163rvn7aajc7388jqb0_13.jpg?x=123&#x26;y=203&#x26;w=1581&#x26;h=1801&#x26;r=0"><p>Figure 7: Learning-based and traditional methods (E1-E4, E6): DGNN [15], SAP [55] and SPSR [27] provide visually the best reconstructions,without prevalent defects. \({}^{ \dagger  }\) non deep-learning-based methods.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>图7：基于学习和传统方法 (E1-E4, E6)：DGNN [15]、SAP [55]和SPSR [27]提供了视觉上最佳的重建，没有明显的缺陷。\({}^{ \dagger  }\) 非深度学习方法。</p></div><p>Table 2: Comparison of methods with dataset-driven parameterization (E1 to E4): We evaluate across 6 metrics various learning-based methods and traditional optimization-based methods with adjustable parameters. We observe that learning-based methods outperform traditional methods in the simple setting where the training and testing set have the same characteristics (E1). However, non-learning methods perform better when the test set contains unseen point defects or more complex objects. \({}^{ \dagger  }\) methods not based on neural networks.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>表2：带有数据集驱动参数化的方法比较 (E1到E4)：我们在6个指标上评估各种基于学习的方法和具有可调参数的传统优化方法。我们观察到，在训练集和测试集具有相同特征的简单设置中，基于学习的方法优于传统方法 (E1)。然而，当测试集包含未见过的点缺陷或更复杂的对象时，非学习方法表现更好。\({}^{ \dagger  }\) 不基于神经网络的方法。</p></div><table><tbody><tr><td rowspan="2">\( \mathbf{{Method}} \)</td><td></td><td colspan="5">Volumetric IoU (%) \( \left\lbrack   \uparrow  \right\rbrack \)</td><td colspan="5">Normal consistency (%)[↑]</td></tr><tr><td></td><td>E1</td><td>E2</td><td>E3</td><td>E4</td><td>Mean</td><td>E1</td><td>E2</td><td>E3</td><td>E4</td><td>Mean</td></tr><tr><td>ConvONet2D</td><td>[11]</td><td>85.0</td><td>47.3</td><td>79.3</td><td>68.3</td><td>70.0</td><td>92.7</td><td>76.4</td><td>90.0</td><td>87.8</td><td>86.7</td></tr><tr><td>ConvONet3D</td><td>[11]</td><td>84.8</td><td>15.1</td><td>83.6</td><td>51.0</td><td>58.6</td><td>93.0</td><td>71.8</td><td>93.1</td><td>82.5</td><td>85.1</td></tr><tr><td>SAP</td><td>[55]</td><td>88.7</td><td>59.8</td><td>89.2</td><td>54.9</td><td>73.2</td><td>93.5</td><td>86.7</td><td>94.1</td><td>87.1</td><td>90.4</td></tr><tr><td>DGNN</td><td>[15]</td><td>84.5</td><td>38.1</td><td>87.0</td><td>84.4</td><td>73.5</td><td>85.4</td><td>68.8</td><td>88.5</td><td>85.5</td><td>82.1</td></tr><tr><td>POCO</td><td>[17]</td><td>89.5</td><td>8.74</td><td>90.6</td><td>40.9</td><td>57.4</td><td>93.6</td><td>75.6</td><td>94.2</td><td>82.9</td><td>86.6</td></tr><tr><td>TSPSR</td><td>[27]</td><td>77.1</td><td>80.7</td><td>80.7</td><td>74.6</td><td>78.3</td><td>87.7</td><td>83.2</td><td>89.1</td><td>87.0</td><td>86.9</td></tr><tr><td>TRESR</td><td>[46]</td><td>80.3</td><td>60.4</td><td>83.9</td><td>80.3</td><td>76.2</td><td>81.0</td><td>73.0</td><td>84.6</td><td>81.0</td><td>79.9</td></tr></tbody></table><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><table><tbody><tr><td rowspan="2">\( \mathbf{{Method}} \)</td><td></td><td colspan="5">体积交并比 (%) \( \left\lbrack   \uparrow  \right\rbrack \)</td><td colspan="5">正常一致性 (%) [↑]</td></tr><tr><td></td><td>E1</td><td>E2</td><td>E3</td><td>E4</td><td>均值</td><td>E1</td><td>E2</td><td>E3</td><td>E4</td><td>均值</td></tr><tr><td>ConvONet2D</td><td>[11]</td><td>85.0</td><td>47.3</td><td>79.3</td><td>68.3</td><td>70.0</td><td>92.7</td><td>76.4</td><td>90.0</td><td>87.8</td><td>86.7</td></tr><tr><td>ConvONet3D</td><td>[11]</td><td>84.8</td><td>15.1</td><td>83.6</td><td>51.0</td><td>58.6</td><td>93.0</td><td>71.8</td><td>93.1</td><td>82.5</td><td>85.1</td></tr><tr><td>SAP</td><td>[55]</td><td>88.7</td><td>59.8</td><td>89.2</td><td>54.9</td><td>73.2</td><td>93.5</td><td>86.7</td><td>94.1</td><td>87.1</td><td>90.4</td></tr><tr><td>DGNN</td><td>[15]</td><td>84.5</td><td>38.1</td><td>87.0</td><td>84.4</td><td>73.5</td><td>85.4</td><td>68.8</td><td>88.5</td><td>85.5</td><td>82.1</td></tr><tr><td>POCO</td><td>[17]</td><td>89.5</td><td>8.74</td><td>90.6</td><td>40.9</td><td>57.4</td><td>93.6</td><td>75.6</td><td>94.2</td><td>82.9</td><td>86.6</td></tr><tr><td>TSPSR</td><td>[27]</td><td>77.1</td><td>80.7</td><td>80.7</td><td>74.6</td><td>78.3</td><td>87.7</td><td>83.2</td><td>89.1</td><td>87.0</td><td>86.9</td></tr><tr><td>TRESR</td><td>[46]</td><td>80.3</td><td>60.4</td><td>83.9</td><td>80.3</td><td>76.2</td><td>81.0</td><td>73.0</td><td>84.6</td><td>81.0</td><td>79.9</td></tr></tbody></table></div><table><tbody><tr><td rowspan="2">\( \mathbf{{Method}} \)</td><td colspan="5">Chamfer distance (\( \left( {\times {10}^{3}}\right) \)</td><td>[↓]</td><td colspan="5">Number of components[1]</td></tr><tr><td></td><td>E1</td><td>E2</td><td>E3</td><td>E4</td><td>Mean</td><td>E1</td><td>E2</td><td>E3</td><td>E4</td><td>Mean</td></tr><tr><td>ConvONet2D</td><td>[11]</td><td>0.55</td><td>7.51</td><td>1.00</td><td>0.98</td><td>2.51</td><td>1.6</td><td>34.8</td><td>2.6</td><td>3.2</td><td>10.6</td></tr><tr><td>ConvONet3D</td><td>[11]</td><td>0.55</td><td>10.90</td><td>0.76</td><td>2.44</td><td>3.66</td><td>1.4</td><td>13.6</td><td>1.6</td><td>1.5</td><td>4.5</td></tr><tr><td>SAP</td><td>[55]</td><td>0.44</td><td>2.09</td><td>0.55</td><td>0.92</td><td>1.00</td><td>2.7</td><td>86.0</td><td>3.5</td><td>10.5</td><td>25.7</td></tr><tr><td>DGNN</td><td>[15]</td><td>0.55</td><td>2.54</td><td>0.63</td><td>0.55</td><td>1.07</td><td>1.3</td><td>16.1</td><td>1.1</td><td>1.3</td><td>5.0</td></tr><tr><td>POCO</td><td>[17]</td><td>0.42</td><td>10.50</td><td>0.52</td><td>1.32</td><td>3.19</td><td>2.3</td><td>178</td><td>2.8</td><td>16.3</td><td>49.9</td></tr><tr><td>TSPSR</td><td>[27]</td><td>0.80</td><td>0.66</td><td>0.87</td><td>0.89</td><td>0.81</td><td>9.3</td><td>185</td><td>11.1</td><td>3.2</td><td>52.0</td></tr><tr><td>TRESR</td><td>[46]</td><td>0.67</td><td>6.97</td><td>0.75</td><td>0.67</td><td>2.27</td><td>1.2</td><td>9.0</td><td>1.0</td><td>1.2</td><td>3.1</td></tr></tbody></table><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><table><tbody><tr><td rowspan="2">\( \mathbf{{Method}} \)</td><td colspan="5">倒角距离 (\( \left( {\times {10}^{3}}\right) \)</td><td>[↓]</td><td colspan="5">组件数量[1]</td></tr><tr><td></td><td>E1</td><td>E2</td><td>E3</td><td>E4</td><td>均值</td><td>E1</td><td>E2</td><td>E3</td><td>E4</td><td>均值</td></tr><tr><td>ConvONet2D</td><td>[11]</td><td>0.55</td><td>7.51</td><td>1.00</td><td>0.98</td><td>2.51</td><td>1.6</td><td>34.8</td><td>2.6</td><td>3.2</td><td>10.6</td></tr><tr><td>ConvONet3D</td><td>[11]</td><td>0.55</td><td>10.90</td><td>0.76</td><td>2.44</td><td>3.66</td><td>1.4</td><td>13.6</td><td>1.6</td><td>1.5</td><td>4.5</td></tr><tr><td>SAP</td><td>[55]</td><td>0.44</td><td>2.09</td><td>0.55</td><td>0.92</td><td>1.00</td><td>2.7</td><td>86.0</td><td>3.5</td><td>10.5</td><td>25.7</td></tr><tr><td>DGNN</td><td>[15]</td><td>0.55</td><td>2.54</td><td>0.63</td><td>0.55</td><td>1.07</td><td>1.3</td><td>16.1</td><td>1.1</td><td>1.3</td><td>5.0</td></tr><tr><td>POCO</td><td>[17]</td><td>0.42</td><td>10.50</td><td>0.52</td><td>1.32</td><td>3.19</td><td>2.3</td><td>178</td><td>2.8</td><td>16.3</td><td>49.9</td></tr><tr><td>TSPSR</td><td>[27]</td><td>0.80</td><td>0.66</td><td>0.87</td><td>0.89</td><td>0.81</td><td>9.3</td><td>185</td><td>11.1</td><td>3.2</td><td>52.0</td></tr><tr><td>TRESR</td><td>[46]</td><td>0.67</td><td>6.97</td><td>0.75</td><td>0.67</td><td>2.27</td><td>1.2</td><td>9.0</td><td>1.0</td><td>1.2</td><td>3.1</td></tr></tbody></table></div><table><tbody><tr><td rowspan="2">\( \mathbf{{Method}} \)</td><td colspan="6">Number of boundary edges \( \left\lbrack   \downarrow  \right\rbrack \)</td><td colspan="5">Number of non-manifold edges \( \left\lbrack   \downarrow  \right\rbrack \)</td></tr><tr><td></td><td>E1</td><td>E2</td><td>E3</td><td>E4</td><td>Mean</td><td>E1</td><td>E2</td><td>E3</td><td>E4</td><td>Mean</td></tr><tr><td>ConvONet2D</td><td>[11]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>ConvONet3D</td><td>[11]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>SAP</td><td>[55]</td><td>0</td><td>0</td><td>0</td><td>8.4</td><td>2.1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>DGNN</td><td>[15]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1.4</td><td>2.2</td><td>0.6</td><td>1.7</td><td>1.5</td></tr><tr><td>POCO</td><td>[17]</td><td>0</td><td>121</td><td>0</td><td>41.7</td><td>40.7</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>TSPSR</td><td>[27]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>TRESR</td><td>[46]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>9.4</td><td>28.5</td><td>8.47</td><td>9.4</td><td>13.9</td></tr></tbody></table><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><table><tbody><tr><td rowspan="2">\( \mathbf{{Method}} \)</td><td colspan="6">边界边的数量 \( \left\lbrack   \downarrow  \right\rbrack \)</td><td colspan="5">非流形边的数量 \( \left\lbrack   \downarrow  \right\rbrack \)</td></tr><tr><td></td><td>E1</td><td>E2</td><td>E3</td><td>E4</td><td>均值</td><td>E1</td><td>E2</td><td>E3</td><td>E4</td><td>均值</td></tr><tr><td>ConvONet2D</td><td>[11]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>ConvONet3D</td><td>[11]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>SAP</td><td>[55]</td><td>0</td><td>0</td><td>0</td><td>8.4</td><td>2.1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>DGNN</td><td>[15]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1.4</td><td>2.2</td><td>0.6</td><td>1.7</td><td>1.5</td></tr><tr><td>POCO</td><td>[17]</td><td>0</td><td>121</td><td>0</td><td>41.7</td><td>40.7</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>TSPSR</td><td>[27]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>TRESR</td><td>[46]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>9.4</td><td>28.5</td><td>8.47</td><td>9.4</td><td>13.9</td></tr></tbody></table></div><!-- Media --><p>IGR stands out among learning-based methods, particularly when processing outlier-free point clouds. It even surpasses traditional methods in terms of volumetric IoU and Chamfer distance in high-resolution and noisy scenarios (HRN). On the other hand, LIG demonstrates generally weaker performance, likely due to its dependency on a model pretrained on defect-free and high-density point clouds. Its post-processing approach also leads to non-watertight reconstructions. Point2Mesh (P2M) delivers reconstructions that are geometrically sound and topologically superior, characterized by fewer components and consistently producing watertight and manifold surfaces. \({\mathrm{{SAP}}}^{ * }\) ,although providing satisfactory reconstructions in the absence of outliers, struggles in more challenging scenarios.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>IGR在基于学习的方法中脱颖而出，特别是在处理无异常值的点云时。它在高分辨率和噪声场景（HRN）中甚至超越了传统方法，在体积IoU和Chamfer距离方面表现更佳。另一方面，LIG的表现普遍较弱，可能是由于其依赖于在无缺陷和高密度点云上预训练的模型。其后处理方法也导致了非水密重建。Point2Mesh (P2M)提供了几何上合理且拓扑上优越的重建，特点是组件更少，并且始终生成水密和流形表面。\({\mathrm{{SAP}}}^{ * }\)虽然在没有异常值的情况下提供了令人满意的重建，但在更具挑战性的场景中表现不佳。</p></div><h3>6.3 Learning- and optimization-based surface recon- struction from synthetic MVS point clouds (E6)</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>6.3 基于学习和优化的合成MVS点云表面重建 (E6)</h3></div><p>In this other experiment, we compare learning- and optimization-based reconstruction methods on the same dataset. We scan the shapes of Berger et al. [19] with the same synthetic scanning method as in E5. We consider learning-based models trained on shapes from ShapeNet scanned with the same procedure, network-based optimization models without training, and traditional optimization approaches. We report the results in Tab. 4 and provide visualizations in the supplementary material. Among the learning-based methods, DGNN and POCO achieve the most accurate surface reconstructions. Consistent with findings from E5, RESR emerges as the most effective among the optimization-based techniques. However, learning-based models achieve higher precision by leveraging priors from ShapeNet thanks to the similar scanning protocol.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在这个实验中，我们比较了基于学习和优化的重建方法在同一数据集上的表现。我们使用与E5相同的合成扫描方法扫描Berger等人的形状[19]。我们考虑在ShapeNet上使用相同程序扫描的形状训练的基于学习的模型、未经过训练的基于网络的优化模型以及传统的优化方法。我们在表4中报告结果，并在补充材料中提供可视化。 在基于学习的方法中，DGNN和POCO实现了最准确的表面重建。与E5的发现一致，RESR在基于优化的技术中表现最为有效。然而，基于学习的模型通过利用ShapeNet的先验知识实现了更高的精度，这得益于相似的扫描协议。</p></div><h3>6.4 Learning- and optimization-based surface recon- struction from real point clouds (E7)</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>6.4 基于学习和优化的真实点云表面重建 (E7)</h3></div><p>In this final experiment, we qualitatively assess the performance of learning- and optimization-based methods on real MVS and range-scanned point clouds (without ground truth). For the learning-based approaches, we use models trained on synthetic MVS scans from ShapeNet (E4), while optimization-based methods are applied independently to each point cloud. Our findings are presented in Fig. 8. Tanks and Temples range scanning, Figs. 8a-8l: Except for DGNN, the learning-based methods struggle to adapt to real range scanning acquisitions. IGR manages to create a reasonable mesh, but traditional methods like SPSR and RESR yield the most complete and accurate surfaces.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在这个最终实验中，我们定性评估了基于学习和优化的方法在真实MVS和范围扫描点云（没有真实值）上的表现。对于基于学习的方法，我们使用在ShapeNet的合成MVS扫描（E4）上训练的模型，而基于优化的方法则独立应用于每个点云。我们的发现呈现在图8中。坦克和寺庙的范围扫描，图8a-8l：除了DGNN，基于学习的方法在适应真实范围扫描采集时表现不佳。IGR设法创建了一个合理的网格，但像SPSR和RESR这样的传统方法则产生了最完整和准确的表面。</p></div><!-- Media --><!-- figureText: Learning (d) SAP (e) POCO (f) DGNN (j) SAP* (k) SPSR (1) RESR (p) SAP (q) POCO (r) DGNN (v) SAP* (w) SPSR (x) RESR (ab) SAP (ac) POCO (ad) DGNN (ah) \( {\mathrm{{SAP}}}^{ * } \) (ai) SPSR (aj) RESR (a) Input (b) CONet2D (c) CONet3D Optimization (g) IGR (h) LIG (i) P2M Learning (m) Input (n) CONet2D (o) CONet3D Optimization (s) IGR (t) LIG (u) P2M Learning (y) Input (z) CONet2D (aa) CONet3D Optimization (ae) IGR (af) LIG (ag) P2M --><img src="https://cdn.noedgeai.com/bo_d163rvn7aajc7388jqb0_15.jpg?x=130&#x26;y=206&#x26;w=1541&#x26;h=1705&#x26;r=0"><p>Figure 8: Comparison of all methods - real data without ground truth (E7): We show reconstructions of two real-world MVS and one range-scanned point clouds. The learning methods were trained on synthetic MVS scans from ShapeNet (cf. E1). Optimization-based methods are optimized per scan using standard settings. The two traditional methods SPSR [27] and RESR [46] reconstruct the visually best surfaces. Their reconstructions only show noticeable defects from the heavy noise of the Temple Ring MVS point cloud (Figs. (w) and (x)).</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>图8：所有方法的比较 - 没有真实值的真实数据 (E7)：我们展示了两个真实世界的MVS和一个范围扫描点云的重建。学习方法是在ShapeNet的合成MVS扫描上训练的（参见E1）。基于优化的方法使用标准设置对每个扫描进行优化。两个传统方法SPSR [27]和RESR [46]重建了视觉上最佳的表面。它们的重建仅在寺庙环MVS点云的重度噪声（图（w）和（x））中显示出明显的缺陷。</p></div><p>Table 3: Comparison of methods without dataset-driven parameterization (E5): We report the performance of neural and traditional methods that do not train or tune their parameters on a training set. We evaluate on point clouds obtained with different scan settings: LR: low resolution, HR: high resolution, HRN: high resolution and noise, HRO: high resolution and outliers,and HRNO: high resolution with noise and outliers. \({}^{ \dagger  }\) methods not based on neural networks.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>表3：没有数据集驱动参数化的方法比较 (E5)：我们报告了不在训练集上训练或调整参数的神经和传统方法的性能。我们在使用不同扫描设置获得的点云上进行评估：LR：低分辨率，HR：高分辨率，HRN：高分辨率和噪声，HRO：高分辨率和异常值，以及HRNO：高分辨率、噪声和异常值。\({}^{ \dagger  }\)不基于神经网络的方法。</p></div><table><tbody><tr><td colspan="2" rowspan="2">\( \mathbf{{Method}} \)</td><td colspan="6">Volumetric IoU (%) [↑]</td><td colspan="6">Normal consistency (%)(%) [↑]</td></tr><tr><td>LR</td><td>HR</td><td>HRN</td><td>HRO</td><td>HRNO</td><td>Mean</td><td>LR</td><td>HR</td><td>HRN</td><td>HRO</td><td>HRNO</td><td>Mean</td></tr><tr><td>\( \mathbf{{IGR}} \)</td><td>[54]</td><td>80.8</td><td>92.5</td><td>83.6</td><td>63.7</td><td>62.7</td><td>76.7</td><td>88.0</td><td>96.3</td><td>83.9</td><td>77.8</td><td>71.5</td><td>83.5</td></tr><tr><td>LIG</td><td>[13]</td><td>46.9</td><td>50.3</td><td>63.9</td><td>66</td><td>63.8</td><td>58.2</td><td>88.7</td><td>92.2</td><td>89.0</td><td>77</td><td>75.2</td><td>84.4</td></tr><tr><td>\( \mathbf{{P2M}} \)</td><td>[40]</td><td>75.2</td><td>83.3</td><td>75.5</td><td>71.3</td><td>67.8</td><td>74.6</td><td>86.3</td><td>92.2</td><td>88.1</td><td>84.5</td><td>82.1</td><td>86.6</td></tr><tr><td>SAP*</td><td>[55]</td><td>75.6</td><td>89.1</td><td>72.4</td><td>55.3</td><td>34.9</td><td>65.4</td><td>83.4</td><td>94.8</td><td>61.6</td><td>74.5</td><td>55.3</td><td>73.9</td></tr><tr><td>TSPSR</td><td>[27]</td><td>77.7</td><td>90.2</td><td>82.8</td><td>90.3</td><td>82.1</td><td>84.6</td><td>88.1</td><td>96</td><td>88.1</td><td>96.2</td><td>85.8</td><td>90.9</td></tr><tr><td>TRESR</td><td>[46]</td><td>81.3</td><td>93.4</td><td>80.1</td><td>93.4</td><td>79.1</td><td>85.5</td><td>87.6</td><td>96</td><td>66.3</td><td>94.9</td><td>66.5</td><td>82.3</td></tr></tbody></table><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><table><tbody><tr><td colspan="2" rowspan="2">\( \mathbf{{Method}} \)</td><td colspan="6">体积IoU (%) [↑]</td><td colspan="6">正常一致性 (%) [↑]</td></tr><tr><td>低分辨率</td><td>高分辨率</td><td>高分辨率网络</td><td>高分辨率优化</td><td>高分辨率无优化</td><td>平均值</td><td>低分辨率</td><td>高分辨率</td><td>高分辨率网络</td><td>高分辨率优化</td><td>高分辨率无优化</td><td>平均值</td></tr><tr><td>\( \mathbf{{IGR}} \)</td><td>[54]</td><td>80.8</td><td>92.5</td><td>83.6</td><td>63.7</td><td>62.7</td><td>76.7</td><td>88.0</td><td>96.3</td><td>83.9</td><td>77.8</td><td>71.5</td><td>83.5</td></tr><tr><td>光照引导</td><td>[13]</td><td>46.9</td><td>50.3</td><td>63.9</td><td>66</td><td>63.8</td><td>58.2</td><td>88.7</td><td>92.2</td><td>89.0</td><td>77</td><td>75.2</td><td>84.4</td></tr><tr><td>\( \mathbf{{P2M}} \)</td><td>[40]</td><td>75.2</td><td>83.3</td><td>75.5</td><td>71.3</td><td>67.8</td><td>74.6</td><td>86.3</td><td>92.2</td><td>88.1</td><td>84.5</td><td>82.1</td><td>86.6</td></tr><tr><td>自适应处理*</td><td>[55]</td><td>75.6</td><td>89.1</td><td>72.4</td><td>55.3</td><td>34.9</td><td>65.4</td><td>83.4</td><td>94.8</td><td>61.6</td><td>74.5</td><td>55.3</td><td>73.9</td></tr><tr><td>时间序列图像超分辨率</td><td>[27]</td><td>77.7</td><td>90.2</td><td>82.8</td><td>90.3</td><td>82.1</td><td>84.6</td><td>88.1</td><td>96</td><td>88.1</td><td>96.2</td><td>85.8</td><td>90.9</td></tr><tr><td>三维超分辨率</td><td>[46]</td><td>81.3</td><td>93.4</td><td>80.1</td><td>93.4</td><td>79.1</td><td>85.5</td><td>87.6</td><td>96</td><td>66.3</td><td>94.9</td><td>66.5</td><td>82.3</td></tr></tbody></table></div><table><tbody><tr><td colspan="2" rowspan="2">\( \mathbf{{Method}} \)</td><td colspan="6">Chamfer distance \( \left( {\times {10}^{3}}\right) \;\left\lbrack   \downarrow  \right\rbrack \)</td><td colspan="6">Number of components \( \left\lbrack   \downarrow  \right\rbrack \)</td></tr><tr><td>LR</td><td>HR</td><td>HRN</td><td>HRO</td><td>HRNO</td><td>Mean</td><td>LR</td><td>HR</td><td>HRN</td><td>HRO</td><td>HRNO</td><td>Mean</td></tr><tr><td>\( \mathbf{{IGR}} \)</td><td>[54]</td><td>0.67</td><td>0.32</td><td>0.55</td><td>7.96</td><td>7.72</td><td>3.45</td><td>6.8</td><td>1.2</td><td>35.2</td><td>44</td><td>97.4</td><td>36.9</td></tr><tr><td>LIG</td><td>[13]</td><td>0.75</td><td>0.58</td><td>0.78</td><td>7.89</td><td>7.80</td><td>3.56</td><td>1</td><td>1</td><td>1</td><td>1.6</td><td>1</td><td>1.12</td></tr><tr><td>\( \mathbf{{P2M}} \)</td><td>[40]</td><td>0.82</td><td>0.47</td><td>0.73</td><td>1.53</td><td>2.13</td><td>1.13</td><td>1.2</td><td>1</td><td>1.2</td><td>1.4</td><td>1.6</td><td>1.28</td></tr><tr><td>SAP*</td><td>[55]</td><td>0.85</td><td>0.32</td><td>0.70</td><td>3.99</td><td>3.93</td><td>1.96</td><td>73.2</td><td>85.6</td><td>937</td><td>1800</td><td>1.60</td><td>971</td></tr><tr><td>TSPSR</td><td>[27]</td><td>0.79</td><td>0.37</td><td>0.57</td><td>0.36</td><td>0.61</td><td>0.54</td><td>1.2</td><td>1.6</td><td>3.6</td><td>3.8</td><td>20.2</td><td>6.08</td></tr><tr><td>TRESR</td><td>[46]</td><td>0.64</td><td>0.31</td><td>0.61</td><td>0.34</td><td>0.64</td><td>0.51</td><td>1</td><td>1</td><td>1.2</td><td>1.2</td><td>1</td><td>1.08</td></tr></tbody></table><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><table><tbody><tr><td colspan="2" rowspan="2">\( \mathbf{{Method}} \)</td><td colspan="6">倒角距离 \( \left( {\times {10}^{3}}\right) \;\left\lbrack   \downarrow  \right\rbrack \)</td><td colspan="6">组件数量 \( \left\lbrack   \downarrow  \right\rbrack \)</td></tr><tr><td>低分辨率</td><td>高分辨率</td><td>高分辨率网络</td><td>高分辨率输出</td><td>高分辨率无输出</td><td>平均值</td><td>低分辨率</td><td>高分辨率</td><td>高分辨率网络</td><td>高分辨率输出</td><td>高分辨率无输出</td><td>平均值</td></tr><tr><td>\( \mathbf{{IGR}} \)</td><td>[54]</td><td>0.67</td><td>0.32</td><td>0.55</td><td>7.96</td><td>7.72</td><td>3.45</td><td>6.8</td><td>1.2</td><td>35.2</td><td>44</td><td>97.4</td><td>36.9</td></tr><tr><td>光照图形</td><td>[13]</td><td>0.75</td><td>0.58</td><td>0.78</td><td>7.89</td><td>7.80</td><td>3.56</td><td>1</td><td>1</td><td>1</td><td>1.6</td><td>1</td><td>1.12</td></tr><tr><td>\( \mathbf{{P2M}} \)</td><td>[40]</td><td>0.82</td><td>0.47</td><td>0.73</td><td>1.53</td><td>2.13</td><td>1.13</td><td>1.2</td><td>1</td><td>1.2</td><td>1.4</td><td>1.6</td><td>1.28</td></tr><tr><td>样条曲线*</td><td>[55]</td><td>0.85</td><td>0.32</td><td>0.70</td><td>3.99</td><td>3.93</td><td>1.96</td><td>73.2</td><td>85.6</td><td>937</td><td>1800</td><td>1.60</td><td>971</td></tr><tr><td>时间序列预测回归</td><td>[27]</td><td>0.79</td><td>0.37</td><td>0.57</td><td>0.36</td><td>0.61</td><td>0.54</td><td>1.2</td><td>1.6</td><td>3.6</td><td>3.8</td><td>20.2</td><td>6.08</td></tr><tr><td>时间回归估计</td><td>[46]</td><td>0.64</td><td>0.31</td><td>0.61</td><td>0.34</td><td>0.64</td><td>0.51</td><td>1</td><td>1</td><td>1.2</td><td>1.2</td><td>1</td><td>1.08</td></tr></tbody></table></div><table><tbody><tr><td colspan="2" rowspan="2">\( \mathbf{{Method}} \)</td><td colspan="6">Number of boundary edges \( \left\lbrack   \downarrow  \right\rbrack \)</td><td colspan="6">Number of non-manifold edges \( \left\lbrack   \downarrow  \right\rbrack \)</td></tr><tr><td>LR</td><td>HR</td><td>HRN</td><td>HRO</td><td>HRNO</td><td>Mean</td><td>LR</td><td>HR</td><td>HRN</td><td>HRO</td><td>HRNO</td><td>Mean</td></tr><tr><td>\( \mathbf{{IGR}} \)</td><td>[54]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.8</td><td>0.8</td><td>5.2</td><td>4.2</td><td>2.2</td></tr><tr><td>LIG</td><td>[13]</td><td>69</td><td>42.8</td><td>17.2</td><td>0</td><td>0</td><td>25.8</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>\( \mathbf{{P2M}} \)</td><td>[40]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>SAP*</td><td>[55]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>449</td><td>89.8</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>TSPSR</td><td>[27]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>TRESR</td><td>[46]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>5.8</td><td>24.4</td><td>3.8</td><td>22</td><td>11.4</td></tr></tbody></table><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><table><tbody><tr><td colspan="2" rowspan="2">\( \mathbf{{Method}} \)</td><td colspan="6">边界边的数量 \( \left\lbrack   \downarrow  \right\rbrack \)</td><td colspan="6">非流形边的数量 \( \left\lbrack   \downarrow  \right\rbrack \)</td></tr><tr><td>左侧 (LR)</td><td>右侧 (HR)</td><td>高分辨率网络 (HRN)</td><td>高分辨率输出 (HRO)</td><td>高分辨率非输出 (HRNO)</td><td>平均值</td><td>左侧 (LR)</td><td>右侧 (HR)</td><td>高分辨率网络 (HRN)</td><td>高分辨率输出 (HRO)</td><td>高分辨率非输出 (HRNO)</td><td>平均值</td></tr><tr><td>\( \mathbf{{IGR}} \)</td><td>[54]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.8</td><td>0.8</td><td>5.2</td><td>4.2</td><td>2.2</td></tr><tr><td>光照图 (LIG)</td><td>[13]</td><td>69</td><td>42.8</td><td>17.2</td><td>0</td><td>0</td><td>25.8</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>\( \mathbf{{P2M}} \)</td><td>[40]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>样本 (SAP*)</td><td>[55]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>449</td><td>89.8</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>时间序列预测 (TSPSR)</td><td>[27]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>时间序列回归 (TRESR)</td><td>[46]</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>5.8</td><td>24.4</td><td>3.8</td><td>22</td><td>11.4</td></tr></tbody></table></div><p>Table 4: Comparison of all methods - synthetic data with ground truth (E6): We report the performance of learning-based models trained on ShapeNet, optimization methods without training, and traditional optimization approaches, on shapes of Berger et al. [19] scanned with our MVS procedure. \({}^{ \dagger  }\) methods not based on neural networks.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>表4：所有方法的比较 - 具有真实值的合成数据（E6）：我们报告了在ShapeNet上训练的基于学习的模型、未经过训练的优化方法以及传统优化方法在使用我们的多视图立体（MVS）程序扫描的Berger等人[19]的形状上的表现。\({}^{ \dagger  }\) 不基于神经网络的方法。</p></div><table><tbody><tr><td colspan="3">\( \mathbf{{Method}} \)</td><td>Vol. IoU (%) [↑]</td><td>Normal consist. (%) [↑]</td><td>Chamfer dist. \( \left( {\times {10}^{3}}\right) \)</td><td>Components [↓]</td><td>BE [↓]</td><td>NME \( \left\lbrack   \downarrow  \right\rbrack \)</td></tr><tr><td rowspan="5">Learning</td><td>ConvONet2D</td><td>[11]</td><td>65.1</td><td>78.0</td><td>1.43</td><td>3.6</td><td>0</td><td>0</td></tr><tr><td>ConvONet3D</td><td>[11]</td><td>76.4</td><td>87.2</td><td>0.89</td><td>2.6</td><td>0</td><td>0</td></tr><tr><td>SAP</td><td>[55]</td><td>78.3</td><td>89.0</td><td>0.73</td><td>5.6</td><td>0</td><td>0</td></tr><tr><td>DGNN</td><td>[15]</td><td>82.9</td><td>85.2</td><td>0.59</td><td>1</td><td>0</td><td>0.4</td></tr><tr><td>POCO</td><td>[17]</td><td>83.9</td><td>89.5</td><td>0.58</td><td>2</td><td>0</td><td>0</td></tr><tr><td rowspan="6">Optimization</td><td>\( \mathbf{{IGR}} \)</td><td>[54]</td><td>78.3</td><td>83.8</td><td>0.78</td><td>15.4</td><td>0</td><td>0.4</td></tr><tr><td>LIG</td><td>[13]</td><td>45.7</td><td>86.6</td><td>0.83</td><td>1</td><td>65.6</td><td>0</td></tr><tr><td>\( \mathbf{{P2M}} \)</td><td>[40]</td><td>74.5</td><td>85.0</td><td>0.77</td><td>2</td><td>0</td><td>0</td></tr><tr><td>SAP*</td><td>[55]</td><td>71.9</td><td>77.0</td><td>0.81</td><td>133</td><td>0</td><td>0</td></tr><tr><td>TSPSR</td><td>[27]</td><td>77.6</td><td>86.4</td><td>0.79</td><td>8</td><td>0</td><td>0</td></tr><tr><td>TRESR</td><td>[46]</td><td>79.4</td><td>80.8</td><td>\( \underline{0.67} \)</td><td>1</td><td>0</td><td>9.6</td></tr></tbody></table><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><table><tbody><tr><td colspan="3">\( \mathbf{{Method}} \)</td><td>体积 IoU (%) [↑]</td><td>正常一致性 (%) [↑]</td><td>斜角距离 \( \left( {\times {10}^{3}}\right) \)</td><td>组件 [↓]</td><td>BE [↓]</td><td>NME \( \left\lbrack   \downarrow  \right\rbrack \)</td></tr><tr><td rowspan="5">学习</td><td>ConvONet2D</td><td>[11]</td><td>65.1</td><td>78.0</td><td>1.43</td><td>3.6</td><td>0</td><td>0</td></tr><tr><td>ConvONet3D</td><td>[11]</td><td>76.4</td><td>87.2</td><td>0.89</td><td>2.6</td><td>0</td><td>0</td></tr><tr><td>SAP</td><td>[55]</td><td>78.3</td><td>89.0</td><td>0.73</td><td>5.6</td><td>0</td><td>0</td></tr><tr><td>DGNN</td><td>[15]</td><td>82.9</td><td>85.2</td><td>0.59</td><td>1</td><td>0</td><td>0.4</td></tr><tr><td>POCO</td><td>[17]</td><td>83.9</td><td>89.5</td><td>0.58</td><td>2</td><td>0</td><td>0</td></tr><tr><td rowspan="6">优化</td><td>\( \mathbf{{IGR}} \)</td><td>[54]</td><td>78.3</td><td>83.8</td><td>0.78</td><td>15.4</td><td>0</td><td>0.4</td></tr><tr><td>LIG</td><td>[13]</td><td>45.7</td><td>86.6</td><td>0.83</td><td>1</td><td>65.6</td><td>0</td></tr><tr><td>\( \mathbf{{P2M}} \)</td><td>[40]</td><td>74.5</td><td>85.0</td><td>0.77</td><td>2</td><td>0</td><td>0</td></tr><tr><td>SAP*</td><td>[55]</td><td>71.9</td><td>77.0</td><td>0.81</td><td>133</td><td>0</td><td>0</td></tr><tr><td>TSPSR</td><td>[27]</td><td>77.6</td><td>86.4</td><td>0.79</td><td>8</td><td>0</td><td>0</td></tr><tr><td>TRESR</td><td>[46]</td><td>79.4</td><td>80.8</td><td>\( \underline{0.67} \)</td><td>1</td><td>0</td><td>9.6</td></tr></tbody></table></div><!-- Media --><p>Middlebury MVS, Figs. 8m-8x: SAP stands out as the only learning-based method capable of reconstructing this challenging MVS scan, resulting in a smooth and complete surface, albeit with minor topological noise, such as holes. The optimization-based method P2M delivers a visually appealing reconstruction with minimal defects (Fig. 8u).</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>Middlebury MVS, 图 8m-8x: SAP 是唯一能够重建这一具有挑战性的 MVS 扫描的基于学习的方法，结果是一个平滑且完整的表面，尽管存在一些小的拓扑噪声，例如孔洞。基于优化的方法 P2M 提供了视觉上令人满意的重建，缺陷最小（图 8u）。</p></div><p>DTU MVS, Figs. 8y-8aj: Both learning- and optimization-based methods find this scene challenging, while traditional methods succeed in producing convincing surfaces.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>DTU MVS, 图 8y-8aj: 学习和优化方法都认为这个场景具有挑战性，而传统方法成功地生成了令人信服的表面。</p></div><p>This experiment reinforces our findings from synthetic point clouds: learning-based methods are vulnerable to unfamiliar defects, whereas traditional methods offer a robust and reliable baseline.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>这个实验强化了我们从合成点云中得出的发现：基于学习的方法对不熟悉的缺陷较为脆弱，而传统方法则提供了一个稳健可靠的基线。</p></div><h3>6.5 Runtimes</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>6.5 运行时间</h3></div><p>The detailed runtimes for the methods evaluated in the learning-based experiments are presented in Tab. 5. SAP stands out as the fastest reconstruction method. DGNN also exhibits efficient runtimes, whereas POCO tends to be slower, attributable primarily to its intensive and costly need to search for query neighbors. Additionally, we include runtime comparisons for P2S. Due to its extensive computational demands during both training and inference, P2S was excluded from experiments E1 through E4.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>在学习基础实验中评估的方法的详细运行时间见表 5。SAP 是最快的重建方法。DGNN 也表现出高效的运行时间，而 POCO 则相对较慢，主要是由于其对查询邻居的密集和高成本的搜索需求。此外，我们还包括 P2S 的运行时间比较。由于在训练和推理期间的计算需求较大，P2S 被排除在实验 E1 到 E4 之外。</p></div><!-- Media --><p>Table 5: Runtimes of surface reconstruction methods: Times (in seconds) for reconstructing one object from a point cloud of 3,000 points averaged over the ShapeNet test set. GC stand for Graph-cut; SE stands for surface extraction, such as marching cubes or triangle-from-tetrahedron. Note that different variants and implementations of marching cubes are used by different methods, which also influences the runtimes. SAP [55] has the fastest total runtime. \({}^{ \dagger  }\) methods not based on neural networks.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>表 5: 表面重建方法的运行时间：从 3,000 个点的点云重建一个对象的时间（以秒为单位），在 ShapeNet 测试集上取平均。GC 代表图切割；SE 代表表面提取，如行进立方体或从四面体生成三角形。请注意，不同的方法使用了不同变体和实现的行进立方体，这也影响了运行时间。SAP [55] 具有最快的总运行时间。\({}^{ \dagger  }\) 不是基于神经网络的方法。</p></div><table><tbody><tr><td>Model</td><td></td><td>Feature extraction</td><td>Decoding/GC</td><td>SE</td><td>Total</td></tr><tr><td>ConvONet2D</td><td>[11]</td><td>0.016</td><td>0.32</td><td>0.17</td><td>0.51</td></tr><tr><td>ConvONet3D</td><td>[11]</td><td>0.008</td><td>0.21</td><td>0.17</td><td>0.40</td></tr><tr><td>SAP</td><td>[55]</td><td>0.022</td><td>0.02</td><td>0.05</td><td>0.09</td></tr><tr><td>DGNN</td><td>[15]</td><td>0.110</td><td>0.28</td><td>0.01</td><td>0.39</td></tr><tr><td>POCO</td><td>[17]</td><td>0.088</td><td>13.72</td><td>0.33</td><td>15.74</td></tr><tr><td>P2S</td><td>[14]</td><td colspan="2">69.06</td><td>11.51</td><td>80.57</td></tr><tr><td>TSPSR</td><td>[27]</td><td>-</td><td>-</td><td>-</td><td>1.25</td></tr><tr><td>TRESR</td><td>[46]</td><td>0.1</td><td>0.07</td><td>0.01</td><td>0.18</td></tr></tbody></table><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><table><tbody><tr><td>模型</td><td></td><td>特征提取</td><td>解码/GC</td><td>SE</td><td>总计</td></tr><tr><td>ConvONet2D</td><td>[11]</td><td>0.016</td><td>0.32</td><td>0.17</td><td>0.51</td></tr><tr><td>ConvONet3D</td><td>[11]</td><td>0.008</td><td>0.21</td><td>0.17</td><td>0.40</td></tr><tr><td>SAP</td><td>[55]</td><td>0.022</td><td>0.02</td><td>0.05</td><td>0.09</td></tr><tr><td>DGNN</td><td>[15]</td><td>0.110</td><td>0.28</td><td>0.01</td><td>0.39</td></tr><tr><td>POCO</td><td>[17]</td><td>0.088</td><td>13.72</td><td>0.33</td><td>15.74</td></tr><tr><td>P2S</td><td>[14]</td><td colspan="2">69.06</td><td>11.51</td><td>80.57</td></tr><tr><td>TSPSR</td><td>[27]</td><td>-</td><td>-</td><td>-</td><td>1.25</td></tr><tr><td>TRESR</td><td>[46]</td><td>0.1</td><td>0.07</td><td>0.01</td><td>0.18</td></tr></tbody></table></div><!-- Media --><h3>6.6 Summary and analysis</h3><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h3>6.6 摘要与分析</h3></div><p>When the point clouds in the training and test sets have similar characteristics, learning-based methods produce high-quality reconstructions and even show robustness to noise and missing data. They are able to generalize to unseen shape categories, provided that the training set is sufficiently large (30k shapes in our experiments) and contains shapes of sufficient complexity. This ability implies that the methods primarily learn priors associated with point cloud attributes rather than the shapes themselves. However, learning-based methods do not produce satisfying results when the training shapes are too simple, or when the point clouds include unknown defects, such as outliers. Hybrid approaches such as SAP or DGNN achieve higher robustness to domain shifts and shorter reconstruction times. With the exception of IGR, the newer optimization-based methods we tested do not exhibit strong resilience to acquisition defects and generally do not outperform the traditional methods SPSR and RESR.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>当训练集和测试集中的点云具有相似特征时，基于学习的方法能够产生高质量的重建，甚至对噪声和缺失数据表现出鲁棒性。只要训练集足够大（在我们的实验中为3万种形状）并包含足够复杂的形状，它们能够推广到未见过的形状类别。这种能力意味着这些方法主要学习与点云属性相关的先验知识，而不是形状本身。然而，当训练形状过于简单，或点云中包含未知缺陷（如离群点）时，基于学习的方法无法产生令人满意的结果。混合方法如SAP或DGNN在领域转移和重建时间上表现出更高的鲁棒性。除了IGR外，我们测试的较新优化方法在面对采集缺陷时并未表现出强大的韧性，通常也不优于传统方法SPSR和RESR。</p></div><h2>7 CONCLUSION</h2><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><h2>7 结论</h2></div><p>Surface reconstruction from point clouds is a central subject in digital geometry processing, continually evolving with great strides in acquisition technologies and innovative approaches to surface reconstruction and analysis. In this paper, we have conducted an extensive survey of the field, benchmarking across various datasets a range of recent learning-based and optimization-based methods, alongside established traditional techniques. Our findings reveal that learning-based methods demonstrate compelling performance when tested on point clouds bearing resemblance to their training sets. However, their effectiveness is contingent upon training with shapes of comparable complexity to the test set and they exhibit limited robustness to out-of-distribution acquisition defects. While they may lag behind in in-distribution scenarios, traditional methods consistently offer robust and reliable performance across a broader range of conditions. We also observe that recent learning-free optimization-based methods are outperformed by these traditional methods in almost all settings.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>从点云进行表面重建是数字几何处理中的一个核心主题，随着采集技术的进步和表面重建与分析的新方法的不断创新而不断发展。在本文中，我们对该领域进行了广泛的调查，基于各种数据集对一系列最新的基于学习和基于优化的方法进行了基准测试，并与已建立的传统技术进行了比较。我们的研究结果表明，基于学习的方法在测试与其训练集相似的点云时表现出令人信服的性能。然而，它们的有效性取决于与测试集具有相似复杂度的形状进行训练，并且对分布外采集缺陷的鲁棒性有限。虽然在分布内场景中可能落后，但传统方法在更广泛的条件下始终提供稳健和可靠的性能。我们还观察到，最近的无学习优化方法在几乎所有设置中都被这些传统方法超越。</p></div><p>Real-world scenes often include a variety of complex acquisition defects. Consequently, learning-based methods face challenges in reconstructing such complex point clouds accurately. Thus, the creation or compilation of training data that encompasses a wide array of complex shapes, scanned with realistic defects, becomes crucial yet poses significant challenges. Future directions in learning-based surface reconstruction should prioritize training on point clouds with realistic acquisition defects, such as those common in typical sensor and acquisition setups, or focus on enhancing the resilience of these methods to novel and unseen defects. REFERENCES</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>现实世界的场景通常包含各种复杂的采集缺陷。因此，基于学习的方法在准确重建如此复杂的点云时面临挑战。因此，创建或汇编包含各种复杂形状的训练数据，并且这些形状在扫描时具有现实缺陷，变得至关重要，但也带来了重大挑战。未来基于学习的表面重建方向应优先考虑在具有现实采集缺陷的点云上进行训练，例如在典型传感器和采集设置中常见的缺陷，或专注于增强这些方法对新颖和未见缺陷的韧性。参考文献</p></div><p>[1] M. Berger, A. Tagliasacchi, L. Seversky, P. Alliez, G. Guennebaud, J. Levine, A. Sharf, and C. Silva, "A survey of surface reconstruction from point clouds," Computer Graphics Forum, 2016.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[1] M. Berger, A. Tagliasacchi, L. Seversky, P. Alliez, G. Guennebaud, J. Levine, A. Sharf, 和 C. Silva, "从点云进行表面重建的调查," 计算机图形论坛, 2016.</p></div><p>[2] F. Cazals and J. Giesen, "Delaunay triangulation based surface reconstruction," in Effective computational geometry for curves and surfaces. Springer, 2006.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[2] F. Cazals 和 J. Giesen, "基于德劳内三角剖分的表面重建," 在有效的曲线和表面计算几何中. 施普林格, 2006.</p></div><p>[3] C. C. You, S. P. Lim, S. C. Lim, J. San Tan, C. K. Lee, and Y. M. J. Khaw, "A survey on surface reconstruction techniques for structured and unstructured data," in 2020 IEEE Conference on Open Systems (ICOS). IEEE, 2020, pp. 37-42.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[3] C. C. You, S. P. Lim, S. C. Lim, J. San Tan, C. K. Lee, 和 Y. M. J. Khaw, "结构化和非结构化数据的表面重建技术调查," 在2020年IEEE开放系统会议（ICOS）. IEEE, 2020, 第37-42页.</p></div><p>[4] R. M. Bolle and B. C. Vemuri, "On three-dimensional surface reconstruction methods," IEEE Transactions on Pattern Analysis &#x26; Machine Intelligence, 1991.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[4] R. M. Bolle 和 B. C. Vemuri, "关于三维表面重建方法," IEEE模式分析与机器智能汇刊, 1991.</p></div><p>[5] Z. Huang, Y. Wen, Z. Wang, J. Ren, and K. Jia, "Surface reconstruction from point clouds: A survey and a benchmark," 2022. [Online]. Available: <a href="https://arxiv.org/abs/2205.02413">https://arxiv.org/abs/2205.02413</a></p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[5] Z. Huang, Y. Wen, Z. Wang, J. Ren, 和 K. Jia, "从点云进行表面重建：调查与基准," 2022. [在线]. 可用: <a href="https://arxiv.org/abs/2205.02413">https://arxiv.org/abs/2205.02413</a></p></div><p>[6] Z.-Q. Cheng, Y. Wang, B. Li, K. Xu, G. Dang, and S. Jin, "A survey of methods for moving least squares surfaces." in VG/PBG at SIGGRAPH, 2008.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[6] Z.-Q. Cheng, Y. Wang, B. Li, K. Xu, G. Dang, 和 S. Jin, "移动最小二乘曲面的方法调查." 在SIGGRAPH的VG/PBG, 2008.</p></div><p>[7] M. Botsch, L. Kobbelt, M. Pauly, P. Alliez, and B. Lévy, Polygon mesh processing. CRC press, 2010.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[7] M. Botsch, L. Kobbelt, M. Pauly, P. Alliez, 和 B. Lévy, 多边形网格处理. CRC出版社, 2010.</p></div><p>[8] G. Farin, Curves and surfaces for computer-aided geometric design: a practical guide. Elsevier, 2014.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[8] G. Farin, 计算机辅助几何设计的曲线和表面：实用指南. 爱思唯尔, 2014.</p></div><p>[9] A. J. Gomes, I. Voiculescu, J. Jorge, B. Wyvill, and C. Galbraith, Implicit curves and surfaces: Mathematics, data structures and algorithms. Springer, 2009.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[9] A. J. Gomes, I. Voiculescu, J. Jorge, B. Wyvill, 和 C. Galbraith, 隐式曲线和表面：数学、数据结构和算法. 施普林格, 2009.</p></div><p>[10] A. Farshian, M. Götz, G. Cavallaro, C. Debus, M. Nießner, J. A. Benediktsson, and A. Streit, "Deep-learning-based 3D surface reconstruction-A survey," Proceedings of the IEEE, 2023.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[10] A. Farshian, M. Götz, G. Cavallaro, C. Debus, M. Nießner, J. A. Benediktsson, 和 A. Streit, "基于深度学习的3D表面重建-调查," IEEE会议录, 2023.</p></div><p>[11] S. Peng, M. Niemeyer, L. Mescheder, M. Pollefeys, and A. Geiger, "Convolutional occupancy networks," in European Conference on Computer Vision (ECCV), 2020.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[11] S. Peng, M. Niemeyer, L. Mescheder, M. Pollefeys, 和 A. Geiger, "卷积占用网络," 在欧洲计算机视觉会议 (ECCV), 2020.</p></div><p>[12] R. Chabra, J. E. Lenssen, E. Ilg, T. Schmidt, J. Straub, S. Lovegrove, and R. Newcombe, "Deep local shapes: Learning local SDF priors for detailed 3D reconstruction," in European Conference on Computer Vision (ECCV), 2020.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[12] R. Chabra, J. E. Lenssen, E. Ilg, T. Schmidt, J. Straub, S. Lovegrove, 和 R. Newcombe, "深度局部形状：学习局部 SDF 先验以进行详细的 3D 重建," 在欧洲计算机视觉会议 (ECCV), 2020.</p></div><p>[13] C. M. Jiang, A. Sud, A. Makadia, J. Huang, M. Nießner, and T. Funkhouser, "Local implicit grid representations for 3D scenes," in Conference on Computer Vision and Pattern Recognition (CVPR), 2020.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[13] C. M. Jiang, A. Sud, A. Makadia, J. Huang, M. Nießner, 和 T. Funkhouser, "3D 场景的局部隐式网格表示," 在计算机视觉与模式识别会议 (CVPR), 2020.</p></div><p>[14] P. Erler, S. Ohrhallinger, N. Mitra, and M. Wimmer, "Points2Surf: Learning implicit surfaces from point clouds," in European Conference on Computer Vision (ECCV), 2020.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[14] P. Erler, S. Ohrhallinger, N. Mitra, 和 M. Wimmer, "Points2Surf：从点云学习隐式表面," 在欧洲计算机视觉会议 (ECCV), 2020.</p></div><p>[15] R. Sulzer, L. Landrieu, R. Marlet, and B. Vallet, "Scalable surface reconstruction with delaunay-graph neural networks," Computer Graphics Forum, 2021.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[15] R. Sulzer, L. Landrieu, R. Marlet, 和 B. Vallet, "使用 Delaunay 图神经网络的可扩展表面重建," 计算机图形学论坛, 2021.</p></div><p>[16] M.-J. Rakotosaona, P. Guerrero, N. Aigerman, N. J. Mitra, and M. Ovsjanikov, "Learning delaunay surface elements for mesh reconstruction," in Conference on Computer Vision and Pattern Recognition (CVPR), 2021.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[16] M.-J. Rakotosaona, P. Guerrero, N. Aigerman, N. J. Mitra, 和 M. Ovsjanikov, "学习 Delaunay 表面元素以进行网格重建," 在计算机视觉与模式识别会议 (CVPR), 2021.</p></div><p>[17] A. Boulch and R. Marlet, "Poco: Point convolution for surface reconstruction," in Conference on Computer Vision and Pattern Recognition (CVPR), 2022.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[17] A. Boulch 和 R. Marlet, "Poco：用于表面重建的点卷积," 在计算机视觉与模式识别会议 (CVPR), 2022.</p></div><p>[18] J. J. Park, P. Florence, J. Straub, R. Newcombe, and S. Lovegrove, "DeepSDF: Learning continuous signed distance functions for shape representation," in Conference on Computer Vision and Pattern Recognition (CVPR), 2019.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[18] J. J. Park, P. Florence, J. Straub, R. Newcombe, 和 S. Lovegrove, "DeepSDF：学习用于形状表示的连续有符号距离函数," 在计算机视觉与模式识别会议 (CVPR), 2019.</p></div><p>[19] M. Berger, J. A. Levine, L. G. Nonato, G. Taubin, and C. T. Silva, "A benchmark for surface reconstruction," ACM Transaction on Graphics., 2013.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[19] M. Berger, J. A. Levine, L. G. Nonato, G. Taubin, 和 C. T. Silva, "表面重建基准," ACM 图形学交易, 2013.</p></div><p>[20] S. Seitz, B. Curless, J. Diebel, D. Scharstein, and R. Szeliski, "A comparison and evaluation of multi-view stereo reconstruction algorithms," in Conference on Computer Vision and Pattern Recognition (CVPR), 2006.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[20] S. Seitz, B. Curless, J. Diebel, D. Scharstein, 和 R. Szeliski, "多视图立体重建算法的比较与评估," 在计算机视觉与模式识别会议 (CVPR), 2006.</p></div><p>[21] R. Jensen, A. Dahl, G. Vogiatzis, E. Tola, and H. Aanæs, "Large scale multi-view stereopsis evaluation," in Conference on Computer Vision and Pattern Recognition (CVPR), 2014.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[21] R. Jensen, A. Dahl, G. Vogiatzis, E. Tola, 和 H. Aanæs, "大规模多视图立体评估," 在计算机视觉与模式识别会议 (CVPR), 2014.</p></div><p>[22] C. Strecha, W. von Hansen, L. V. Gool, P. Fua, and U. Thoennessen, "On benchmarking camera calibration and multi-view stereo for high resolution imagery," in Conference on Computer Vision and Pattern Recognition (CVPR). IEEE Computer Society, 2008.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[22] C. Strecha, W. von Hansen, L. V. Gool, P. Fua, 和 U. Thoennessen, "关于高分辨率图像的相机标定和多视图立体的基准测试," 在计算机视觉与模式识别会议 (CVPR). IEEE 计算机学会, 2008.</p></div><p>[23] T. Schöps, J. L. Schönberger, S. Galliani, T. Sattler, K. Schindler, M. Pollefeys, and A. Geiger, "A multi-view stereo benchmark with high-resolution images and multi-camera videos," in Conference on Computer Vision and Pattern Recognition (CVPR), 2017.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[23] T. Schöps, J. L. Schönberger, S. Galliani, T. Sattler, K. Schindler, M. Pollefeys, 和 A. Geiger, "一个具有高分辨率图像和多摄像头视频的多视图立体基准," 在计算机视觉与模式识别会议 (CVPR), 2017.</p></div><p>[24] A. Knapitsch, J. Park, Q.-Y. Zhou, and V. Koltun, "Tanks and Temples," ACM Transactions on Graphics (TOG), 2017.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[24] A. Knapitsch, J. Park, Q.-Y. Zhou, 和 V. Koltun, "坦克与神庙," ACM 图形学交易 (TOG), 2017.</p></div><p>[25] H. Hoppe, T. DeRose, T. Duchamp, J. McDonald, and W. Stuetzle, "Surface reconstruction from unorganized points," in Conference on computer graphics and interactive techniques, 1992.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[25] H. Hoppe, T. DeRose, T. Duchamp, J. McDonald, 和 W. Stuetzle, "从无组织点进行表面重建," 在计算机图形学与交互技术会议, 1992.</p></div><p>[26] B. O'neill, Elementary differential geometry. Elsevier, 2006.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[26] B. O'neill, 《初等微分几何》。Elsevier, 2006.</p></div><p>[27] M. Kazhdan and H. Hoppe, "Screened Poisson surface reconstruction," ACM Transaction on Graphics., 2013.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[27] M. Kazhdan 和 H. Hoppe, "筛选的泊松表面重建," ACM 图形学交易, 2013.</p></div><p>[28] H. H. Vu, P. Labatut, J. P. Pons, and R. Keriven, "High accuracy and visibility-consistent dense multiview stereo," IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 2012.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[28] H. H. Vu, P. Labatut, J. P. Pons, 和 R. Keriven, "高精度和可见性一致的稠密多视图立体视觉," IEEE 模式分析与机器智能交易 (PAMI), 2012.</p></div><p>[29] L. Kettner, "Using generic programming for designing a data structure for polyhedral surfaces," Computational Geometry, 1999.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[29] L. Kettner, "使用通用编程设计多面体表面的数据结构," 计算几何, 1999.</p></div><p>[30] M. Mäntylä, An introduction to solid modeling. Computer Science Press, Inc., 1987.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[30] M. Mäntylä, 固体建模导论. 计算机科学出版社, 1987.</p></div><p>[31] F. Bernardini, J. Mittleman, H. Rushmeier, C. Silva, and G. Taubin, "The ball-pivoting algorithm for surface reconstruction," IEEE transactions on visualization and computer graphics, 1999.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[31] F. Bernardini, J. Mittleman, H. Rushmeier, C. Silva, 和 G. Taubin, "用于表面重建的球体旋转算法," IEEE 可视化与计算机图形交易, 1999.</p></div><p>[32] S. Petitjean and E. Boyer, "Regular and non-regular point sets: Properties and reconstruction," Computational Geometry, 2001.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[32] S. Petitjean 和 E. Boyer, "规则和非规则点集：属性与重建," 计算几何, 2001.</p></div><p>[33] J. Digne, "An analysis and implementation of a parallel ball pivoting algorithm," Image Processing On Line, 2014.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[33] J. Digne, "并行球体旋转算法的分析与实现," 在线图像处理, 2014.</p></div><p>[34] N. Sharp and M. Ovsjanikov, "PointTriNet: Learned triangulation of 3D point sets," in European Conference on Computer Vision (ECCV), 2020, pp. 762-778.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[34] N. Sharp 和 M. Ovsjanikov, "PointTriNet：学习三维点集的三角剖分," 在欧洲计算机视觉会议 (ECCV), 2020, 第762-778页.</p></div><p>[35] M. Liu, X. Zhang, and H. Su, "Meshing point clouds with predicted intrinsic-extrinsic ratio guidance," in European Conference on Computer Vision (ECCV). Springer, 2020.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[35] M. Liu, X. Zhang, 和 H. Su, "使用预测的内在-外在比率指导点云网格化," 在欧洲计算机视觉会议 (ECCV). 施普林格, 2020.</p></div><p>[36] J.-D. Boissonnat, "Geometric structures for 3D shape representation," ACM Transactions on Graphics, 1984.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[36] J.-D. Boissonnat, "三维形状表示的几何结构," ACM 图形学交易, 1984.</p></div><p>[37] T. Groueix, M. Fisher, V. G. Kim, B. C. Russell, and M. Aubry, "AtlasNet: A papier-mâché approach to learning 3D surface generation," in Conference on Computer Vision and Pattern Recognition (CVPR), 2018.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[37] T. Groueix, M. Fisher, V. G. Kim, B. C. Russell, 和 M. Aubry, "AtlasNet：一种纸浆法学习三维表面生成," 在计算机视觉与模式识别会议 (CVPR), 2018.</p></div><p>[38] T. Deprelle, T. Groueix, M. Fisher, V. Kim, B. Russell, and M. Aubry, "Learning elementary structures for \(3\mathrm{\;d}\) shape generation and matching," Advances in Neural Information Processing Systems, 2019.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[38] T. Deprelle, T. Groueix, M. Fisher, V. Kim, B. Russell, 和 M. Aubry, "学习基本结构用于\(3\mathrm{\;d}\)形状生成与匹配," 神经信息处理系统进展, 2019.</p></div><p>[39] A. Sharf, T. Lewiner, A. Shamir, L. Kobbelt, and D. Cohen-Or, "Competing fronts for coarse-to-fine surface reconstruction," in Computer Graphics Forum. Wiley Online Library, 2006.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[39] A. Sharf, T. Lewiner, A. Shamir, L. Kobbelt, 和 D. Cohen-Or, "粗到细表面重建的竞争前沿," 在计算机图形学论坛. 威利在线图书馆, 2006.</p></div><p>[40] R. Hanocka, G. Metzer, R. Giryes, and D. Cohen-Or, "Point2Mesh: A self-prior for deformable meshes," ACM Transaction on Graphics, 2020.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[40] R. Hanocka, G. Metzer, R. Giryes, 和 D. Cohen-Or, "Point2Mesh：可变形网格的自先验," ACM 图形学交易, 2020.</p></div><p>[41] F. Bernardini and C. L. Bajaj, "Sampling and reconstructing manifolds using alpha-shapes," Proc. 9th Canad. Conf. Comput. Geom., 1997.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[41] F. Bernardini 和 C. L. Bajaj, "使用α形状对流形进行采样和重建," 第9届加拿大计算几何会议论文集, 1997.</p></div><p>[42] C. Portaneri, M. Rouxel-Labbé, M. Hemmer, D. Cohen-Steiner, and P. Alliez, "Alpha wrapping with an offset," ACM Transactions on Graphics (TOG), 2022.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[42] C. Portaneri, M. Rouxel-Labbé, M. Hemmer, D. Cohen-Steiner, 和 P. Alliez, "带偏移的α包裹," ACM 图形学交易 (TOG), 2022.</p></div><p>[43] R. Kolluri, J. R. Shewchuk, and J. F. O'Brien, "Spectral surface reconstruction from noisy point clouds," in Eurographics Symposium on Geometry Processing (SGP), 2004.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[43] R. Kolluri, J. R. Shewchuk, 和 J. F. O'Brien, "从噪声点云中重建光谱表面," 在欧洲图形学几何处理研讨会 (SGP), 2004.</p></div><p>[44] S. N. Sinha, P. Mordohai, and M. Pollefeys, "Multi-view stereo via graph cuts on the dual of an adaptive tetrahedral mesh," in International Conference on Computer Vision (ICCV). IEEE, 2007.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[44] S. N. Sinha, P. Mordohai, 和 M. Pollefeys, "通过在自适应四面体网格的对偶上进行图切割的多视图立体," 在国际计算机视觉会议 (ICCV). IEEE, 2007.</p></div><p>[45] V. H. Hiep, R. Keriven, P. Labatut, and J.-P. Pons, "Towards high-resolution large-scale multi-view stereo," in Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 2009.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[45] V. H. Hiep, R. Keriven, P. Labatut, 和 J.-P. Pons, "朝向高分辨率大规模多视图立体," 在计算机视觉与模式识别会议 (CVPR). IEEE, 2009.</p></div><p>[46] P. Labatut, J. P. Pons, and R. Keriven, "Robust and efficient surface reconstruction from range data," Computer Graphics Forum (CGF), 2009.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[46] P. Labatut, J. P. Pons, 和 R. Keriven, "从范围数据中稳健且高效的表面重建," 计算机图形学论坛 (CGF), 2009.</p></div><p>[47] C. Mostegel, R. Prettenthaler, F. Fraundorfer, and H. Bischof, "Scalable surface reconstruction from point clouds with extreme scale and density diversity," in Conference on Computer Vision and Pattern Recognition (CVPR), 2017.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[47] C. Mostegel, R. Prettenthaler, F. Fraundorfer, 和 H. Bischof, "从具有极端规模和密度多样性的点云中可扩展的表面重建," 在计算机视觉与模式识别会议 (CVPR), 2017.</p></div><p>[48] L. Caraffa, M. Brédif, and B. Vallet, "3D watertight mesh generation with uncertainties from ubiquitous data," in Asian Conference on Computer Vision (ACCV), 2017.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[48] L. Caraffa, M. Brédif, 和 B. Vallet, "基于普遍数据的不确定性生成3D密闭网格," 在亚洲计算机视觉会议 (ACCV), 2017.</p></div><p>[49] Y. Luo, Z. Mi, and W. Tao, "Deepdt: Learning geometry from delaunay triangulation for surface reconstruction," in AAAI Conference on Artificial Intelligence, 2021.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[49] Y. Luo, Z. Mi, 和 W. Tao, "Deepdt: 从德劳内三角剖分中学习几何以进行表面重建," 在AAAI人工智能会议, 2021.</p></div><p>[50] M. Kazhdan, M. Bolitho, and H. Hoppe, "Poisson surface reconstruction," in Eurographics Symposium on Geometry Processing (SGP). Eurographics Association, 2006.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[50] M. Kazhdan, M. Bolitho, 和 H. Hoppe, "泊松表面重建," 在欧洲图形学几何处理研讨会 (SGP). 欧洲图形学协会, 2006.</p></div><p>[51] R. Kolluri, "Provably good moving least squares," ACM Transactions on Algorithms (TALG), 2008.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[51] R. Kolluri, "可证明的良好移动最小二乘法," ACM算法交易 (TALG), 2008.</p></div><p>[52] M. Kazhdan, M. Chuang, S. Rusinkiewicz, and H. Hoppe, "Poisson Surface Reconstruction with Envelope Constraints," Computer Graphics Forum, 2020.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[52] M. Kazhdan, M. Chuang, S. Rusinkiewicz, 和 H. Hoppe, "带有包络约束的泊松表面重建," 计算机图形学论坛, 2020.</p></div><p>[53] L. Mescheder, M. Oechsle, M. Niemeyer, S. Nowozin, and A. Geiger, "Occupancy networks: Learning 3D reconstruction in function space," in Conference on Computer Vision and Pattern Recognition (CVPR), 2019.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[53] L. Mescheder, M. Oechsle, M. Niemeyer, S. Nowozin, 和 A. Geiger, "占用网络：在函数空间中学习3D重建," 在计算机视觉与模式识别会议 (CVPR), 2019.</p></div><p>[54] A. Gropp, L. Yariv, N. Haim, M. Atzmon, and Y. Lipman, "Implicit geometric regularization for learning shapes," in Machine Learning and Systems. JMLR.org, 2020.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[54] A. Gropp, L. Yariv, N. Haim, M. Atzmon, 和 Y. Lipman, "用于学习形状的隐式几何正则化," 在机器学习与系统. JMLR.org, 2020.</p></div><p>[55] S. Peng, C. M. Jiang, Y. Liao, M. Niemeyer, M. Pollefeys, and A. Geiger, "Shape as points: A differentiable Poisson solver," in Conference on Neural Information Processing Systems (NeurIPS), 2021.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[55] S. Peng, C. M. Jiang, Y. Liao, M. Niemeyer, M. Pollefeys, 和 A. Geiger, "形状作为点：一种可微分的泊松求解器," 在神经信息处理系统会议 (NeurIPS), 2021.</p></div><p>[56] J. Huang, H.-X. Chen, and S.-M. Hu, "A neural galerkin solver for accurate surface reconstruction," ACM Transactions on Graphics (TOG), 2022.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[56] J. Huang, H.-X. Chen, 和 S.-M. Hu, "一种用于精确表面重建的神经Galerkin求解器," ACM图形学交易 (TOG), 2022.</p></div><p>[57] F. Williams, Z. Gojcic, S. Khamis, D. Zorin, J. Bruna, S. Fidler, and O. Litany, "Neural fields as learnable kernels for 3D reconstruction," in Conference on Computer Vision and Pattern Recognition (CVPR), 2022.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[57] F. Williams, Z. Gojcic, S. Khamis, D. Zorin, J. Bruna, S. Fidler, 和 O. Litany, "神经场作为可学习的3D重建核," 在计算机视觉与模式识别会议 (CVPR), 2022.</p></div><p>[58] J. Huang, Z. Gojcic, M. Atzmon, O. Litany, S. Fidler, and F. Williams, "Neural kernel surface reconstruction," in Conference on Computer Vision and Pattern Recognition (CVPR), 2023.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[58] J. Huang, Z. Gojcic, M. Atzmon, O. Litany, S. Fidler, 和 F. Williams, "神经核表面重建," 在计算机视觉与模式识别会议 (CVPR), 2023.</p></div><p>[59] J.-D. Boissonnat and S. Oudot, "Provably good sampling and meshing of surfaces," Graphical Models, 2005.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[59] J.-D. Boissonnat 和 S. Oudot, "可证明的良好采样和表面网格化," 图形模型, 2005.</p></div><p>[60] W. E. Lorensen and H. E. Cline, "Marching cubes: A high resolution 3D surface construction algorithm," ACM SIGGRAPH Computer Graphics, 1987.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[60] W. E. Lorensen 和 H. E. Cline, "行进立方体：一种高分辨率3D表面构建算法," ACM SIGGRAPH 计算机图形, 1987.</p></div><p>[61] N. Maruani, R. Klokov, M. Ovsjanikov, P. Alliez, and M. Desbrun, "VoroMesh: Learning watertight surface meshes with Voronoi diagrams," in International Conference on Computer Vision (ICCV), 2023.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[61] N. Maruani, R. Klokov, M. Ovsjanikov, P. Alliez, 和 M. Desbrun, "VoroMesh：使用Voronoi图学习密闭表面网格," 在国际计算机视觉会议 (ICCV), 2023.</p></div><p>[62] Z. Chen, A. Tagliasacchi, T. Funkhouser, and H. Zhang, "Neural dual contouring," ACM Transactions on Graphics (TOG), 2022.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[62] Z. Chen, A. Tagliasacchi, T. Funkhouser, 和 H. Zhang, "神经双重轮廓," ACM 图形学交易 (TOG), 2022.</p></div><p>[63] Z. Chen and H. Zhang, "Neural marching cubes," ACM Transactions on Graphics (TOG), 2021.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[63] Z. Chen 和 H. Zhang, "神经行进立方体," ACM 图形学交易 (TOG), 2021.</p></div><p>[64] M. Vetsch, S. Lombardi, M. Pollefeys, and M. R. Oswald, "Neu-ralMeshing: Differentiable meshing of implicit neural representations," in Pattern Recognition, B. Andres, F. Bernard, D. Cremers, S. Frintrop, B. Goldlücke, and I. Ihrke, Eds. Springer, 2022.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[64] M. Vetsch, S. Lombardi, M. Pollefeys, 和 M. R. Oswald, "神经网格化：隐式神经表示的可微网格化," 在模式识别, B. Andres, F. Bernard, D. Cremers, S. Frintrop, B. Goldlücke, 和 I. Ihrke, 编辑. 施普林格, 2022.</p></div><p>[65] D. Attali, J.-D. Boissonnat, and A. Lieutier, "Complexity of the Delaunay triangulation of points on surfaces the smooth case," in Eurographics Symposium on Geometry Processing (SGP), 2003.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[65] D. Attali, J.-D. Boissonnat, 和 A. Lieutier, "表面上点的德劳内三角剖分的复杂性：光滑情况," 在欧洲图形学几何处理研讨会 (SGP), 2003.</p></div><p>[66] N. Amenta, M. Bern, and D. Eppstein, "The crust and the \(\beta\) - skeleton: Combinatorial curve reconstruction," Graphical models and image processing, 1998.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[66] N. Amenta, M. Bern, 和 D. Eppstein, "壳和\(\beta\) - 骨架：组合曲线重建," 图形模型与图像处理, 1998.</p></div><p>[67] Y. Zhou, S. Shen, and Z. Hu, "Detail preserved surface reconstruction from point cloud," Sensors, 2019.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[67] Y. Zhou, S. Shen, 和 Z. Hu, "从点云中重建保留细节的表面," 传感器, 2019.</p></div><p>[68] M. Jancosek and T. Pajdla, "Multi-view reconstruction preserving weakly-supported surfaces," in Conference on Computer Vision and Pattern Recognition (CVPR), 2011.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[68] M. Jancosek 和 T. Pajdla, "保留弱支撑表面的多视图重建," 在计算机视觉与模式识别会议 (CVPR), 2011.</p></div><p>[69] M. Jancosek and T. Pajdla, "Exploiting visibility information in surface reconstruction to preserve weakly supported surfaces," International Scholarly Research Notices, 2014.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[69] M. Jancosek 和 T. Pajdla, "利用可见性信息进行表面重建以保留弱支撑表面," 国际学术研究通知, 2014.</p></div><p>[70] Y. Boykov and V. Kolmogorov, "An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision," IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 2004.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[70] Y. Boykov 和 V. Kolmogorov, "用于视觉中能量最小化的最小割/最大流算法的实验比较," IEEE 模式分析与机器智能交易 (PAMI), 2004.</p></div><p>[71] L. Caraffa, Y. Marchand, M. Brédif, and B. Vallet, "Efficiently distributed watertight surface reconstruction," in 3DV, 2021.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[71] L. Caraffa, Y. Marchand, M. Brédif, 和 B. Vallet, "高效分布式密闭表面重建," 在3DV, 2021.</p></div><p>[72] A. H.-D. Cheng and D. T. Cheng, "Heritage and early history of the boundary element method," Engineering analysis with boundary elements, 2005.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[72] A. H.-D. Cheng 和 D. T. Cheng, "边界元法的遗产和早期历史," 边界元法工程分析, 2005.</p></div><p>[73] Z. Chen and H. Zhang, "Learning implicit fields for generative shape modeling," in Conference on Computer Vision and Pattern Recognition (CVPR), 2019.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[73] Z. Chen 和 H. Zhang, "学习隐式场以进行生成形状建模," 在计算机视觉与模式识别会议 (CVPR), 2019.</p></div><p>[74] O. Ronneberger, P. Fischer, and T. Brox, "U-net: Convolutional networks for biomedical image segmentation," in International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). Springer, 2015.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[74] O. Ronneberger, P. Fischer, 和 T. Brox, "U-net：用于生物医学图像分割的卷积网络," 在国际医学图像计算与计算机辅助干预会议 (MICCAI). 施普林格, 2015.</p></div><p>[75] Ö. Çiçek, A. Abdulkadir, S. S. Lienkamp, T. Brox, and O. Ron-neberger, "3D U-Net: Learning dense volumetric segmentation from sparse annotation," in International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). Springer, 2016.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[75] Ö. Çiçek, A. Abdulkadir, S. S. Lienkamp, T. Brox, 和 O. Ron-neberger, "3D U-Net: 从稀疏注释中学习密集体积分割," 在国际医学图像计算与计算机辅助干预会议 (MICCAI) 中. Springer, 2016.</p></div><p>[76] A. Boulch, "Convpoint: Continuous convolutions for point cloud processing," Computers &#x26; Graphics, 2020.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[76] A. Boulch, "Convpoint: 用于点云处理的连续卷积," 计算机与图形, 2020.</p></div><p>[77] B. Mildenhall, P. P. Srinivasan, M. Tancik, J. T. Barron, R. Ra-mamoorthi, and R. Ng, "NeRF: Representing scenes as neural radiance fields for view synthesis," in European Conference on Computer Vision (ECCV), 2020.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[77] B. Mildenhall, P. P. Srinivasan, M. Tancik, J. T. Barron, R. Ra-mamoorthi, 和 R. Ng, "NeRF: 将场景表示为神经辐射场以进行视图合成," 在欧洲计算机视觉会议 (ECCV), 2020.</p></div><p>[78] ——, “NERF: Representing scenes as neural radiance fields for view synthesis," Communications of the ACM, 2021.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[78] ——, “NERF: 将场景表示为神经辐射场以进行视图合成," ACM通讯, 2021.</p></div><p>[79] J. Ichnowski*, Y. Avigal*, J. Kerr, and K. Goldberg, "Dex-NeRF: Using a neural radiance field to grasp transparent objects," in Conference on Robot Learning (CoRL), 2020.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[79] J. Ichnowski*, Y. Avigal*, J. Kerr, 和 K. Goldberg, "Dex-NeRF: 使用神经辐射场抓取透明物体," 在机器人学习会议 (CoRL), 2020.</p></div><p>[80] M. Oechsle, S. Peng, and A. Geiger, "UNISURF: Unifying neural implicit surfaces and radiance fields for multi-view reconstruction," in International Conference on Computer Vision (ICCV), 2021.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[80] M. Oechsle, S. Peng, 和 A. Geiger, "UNISURF: 统一神经隐式表面和辐射场以进行多视图重建," 在国际计算机视觉会议 (ICCV), 2021.</p></div><p>[81] L. Yariv, P. Hedman, C. Reiser, D. Verbin, P. P. Srinivasan, R. Szeliski, J. T. Barron, and B. Mildenhall, "Bakedsdf: Meshing neural sdfs for real-time view synthesis," arXiv, 2023.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[81] L. Yariv, P. Hedman, C. Reiser, D. Verbin, P. P. Srinivasan, R. Szeliski, J. T. Barron, 和 B. Mildenhall, "Bakedsdf: 为实时视图合成网格化神经 sdf," arXiv, 2023.</p></div><p>[82] A. Guédon and V. Lepetit, "SuGaR: Surface-aligned gaussian splatting for efficient \(3\mathrm{D}\) mesh reconstruction and high-quality mesh rendering," CVPR, 2023.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[82] A. Guédon 和 V. Lepetit, "SuGaR: 表面对齐高斯喷溅以实现高效的 \(3\mathrm{D}\) 网格重建和高质量网格渲染," CVPR, 2023.</p></div><p>[83] P. Wang, L. Liu, Y. Liu, C. Theobalt, T. Komura, and W. Wang, "Neus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction," NeurIPS, 2021.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[83] P. Wang, L. Liu, Y. Liu, C. Theobalt, T. Komura, 和 W. Wang, "Neus: 通过体积渲染学习神经隐式表面以进行多视图重建," NeurIPS, 2021.</p></div><p>[84] L. Yariv, J. Gu, Y. Kasten, and Y. Lipman, "Volume rendering of neural implicit surfaces," NeurIPS, 2021.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[84] L. Yariv, J. Gu, Y. Kasten, 和 Y. Lipman, "神经隐式表面的体积渲染," NeurIPS, 2021.</p></div><p>[85] K. Rematas, A. Liu, P. P. Srinivasan, J. T. Barron, A. Tagliasacchi, T. Funkhouser, and V. Ferrari, "Urban radiance fields," in CVPR, 2022.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[85] K. Rematas, A. Liu, P. P. Srinivasan, J. T. Barron, A. Tagliasacchi, T. Funkhouser, 和 V. Ferrari, "城市辐射场," 在 CVPR, 2022.</p></div><p>[86] Z. Li, T. Müller, A. Evans, R. H. Taylor, M. Unberath, M.-Y. Liu, and C.-H. Lin, "Neuralangelo: High-fidelity neural surface reconstruction," in CVPR, 2023.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[86] Z. Li, T. Müller, A. Evans, R. H. Taylor, M. Unberath, M.-Y. Liu, 和 C.-H. Lin, "Neuralangelo: 高保真神经表面重建," 在 CVPR, 2023.</p></div><p>[87] B. Kerbl, G. Kopanas, T. Leimkühler, and G. Drettakis, "3D Gaussian splatting for real-time radiance field rendering," ACM Transactions on Graphics, 2023.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[87] B. Kerbl, G. Kopanas, T. Leimkühler, 和 G. Drettakis, "用于实时辐射场渲染的 3D 高斯喷溅," ACM 图形学交易, 2023.</p></div><p>[88] A. Guédon and V. Lepetit, "Gaussian frosting: Editable complex radiance fields with real-time rendering," ECCV, 2024.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[88] A. Guédon 和 V. Lepetit, "高斯霜冻: 可编辑的复杂辐射场与实时渲染," ECCV, 2024.</p></div><p>[89] A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su et al., "Shapenet: An information-rich 3D model repository," arXiv preprint arXiv:1512.03012, 2015.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[89] A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su 等, "Shapenet: 一个信息丰富的 3D 模型库," arXiv 预印本 arXiv:1512.03012, 2015.</p></div><p>[90] Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and J. Xiao, "3S ShapeNets: A deep representation for volumetric shapes," in Conference on Computer Vision and Pattern Recognition (CVPR), 2015.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[90] Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, 和 J. Xiao, "3S ShapeNets: 一种体积形状的深度表示," 在计算机视觉与模式识别会议 (CVPR), 2015.</p></div><p>[91] J. Huang, Y. Zhou, and L. Guibas, "ManifoldPlus: A robust and scalable watertight manifold surface generation method for triangle soups," arXiv preprint arXiv:2005.11621, 2020.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[91] J. Huang, Y. Zhou, 和 L. Guibas, "ManifoldPlus: 一种稳健且可扩展的三角形汤的密闭流形表面生成方法," arXiv 预印本 arXiv:2005.11621, 2020.</p></div><p>[92] C. B. Choy, D. Xu, J. Gwak, K. Chen, and S. Savarese, "3D-R2N2: A unified approach for single and multi-view 3D object reconstruction," in European Conference on Computer Vision (ECCV), 2016.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[92] C. B. Choy, D. Xu, J. Gwak, K. Chen, 和 S. Savarese, "3D-R2N2：单视图和多视图3D物体重建的统一方法," 发表在欧洲计算机视觉会议（ECCV），2016年。</p></div><p>[93] F. Cazals and M. Pouget, "Estimating differential quantities using polynomial fitting of osculating jets," Computer Aided Geometric Design, 2005.</p><div style="background-color: rgb(240, 240, 240); padding: 2px 8px; border-radius: 4px; margin: 8px 0px; visibility: visible;"><p>[93] F. Cazals 和 M. Pouget, "使用摆动喷流的多项式拟合估计微分量," 计算机辅助几何设计, 2005年。</p></div>
      </body>
    </html>
  