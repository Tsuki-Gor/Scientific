
    <!DOCTYPE html>
    <html lang="en">
      <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>2024-A Pipeline of Neural-Symbolic Integration to Enhance Spatial Reasoning </title>
        <style>
            * {
              padding: 0;
              margin: 0;
              box-sizing: border-box;
            }
             html {
              line-height: 1.15; /* 1 */
              -webkit-text-size-adjust: 100%; /* 2 */
            }
            body {
              padding: 20px 350px;
              margin: 0;
            }
            main {
              display: block;
            }
            h1 {
              font-size: 2em;
              margin: 0.67em 0;
            }
            hr {
              box-sizing: content-box; /* 1 */
              height: 0; /* 1 */
              overflow: visible; /* 2 */
            }
            pre {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            a {
              background-color: transparent;
            }
            abbr[title] {
              border-bottom: none; /* 1 */
              text-decoration: underline; /* 2 */
              text-decoration: underline dotted; /* 2 */
            }
            b,
            strong {
              font-weight: bolder;
            }
            code,
            kbd,
            samp {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            small {
              font-size: 80%;
            }
            sub,
            sup {
              font-size: 75%;
              line-height: 0;
              position: relative;
              vertical-align: baseline;
            }
            sub {
              bottom: -0.25em;
            }
            sup {
              top: -0.5em;
            }
            img {
              border-style: none;
            }
            button,
            input,
            optgroup,
            select,
            textarea {
              font-family: inherit; /* 1 */
              font-size: 100%; /* 1 */
              line-height: 1.15; /* 1 */
              margin: 0; /* 2 */
            }
            button,
            input { /* 1 */
              overflow: visible;
            }
            button,
            select { /* 1 */
              text-transform: none;
            }
            button,
            [type="button"],
            [type="reset"],
            [type="submit"] {
              -webkit-appearance: button;
            }
            button::-moz-focus-inner,
            [type="button"]::-moz-focus-inner,
            [type="reset"]::-moz-focus-inner,
            [type="submit"]::-moz-focus-inner {
              border-style: none;
              padding: 0;
            }
            button:-moz-focusring,
            [type="button"]:-moz-focusring,
            [type="reset"]:-moz-focusring,
            [type="submit"]:-moz-focusring {
              outline: 1px dotted ButtonText;
            }
            fieldset {
              padding: 0.35em 0.75em 0.625em;
            }
            legend {
              box-sizing: border-box; /* 1 */
              color: inherit; /* 2 */
              display: table; /* 1 */
              max-width: 100%; /* 1 */
              padding: 0; /* 3 */
              white-space: normal; /* 1 */
            }
            progress {
              vertical-align: baseline;
            }
            textarea {
              overflow: auto;
            }
            [type="checkbox"],
            [type="radio"] {
              box-sizing: border-box; /* 1 */
              padding: 0; /* 2 */
            }
            [type="number"]::-webkit-inner-spin-button,
            [type="number"]::-webkit-outer-spin-button {
              height: auto;
            }
            [type="search"] {
              -webkit-appearance: textfield; /* 1 */
              outline-offset: -2px; /* 2 */
            }
            [type="search"]::-webkit-search-decoration {
              -webkit-appearance: none;
            }
            ::-webkit-file-upload-button {
              -webkit-appearance: button; /* 1 */
              font: inherit; /* 2 */
            }
            details {
              display: block;
            }
            summary {
              display: list-item;
            }
            [hidden] {
              display: none;
            }
             table {
                border-collapse: collapse;
                width: 100%;
                margin-top: 20px;
                margin-bottom: 20px;
              }
              table thead {
                background-color: #e5e5e5;
              }
              table td {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              table th {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              h1, h2, h3, h4, h5, h6 {
                margin-bottom: 20px;
              }
              p {
                margin-top: 20px;
                text-indent: 2em;
                margin-bottom: 20px;
              }
        </style>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      </head>
      <body>
        <div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-0="0,0"><div style="height: auto;"><h1><div><div>A Pipeline of Neural-Symbolic Integration to Enhance Spatial Reasoning in Large Language Models<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">神经符号集成的管道以增强大型语言模型的空间推理能力</div></div></div></h1></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-0="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-0="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>Rong Wang <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="644" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2217"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mo>∗</mo><mn>1</mn></mrow></msup></math></mjx-assistive-mml></mjx-container> ,Kun Sun <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="645" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msup></math></mjx-assistive-mml></mjx-container> ,and Jonas Kuhn <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="646" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>3</mn></mrow></msup></math></mjx-assistive-mml></mjx-container><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Rong Wang <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="647" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2217"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mo>∗</mo><mn>1</mn></mrow></msup></math></mjx-assistive-mml></mjx-container>，Kun Sun <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="648" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msup></math></mjx-assistive-mml></mjx-container>，和 Jonas Kuhn <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="649" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>3</mn></mrow></msup></math></mjx-assistive-mml></mjx-container></div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-0="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-0="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="650" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn><mo>,</mo><mn>3</mn></mrow></msup></math></mjx-assistive-mml></mjx-container> The Institute of Natural Language Processing,Stuttgart University,Stuttgart,<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="651" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn><mo>,</mo><mn>3</mn></mrow></msup></math></mjx-assistive-mml></mjx-container> 斯图加特大学自然语言处理研究所，斯图加特，</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-0="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-0="0,0"><div style="height: auto;"><div><div><div>Germany<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">德国</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-0="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-0="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="652" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msup></math></mjx-assistive-mml></mjx-container> Tübingen,Germany<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="653" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msup></math></mjx-assistive-mml></mjx-container> 图宾根，德国</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-0="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-0="0,0"><div style="height: auto;"><h2><div><div>Abstract<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">摘要</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-0="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-0="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div xt-marked="ok">Large Language Models (LLMs) have demonstrated impressive capabilities across various tasks. However, LLMs often struggle with spatial reasoning which is one essential part of reasoning and inference and requires understanding complex relationships between objects in space. This paper proposes a novel neural-symbolic framework that enhances LLMs' spatial reasoning abilities. We evaluate our approach on two benchmark datasets: StepGame and SparQA, implementing three distinct strategies: (1) ASP (Answer Set Programming)-based symbolic reasoning, (2) LLM + ASP pipeline using DSPy, and (3) Fact + Logical rules. Our experiments demonstrate significant improvements over the baseline prompting methods, with accuracy increases of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="654" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>40</mn></mrow><mo>−</mo><mrow data-mjx-texclass="ORD"><mn>50</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> on StepGame dataset and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="655" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>3</mn><mo>−</mo><mrow data-mjx-texclass="ORD"><mn>13</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> on the more complex SparQA dataset. The "LLM + ASP" pipeline achieves particularly strong results on the tasks of Finding Relations (FR) and Finding Block (FB) questions, though performance varies across different question types. Our impressive results suggest that while neural-symbolic approaches offer promising directions for enhancing spatial reasoning in LLMs, their effectiveness depends heavily on the specific task characteristics and implementation strategies. We propose an <xt-mark w="integrate" style="color: #ff8861 !important">integrated</xt-mark>, simple yet effective set of strategies using a neural-symbolic pipeline to boost spatial reasoning abilities in LLMs. This pipeline and its strategies demonstrate strong generalizability and broader applicability to other reasoning domains in LLMs, such as temporal reasoning, <xt-mark w="deductive" style="color: #ff8861 !important">deductive</xt-mark> inference etc.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">大型语言模型（LLMs）在各种任务中展示了令人印象深刻的能力。然而，LLMs 在空间推理方面常常面临挑战，而空间推理是推理和推断的一个重要部分，要求理解空间中物体之间的复杂关系。本文提出了一种新颖的神经符号框架，以增强 LLMs 的空间推理能力。我们在两个基准数据集上评估我们的方法：StepGame 和 SparQA，实施三种不同的策略：（1）基于 ASP（答案集编程）的符号推理，（2）使用 DSPy 的 LLM + ASP 管道，以及（3）事实 + 逻辑规则。我们的实验显示，相较于基线提示方法，准确率在 StepGame 数据集上提高了 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="656" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>40</mn></mrow><mo>−</mo><mrow data-mjx-texclass="ORD"><mn>50</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container>，在更复杂的 SparQA 数据集上提高了 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="657" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>3</mn><mo>−</mo><mrow data-mjx-texclass="ORD"><mn>13</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container>。“LLM + ASP”管道在寻找关系（FR）和寻找块（FB）问题的任务上取得了特别强的结果，尽管不同问题类型的表现有所不同。我们令人印象深刻的结果表明，尽管神经符号方法为增强 LLMs 的空间推理提供了有希望的方向，但其有效性在很大程度上依赖于具体任务的特征和实施策略。我们提出了一套集成的、简单而有效的策略，利用神经符号管道来提升 LLMs 的空间推理能力。该管道及其策略展示了强大的可推广性和更广泛的适用性，可以应用于 LLMs 中的其他推理领域，如时间推理、演绎推理等。</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-0="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><hr><paragraphpositioning data-position-0="0,0"></paragraphpositioning></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-0="0,0"><div style="height: auto;"><div><div><div>*Correspondence to R. W., Email:rongw. de@gmail.com<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">*通讯作者：R. W.，电子邮件：rongw.de@gmail.com</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-0="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-b2fd8767-45de-49f0-9d11-41d8168073b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><hr><paragraphpositioning data-position-0="0,0"></paragraphpositioning></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-9c528c5c-dd5d-4bee-b3ae-bfa2c782c7a3" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-2="0,0"><div style="height: auto;"><h2><div><div>1 Introduction<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">1 引言</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-9c528c5c-dd5d-4bee-b3ae-bfa2c782c7a3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-2="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-9c528c5c-dd5d-4bee-b3ae-bfa2c782c7a3" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-2="0,0"><div style="height: auto;"><div><div><div>Large Language Models (LLMs) are known for their impressive performance across a range of tasks, demonstrating certain commonsense reasoning abilities. However, since LLMs are trained to predict subsequent words in a sequence, they seem to lack sufficient grounding to excel at tasks requiring spatial, physical, and embodied reasoning. Recent studies (Bang et al., 2023; Cohn, 2023), highlighted the limitations of models like ChatGPT in deductive logical reasoning, spatial reasoning and non-textual semantic reasoning, underlining the need for further improvements in spatial reasoning.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">大型语言模型（LLMs）以其在多种任务中的出色表现而闻名，展现了一定的常识推理能力。然而，由于LLMs是通过预测序列中的后续单词进行训练的，它们似乎缺乏足够的基础来在需要空间、物理和具身推理的任务中表现出色。最近的研究（Bang et al., 2023; Cohn, 2023）强调了像ChatGPT这样的模型在演绎逻辑推理、空间推理和非文本语义推理方面的局限性，突显了在空间推理方面进一步改进的必要性。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-9c528c5c-dd5d-4bee-b3ae-bfa2c782c7a3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-2="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-9c528c5c-dd5d-4bee-b3ae-bfa2c782c7a3" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-2="0,0"><div style="height: auto;"><div><div><div>Spatial reasoning is a crucial cognitive function that enables humans to conceptualize and predict the movement and interactions of objects in two or three-dimensional spaces (Byrne and Johnson-Laird, 1989). Spatial reasoning is one essential part of reasoning and inference. Reasoning and inference are essential building blocks in advancing Artificial General Intelligence (AGI), which aims to create AI systems that can perform at or beyond human levels across a wide range of cognitive tasks (Kumar et al., 2023). If LLMs are to approach AGI, they must be equipped with spatial reasoning abilities comparable to those of humans. These capabilities are not only valuable in themselves but also essential for LLM-based applications in robotics, task planning, path planning, and navigation (Sharma, 2023; Chen et al., 2024).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">空间推理是一个关键的认知功能，使人类能够在二维或三维空间中概念化和预测物体的运动和相互作用（Byrne和Johnson-Laird, 1989）。空间推理是推理和推断的重要组成部分。推理和推断是推进人工通用智能（AGI）的基本构件，AGI旨在创建能够在广泛的认知任务中达到或超越人类水平的人工智能系统（Kumar et al., 2023）。如果LLMs要接近AGI，它们必须具备与人类相当的空间推理能力。这些能力不仅本身具有价值，而且对于基于LLM的机器人技术、任务规划、路径规划和导航应用至关重要（Sharma, 2023; Chen et al., 2024）。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-9c528c5c-dd5d-4bee-b3ae-bfa2c782c7a3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-2="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-9c528c5c-dd5d-4bee-b3ae-bfa2c782c7a3" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-2="0,0"><div style="height: auto;"><div><div><div>Spatial reasoning includes two primary categories: quantitative and qualitative reasoning. Quantitative spatial reasoning involves precise mathematical computations of spatial properties such as distances, angles, coordinates, and dimensions. In contrast, qualitative spatial reasoning (QSR) deals with more abstract, symbolic relationships and relative positions between objects (Cohn and Renz, 2008). QSR comprises directional relations describing how objects are oriented relative to each other (e.g., "north", "left"), distance relations capturing relative proximity (e.g., "near", "far"), and topological relations characterizing how spatial regions connect and contain each other (e.g., "inside", "overlapping", "disconnected"). LLMs face significant challenges in processing these spatial relationships, as they must not only comprehend semantic descriptions of scenes but also perform complex multi-hop reasoning about how objects relate to one another in space (Li et al., 2024a; Yang et al., 2024).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">空间推理包括两个主要类别：定量推理和定性推理。定量空间推理涉及对空间属性的精确数学计算，如距离、角度、坐标和维度。相反，定性空间推理（QSR）处理更抽象的符号关系和对象之间的相对位置（Cohn 和 Renz, 2008）。QSR 包括描述对象相对方向的关系（例如，“北”，“左”）、捕捉相对接近性的距离关系（例如，“近”，“远”）以及表征空间区域如何相互连接和包含的拓扑关系（例如，“内部”，“重叠”，“断开”）。大型语言模型在处理这些空间关系时面临重大挑战，因为它们不仅必须理解场景的语义描述，还必须对对象在空间中的相互关系进行复杂的多跳推理（Li et al., 2024a; Yang et al., 2024）。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-9c528c5c-dd5d-4bee-b3ae-bfa2c782c7a3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-2="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-9c528c5c-dd5d-4bee-b3ae-bfa2c782c7a3" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-2="0,0"><div style="height: auto;"><div><div><div>Traditional approaches in LLMs mainly rely on free-form prompting in a single call to LLMs for facilitating spatial reasoning. However, these methods have demonstrated notable limitations, particularly on challenging datasets like StepGame (Shi et al., 2022) and SparQA (Mirzaee and Kordjamshidi, 2022), which require multi-step planning. In these scenarios, LLMs often struggle with maintaining coherence, frequently hallucinating or losing sight of the original objectives, resulting in inaccurate and unreliable outputs. Recent advancements have shown promise in augmenting LLMs with external tools for tasks requiring arithmetic, navigation, and knowledge base lookups (Fang et al., 2024). However, these efforts are insufficient for enhancing spatial reasoning in LLMs significantly. Recent studies have introduced neural-symbolic strategies, such as ASP (Answer Set Programming) (Yang et al., 2023), to address the limitations of prompting-based approaches. Neural-symbolic methods typically follow a two-step process: extracting facts using LLMs and then applying logical reasoning. As is known, LLMs excel at extracting facts but struggle with reasoning. However, integrating logical reasoning can effectively bridge this gap in their reasoning capabilities. This approach therefore mitigates the weaknesses of reasoning in LLMs and has been shown to significantly outperform prompting methods (Mirzaee and Kordjamshidi, 2023). However, despite their advantages, current research on employing neural-symbolic approaches to enhance LLMs' spatial reasoning capabilities still faces several challenges. For example, some research merely tested performance on specific datasets without comprehensive evaluation (Yang et al., 2023). Some researchers have not properly applied neural-symbolic methods (Li et al., 2024a). Furthermore, some studies fail to fully explore LLMs' spatial reasoning by implementing incomplete feedback loops via multiple LLMs (Mirzaee and Kordjamshidi, 2023). A detailed analysis is presented in the related work section. Such limitations require the need for more rigorous, integrated and effective approaches.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">传统的 LLM 方法主要依赖于在单次调用 LLM 时进行自由形式的提示，以促进空间推理。然而，这些方法在处理像 StepGame (Shi et al., 2022) 和 SparQA (Mirzaee 和 Kordjamshidi, 2022) 这样的挑战性数据集时表现出明显的局限性，这些数据集需要多步骤的规划。在这些情况下，LLM 往往难以保持连贯性，频繁出现幻觉或失去对原始目标的关注，导致输出不准确且不可靠。最近的进展显示，利用外部工具增强 LLM 在需要算术、导航和知识库查询的任务中的表现具有一定的前景 (Fang et al., 2024)。然而，这些努力对于显著提升 LLM 的空间推理能力仍然不够。最近的研究引入了神经-符号策略，例如 ASP（答案集编程）(Yang et al., 2023)，以解决基于提示的方法的局限性。神经-符号方法通常遵循两个步骤：使用 LLM 提取事实，然后应用逻辑推理。众所周知，LLM 擅长提取事实，但在推理方面表现不佳。然而，整合逻辑推理可以有效弥补它们推理能力的差距。因此，这种方法减轻了 LLM 推理的弱点，并已被证明显著优于提示方法 (Mirzaee 和 Kordjamshidi, 2023)。然而，尽管有其优势，目前关于采用神经-符号方法增强 LLM 空间推理能力的研究仍面临若干挑战。例如，一些研究仅在特定数据集上测试性能，而没有进行全面评估 (Yang et al., 2023)。一些研究者没有正确应用神经-符号方法 (Li et al., 2024a)。此外，一些研究未能通过多个 LLM 实施不完整的反馈循环，充分探索 LLM 的空间推理 (Mirzaee 和 Kordjamshidi, 2023)。相关工作部分提供了详细分析。这些局限性要求我们需要更严格、综合和有效的方法。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-c926f033-540b-40ae-b605-23b51acb40dc" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-3="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-c926f033-540b-40ae-b605-23b51acb40dc" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-3="0,0"><div style="height: auto;"><div><div><div>To address these limitations, we propose a systematic pipeline that effectively enhances LLMs' spatial reasoning capabilities. Our approach combines strategic prompting with symbolic reasoning to create a robust framework that significantly improves performance of spatial reasoning across different LLM architectures. By integrating feedback loops and ASP-based verification, our methodology demonstrates strong generalizability when tackling complex spatial reasoning tasks. Specifically, building on these insights, we propose a novel neural-symbolic pipeline that integrates LLMs with ASP, aimed at enhancing the LLMs' capabilities of spatial reasoning in SparQA and StepGame datasets. We investigate the potential benefits of integrating symbolic reasoning components into LLMs to further boost their spatial reasoning capabilities. Within the broader field of neural-symbolic AI, the combination of LLMs as parsers with ASP solvers has emerged as a particularly effective approach for complex reasoning tasks. Additionally, the present study is one of the pioneering projects which uses DSPy (Khattab et al., 2023) to pipeline and program LLM.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">为了解决这些局限性，我们提出了一种系统化的流程，有效增强大型语言模型（LLMs）的空间推理能力。我们的方法结合了战略性提示和符号推理，创建了一个强大的框架，显著提高了不同LLM架构在空间推理方面的表现。通过整合反馈循环和基于ASP的验证，我们的方法在处理复杂的空间推理任务时表现出强大的普适性。具体而言，基于这些见解，我们提出了一种新颖的神经-符号流程，将LLMs与ASP集成，旨在增强LLMs在SparQA和StepGame数据集中的空间推理能力。我们探讨了将符号推理组件集成到LLMs中的潜在好处，以进一步提升它们的空间推理能力。在神经-符号人工智能的更广泛领域中，将LLMs作为解析器与ASP求解器结合，已成为处理复杂推理任务的特别有效的方法。此外，本研究是使用DSPy（Khattab等，2023）进行LLM管道和编程的开创性项目之一。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-c926f033-540b-40ae-b605-23b51acb40dc" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-3="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-c926f033-540b-40ae-b605-23b51acb40dc" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-3="0,0"><div style="height: auto;"><div><div><div>Our pipeline's effectiveness is evident across diverse datasets, ranging from simple directional relationships to intricate spatial configurations involving multiple objects and relationships. This systematic approach not only boosts performance but also provides a transparent and reproducible framework for spatial reasoning tasks. Unlike previous methods that work only with specific models or simple scenarios, our strategy can be adapted to various LLMs and maintains its effectiveness and generalizability across different levels of complexity in spatial reasoning challenges. The current study addresses the following research questions:<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">我们的流程在各种数据集中的有效性显而易见，从简单的方向关系到涉及多个对象和关系的复杂空间配置。这种系统化的方法不仅提升了性能，还为空间推理任务提供了一个透明且可重复的框架。与以往仅适用于特定模型或简单场景的方法不同，我们的策略可以适应各种LLMs，并在不同复杂度的空间推理挑战中保持其有效性和普适性。本研究解决以下研究问题：</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-4="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-4="0,0"><div style="height: auto;"><div><div><div>1) How does the performance of our integrating symbolic modules compare with the strategies proposed in previous related work?<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">1) 我们集成符号模块的性能与之前相关工作的策略相比如何？</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-4="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-4="0,0"><div style="height: auto;"><div><div><div>2) Why can the integration of symbolic modules enhance the performance of LLMs in spatial reasoning tasks?<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2) 为什么集成符号模块能够增强LLMs在空间推理任务中的表现？</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-4="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-4="0,0"><div style="height: auto;"><h2><div><div>2 Related Work<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2 相关工作</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-4="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-4="0,0"><div style="height: auto;"><h3><div><div>2.1 Prompting LLMs for spatial reasoning<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2.1 针对空间推理的LLM提示</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-4="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-4="0,0"><div style="height: auto;"><div><div><div>Research in spatial reasoning includes both visual and textual domains, with Visual Spatial Reasoning (VSR) facing challenges even in advanced models like CLIP (Radford et al., 2021). On the other hand, text-based reasoning adds complexity due to linguistic ambiguity (Landau and Jackendoff, 1993). Recent studies by Rozanova et al. (2021) and Mirzaee and Kordjamshidi (2022) have explored transformer models and introduced SparQA, addressing challenges in bridging symbolic language and spatial concepts (Tenbrink and Kuhn, 2011), with (Geibinger, 2023) advancing neural-symbolic approaches. The field has evolved through various traditional prompting strategies to enhance LLM reasoning capabilities, including chain of thought (CoT) (Wei et al., 2022; Chu et al., 2023), few-shot prompting (Schick and Schütze, 2021), least-to-most prompting (Zhou et al., 2022), and self-consistency (Wang et al., 2022b), with newer techniques like tree of thoughts, visualization of thought (Wang et al., 2023), and program-aided language models (Gao et al., 2022) further advancing structured, interpretable approaches for complex reasoning tasks.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">空间推理的研究包括视觉和文本领域，视觉空间推理（VSR）即使在像 CLIP（Radford 等，2021）这样的先进模型中也面临挑战。另一方面，基于文本的推理因语言歧义而增加了复杂性（Landau 和 Jackendoff，1993）。Rozanova 等（2021）和 Mirzaee 与 Kordjamshidi（2022）的最新研究探讨了变换器模型并引入了 SparQA，解决了在符号语言与空间概念之间架起桥梁的挑战（Tenbrink 和 Kuhn，2011），而（Geibinger，2023）则推动了神经符号方法的发展。该领域通过各种传统提示策略发展，以增强 LLM 的推理能力，包括思维链（CoT）（Wei 等，2022；Chu 等，2023）、少量提示（Schick 和 Schütze，2021）、从少到多的提示（Zhou 等，2022）和自一致性（Wang 等，2022b），以及像思维树、思维可视化（Wang 等，2023）和程序辅助语言模型（Gao 等，2022）等新技术，进一步推动了复杂推理任务的结构化、可解释方法的发展。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-4="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-4="0,0"><div style="height: auto;"><h3><div><div>2.2 Neural-symbolic approach to reasoning<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2.2 神经符号推理方法</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-4="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-6d509d25-ed36-4263-860a-c988628ec5e9" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-4="0,0"><div style="height: auto;"><div><div><div>Neural-symbolic AI has a long history. However, it remained a rather new topic until recently, driven largely by breakthrough advances in deep learning and transformer architectures. Despite deep learning's success, its limitations in reasoning, interpretability, and generalization have driven interest in combining neural and symbolic approaches to employ their complementary strengths.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">神经符号人工智能有着悠久的历史。然而，直到最近，这一主题仍然相对较新，主要受到深度学习和变换器架构突破性进展的推动。尽管深度学习取得了成功，但其在推理、可解释性和泛化方面的局限性促使人们对结合神经和符号方法以利用其互补优势产生了兴趣。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-ef8d865c-aa39-4583-a0ba-cf007159de07" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-5="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-ef8d865c-aa39-4583-a0ba-cf007159de07" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-5="0,0"><div style="height: auto;"><div><div><div>Different from the prompting strategies, the core idea behind neural-symbolic approaches is to integrate the strengths of neural networks, such as learning from data and handling uncertainty, with the strengths of symbolic systems, such as logical reasoning and knowledge representation. This integration aims to address the limitations of each approach when used in isolation. As Garcez and Lamb (2023) point out, neural networks often struggle with explicit reasoning and generalization beyond their training distribution, while symbolic systems can be brittle and struggle with real-world data. Hamilton et al. (2022) emphasize that successful AI systems must incorporate rich representations that facilitate precise, human-interpretable inference. By combining neural architectures with symbolic reasoning, researchers aim to create systems capable of learning from experience but applying logical rules to reason about new situations, thereby addressing some shortcomings of purely neural models (Besold et al., 2021).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">与提示策略不同，神经符号方法的核心思想是将神经网络的优势（如从数据中学习和处理不确定性）与符号系统的优势（如逻辑推理和知识表示）相结合。这种整合旨在解决各自单独使用时的局限性。正如 Garcez 和 Lamb（2023）所指出的，神经网络在显式推理和超出其训练分布的泛化方面往往面临挑战，而符号系统则可能脆弱，并且在处理现实世界数据时存在困难。Hamilton 等人（2022）强调，成功的人工智能系统必须包含丰富的表示，以促进精确且易于人类理解的推理。通过将神经架构与符号推理相结合，研究人员旨在创建能够从经验中学习但又能应用逻辑规则来推理新情况的系统，从而解决纯神经模型的一些不足之处（Besold 等人，2021）。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-ef8d865c-aa39-4583-a0ba-cf007159de07" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-5="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-ef8d865c-aa39-4583-a0ba-cf007159de07" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-5="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>Based on how neural and symbolic components interact and complement each other, these approaches can be categorized into five distinct patterns: Symbolic[neural], where symbolic systems are enhanced with neural capabilities; neural|Symbolic, implementing hybrid pipelines; neural:Symbolic <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="658" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container> neural,compiling symbolic rules into neural structures; neural <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="659" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2297"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>⊗</mo></math></mjx-assistive-mml></mjx-container> Symbolic,combining logic rules through embeddings; and neural[Symbolic], enhancing neural systems with symbolic reasoning. Although this taxonomy provides valuable insights, there is significant overlap between these patterns, particularly in how they incorporate symbolic reasoning into neural networks. To provide a more practical framework, we can consolidate these approaches into four fundamental integration architectures, each capturing a distinct way of combining neural and symbolic capabilities: a) Neural| symbolic Sequential Integration (Weber et al., 2019); b) Neural-symbolic Iterative Integration (Evans and Stanovich, 2013; Bellini-Leite, 2022); c) Symbolic Embedded NN architecture (Riegel et al., 2020); d) LLM+Tools (Parisi et al., 2022) (The details are seen in Appendix A). These approaches have inspired us to develop more effective integration neural-symbolic strategies and a generalized integrated pipeline to enhance the performance of spatial reasoning in LLMs.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">根据神经和符号组件的交互方式及其互补性，这些方法可以分为五种不同的模式：Symbolic[neural]，即通过神经能力增强符号系统；neural|Symbolic，执行混合管道；neural:Symbolic <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="660" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container> neural，将符号规则编译为神经结构；neural <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="661" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2297"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>⊗</mo></math></mjx-assistive-mml></mjx-container> Symbolic，通过嵌入结合逻辑规则；以及 neural[Symbolic]，通过符号推理增强神经系统。尽管这一分类提供了有价值的见解，这些模式之间存在显著的重叠，尤其是在它们如何将符号推理引入神经网络方面。为了提供一个更实用的框架，我们可以将这些方法整合为四种基本的集成架构，每种架构都体现了一种将神经和符号能力结合的独特方式：a) 神经|符号顺序集成（Weber 等人, 2019）；b) 神经-符号迭代集成（Evans 和 Stanovich, 2013；Bellini-Leite, 2022）；c) 符号嵌入神经网络架构（Riegel 等人, 2020）；d) 大型语言模型+工具（Parisi 等人, 2022）（详见附录 A）。这些方法启发了我们开发更有效的神经-符号集成策略，以及一个通用的集成管道，以提升大型语言模型在空间推理中的性能。</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-ef8d865c-aa39-4583-a0ba-cf007159de07" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-5="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-ef8d865c-aa39-4583-a0ba-cf007159de07" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-5="0,0"><div style="height: auto;"><div><div><div>We take specific examples to demonstrate the effectiveness of neural-symbolic approaches to boosting various systems. Neural-symbolic systems excel in complex applications by blending data-driven learning with rule-based inference across domains like computer vision, NLP, and robotics. They integrate visual recognition with semantic understanding (Mao et al., 2019a), language with logical inference (Yu et al., 2024), and perception with decision-making (Wang et al., 2022a). Spatial-temporal reasoning, crucial in neural-symbolic AI, enhances problem-solving in physical contexts (Lee et al., 2023). In Qualitative Spatial Reasoning (QSR), combining LLMs with spatial calculi (e.g., RCC-8, CDC) strengthens spatial reasoning (Liu et al., 2009; Katerinenko, 2015), while neural-symbolic integration improves geospatial segmentation (Alirezaie et al., 2019). Multi-hop question answering benefits from systems like NLProlog, which merge neural networks with symbolic reasoning for multi-step inference (Weber et al., 2019; Chen et al., 2019). Language contextualization is advanced by systems like PIGLeT, grounding understanding in a 3D world (Zellers et al., 2021), and neural-symbolic VQA, combining visual perception and logical reasoning (Lu et al., 2024). Overall, neural-symbolic approaches enhance explainability through interpretable reasoning paths, improve robustness by handling edge cases and ensuring consistency, and allow flexible integration of domain-specific knowledge.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">我们通过具体示例来展示神经符号方法在提升各种系统中的有效性。神经符号系统通过将数据驱动的学习与基于规则的推理相结合，在复杂应用中表现出色，涉及计算机视觉、自然语言处理和机器人等领域。它们将视觉识别与语义理解相结合（Mao et al., 2019a），将语言与逻辑推理相结合（Yu et al., 2024），并将感知与决策制定相结合（Wang et al., 2022a）。时空推理在神经符号人工智能中至关重要，增强了物理环境中的问题解决能力（Lee et al., 2023）。在定性空间推理（QSR）中，将大型语言模型与空间计算（例如，RCC-8，CDC）相结合，增强了空间推理能力（Liu et al., 2009；Katerinenko, 2015），而神经符号集成则改善了地理空间分割（Alirezaie et al., 2019）。多跳问答受益于像NLProlog这样的系统，它将神经网络与符号推理结合，实现多步骤推理（Weber et al., 2019；Chen et al., 2019）。语言上下文化通过像PIGLeT这样的系统得以推进，将理解扎根于三维世界（Zellers et al., 2021），而神经符号视觉问答（VQA）则结合了视觉感知和逻辑推理（Lu et al., 2024）。总体而言，神经符号方法通过可解释的推理路径增强了可解释性，通过处理边缘案例和确保一致性提高了鲁棒性，并允许灵活集成领域特定知识。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-ba6709f4-b82f-49ac-b13c-83043ca3929f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-6="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-ba6709f4-b82f-49ac-b13c-83043ca3929f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-6="0,0"><div style="height: auto;"><div><div><div>Next we focus on neural-symbolic approach on spatial reasoning in LLMs. Yang et al. (2023) proposed a novel strategy to convert language into logic serving as ASP(Answer Set Programs, a logic-based declarative knowledge representation formalism), and claimed to boost LLMs' spatial reasoning capabilities. However, they merely used LLMs to extract some facts. Instead they tested performance on specific datasets without comprehensive evaluations on spatial reasoning on LLMs. In other words, their ASP method is novel but the method was not actually tested on spatial reasoning in the simplistic dataset (i.e., StepGame. Li et al. (2024a) focus on simplistic datasets (i.e., StepGame) by applying some method which is not neural-symbolic. The method in Li et al. (2024a) is essentially language-based prompting strategy. Furthermore, some studies proposed using mutiple LLMs to form multi-agent to facilitate spatial reasoning, attempting to fully explore LLMs' spatial reasoning by implementing via multiple LLMs (Mirzaee and Kordjamshidi, 2023) on another complex test data (i.e., SparQA). However, it seems that Mirzaee and Kordjamshidi (2023) did not realize loop via mutiple LLM agents. These limitations show the need for better and more comprehensive neural-symbolic strategies. In order to overcome these limitations, we propose a systematic pipeline that enhances LLMs' spatial reasoning by combining strategic prompting with symbolic reasoning. Incorporating feedback loops and ASP-based verification, our method generalizes effectively to complex tasks across diverse LLM architectures.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">接下来，我们关注于大语言模型中的神经符号方法在空间推理方面的应用。杨等人（2023）提出了一种新颖的策略，将语言转换为逻辑，以作为ASP（答案集程序，一种基于逻辑的声明性知识表示形式），并声称能够提升大语言模型的空间推理能力。然而，他们仅仅使用大语言模型提取了一些事实。相反，他们在特定数据集上测试了性能，而没有对大语言模型的空间推理进行全面评估。换句话说，他们的ASP方法是新颖的，但该方法实际上并未在简单数据集（即StepGame）上进行空间推理测试。李等人（2024a）通过应用一些非神经符号的方法，专注于简单数据集（即StepGame）。李等人（2024a）的方法本质上是一种基于语言的提示策略。此外，一些研究提出使用多个大语言模型形成多代理，以促进空间推理，试图通过实现多个大语言模型（Mirzaee和Kordjamshidi，2023）在另一个复杂测试数据（即SparQA）上充分探索大语言模型的空间推理。然而，Mirzaee和Kordjamshidi（2023）似乎没有意识到通过多个大语言模型代理形成循环。这些局限性显示了对更好和更全面的神经符号策略的需求。为了克服这些局限性，我们提出了一种系统化的流程，通过将战略提示与符号推理相结合，增强大语言模型的空间推理。通过引入反馈循环和基于ASP的验证，我们的方法能够有效地推广到各种大语言模型架构的复杂任务中。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-ba6709f4-b82f-49ac-b13c-83043ca3929f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-6="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-ba6709f4-b82f-49ac-b13c-83043ca3929f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-6="0,0"><div style="height: auto;"><div><div><div>Our strategies are grounded in two key observations from prior research. First, LLMs have demonstrated strong capabilities in understanding and generating spatial descriptions, as well as representing abstract spatial relationships and environments through extensive training on diverse textual data, suggesting their ability to learn and reason about spatial concepts from language alone (Santoro et al., 2018; Smith et al., 2022). Second, recent studies have shown that verbalizing visual input and describing 3D environments in natural language can enable LLMs to outperform vision-language models in certain task domains (Geigle et al., 2023; Ghosh et al., 2024; Chen et al., 2024). Building upon these insights, our study aims to push the boundaries of LLMs' spatial reasoning capabilities by proposing novel new strategies. Moreover, by focusing on language, our study seeks to develop methodologies that capitalize on the inherent strengths of LLMs in processing textual information while addressing their limitations in multi-hop reasoning tasks.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">我们的策略基于先前研究的两个关键观察。首先，LLM（大型语言模型）在理解和生成空间描述方面表现出强大的能力，并且通过对多样化文本数据的广泛训练，能够表示抽象的空间关系和环境，这表明它们能够仅通过语言学习和推理空间概念（Santoro et al., 2018; Smith et al., 2022）。其次，最近的研究表明，将视觉输入进行语言化并用自然语言描述三维环境可以使LLM在某些任务领域超越视觉-语言模型（Geigle et al., 2023; Ghosh et al., 2024; Chen et al., 2024）。基于这些见解，我们的研究旨在通过提出新颖的策略来推动LLM的空间推理能力的边界。此外，通过关注语言，我们的研究旨在开发利用LLM在处理文本信息方面固有优势的方法，同时解决它们在多跳推理任务中的局限性。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-7="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-7="0,0"><div style="height: auto;"><h2><div><div>3 Methods<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3 方法</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-7="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-7="0,0"><div style="height: auto;"><h3><div><div>3.1 Datasets<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.1 数据集</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-7="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-7="0,0"><div style="height: auto;"><div><div><div>The two test benchmark datasets are taken to help evaluate the effectivenss of our strategies comprehensively: StepGame (Shi et al., 2022), and SparQA (Mirzaee and Kordjamshidi, 2022). The following provides a detailed account of the two datasets.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">为了全面评估我们策略的有效性，选择了两个测试基准数据集：StepGame（Shi et al., 2022）和SparQA（Mirzaee and Kordjamshidi, 2022）。以下提供了这两个数据集的详细说明。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-7="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-7="0,0"><div style="height: auto;"><div><div><div>StepGame (Shi et al., 2022) is a synthetic spatial question answering dataset featuring Finding Relations questions that require between 1 to 10 reasoning steps to answer. It employs eight spatial relations (top, down, left, right, top-left, top-right, down-left, and down-right) for story generation. The specific details and samples of StepGame are seen in Appendix B1.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">StepGame（Shi et al., 2022）是一个合成的空间问答数据集，包含需要1到10个推理步骤才能回答的寻找关系问题。它采用八种空间关系（上、下、左、右、左上、右上、左下和右下）进行故事生成。StepGame的具体细节和示例见附录B1。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-7="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-7="0,0"><div style="height: auto;"><div><div><div>Mirzaee and Kordjamshidi (2022) introduced SparQA, a textual question answering benchmark for spatial reasoning, highlighting the unique challenges posed by text-based spatial tasks. Their work emphasized the need for models to understand complex spatial relationships described in natural language and to perform multi-hop reasoning to answer questions accurately. The details and samples of SparQA are seen in Appendix B2. The SparQA dataset advances benchmarking for spatial reasoning in AI, offering a more sophisticated and realistic scenario than predecessors like StepGame. Key features include:<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Mirzaee 和 Kordjamshidi (2022) 引入了 SparQA，这是一个用于空间推理的文本问答基准，突出了基于文本的空间任务所带来的独特挑战。他们的工作强调了模型理解自然语言中描述的复杂空间关系以及进行多跳推理以准确回答问题的必要性。SparQA 的详细信息和示例见附录 B2。SparQA 数据集推动了人工智能领域空间推理的基准测试，提供了比前身如 StepGame 更复杂和现实的场景。其主要特点包括：</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-7="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-7="0,0"><div style="height: auto;"><div><ul><li>Broader Language Use: SparQA includes longer, more complex sentences (approximately 2.5 times the length of StepGame). Each scenario typically consists of three blocks arranged vertically or horizontally, with around four objects per block, characterized by attributes like size, color, and shape. In a typical context, there are twelve objects across three blocks, with roughly ten explicitly defined relationships.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>更广泛的语言使用：SparQA 包含更长、更复杂的句子（大约是 StepGame 的 2.5 倍长度）。每个场景通常由三个垂直或水平排列的块组成，每个块大约有四个对象，具有大小、颜色和形状等属性。在典型的上下文中，三个块中有十二个对象，约有十个明确定义的关系。</li></ul></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-7="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-e74882bd-a9f4-49c6-a206-4d611ea72c2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-7="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li>Diverse Question Types: SparQA includes Yes/No, FR, CO, and FB question types, often involving multiple objects and relations. For instance, `"What is the relation between the blue circle touching the top edge of block <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="662" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi></math></mjx-assistive-mml></mjx-container> and the small square?"`</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>多样化的问题类型：SparQA 包含是/否、FR、CO 和 FB 问题类型，通常涉及多个对象和关系。例如，“与触碰块 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="663" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi></math></mjx-assistive-mml></mjx-container> 顶边的蓝色圆圈和小方块之间的关系是什么？”</li></ul></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-8="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-8="0,0"><div style="height: auto;"><div><ul><li>Complex Relational Dynamics: SparQA incorporates 3D spatial reasoning, topological relations, and distance relations, with candidate choices such as left, above, near to, and additional synonym terms.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>复杂的关系动态：SparQA 包含 3D 空间推理、拓扑关系和距离关系，候选选择包括左侧、上方、靠近等同义词。</li></ul></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-8="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-8="0,0"><div style="height: auto;"><div><ul><li>Quantifier Questions: These questions test quantification abilities, e.g.,`"Are all of the squares in B?"` or `"Which block has only small black things inside?"` demanding higher-level reasoning.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>量词问题：这些问题测试量化能力，例如，“B 中的所有方块都在吗？”或“哪个块内部只有小黑色物体？”要求更高级的推理。</li></ul></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-8="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-8="0,0"><div style="height: auto;"><div><div><div>Both datasets are employed in the present study to test the effectiveness of our proposed strategies. The following sections introduces these strategies applied in enhancing spatial reasoning abilities in LLMs: 1) Answer Set Programming (ASP); 2) Proposed LLM + ASP Pipeline with DSPy. 3) Fact + Logical rules. We applied the first strategy to StepGame and the second and third strategies to both SparQA and StepGame to evaluate their effectiveness through experiments.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">本研究中使用了两个数据集来测试我们提出的策略的有效性。以下部分介绍了这些策略在增强大型语言模型（LLMs）空间推理能力中的应用：1）答案集编程（ASP）；2）提出的 LLM + ASP 管道与 DSPy；3）事实 + 逻辑规则。我们将第一种策略应用于 StepGame，将第二和第三种策略应用于 SparQA 和 StepGame，以通过实验评估其有效性。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-8="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-8="0,0"><div style="height: auto;"><h3><div><div>3.2 Answer set programming (ASP)<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.2 答案集编程（ASP）</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-8="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-8="0,0"><div style="height: auto;"><div><div><div>ASP is a powerful declarative programming paradigm tailored for complex reasoning tasks, particularly those that involve knowledge representation and combinatorial search problems (Yang et al., 2023). ASP is declarative, meaning problems are defined through logical relationships between entities, while ASP solvers automatically determine solutions that satisfy given conditions. ASP consists of the following elements: facts, rules, constraints and queries. The following briefly describes these elements.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">ASP 是一种强大的声明式编程范式，专为复杂推理任务而设计，特别是涉及知识表示和组合搜索问题的任务（Yang 等，2023）。ASP 是声明式的，这意味着问题通过实体之间的逻辑关系来定义，而 ASP 求解器会自动确定满足给定条件的解决方案。ASP 由以下元素组成：事实、规则、约束和查询。以下简要描述这些元素。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-8="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-8="0,0"><div style="height: auto;"><div><div><div>Facts in ASP form the foundation of the problem domain, representing fundamental truths or atoms. These unconditional statements consist of predicates with arguments. For example, in spatial reasoning, predicates might include:<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">ASP 中的事实构成问题领域的基础，表示基本真理或原子。这些无条件语句由带有参数的谓词组成。例如，在空间推理中，谓词可能包括：</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-8="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-8="0,0"><div style="height: auto;"><div><ul><li>block/1: Represents a block with one argument.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>block/1：表示一个具有一个参数的块。</li></ul></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-8="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-8="0,0"><div style="height: auto;"><div><ul><li>object/5: Represents an object with five attributes (name, size, color, shape, block).</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>object/5：表示一个具有五个属性（名称、大小、颜色、形状、块）的对象。</li></ul></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-8="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-8="0,0"><div style="height: auto;"><div><ul><li>is/3: Describes spatial relationships between objects.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>is/3：描述对象之间的空间关系。</li></ul></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-8="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-a2379cc8-e633-449a-bd2c-5587e9fa16ef" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-8="0,0"><div style="height: auto;"><div><div><div>Example facts can be expressed as:<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">示例事实可以表示为：</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>block(a).</div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>object(BlueTriangle, large, blue, triangle, a).</div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>object(BlackSquare, large, black, square, a).</div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>is (BlueTriangle, left, BlackSquare).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">是 (BlueTriangle, left, BlackSquare)。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>Rules are essential in ASP as they define relationships between facts and enable the derivation of new knowledge. Expressed as "Head :- Body", rules indicate that if the conditions in the "Body" are true, then the "Head" is also true. For example:<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">规则在 ASP 中至关重要，因为它们定义了事实之间的关系，并使得新知识的推导成为可能。规则以“头 :- 身体”的形式表示，指示如果“身体”中的条件为真，则“头”也为真。例如：</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><hr><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>	is(Object1, Relation, Object2) :-</div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>	object(Object1, _, _, _, Block1),</div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>object(Object2, _, _, _, Block2),</div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>is(Block1, Relation, Block2),</div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>Object1 != Object2.</div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><hr><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>Constraints in ASP narrow down the solution space by eliminating invalid solutions. Unlike rules, constraints are expressed without a Head, meaning that if the Body conditions are satisfied, the answer set is rejected. For instance:<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">ASP 中的约束通过消除无效解来缩小解空间。与规则不同，约束不包含头，这意味着如果身体条件得到满足，则答案集会被拒绝。例如：</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>:- object(_, large, _, , Block), object(, small, _, _, Block).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">:- object(_, large, _, , Block), object(, small, _, _, Block)。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>This constraint ensures that large and small objects cannot occupy the same block.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">该约束确保大物体和小物体不能占据同一个块。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>Queries allow the system to extract specific information by evaluating whether certain conditions are met. For example:<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">查询允许系统通过评估特定条件是否满足来提取特定信息。例如：</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>query(Relation) :-</div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>object(LargeBlueC, large, blue, _, c),</div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>object(OtherLargeBlue, large, blue, _, OtherBlock),</div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>is (LargeBlueC, Relation, OtherLargeBlue).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">是 (LargeBlueC, Relation, OtherLargeBlue)。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><div><div><div>To implement ASP programs, specialized solvers like Clingo, DLV, or Clasp are used. These solvers compute "answer sets" that represent valid solutions satisfying all rules and constraints. Since multiple answer sets may be generated, post-processing is often necessary to extract the most relevant solutions for specific queries.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">为了实现 ASP 程序，使用 Clingo、DLV 或 Clasp 等专用求解器。这些求解器计算“答案集”，代表满足所有规则和约束的有效解。由于可能生成多个答案集，因此通常需要后处理以提取特定查询的最相关解。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><h3><div><div>3.3 Proposed LLM + ASP pipeline with DSPy<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.3 提出的 LLM + ASP 管道与 DSPy</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-014eeab9-cb70-424a-abf4-4f99defa3a97" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>ASP is a fundamental neural-symbolic strategy in improving LLMs' spatial reasoning. However, some weaknesses are obvious. For instance, recent studies have demonstrated LLMs' effectiveness as semantic parsers, often surpassing traditional parsing tools. While Geibinger (2023) and Eiter et al. (2022) showed promising results integrating LLMs with ASP, challenges remain. Ishay et al. (2023) found LLMs could generate complex ASP programs but often with errors,while Yang et al. (2023) achieved <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="664" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>90</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> accuracy on StepGame using GPT-3 and ASP, though scalability remains uncertain.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">ASP 是一种基本的神经符号策略，用于改善 LLM 的空间推理。然而，一些弱点显而易见。例如，最近的研究表明，LLM 作为语义解析器的有效性，通常超越传统解析工具。虽然 Geibinger (2023) 和 Eiter 等人 (2022) 显示了将 LLM 与 ASP 集成的良好结果，但仍然存在挑战。Ishay 等人 (2023) 发现 LLM 可以生成复杂的 ASP 程序，但通常存在错误，而 Yang 等人 (2023) 在使用 GPT-3 和 ASP 的 StepGame 上达到了 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="665" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>90</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> 的准确性，尽管可扩展性仍不确定。</div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-ded1adf8-75bf-42ce-a350-c440072d866b" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-10="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-ded1adf8-75bf-42ce-a350-c440072d866b" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><!-- Media --></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-ded1adf8-75bf-42ce-a350-c440072d866b" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-10="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-ded1adf8-75bf-42ce-a350-c440072d866b" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-10="0,0"><div style="height: auto;"><div><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01937d54-d496-7e49-afc6-565908ddfdd3_10.jpg?x=277&amp;y=632&amp;w=1092&amp;h=664"></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-ded1adf8-75bf-42ce-a350-c440072d866b" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-10="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-ded1adf8-75bf-42ce-a350-c440072d866b" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-10="0,0"><div style="height: auto;"><div><div><div>Figure 1: Pipeline of LLM +ASP approach.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">图 1：LLM + ASP 方法的管道。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-ded1adf8-75bf-42ce-a350-c440072d866b" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-10="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-ded1adf8-75bf-42ce-a350-c440072d866b" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><!-- Media --></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-ded1adf8-75bf-42ce-a350-c440072d866b" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-10="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-ded1adf8-75bf-42ce-a350-c440072d866b" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-10="0,0"><div style="height: auto;"><div><div><div>In order to overcome these weaknesses, inspired by Pan et al. (2023)'s LOGIC-LM framework and integration neural-symbolic strategies, we propose a novel neural-symbolic pipeline employing ASP using DSPy that treats the LLM as an agent capable of feedback and iteration. DSPy (Declarative Self-improving Language Programs, pythonically) is a Python framework that uses a declarative and self-improving approach to simplify working with LLMs (Khattab et al., 2023). It automates the optimization of prompts and model tuning, enhancing reliability and scalability in AI applications. By defining tasks and metrics rather than manual prompts, DSPy streamlines the development of various NLP tasks and complex AI systems. The framework of this pipeline is shown in Fig.1.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">为了克服这些弱点，受到 Pan 等人 (2023) 的 LOGIC-LM 框架和集成神经符号策略的启发，我们提出了一种新颖的神经符号管道，采用使用 DSPy 的 ASP，将 LLM 视为能够进行反馈和迭代的代理。DSPy（声明式自我改进语言程序，pythonically）是一个 Python 框架，采用声明式和自我改进的方法来简化与 LLM 的工作（Khattab 等人，2023）。它自动化了提示和模型调优的优化，增强了 AI 应用中的可靠性和可扩展性。通过定义任务和指标而不是手动提示，DSPy 简化了各种 NLP 任务和复杂 AI 系统的开发。该管道的框架如图 1 所示。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-ded1adf8-75bf-42ce-a350-c440072d866b" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-10="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-ded1adf8-75bf-42ce-a350-c440072d866b" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-10="0,0"><div style="height: auto;"><div><div><div>The pipeline consists of four main stages: a) Facts Generation Stage: LLM converts natural language descriptions into symbolic formulations and formal queries. b) ASP Refining Stage: LLM iteratively refines the ASP representation over three iterations, adding rules, checking consistency, and incorporating feedback from error messages. c) Symbolic Reasoning Stage: The refined ASP undergoes inference using the Clingo solver, ensuring accurate and explainable reasoning by combining LLM capabilities with logical inference. d) Result Interpretation and Evaluation: This stage involves mapping the Clingo solver's outputs to candidate answers. For certain question types, like Yes/No and Finding-Block questions, the solver's output can directly serve as the correct answer. However, for Finding Relations and Choose Object questions, additional processing is necessary to filter relevant solutions. In the StepGame context, outputs from the ASP solver are evaluated against a synonym dictionary to determine accuracy.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">该管道由四个主要阶段组成：a) 事实生成阶段：LLM 将自然语言描述转换为符号表述和形式查询。b) ASP 精炼阶段：LLM 在三个迭代中反复精炼 ASP 表示，添加规则，检查一致性，并结合错误信息反馈。c) 符号推理阶段：经过精炼的 ASP 使用 Clingo 求解器进行推理，通过将 LLM 能力与逻辑推理相结合，确保准确且可解释的推理。d) 结果解释与评估：该阶段涉及将 Clingo 求解器的输出映射到候选答案。对于某些问题类型，如是/否和寻找块问题，求解器的输出可以直接作为正确答案。然而，对于寻找关系和选择对象问题，需要额外处理以过滤相关解决方案。在 StepGame 上下文中，ASP 求解器的输出会与同义词字典进行评估以确定准确性。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="12" id="mark-f304dc0a-bee2-49d4-864d-7d013593fca3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-11="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="12" id="mark-f304dc0a-bee2-49d4-864d-7d013593fca3" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-11="0,0"><div style="height: auto;"><div><div><div>Overall, this pipeline requires multiple interactions with LLMs during ASP generation and refinement. We employ the DSPy framework to manage these complex workflows (e.g., interfacing with Llama3 60B DeepSeek and GPT 4.0 mini models via their APIs). DSPy's modular features enhance memory retention between modules, enabling adjustments and optimizations while maintaining workflow integrity.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">总体而言，该管道在 ASP 生成和精炼过程中需要与 LLM 进行多次交互。我们采用 DSPy 框架来管理这些复杂的工作流程（例如，通过其 API 与 Llama3 60B DeepSeek 和 GPT 4.0 mini 模型进行接口）。DSPy 的模块化特性增强了模块之间的记忆保留，使得在保持工作流程完整性的同时进行调整和优化。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="12" id="mark-f304dc0a-bee2-49d4-864d-7d013593fca3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-11="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="12" id="mark-f304dc0a-bee2-49d4-864d-7d013593fca3" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-11="0,0"><div style="height: auto;"><div><div><div>Additionally, DSPy optimizes LLM prompts and weights, reducing the need for manual prompt engineering and ensuring consistent performance across datasets. Its optimization compiler iteratively generates and refines prompts, enhancing task performance. To support transparency and debugging, outputs from all modules are logged, capturing errors and providing insights for prompt engineering and system optimization, facilitating continuous improvement of the system and enhancing the integration of neural and symbolic components. In this way, this integrated neural-symbolic pipeline could greatly facilitate spatial reasoning in LLMs.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">此外，DSPy 优化 LLM 提示和权重，减少了手动提示工程的需求，并确保在数据集之间的一致性能。其优化编译器迭代生成和精炼提示，提升任务性能。为了支持透明性和调试，所有模块的输出都会被记录，捕捉错误并为提示工程和系统优化提供见解，从而促进系统的持续改进并增强神经与符号组件的集成。通过这种方式，这一集成的神经-符号管道可以极大地促进 LLM 的空间推理。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="12" id="mark-f304dc0a-bee2-49d4-864d-7d013593fca3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-11="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="12" id="mark-f304dc0a-bee2-49d4-864d-7d013593fca3" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-11="0,0"><div style="height: auto;"><h3><div><div>3.4 Fact + logical rules<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.4 事实 + 逻辑规则</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="12" id="mark-f304dc0a-bee2-49d4-864d-7d013593fca3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-11="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="12" id="mark-f304dc0a-bee2-49d4-864d-7d013593fca3" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-11="0,0"><div style="height: auto;"><div><div><div>The "LLM + ASP" approach could have some fundamental limitations in applying neural-symbolic integration to complex spatial reasoning tasks. Despite their strong in-context learning capabilities, LLMs may consistently struggle to generate precise logical programs from few-shot examples, particularly when dealing with the formal syntax requirements of ASP or Prolog. This limitation could become especially pronounced in testing in some complex tasks such as the SparQA, where the iterative refinement process necessitates multiple LLM calls for a single ASP program generation, creating significant computational overhead even with a modest three-iteration limit.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">“LLM + ASP” 方法在将神经符号集成应用于复杂空间推理任务时可能存在一些基本限制。尽管它们具有强大的上下文学习能力，但 LLM 在从少量示例中生成精确的逻辑程序时可能始终面临困难，特别是在处理 ASP 或 Prolog 的正式语法要求时。这一限制在某些复杂任务的测试中可能尤为明显，例如 SparQA，其中迭代精炼过程需要多次调用 LLM 来生成单个 ASP 程序，即使在适度的三次迭代限制下，也会造成显著的计算开销。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="12" id="mark-f304dc0a-bee2-49d4-864d-7d013593fca3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-11="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="12" id="mark-f304dc0a-bee2-49d4-864d-7d013593fca3" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-11="0,0"><div style="height: auto;"><div><div><div>To address these challenges, we propose an alternative neural-symbolic approach that preserves the advantages of structured knowledge representation while reducing the complexity of formal logical programming. Specifically, inspired by Symbolic Embedded Neural Network architectures, our alternative approach embeds logical rules directly into natural language prompts, enabling LLMs to perform reasoning within structured knowledge representations. Instead of relying on the external logical solver to do the reasoning, this approach explicitly prompts LLMs of which rules should be used for certain scenarios. That is why the approach is termed as "fact +logical rules". It is expected that direct rule application in natural language may offer a more reliable path to spatial reasoning than attempting to generate and execute formal logical programs.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">为了解决这些挑战，我们提出了一种替代的神经符号方法，该方法保留了结构化知识表示的优势，同时降低了形式逻辑编程的复杂性。具体而言，受到符号嵌入神经网络架构的启发，我们的替代方法将逻辑规则直接嵌入自然语言提示中，使 LLM 能够在结构化知识表示中进行推理。该方法不是依赖外部逻辑求解器进行推理，而是明确提示 LLM 在特定场景下应使用哪些规则。这就是该方法被称为“事实 + 逻辑规则”的原因。预计在自然语言中直接应用规则可能比尝试生成和执行形式逻辑程序提供更可靠的空间推理路径。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="13" id="mark-c1adbaff-f277-419a-9e7c-d17dc496dfb3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-12="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="13" id="mark-c1adbaff-f277-419a-9e7c-d17dc496dfb3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><!-- Media --></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="13" id="mark-c1adbaff-f277-419a-9e7c-d17dc496dfb3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-12="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="13" id="mark-c1adbaff-f277-419a-9e7c-d17dc496dfb3" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-12="0,0"><div style="height: auto;"><div><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01937d54-d496-7e49-afc6-565908ddfdd3_12.jpg?x=375&amp;y=345&amp;w=898&amp;h=1864"></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="13" id="mark-c1adbaff-f277-419a-9e7c-d17dc496dfb3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-12="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="13" id="mark-c1adbaff-f277-419a-9e7c-d17dc496dfb3" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-12="0,0"><div style="height: auto;"><div><div><div>Figure 2: The roadmap of this study.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">图 2：本研究的路线图。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="13" id="mark-c1adbaff-f277-419a-9e7c-d17dc496dfb3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-12="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="13" id="mark-c1adbaff-f277-419a-9e7c-d17dc496dfb3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><!-- Media --></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="13" id="mark-c1adbaff-f277-419a-9e7c-d17dc496dfb3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-12="0,0"></paragraphpositioning></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="14" id="mark-10efd2ab-84cc-49bd-8990-83b8d262b974" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-13="0,0"><div style="height: auto;"><div><div><div>The core principle of our alternative approach aligns with a fundamental aspect of neural-symbolic AI: the translation of raw data into structured, symbolic representations that serve as meaning ASP. By using predicates with precise argument structures, we instruct LLMs to create consistent knowledge representations that serve as an intermediate basis for question answering. This structured approach simplifies the previous complex process of generating and refining ASP code while maintaining the benefits of formal reasoning.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">我们替代方法的核心原则与神经符号人工智能的一个基本方面相一致：将原始数据转换为结构化的符号表示，这些表示作为意义的 ASP。通过使用具有精确参数结构的谓词，我们指示 LLM 创建一致的知识表示，作为回答问题的中介基础。这种结构化方法简化了之前生成和精炼 ASP 代码的复杂过程，同时保持了形式推理的优势。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="14" id="mark-10efd2ab-84cc-49bd-8990-83b8d262b974" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-13="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="14" id="mark-10efd2ab-84cc-49bd-8990-83b8d262b974" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-13="0,0"><div style="height: auto;"><h3><div><div>3.5 Tools, LLMs and evaluation criteria<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.5 工具、LLM 和评估标准</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="14" id="mark-10efd2ab-84cc-49bd-8990-83b8d262b974" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-13="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="14" id="mark-10efd2ab-84cc-49bd-8990-83b8d262b974" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-13="0,0"><div style="height: auto;"><div><div><div>In our experiments, we used DSPy framework to optimize multi-stage prompting workflows, moving from manual prompt engineering to a structured, automated process. DSPy was key in defining and refining each stage of our pipeline - from converting natural language to logical expressions, to generating Python code, and running ASP tasks with Clingo. This setup allows us to streamline complex reasoning processes and achieve high-quality, multistep outputs. While LangChain could support similar workflows, DSPy's focus on multi-stage LLM optimization made it a better fit for our needs.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在我们的实验中，我们使用了DSPy框架来优化多阶段提示工作流程，从手动提示工程转向结构化的自动化过程。DSPy在定义和完善我们管道的每个阶段中发挥了关键作用——从将自然语言转换为逻辑表达式，到生成Python代码，再到使用Clingo运行ASP任务。这个设置使我们能够简化复杂的推理过程，并实现高质量的多步骤输出。虽然LangChain可以支持类似的工作流程，但DSPy对多阶段LLM优化的关注使其更适合我们的需求。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="14" id="mark-10efd2ab-84cc-49bd-8990-83b8d262b974" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-13="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="14" id="mark-10efd2ab-84cc-49bd-8990-83b8d262b974" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-13="0,0"><div style="height: auto;"><div><div><div>To evaluate the effectiveness of our approaches in spatial reasoning comprehensively, we selected three representative LLMs with diverse architectures and capabilities: DeepSeek, Llama3, and GPT4.0 Mini. These LLMs were chosen to ensure a comprehensive assessment across different types of language representations, ranging from lightweight and specialized models like DeepSeek to more advanced general-purpose systems like GPT4.0 Mini. Llama3, known for its balance between performance and computational efficiency, provides an intermediate perspective. By testing our methods on these distinct models, we want to demonstrate the adaptability and robustness of our approach across a variety of LLM architectures and reasoning capacities.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">为了全面评估我们在空间推理中的方法的有效性，我们选择了三种具有不同架构和能力的代表性LLM：DeepSeek、Llama3和GPT4.0 Mini。这些LLM的选择旨在确保对不同类型语言表示的全面评估，从轻量级和专业模型如DeepSeek到更先进的通用系统如GPT4.0 Mini。Llama3以其在性能和计算效率之间的平衡而闻名，提供了一个中间视角。通过在这些不同模型上测试我们的方法，我们希望展示我们的方法在各种LLM架构和推理能力下的适应性和稳健性。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="14" id="mark-10efd2ab-84cc-49bd-8990-83b8d262b974" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-13="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="14" id="mark-10efd2ab-84cc-49bd-8990-83b8d262b974" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-13="0,0"><div style="height: auto;"><div><div><div>Moreover, to effectively evaluate the impact of our proposed integration methods, we used "direct prompting" as the baseline for comparison. In the following sections, "direct" is used to refer to this baseline method<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">此外，为了有效评估我们提出的集成方法的影响，我们使用“直接提示”作为比较的基线。在接下来的部分中，“直接”用于指代这一基线方法。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-14="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-14="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>LLM performance evaluation includes a range of metrics depending on the task, such as objectivity, truthfulness, human alignment, fluency, coherence,relevance,and task-specific indicators like <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="666" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D448 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>B</mi><mi>L</mi><mi>E</mi><mi>U</mi></mrow></math></mjx-assistive-mml></mjx-container> ,ROUGE,F1,and exact match. For creative or reasoning-intensive tasks, human assessment is often essential to complement automated measures. Frameworks like LangChain and DSPy offer evaluation tools for LLMs. LangChain includes string-based and semantic metrics, while DSPy provides core metrics for NLP tasks, although it lacks direct support for evaluating Answer Set Programming, where no reference answer exists. Considering these, our study adopts micro-F1 score as the main evaluation metric. Table 1 is the summary of the methods, tools, datasets and LLMs used in the present study. Fig. 2 visualizes the methods, tools, datasets and procedures.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">LLM 性能评估包括一系列根据任务而定的指标，如客观性、真实性、人类对齐、流畅性、一致性、相关性，以及特定任务的指标，如 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="667" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D448 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>B</mi><mi>L</mi><mi>E</mi><mi>U</mi></mrow></math></mjx-assistive-mml></mjx-container>、ROUGE、F1 和精确匹配。对于创造性或推理密集型任务，人类评估通常是补充自动化测量的关键。像 LangChain 和 DSPy 这样的框架提供了 LLM 的评估工具。LangChain 包括基于字符串和语义的指标，而 DSPy 提供了 NLP 任务的核心指标，尽管它缺乏对没有参考答案的答案集编程的直接评估支持。考虑到这些，我们的研究采用微 F1 分数作为主要评估指标。表 1 是本研究中使用的方法、工具、数据集和 LLM 的总结。图 2 可视化了方法、工具、数据集和程序。</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-14="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><!-- Media --></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-14="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-14="0,0"><div style="height: auto;"><div><div><div>Table 1: Summary of Methods, Tools, and Datasets<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">表 1：方法、工具和数据集的总结</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-14="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-14="0,0"><div style="height: auto;"><div><div class="table-container"><table class="fixed-table"><tbody><tr><td>Method</td><td>Pipeline</td><td>Dataset</td><td>LLMs</td><td>Evaluation Criteria</td></tr><tr><td>Answer set programming (ASP)</td><td>Clingo, DLV, or Clasp</td><td>StepGame</td><td rowspan="3">DeepSeek, Llama3, GPT4.0 mini</td><td rowspan="3">micro F1-score accuracy</td></tr><tr><td>Proposed LLM + ASP pipeline</td><td>DSPy</td><td>StepGame, SparQA</td></tr><tr><td>Fact + logical rules</td><td>DSPy</td><td>StepGame, SparQA</td></tr></tbody></table></div><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><div class="table-container"><table class="fixed-table"><tbody><tr><td>方法</td><td>流水线</td><td>数据集</td><td>大型语言模型</td><td>评估标准</td></tr><tr><td>答案集编程 (ASP)</td><td>Clingo、DLV 或 Clasp</td><td>StepGame</td><td rowspan="3">DeepSeek、Llama3、GPT4.0 mini</td><td rowspan="3">微观 F1-score 准确率</td></tr><tr><td>提出的 LLM + ASP 流水线</td><td>DSPy</td><td>StepGame, SparQA</td></tr><tr><td>事实 + 逻辑规则</td><td>DSPy</td><td>StepGame, SparQA</td></tr></tbody></table></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-14="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><!-- Media --></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-14="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-14="0,0"><div style="height: auto;"><h2><div><div>4 Experiment 1: Proposed LLM + ASP<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">4 实验 1：提议的 LLM + ASP</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-14="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-14="0,0"><div style="height: auto;"><div><div><div>Due to the widespread application of ASP in spatial reasoning tasks and the relative simplicity of the StepGame dataset, we have included the detailed implementation and results in Appendix C. These results serve as a baseline for comparisons with other datasets and methodologies in the spatial reasoning domain.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">由于 ASP 在空间推理任务中的广泛应用以及 StepGame 数据集的相对简单性，我们在附录 C 中包含了详细的实现和结果。这些结果作为与空间推理领域其他数据集和方法比较的基线。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-14="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-14="0,0"><div style="height: auto;"><div><div><div>In this section, we assess the effectiveness and generalizability of the "LLM + ASP" approach on SparQA, a more challenging benchmark than StepGame, with its longer sentences, varied question types, and complex reasoning requirements.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在本节中，我们评估了“LLM + ASP”方法在 SparQA 上的有效性和普遍性，SparQA 是一个比 StepGame 更具挑战性的基准，具有更长的句子、多样的问题类型和复杂的推理要求。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-14="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-14="0,0"><div style="height: auto;"><h3><div><div>4.1 Implementation<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">4.1 实现</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-14="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-14="0,0"><div style="height: auto;"><div><div><div>Due to the task complexity and need for high-quality ASP fact generation, we focused on powerful LLMs: GPT4.0 mini, llama3 70B, and Deepseek 76B. We built a subset of the SparQA dataset with 220 examples (55 from each question type) for model inference.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">由于任务的复杂性和对高质量 ASP 事实生成的需求，我们专注于强大的 LLM：GPT4.0 mini、llama3 70B 和 Deepseek 76B。我们为模型推理构建了一个包含 220 个示例（每种问题类型 55 个）的 SparQA 数据集子集。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-14="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-80288109-7467-45ff-a1fd-962e562e803f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-14="0,0"><div style="height: auto;"><div><div><div>We adopted the same pipeline as StepGame to SparQA: (1) Converting Natural Language Context and Question to ASP Facts; (2) Adding Rules and Refining ASP Program; (3) Symbolic Reasoning; (4) Result Mapping and Evaluation.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">我们采用了与 StepGame 相同的流程来处理 SparQA: (1) 将自然语言上下文和问题转换为 ASP 事实; (2) 添加规则并优化 ASP 程序; (3) 符号推理; (4) 结果映射和评估。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-15="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-15="0,0"><div style="height: auto;"><div><div><div>The first module prompts LLMs to identify blocks, objects, and relation facts using three predicates: block/1, object/5, and is/3. The second module involves rule adoption and ASP refinement, with manually designed rules for inverse, transitive, and symmetric relations. The specific code and samples are seen in Appendix D.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">第一个模块提示 LLM 识别块、对象和关系事实，使用三个谓词：block/1、object/5 和 is/3。第二个模块涉及规则采用和 ASP 优化，手动设计了逆、传递和对称关系的规则。具体代码和示例见附录 D。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-15="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-15="0,0"><div style="height: auto;"><h3><div><div>4.2 Results and discussion<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">4.2 结果与讨论</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-15="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-15="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>Our neural-symbolic pipeline showed mixed results across different models and question types, as shown in Table ??. Finding Relation (FR) questions demonstrated significant improvement with accuracy increasing by approximately <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="668" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>20</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> across all models (from 26.92% to 53.12% on Llama3,38.18% to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="669" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>58.94</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> on Deepseek,and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="670" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>45.45</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="671" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>65.32</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> on GPT 4.0). Finding Block (FB) questions benefited from structured block/5 predicate representation, showing substantial gains particularly in GPT 4.0 (from 60.91% to 80.49%). Choose Object (CO) questions showed varied results, with GPT-4.0 achieving a notable <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="672" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>15</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> improvement while other models showed minimal changes. Interestingly, Yes/No (YN) questions performed better with direct prompting across all models, suggesting that simpler question types may not benefit from the additional complexity of neural-symbolic methods.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">我们的神经符号管道在不同模型和问题类型中显示出混合结果，如表 ?? 所示。寻找关系 (FR) 问题显示出显著改善，准确率在所有模型中大约提高了 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="673" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>20</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container>（在 Llama3 上从 26.92% 提高到 53.12%，在 Deepseek 上从 38.18% 提高到 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="674" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>58.94</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container>，在 GPT 4.0 上从 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="675" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>45.45</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> 提高到 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="676" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>65.32</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container>）。寻找块 (FB) 问题受益于结构化的 block/5 谓词表示，特别是在 GPT 4.0 中显示出显著提升（从 60.91% 提高到 80.49%）。选择对象 (CO) 问题结果各异，GPT-4.0 实现了显著的 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="677" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>15</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> 改进，而其他模型变化不大。有趣的是，Yes/No (YN) 问题在所有模型中通过直接提示表现更好，这表明较简单的问题类型可能不会从神经符号方法的额外复杂性中受益。</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-15="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-15="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>Table 2: Performance Comparison on SparQA (micro F1-score: Accuracy %) (Note: The <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="678" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c394"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">Δ</mi></math></mjx-assistive-mml></mjx-container> column contains data on the improved accuracy by comparing the "LLM + ASP" method with the "direct" prompting method.)<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">表 2: SparQA 性能比较（微 F1-score: 准确率 %）（注意：<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="679" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c394"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">Δ</mi></math></mjx-assistive-mml></mjx-container> 列包含通过比较“LLM + ASP”方法与“直接”提示方法提高的准确率数据。）</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-15="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><!-- Media --></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-15="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-15="0,0"><div style="height: auto;"><span style="display: inline;"><div><div class="table-container"><table class="fixed-table"><tbody><tr><td>Question Type</td><td>Model</td><td>Direct</td><td>LLM+ASP</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="680" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c394"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">Δ</mi></math></mjx-assistive-mml></mjx-container></td></tr><tr><td rowspan="3">FR</td><td>Deepseek</td><td>38.18</td><td>58.94</td><td>+20.76</td></tr><tr><td>Llama3</td><td>26.92</td><td>53.12</td><td>+26.20</td></tr><tr><td>GPT4.0</td><td>45.45</td><td>65.32</td><td>+19.87</td></tr><tr><td rowspan="3">FB</td><td>Deepseek</td><td>80.56</td><td>85.37</td><td>+4.81</td></tr><tr><td>Llama3</td><td>66.67</td><td>83.33</td><td>+16.66</td></tr><tr><td>GPT4.0</td><td>60.91</td><td>80.49</td><td>+19.58</td></tr><tr><td rowspan="3">YN</td><td>Deepseek</td><td>78.19</td><td>70.90</td><td>-7.29</td></tr><tr><td>Llama3</td><td>78.19</td><td>67.27</td><td>-10.92</td></tr><tr><td>GPT4.0</td><td>58.18</td><td>54.54</td><td>-3.64</td></tr><tr><td rowspan="3">CO</td><td>Deepseek</td><td>48.26</td><td>42.81</td><td>-5.45</td></tr><tr><td>Llama3</td><td>55.77</td><td>57.15</td><td>+1.38</td></tr><tr><td>GPT4.0</td><td>57.69</td><td>72.72</td><td>+15.03</td></tr></tbody></table></div><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><div class="table-container"><table class="fixed-table"><tbody><tr><td>问题类型</td><td>模型</td><td>直接</td><td>LLM+ASP</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="681" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c394"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">Δ</mi></math></mjx-assistive-mml></mjx-container></td></tr><tr><td rowspan="3">FR</td><td>Deepseek</td><td>38.18</td><td>58.94</td><td>+20.76</td></tr><tr><td>Llama3</td><td>26.92</td><td>53.12</td><td>+26.20</td></tr><tr><td>GPT4.0</td><td>45.45</td><td>65.32</td><td>+19.87</td></tr><tr><td rowspan="3">FB</td><td>Deepseek</td><td>80.56</td><td>85.37</td><td>+4.81</td></tr><tr><td>Llama3</td><td>66.67</td><td>83.33</td><td>+16.66</td></tr><tr><td>GPT4.0</td><td>60.91</td><td>80.49</td><td>+19.58</td></tr><tr><td rowspan="3">YN</td><td>Deepseek</td><td>78.19</td><td>70.90</td><td>-7.29</td></tr><tr><td>Llama3</td><td>78.19</td><td>67.27</td><td>-10.92</td></tr><tr><td>GPT4.0</td><td>58.18</td><td>54.54</td><td>-3.64</td></tr><tr><td rowspan="3">CO</td><td>Deepseek</td><td>48.26</td><td>42.81</td><td>-5.45</td></tr><tr><td>Llama3</td><td>55.77</td><td>57.15</td><td>+1.38</td></tr><tr><td>GPT4.0</td><td>57.69</td><td>72.72</td><td>+15.03</td></tr></tbody></table></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-15="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><!-- Media --></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-f5f8ea9b-d84f-428e-bf26-faf2554fb74a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-15="0,0"></paragraphpositioning></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-16="0,0"><div style="height: auto;"><h3><div><div>4.3 Error analysis<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">4.3 错误分析</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-16="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-16="0,0"><div style="height: auto;"><div><div><div>The ASP solver outputs reveal four main types of errors when inconsistent with ground truth. Grounding Errors occur due to inconsistent variable naming or undefined objects/relations in the ASP code, highlighting the importance of maintaining consistency between facts and queries. Parsing Errors are caused by unqualified relations, punctuation problems, irrelevant comments, or undefined variables. For example, Deepseek often failed to properly comment code with "%", while GPT-4.0 mini frequently mixed argument orders in block/5 facts.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">ASP 求解器的输出揭示了四种主要类型的错误，当与真实情况不一致时。归因错误是由于变量命名不一致或 ASP 代码中未定义的对象/关系而发生的，这突显了在事实和查询之间保持一致性的重要性。解析错误是由不合格的关系、标点问题、无关评论或未定义变量引起的。例如，Deepseek 经常未能正确使用 "%" 注释代码，而 GPT-4.0 mini 则经常在块/5 事实中混淆参数顺序。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-16="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-16="0,0"><div style="height: auto;"><div><div><div>Satisfiability without Query Results arise when facts and rules are insufficient to solve queries, often due to implied relations not being explicitly coded. Consider this example:<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">当事实和规则不足以解决查询时，会出现没有查询结果的可满足性问题，这通常是由于隐含关系未被明确编码。考虑以下示例：</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-16="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-16="0,0"><div style="height: auto;"><div><div><div>"The medium triangle is touching the bottom edge of the block. The circle is below and to the left of the small triangle. It is above the medium triangle."<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">“中等三角形接触块的底边。圆形位于小三角形的下方和左侧。它在中等三角形的上方。”</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-16="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-16="0,0"><div style="height: auto;"><div><div><div>Here, the query query(R):-is(medium_triangle, circle) becomes unsatisfiable without explicit relation definitions.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在这里，查询 query(R):-is(medium_triangle, circle) 在没有明确关系定义的情况下变得不可满足。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-16="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-16="0,0"><div style="height: auto;"><div><div><div>Wrong choices occurred when the ASP solver produced logically consistent but incorrect results compared to ground truth. Most parsing and grounding errors occurred during query parsing, particularly with complex spatial descriptions involving multiple objects and nested relations. Different models showed distinct error patterns, suggesting the need for model-specific optimization strategies and prompting approaches.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">当 ASP 求解器生成逻辑上一致但与真实情况不符的结果时，错误选择就会发生。大多数解析和归因错误发生在查询解析过程中，特别是在涉及多个对象和嵌套关系的复杂空间描述中。不同模型显示出不同的错误模式，这表明需要特定于模型的优化策略和提示方法。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-16="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-16="0,0"><div style="height: auto;"><h2><div><div>5 Experiment 2: Fact + Logical rules<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">5 实验 2：事实 + 逻辑规则</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-16="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-16="0,0"><div style="height: auto;"><h3><div><div>5.1 Implementation<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">5.1 实施</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-16="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-bdf9479b-24a0-4f71-97b8-ce283c5dfe18" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-16="0,0"><div style="height: auto;"><div><div><div>The implementation consists of two primary stages. The first stage maintains the initial semantic parsing component from the "LLM + ASP" pipeline, where models convert natural language into structured facts using predefined predicates. This conversion provides a clear and organized foundation for subsequent reasoning steps. In the second stage, rather than generating formal logical programs, LLMs directly apply logical rules (inverse, symmetric, transitive, and inter-block relationships for SparQA dataset, and chain linking based on offset for StepGame) through natural language reasoning to derive new knowledge and answer queries. The specific prompt and code samples are seen in Appendix E.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">实施分为两个主要阶段。第一阶段保持“LLM + ASP”管道中的初始语义解析组件，在该阶段，模型使用预定义的谓词将自然语言转换为结构化事实。这一转换为后续推理步骤提供了清晰且有组织的基础。在第二阶段，LLM 直接通过自然语言推理应用逻辑规则（反向、对称、传递和 SparQA 数据集的块间关系，以及基于偏移的链链接用于 StepGame），而不是生成正式的逻辑程序，以推导新知识并回答查询。具体的提示和代码示例见附录 E。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-17="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-17="0,0"><div style="height: auto;"><h3><div><div>5.2 Result<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">5.2 结果</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-17="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-17="0,0"><div style="height: auto;"><div><div><div>The evaluation demonstrates the effectiveness of the "Facts + Rules" approach across both SparQA and StepGame datasets. Table 3 presents a comprehensive performance comparison. To make the comparison easy to observe, we only report the overall F1 score on the dataset, leaving out the question type accuracy.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">评估展示了“事实 + 规则”方法在 SparQA 和 StepGame 数据集上的有效性。表 3 提供了全面的性能比较。为了便于观察比较，我们仅报告数据集上的整体 F1 分数，省略了问题类型的准确性。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-17="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><!-- Media --></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-17="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-17="0,0"><div style="height: auto;"><div><div><div>Table 3: Performance Comparison of different methods (micro F1-score: Accuracy %)<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">表 3：不同方法的性能比较（微 F1 分数：准确率 %）</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-17="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-17="0,0"><div style="height: auto;"><div><div class="table-container"><table class="fixed-table"><tbody><tr><td>Dataset</td><td>Model</td><td>Direct</td><td>LLM + ASP</td><td>Facts + Rules</td></tr><tr><td rowspan="3">SparQA</td><td>Deepseek</td><td>61.30</td><td>64.51</td><td>66.12</td></tr><tr><td>Llama3</td><td>56.89</td><td>65.22</td><td>65.69</td></tr><tr><td>GPT4.0 mini</td><td>55.56</td><td>68.27</td><td>61.23</td></tr><tr><td rowspan="3">StepGame</td><td>Deepseek</td><td>33.3</td><td>90.9</td><td>46.2</td></tr><tr><td>Llama3</td><td>29.8</td><td>82.4</td><td>64.3</td></tr><tr><td>GPT4.0 mini</td><td>29.9</td><td>83.2</td><td>58.6</td></tr></tbody></table></div><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><div class="table-container"><table class="fixed-table"><tbody><tr><td>数据集</td><td>模型</td><td>直接</td><td>LLM + ASP</td><td>事实 + 规则</td></tr><tr><td rowspan="3">SparQA</td><td>Deepseek</td><td>61.30</td><td>64.51</td><td>66.12</td></tr><tr><td>Llama3</td><td>56.89</td><td>65.22</td><td>65.69</td></tr><tr><td>GPT4.0 mini</td><td>55.56</td><td>68.27</td><td>61.23</td></tr><tr><td rowspan="3">StepGame</td><td>Deepseek</td><td>33.3</td><td>90.9</td><td>46.2</td></tr><tr><td>Llama3</td><td>29.8</td><td>82.4</td><td>64.3</td></tr><tr><td>GPT4.0 mini</td><td>29.9</td><td>83.2</td><td>58.6</td></tr></tbody></table></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-17="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><!-- Media --></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-17="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-17="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>The "Facts + Rules" method demonstrates competitive performance with the "LLM + ASP" approach on the SparQA dataset while significantly outperforming direct prompting <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="682" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mo>&gt;</mo><mn>5</mn><mi mathvariant="normal">%</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> . This success can be attributed to the elimination of parsing errors and inconsistent naming issues that plagued the ASP-based approach. When the facts are correctly represented and logical rules properly applied, the reasoning process becomes more transparent and reliable.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">“事实 + 规则”方法在 SparQA 数据集上表现出与“LLM + ASP”方法的竞争力，同时显著优于直接提示 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="683" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mo>&gt;</mo><mn>5</mn><mi mathvariant="normal">%</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>。这一成功可以归因于消除了困扰 ASP 基础方法的解析错误和不一致命名问题。当事实被正确表示且逻辑规则得当地应用时，推理过程变得更加透明和可靠。</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-17="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-17="0,0"><div style="height: auto;"><h3><div><div>5.3 Extension<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">5.3 扩展</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-17="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-17="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>We extended this approach to the StepGame dataset by translating its two-dimensional offset-based rules into natural language prompts. While the performance (66.7-77.2%) does not match the exceptional results of the ASP-based approach <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="684" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c39"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mn>82.4</mn></mrow><mo>−</mo><mrow data-mjx-texclass="ORD"><mn>90.9</mn></mrow><mi mathvariant="normal">%</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> ,it represents a substantial improvement over baseline direct prompting (29.8-33.3%). Surprisingly, the "Facts + Rule" natural language prompts work especially best for Llama3 70B. This improvement is particularly notable in handling extended reasoning chains (k <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="685" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>≥</mo><mn>5</mn></math></mjx-assistive-mml></mjx-container> ),where the structured approach provides clear guidance for step-by-step inference.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">我们通过将 StepGame 数据集的二维偏移基规则翻译成自然语言提示，扩展了这一方法。尽管性能（66.7-77.2%）未能与 ASP 基础方法的卓越结果相匹配 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="686" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c39"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mn>82.4</mn></mrow><mo>−</mo><mrow data-mjx-texclass="ORD"><mn>90.9</mn></mrow><mi mathvariant="normal">%</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>，但相较于基线直接提示（29.8-33.3%），这代表了显著的改进。令人惊讶的是，“事实 + 规则”自然语言提示在 Llama3 70B 上表现尤其出色。这一改进在处理扩展推理链（k <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="687" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>≥</mo><mn>5</mn></math></mjx-assistive-mml></mjx-container>）时尤为显著，结构化方法为逐步推理提供了清晰的指导。</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-17="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-890e817b-5f47-4e85-b16a-d895bb1cf6e7" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-17="0,0"><div style="height: auto;"><div><div><div>The success of this simplified approach illustrates an important principle in neural-symbolic integration: effective reasoning can be achieved by employing LLMs' natural language capabilities within a structured framework, without necessarily requiring formal logical programming. By eliminating the computational overhead of ASP generation and refinement while maintaining the benefits of structured reasoning, this method offers a practical alternative for applications where implementation simplicity and computational efficiency are paramount considerations.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">这一简化方法的成功说明了神经符号集成中的一个重要原则：通过在结构化框架内利用 LLM 的自然语言能力，可以实现有效的推理，而不必依赖于形式逻辑编程。通过消除 ASP 生成和细化的计算开销，同时保持结构化推理的优势，该方法为实现简单性和计算效率至关重要的应用提供了一个实用的替代方案。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-7351c5ab-64ed-4138-9df5-e680658dc594" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-18="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-7351c5ab-64ed-4138-9df5-e680658dc594" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-18="0,0"><div style="height: auto;"><h2><div><div>6 Discussion<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">6 讨论</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-7351c5ab-64ed-4138-9df5-e680658dc594" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-18="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-7351c5ab-64ed-4138-9df5-e680658dc594" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-18="0,0"><div style="height: auto;"><h3><div><div>6.1 Strengths<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">6.1 优势</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-7351c5ab-64ed-4138-9df5-e680658dc594" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-18="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-7351c5ab-64ed-4138-9df5-e680658dc594" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-18="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>Compared with the previous related work (Yang et al., 2023; Li et al., 2024a; Mirzaee and Kordjamshidi, 2023), our results shown in Tables ?? and 3 have made substantial improvements in using neural-symbolic methods to enhance spatial reasoning in LLMs. For example, our neural-symbolic approaches achieved over <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="688" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-b"><mjx-c class="mjx-c1D7D6 TEX-B"></mjx-c><mjx-c class="mjx-c1D7CE TEX-B"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-b"><mjx-c class="mjx-c25 TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mn mathvariant="bold">80</mn></mrow><mi mathvariant="bold">%</mi></mrow></math></mjx-assistive-mml></mjx-container> accuracy on StepGame,and averaged <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="689" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-b"><mjx-c class="mjx-c1D7D4 TEX-B"></mjx-c><mjx-c class="mjx-c1D7CE TEX-B"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-b"><mjx-c class="mjx-c25 TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mn mathvariant="bold">60</mn></mrow><mi mathvariant="bold">%</mi></mrow></math></mjx-assistive-mml></mjx-container> on the more complex SparQA dataset. We first confirm that our integration methods are much more effective. Second, our methods greatly outperform the existing methods. For instance, our experiments demonstrate significant improvements over the baseline prompting methods, with accuracy increases of 40-50% on StepGame dataset and 3-13% on the more complex SparQA dataset. The "LLM + ASP" pipeline achieves particularly strong results on the tasks of Finding Relations (FR) and Finding Block (FB) questions, though performance varies across different question types. Additionally, our methods have formed an integrated pipeline compared with previous related work, and further could be easily applied in other domains. We have addressed our first research question. The following will resolve the second research question.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">与之前的相关工作（Yang et al., 2023; Li et al., 2024a; Mirzaee 和 Kordjamshidi, 2023）相比，我们在表 ?? 和 3 中展示的结果在使用神经符号方法增强大语言模型的空间推理方面取得了显著改善。例如，我们的神经符号方法在 StepGame 上达到了超过 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="690" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-b"><mjx-c class="mjx-c1D7D6 TEX-B"></mjx-c><mjx-c class="mjx-c1D7CE TEX-B"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-b"><mjx-c class="mjx-c25 TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mn mathvariant="bold">80</mn></mrow><mi mathvariant="bold">%</mi></mrow></math></mjx-assistive-mml></mjx-container> 的准确率，并在更复杂的 SparQA 数据集上平均达到了 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="691" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-b"><mjx-c class="mjx-c1D7D4 TEX-B"></mjx-c><mjx-c class="mjx-c1D7CE TEX-B"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-b"><mjx-c class="mjx-c25 TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mn mathvariant="bold">60</mn></mrow><mi mathvariant="bold">%</mi></mrow></math></mjx-assistive-mml></mjx-container>。我们首先确认我们的集成方法更为有效。其次，我们的方法大大超越了现有方法。例如，我们的实验显示，与基线提示方法相比，准确率在 StepGame 数据集上提高了 40-50%，在更复杂的 SparQA 数据集上提高了 3-13%。"LLM + ASP" 流水线在寻找关系（FR）和寻找块（FB）问题的任务上取得了特别强的结果，尽管不同问题类型的表现有所不同。此外，与之前的相关工作相比，我们的方法形成了一个集成流水线，并且可以很容易地应用于其他领域。我们已经解决了第一个研究问题。接下来将解决第二个研究问题。</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-7351c5ab-64ed-4138-9df5-e680658dc594" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-18="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-7351c5ab-64ed-4138-9df5-e680658dc594" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-18="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>Our experiments demonstrated the potential of neural-symbolic integration,achieving consistent accuracy above <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="692" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-b"><mjx-c class="mjx-c1D7D6 TEX-B"></mjx-c><mjx-c class="mjx-c1D7CE TEX-B"></mjx-c></mjx-mn></mjx-texatom></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mn mathvariant="bold">80</mn></mrow></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> across different models. This success can be attributed to three key factors: (1) the effective separation of semantic parsing and logical reasoning, enabling precise control over each component; (2) the well-defined spatial relationships in a 2D environment, allowing for unambiguous predicate representation; and (3) the efficient handling of multi-hop reasoning chains through explicit logical rules.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">我们的实验展示了神经符号集成的潜力，在不同模型中实现了一致的准确率超过 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="693" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-b"><mjx-c class="mjx-c1D7D6 TEX-B"></mjx-c><mjx-c class="mjx-c1D7CE TEX-B"></mjx-c></mjx-mn></mjx-texatom></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mn mathvariant="bold">80</mn></mrow></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container>。这一成功可以归因于三个关键因素：（1）语义解析和逻辑推理的有效分离，使得对每个组件的精确控制成为可能；（2）在二维环境中明确的空间关系，允许不含歧义的谓词表示；（3）通过明确的逻辑规则高效处理多跳推理链。</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-7351c5ab-64ed-4138-9df5-e680658dc594" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-18="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-7351c5ab-64ed-4138-9df5-e680658dc594" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-18="0,0"><div style="height: auto;"><div><div><div>We summarize our contributions on using neural-symbloic methods to systematically improve the performance of spatial reasoning in LLMs. The five contributions could be described as follows.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">我们总结了使用神经符号方法系统性提高大语言模型空间推理性能的贡献。这五项贡献可以描述如下。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-7351c5ab-64ed-4138-9df5-e680658dc594" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-18="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-7351c5ab-64ed-4138-9df5-e680658dc594" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-18="0,0"><div style="height: auto;"><div><div><div>First, boost spatial reasoning: our integration methods significantly enhance spatial reasoning in complex tasks across various LLMs. While<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">首先，增强空间推理：我们的集成方法显著提升了各种大语言模型在复杂任务中的空间推理能力。虽然</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="20" id="mark-0a56c439-38d9-44f3-ba5c-d83cb85b23ba" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-19="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="20" id="mark-0a56c439-38d9-44f3-ba5c-d83cb85b23ba" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-19="0,0"><div style="height: auto;"><div><div><div>LLMs can struggle with maintaining consistency over long, complex reasoning chains (like navigating through a series of spatial steps), symbolic modules can enforce strict rules of inference and logic, which enhances accuracy and coherence in spatial tasks. Second, advance neural-symbolic approaches: we provide a cohesive pipeline that strengthens neural-symbolic methods for improving LLM reasoning. Third, structured knowledge representation: our approach facilitates efficient knowledge representation and inference through advanced encoding techniques. Our symbolic modules enable LLMs to handle structured, explicit representations of spatial information, such as geometric shapes, positions, and spatial relationships. This allows LLMs to reason in a more organized and interpretable manner compared to raw, unstructured data processing alone. Forth, robust and generalizable: our approach is robust and highly generalizable, making it suitable for other complex reasoning tasks where LLMs typically struggle, such as temporal and deductive reasoning. Our symbolic reasoning systems are designed to generalize better across a wide range of situations by applying logical rules. Integrating this with the probabilistic nature of LLMs provides the system with a more robust way to infer spatial relationships, even in new or unseen scenarios. Moreover, LLMs are strong in natural language processing, while symbolic systems excel at tasks requiring formal logic. By combining both, LLMs can leverage the flexibility of language generation and the rigor of symbolic reasoning, making spatial tasks more efficient and accurate.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">LLM 在长时间、复杂推理链（如在一系列空间步骤中导航）中可能会遇到保持一致性的问题，而符号模块可以强制执行严格的推理和逻辑规则，从而增强空间任务的准确性和连贯性。其次，先进的神经-符号方法：我们提供了一个连贯的管道，强化了神经-符号方法以改善 LLM 的推理。第三，结构化知识表示：我们的方法通过先进的编码技术促进高效的知识表示和推理。我们的符号模块使 LLM 能够处理结构化、明确的空间信息表示，例如几何形状、位置和空间关系。这使得 LLM 能够以比单纯的原始非结构化数据处理更有组织和可解释的方式进行推理。第四，稳健且具有广泛适用性：我们的方法稳健且高度通用，适合其他 LLM 通常面临挑战的复杂推理任务，如时间推理和演绎推理。我们的符号推理系统旨在通过应用逻辑规则在各种情况下更好地进行泛化。将这一点与 LLM 的概率特性相结合，为系统提供了一种更稳健的方式来推断空间关系，即使在新的或未见过的场景中。此外，LLM 在自然语言处理方面表现出色，而符号系统在需要形式逻辑的任务中表现优异。通过结合两者，LLM 可以利用语言生成的灵活性和符号推理的严谨性，使空间任务更加高效和准确。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="20" id="mark-0a56c439-38d9-44f3-ba5c-d83cb85b23ba" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-19="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="20" id="mark-0a56c439-38d9-44f3-ba5c-d83cb85b23ba" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-19="0,0"><div style="height: auto;"><h3><div><div>6.2 Limitations<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">6.2 限制</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="20" id="mark-0a56c439-38d9-44f3-ba5c-d83cb85b23ba" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-19="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="20" id="mark-0a56c439-38d9-44f3-ba5c-d83cb85b23ba" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-19="0,0"><div style="height: auto;"><div><div><div>This section focuses on the potential problems and limitations on our approaches and experiments. Our experiments with StepGame and SparQA datasets reveal excellent performance of neural-symbolic integration for spatial reasoning tasks. Through systematic evaluation across different question types and reasoning complexities, we observed distinct performance patterns that illuminate the practical considerations for deploying such systems.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">本节重点讨论我们的方法和实验中可能存在的问题和限制。我们在 StepGame 和 SparQA 数据集上的实验揭示了神经-符号集成在空间推理任务中的出色表现。通过对不同问题类型和推理复杂性进行系统评估，我们观察到明显的性能模式，这些模式阐明了部署此类系统的实际考虑因素。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="20" id="mark-0a56c439-38d9-44f3-ba5c-d83cb85b23ba" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-19="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="20" id="mark-0a56c439-38d9-44f3-ba5c-d83cb85b23ba" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-19="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>SparQA saw averaging <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="694" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-b"><mjx-c class="mjx-c1D7D4 TEX-B"></mjx-c><mjx-c class="mjx-c1D7CE TEX-B"></mjx-c></mjx-mn></mjx-texatom></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mn mathvariant="bold">60</mn></mrow></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> accuracy across four question types. However, the SparQA experiments perform differently across the four questions. First, though the over F1 accuracy is higher than the baseline direct prompting strategy, the performance is not consistent among the four types of questions, particularly in YN questions with quantifiers and implicit spatial relationships. Second, the system struggled with query generation for sophisticated question types, often failing to capture the full semantic complexity of natural language descriptions. Third, the refinement process introduced substantial computational overhead, raising questions about scalability in real-world applications.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">SparQA 在四种问题类型上看到了平均 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="695" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-b"><mjx-c class="mjx-c1D7D4 TEX-B"></mjx-c><mjx-c class="mjx-c1D7CE TEX-B"></mjx-c></mjx-mn></mjx-texatom></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mn mathvariant="bold">60</mn></mrow></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> 准确性。然而，SparQA 实验在这四个问题上的表现却有所不同。首先，尽管总体 F1 准确率高于基线直接提示策略，但在四种问题类型之间的表现并不一致，特别是在涉及量词和隐含空间关系的是非问题中。其次，该系统在生成复杂问题类型的查询时遇到了困难，常常无法捕捉自然语言描述的全部语义复杂性。第三，细化过程引入了大量计算开销，提出了在实际应用中可扩展性的问题。</div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="21" id="mark-9f4decc0-6464-4da1-8a51-d4b480a171d7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-20="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="21" id="mark-9f4decc0-6464-4da1-8a51-d4b480a171d7" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-20="0,0"><div style="height: auto;"><div><div><div>This performance disparity between datasets highlights a crucial challenge in neural-symbolic integration: domain sensitivity. While StepGame's structured environment enabled efficient predicate-based representation, SparQA's naturalistic descriptions exposed the difficulties in maintaining consistent mappings between neural and symbolic components. This observation aligns with Yang et al. (2023) findings regarding the domain-specific nature of knowledge modules in symbolic reasoning. Their work demonstrated that even relatively simple reasoning tasks, such as those in the bAbI dataset, require multiple specialized knowledge modules for different types of reasoning (e.g., temporal reasoning, spatial relations, and basic inference). Creating and maintaining such modules can be time-consuming and requires domain expertise.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">数据集之间的性能差异突显了神经符号集成中的一个关键挑战：领域敏感性。虽然 StepGame 的结构化环境实现了高效的基于谓词的表示，但 SparQA 的自然描述暴露了在神经和符号组件之间保持一致映射的困难。这一观察与 Yang 等人（2023）的研究结果一致，后者指出符号推理中知识模块的领域特定性质。他们的工作表明，即使是相对简单的推理任务，例如 bAbI 数据集中的任务，也需要多个专门的知识模块来处理不同类型的推理（例如，时间推理、空间关系和基本推理）。创建和维护这些模块可能耗时且需要领域专业知识。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="21" id="mark-9f4decc0-6464-4da1-8a51-d4b480a171d7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-20="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="21" id="mark-9f4decc0-6464-4da1-8a51-d4b480a171d7" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-20="0,0"><div style="height: auto;"><h3><div><div>6.3 Future directions<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">6.3 未来方向</div></div></div></h3></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="21" id="mark-9f4decc0-6464-4da1-8a51-d4b480a171d7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-20="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="21" id="mark-9f4decc0-6464-4da1-8a51-d4b480a171d7" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-20="0,0"><div style="height: auto;"><div><div><div>The neural-symbolic pipeline allows for more explainable and traceable reasoning processes, addressing a major criticism of pure neural network approaches. Nevertheless, this advantage comes at the cost of increased system complexity and the need for careful design of the interaction between neural and symbolic components. The error-prone nature of converting natural language to logic programs, as observed in our experiments, remains a bottleneck of the neural-symbolic approach. This challenge could be addressed by implementing more effective feedback loops between different models and components in the pipeline. Due to the limitations of the DSPy framework and for model comparison purposes, we relied on a single LLM to refine the ASP program.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">神经符号管道允许更可解释和可追溯的推理过程，解决了纯神经网络方法的一个主要批评。然而，这一优势以系统复杂性增加和神经与符号组件之间交互设计的谨慎需求为代价。将自然语言转换为逻辑程序的错误倾向性，如我们实验中所观察到的，仍然是神经符号方法的瓶颈。通过在管道中实现不同模型和组件之间更有效的反馈循环，可以解决这一挑战。由于 DSPy 框架的局限性以及模型比较的需要，我们依赖于单个 LLM 来细化 ASP 程序。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="21" id="mark-9f4decc0-6464-4da1-8a51-d4b480a171d7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-20="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="21" id="mark-9f4decc0-6464-4da1-8a51-d4b480a171d7" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-20="0,0"><div style="height: auto;"><div><div><div>These limitations point toward several promising directions for future research. Future developments should focus on enhancing the robustness and adaptability of these systems while maintaining their core advantage in combining neural flexibility with symbolic precision.The work on context-aware knowledge graph embeddings (Zhu and Sun, 2024) suggests potential approaches for capturing implicit relationships more effectively. Additionally, incorporating probabilistic reasoning capabilities, as demonstrated by De Raedt et al. (2020), could enhance the system's ability to handle uncertainty in spatial relationships. Furthermore, developing error finding and automatic debugging mechanisms (Gu et al., 2023) could improve the system's reliability and reduce the need for manual intervention.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">这些限制指向未来研究的几个有前景的方向。未来的发展应集中于增强这些系统的鲁棒性和适应性，同时保持其在结合神经灵活性与符号精确性方面的核心优势。关于上下文感知知识图谱嵌入的研究（Zhu 和 Sun, 2024）提出了更有效捕捉隐含关系的潜在方法。此外，结合概率推理能力，如 De Raedt 等人（2020）所示，可能增强系统处理空间关系不确定性的能力。此外，开发错误查找和自动调试机制（Gu 等人，2023）可以提高系统的可靠性并减少对人工干预的需求。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="21" id="mark-9f4decc0-6464-4da1-8a51-d4b480a171d7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-20="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="21" id="mark-9f4decc0-6464-4da1-8a51-d4b480a171d7" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-20="0,0"><div style="height: auto;"><div><div><div>In essence, the neural-symbolic approach treats LLMs as agents within a carefully orchestrated system. This perspective shifts the focus from improving individual LLM performance to optimizing the interplay between different components of the system. Future work should explore optimizing interactions between multiple models and reasoning components, involving more sophisticated orchestration techniques, improved integration of probabilistic reasoning with symbolic solvers, and employing the strengths of different LLMs at various stages of neural-symbolic systems.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">本质上，神经-符号方法将大规模语言模型（LLMs）视为一个精心编排系统中的代理。这一视角将重点从提高单个 LLM 的性能转向优化系统不同组件之间的相互作用。未来的工作应探索优化多个模型和推理组件之间的交互，涉及更复杂的编排技术、概率推理与符号求解器的更好集成，以及在神经-符号系统的不同阶段利用不同 LLM 的优势。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="22" id="mark-418e38d9-d30b-49d1-b3e2-d5cb1fa10a57" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-21="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="22" id="mark-418e38d9-d30b-49d1-b3e2-d5cb1fa10a57" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-21="0,0"><div style="height: auto;"><h2><div><div>7 Conclusion<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">7 结论</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="22" id="mark-418e38d9-d30b-49d1-b3e2-d5cb1fa10a57" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-21="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="22" id="mark-418e38d9-d30b-49d1-b3e2-d5cb1fa10a57" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-21="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>This study introduced a novel neural-symbolic pipeline that effectively enhances LLMs' spatial reasoning capabilities. The experimental results demonstrate significant improvements over traditional neural-symbolic methods, showing enhanced performance in complex spatial reasoning tasks across various LLMs. The evaluation results demonstrate the effectiveness, robustness, and generalizability of our approach. However, challenges remain, as evidenced by the performance discrepancy between the two datasets. While the approach achieved over <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="696" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>80</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> accuracy on StepGame,it averaged <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="697" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>60</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> on the more complex SparQA. This requires to further optimize neural-symbolic systems that generalize effectively across diverse problem domains. Nonetheless, our pipeline and strategies show excellent overall performance and significant advancements in spatial reasoning for LLMs. With further refinement, these methods have the potential to revolutionize spatial reasoning capabilities in LLMs and can be adapted to other reasoning domains, marking a substantial leap in neural-symbolic AI. Our work lays a critical foundation for future breakthroughs in AI, driving forward the quest for more intelligent, interpretable, and efficient systems, and offering a pivotal step toward achieving AGI.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">本研究引入了一种新颖的神经-符号管道，有效增强了大型语言模型（LLMs）的空间推理能力。实验结果表明，相较于传统的神经-符号方法，取得了显著的改进，显示出在各种大型语言模型中的复杂空间推理任务中的性能提升。评估结果证明了我们方法的有效性、稳健性和普适性。然而，仍然存在挑战，两个数据集之间的性能差异便是证据。尽管该方法在 StepGame 上达到了超过 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="698" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>80</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> 的准确率，但在更复杂的 SparQA 上平均仅为 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="699" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>60</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container>。这需要进一步优化能够在多样化问题领域中有效泛化的神经-符号系统。尽管如此，我们的管道和策略显示出整体性能优秀，并在大型语言模型的空间推理方面取得了显著进展。通过进一步的改进，这些方法有潜力彻底改变大型语言模型的空间推理能力，并可以适应其他推理领域，标志着神经-符号人工智能的重大飞跃。我们的工作为未来在人工智能领域的突破奠定了关键基础，推动了对更智能、可解释和高效系统的追求，并为实现通用人工智能（AGI）提供了重要一步。</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="22" id="mark-418e38d9-d30b-49d1-b3e2-d5cb1fa10a57" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-21="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="22" id="mark-418e38d9-d30b-49d1-b3e2-d5cb1fa10a57" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-21="0,0"><div style="height: auto;"><h2><div><div>References<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">参考文献</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="22" id="mark-418e38d9-d30b-49d1-b3e2-d5cb1fa10a57" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-21="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="22" id="mark-418e38d9-d30b-49d1-b3e2-d5cb1fa10a57" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-21="0,0"><div style="height: auto;"><div><div><div>Alirezaie, M., Längkvist, M., Sioutis, M., and Loutfi, A. (2019). Semantic referee: A neural-symbolic framework for enhancing geospatial semantic segmentation. Semantic Web, 10(5):863-880.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Alirezaie, M., Längkvist, M., Sioutis, M., 和 Loutfi, A. (2019). 语义裁判：一个增强地理空间语义分割的神经-符号框架。语义网, 10(5):863-880.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="22" id="mark-418e38d9-d30b-49d1-b3e2-d5cb1fa10a57" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-21="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="22" id="mark-418e38d9-d30b-49d1-b3e2-d5cb1fa10a57" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-21="0,0"><div style="height: auto;"><div><div><div>Bang, Y., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., Lovenia, H., Ji, Z., Yu, T., Chung, W., et al. (2023). A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. In Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages 675-718.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Bang, Y., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., Lovenia, H., Ji, Z., Yu, T., Chung, W., 等. (2023). 对 ChatGPT 在推理、幻觉和互动方面的多任务、多语言、多模态评估. 载于第十三届国际自然语言处理联合会议及亚太计算语言学协会第三届会议论文集（第一卷：长篇论文），第675-718页。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-22="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-22="0,0"><div style="height: auto;"><div><div><div>Bellini-Leite, S. C. (2022). Dual process theory: Embodied and predictive; symbolic and classical. Frontiers in Psychology, 13:805386.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Bellini-Leite, S. C. (2022). 双重过程理论：具身与预测；符号与经典. 心理学前沿, 13:805386。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-22="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-22="0,0"><div style="height: auto;"><div><div><div>Besold, T. R., d'Avila Garcez, A., Bader, S., Bowman, H., Domingos, P., Hitzler, P., Kühnberger, K.-U., Lamb, L. C., Lima, P. M. V., de Penning, L., et al. (2021). Neural-symbolic learning and reasoning: A survey and interpretation 1. In Neuro-Symbolic Artificial Intelligence: The State of the Art, pages 1-51. IOS press.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Besold, T. R., d'Avila Garcez, A., Bader, S., Bowman, H., Domingos, P., Hitzler, P., Kühnberger, K.-U., Lamb, L. C., Lima, P. M. V., de Penning, L., 等. (2021). 神经符号学习与推理：一项调查与解读. 载于神经符号人工智能：现状, 第1-51页. IOS出版社。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-22="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-22="0,0"><div style="height: auto;"><div><div><div>Bhandari, P., Anastasopoulos, A., and Pfoser, D. (2023). Are large language models geospatially knowledgeable? In Proceedings of the 31st ACM International Conference on Advances in Geographic Information Systems, pages 1-4.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Bhandari, P., Anastasopoulos, A., 和 Pfoser, D. (2023). 大型语言模型是否具备地理空间知识？ 载于第31届ACM国际地理信息系统进展会议论文集，第1-4页。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-22="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-22="0,0"><div style="height: auto;"><div><div><div>Byrne, R. M. and Johnson-Laird, P. N. (1989). Spatial reasoning. Journal of Memory and Language, 28(5):564-575.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Byrne, R. M. 和 Johnson-Laird, P. N. (1989). 空间推理. 记忆与语言杂志, 28(5):564-575。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-22="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-22="0,0"><div style="height: auto;"><div><div><div>Cai, T., Wang, X., Ma, T., Chen, X., and Zhou, D. (2023). Large language models as tool makers. arXiv preprint arXiv:2305.17126.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Cai, T., Wang, X., Ma, T., Chen, X., 和 Zhou, D. (2023). 大型语言模型作为工具制造者. arXiv 预印本 arXiv:2305.17126.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-22="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-22="0,0"><div style="height: auto;"><div><div><div>Chen, B., Xu, Z., Kirmani, S., Ichter, B., Sadigh, D., Guibas, L., and Xia, F. (2024). Spatialvlm: Endowing vision-language models with spatial reasoning capabilities. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14455-14465.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Chen, B., Xu, Z., Kirmani, S., Ichter, B., Sadigh, D., Guibas, L., 和 Xia, F. (2024). Spatialvlm: 赋予视觉-语言模型空间推理能力. 在 IEEE/CVF 计算机视觉与模式识别会议论文集中, 页码 14455-14465.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-22="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-22="0,0"><div style="height: auto;"><div><div><div>Chen, H., Suhr, A., Misra, D., Snavely, N., and Artzi, Y. (2019). Touchdown: Natural language navigation and spatial reasoning in visual street environments. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12538-12547.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Chen, H., Suhr, A., Misra, D., Snavely, N., 和 Artzi, Y. (2019). Touchdown: 自然语言导航和视觉街道环境中的空间推理. 在 IEEE/CVF 计算机视觉与模式识别会议论文集中, 页码 12538-12547.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-22="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-22="0,0"><div style="height: auto;"><div><div><div>Chu, Z., Chen, J., Chen, Q., Yu, W., He, T., Wang, H., Peng, W., Liu, M., Qin, B., and Liu, T. (2023). A survey of chain of thought reasoning: Advances, frontiers and future. ArXiv, abs/2309.15402.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Chu, Z., Chen, J., Chen, Q., Yu, W., He, T., Wang, H., Peng, W., Liu, M., Qin, B., 和 Liu, T. (2023). 思维链推理的调查: 进展、前沿与未来. ArXiv, abs/2309.15402.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-22="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-22="0,0"><div style="height: auto;"><div><div><div>Cohn, A. G. (2023). An evaluation of chatgpt-4's qualitative spatial reasoning capabilities in rcc-8. arXiv preprint arXiv:2309.15577.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Cohn, A. G. (2023). 对 chatgpt-4 在 rcc-8 中的定性空间推理能力的评估. arXiv 预印本 arXiv:2309.15577.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-22="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-22="0,0"><div style="height: auto;"><div><div><div>Cohn, A. G. and Renz, J. (2008). Qualitative spatial representation and reasoning. Foundations of Artificial Intelligence, 3:551-596.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Cohn, A. G. 和 Renz, J. (2008). 定性空间表示与推理. 人工智能基础, 3:551-596.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-22="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-862acc3e-29b0-4572-905d-be809ee3a3c8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-22="0,0"><div style="height: auto;"><div><div><div>De Raedt, L., Dumančić, S., Manhaeve, R., and Marra, G. (2020). From statistical relational to neuro-symbolic artificial intelligence. arXiv preprint arXiv:2003.08316.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">De Raedt, L., Dumančić, S., Manhaeve, R., 和 Marra, G. (2020). 从统计关系到神经符号人工智能。arXiv 预印本 arXiv:2003.08316。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-23="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-23="0,0"><div style="height: auto;"><div><div><div>Eiter, T., Higuera, N., Oetsch, J., and Pritz, M. (2022). A neuro-symbolic asp pipeline for visual question answering. Theory and Practice of Logic Programming, 22(5):739–754.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Eiter, T., Higuera, N., Oetsch, J., 和 Pritz, M. (2022). 一种用于视觉问答的神经符号 ASP 流水线。《逻辑编程的理论与实践》，22(5):739–754。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-23="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-23="0,0"><div style="height: auto;"><div><div><div>Evans, J. S. B. and Stanovich, K. E. (2013). Dual-process theories of higher cognition: Advancing the debate. Perspectives on psychological science, 8(3):223–241.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Evans, J. S. B. 和 Stanovich, K. E. (2013). 高级认知的双过程理论：推动辩论。《心理科学的视角》，8(3):223–241。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-23="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-23="0,0"><div style="height: auto;"><div><div><div>Fang, M., Deng, S., Zhang, Y., Shi, Z., Chen, L., Pechenizkiy, M., and Wang, J. (2024). Large language models are neurosymbolic reasoners. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 17985-17993.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Fang, M., Deng, S., Zhang, Y., Shi, Z., Chen, L., Pechenizkiy, M., 和 Wang, J. (2024). 大型语言模型是神经符号推理者。在《人工智能协会会议论文集》，第 38 卷，页17985-17993。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-23="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-23="0,0"><div style="height: auto;"><div><div><div>Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan, J., and Neubig, G. (2022). Pal: Program-aided language models. ArXiv, abs/2211.10435.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan, J., 和 Neubig, G. (2022). PAL：程序辅助语言模型。ArXiv, abs/2211.10435。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-23="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-23="0,0"><div style="height: auto;"><div><div><div>Garcez, A. d. and Lamb, L. C. (2023). Neurosymbolic ai: The 3 rd wave. Artificial Intelligence Review, 56(11):12387-12406.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Garcez, A. d. 和 Lamb, L. C. (2023). 神经符号人工智能：第三波。《人工智能评论》，56(11):12387-12406。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-23="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-23="0,0"><div style="height: auto;"><div><div><div>Geibinger, T. (2023). Explainable answer-set programming. arXiv preprint arXiv:2308.15901.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Geibinger, T. (2023). 可解释的答案集编程。arXiv 预印本 arXiv:2308.15901。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-23="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-23="0,0"><div style="height: auto;"><div><div><div>Geigle, G., Jain, A., Timofte, R., and Glavaš, G. (2023). mblip: Efficient bootstrapping of multilingual vision-llms. arXiv preprint arXiv:2307.06930.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Geigle, G., Jain, A., Timofte, R., 和 Glavaš, G. (2023). mblip: 多语言视觉大语言模型的高效引导. arXiv 预印本 arXiv:2307.06930.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-23="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-23="0,0"><div style="height: auto;"><div><div><div>Ghosh, A., Acharya, A., Saha, S., Jain, V., and Chadha, A. (2024). Exploring the frontier of vision-language models: A survey of current methodologies and future directions. arXiv preprint arXiv:2404.07214.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Ghosh, A., Acharya, A., Saha, S., Jain, V., 和 Chadha, A. (2024). 探索视觉-语言模型的前沿：当前方法论和未来方向的调查. arXiv 预印本 arXiv:2404.07214.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-23="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-23="0,0"><div style="height: auto;"><div><div><div>Gu, K., Jun, E., and Althoff, T. (2023). Understanding and supporting debugging workflows in multiverse analysis. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, pages 1-19.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Gu, K., Jun, E., 和 Althoff, T. (2023). 理解和支持多元宇宙分析中的调试工作流程. 载于2023年计算机系统人因会议论文集, 页码 1-19.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-23="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-23="0,0"><div style="height: auto;"><div><div><div>Hamilton, K., Nayak, A., Božić, B., and Longo, L. (2022). Is neuro-symbolic ai meeting its promises in natural language processing? a structured review. Semantic Web, (Preprint):1-42.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Hamilton, K., Nayak, A., Božić, B., 和 Longo, L. (2022). 神经符号人工智能在自然语言处理中的承诺是否得以实现？一项结构化评审. 语义网, (预印本): 1-42.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-23="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-23="0,0"><div style="height: auto;"><div><div><div>Hersche, M., Zeqiri, M., Benini, L., Sebastian, A., and Rahimi, A. (2023). A neuro-vector-symbolic architecture for solving raven's progressive matrices. Nature Machine Intelligence, 5(4):363-375.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Hersche, M., Zeqiri, M., Benini, L., Sebastian, A., 和 Rahimi, A. (2023). 一种神经-向量-符号架构用于解决乌鸦的渐进矩阵. 自然机器智能, 5(4): 363-375.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-23="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-a2a5cb8b-c5a5-44ed-9378-dc7303d33c3c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-23="0,0"><div style="height: auto;"><div><div><div>Ishay, A., Yang, Z., and Lee, J. (2023). Leveraging large language models to generate answer set programs. arXiv preprint arXiv:2307.07699.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Ishay, A., Yang, Z., 和 Lee, J. (2023). 利用大型语言模型生成答案集程序. arXiv 预印本 arXiv:2307.07699.</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-24="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-24="0,0"><div style="height: auto;"><div><div><div>Katerinenko, R. (2015). Semantic spatial reasoning. In KEOD, pages 257- 262.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Katerinenko, R. (2015). 语义空间推理. 载于 KEOD, 页码 257-262.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-24="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-24="0,0"><div style="height: auto;"><div><div><div>Khattab, O., Singhvi, A., Maheshwari, P., Zhang, Z., Santhanam, K., Vard-hamanan, S., Haq, S., Sharma, A., Joshi, T. T., Moazam, H., et al. (2023). Dspy: Compiling declarative language model calls into self-improving pipelines. arXiv preprint arXiv:2310.03714.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Khattab, O., Singhvi, A., Maheshwari, P., Zhang, Z., Santhanam, K., Vard-hamanan, S., Haq, S., Sharma, A., Joshi, T. T., Moazam, H., 等. (2023). Dspy: 将声明性语言模型调用编译为自我改进的管道. arXiv 预印本 arXiv:2310.03714.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-24="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-24="0,0"><div style="height: auto;"><div><div><div>Kumar, S., Jain, N., Arora, R., and Nafis, M. T. (2023). Understanding agi: A comprehensive review of theory and application in artificial general intelligence. Available at SSRN 4957203.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Kumar, S., Jain, N., Arora, R., 和 Nafis, M. T. (2023). 理解 AGI：人工通用智能理论与应用的全面回顾. 可在 SSRN 4957203 获取.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-24="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-24="0,0"><div style="height: auto;"><div><div><div>Landau, B. and Jackendoff, R. (1993). Whence and whither in spatial language and spatial cognition? Behavioral and Brain sciences, 16(2):255- 265.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Landau, B. 和 Jackendoff, R. (1993). 空间语言和空间认知的来源与去向？行为与脑科学, 16(2):255-265.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-24="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-24="0,0"><div style="height: auto;"><div><div><div>Lee, J. H., Sioutis, M., Ahrens, K., Alirezaie, M., Kerzel, M., and Wermter, S. (2023). Neuro-symbolic spatio-temporal reasoning. In Compendium of Neurosymbolic Artificial Intelligence, pages 410-429. IOS Press.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Lee, J. H., Sioutis, M., Ahrens, K., Alirezaie, M., Kerzel, M., 和 Wermter, S. (2023). 神经符号时空推理. 收录于《神经符号人工智能汇编》，第 410-429 页. IOS 出版社.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-24="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-24="0,0"><div style="height: auto;"><div><div><div>Li, F., Hogg, D. C., and Cohn, A. G. (2024a). Advancing spatial reasoning in large language models: An in-depth evaluation and enhancement using the stepgame benchmark. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 18500-18507.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Li, F., Hogg, D. C., 和 Cohn, A. G. (2024a). 在大型语言模型中推进空间推理：使用 stepgame 基准的深入评估与增强. 收录于 AAAI 人工智能会议论文集，第 38 卷，第 18500-18507 页.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-24="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-24="0,0"><div style="height: auto;"><div><div><div>Li, F., Hogg, D. C., and Cohn, A. G. (2024b). Reframing spatial reasoning evaluation in language models: A real-world simulation benchmark for qualitative reasoning. arXiv preprint arXiv:2405.15064.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Li, F., Hogg, D. C., 和 Cohn, A. G. (2024b). 在语言模型中重新框定空间推理评估：定性推理的现实世界模拟基准. arXiv 预印本 arXiv:2405.15064.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-24="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-24="0,0"><div style="height: auto;"><div><div><div>Liu, W., Sanjiang, L., and Jochen, R. (2009). Combining rcc-8 with qualitative direction calculi: Algorithms and complexity. In Twenty-First International Joint Conference on Artificial Intelligence.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Liu, W., Sanjiang, L., 和 Jochen, R. (2009). 将 rcc-8 与定性方向计算结合：算法与复杂性。发表于第二十一届国际人工智能联合会议。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-24="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-24="0,0"><div style="height: auto;"><div><div><div>Lu, Z., Afridi, I., Kang, H. J., Ruchkin, I., and Zheng, X. (2024). Surveying neuro-symbolic approaches for reliable artificial intelligence of things. Journal of Reliable Intelligent Environments, 10(3):257-279.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Lu, Z., Afridi, I., Kang, H. J., Ruchkin, I., 和 Zheng, X. (2024). 调查可靠的物联网人工智能的神经符号方法。《可靠智能环境杂志》，10(3):257-279。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-24="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-24="0,0"><div style="height: auto;"><div><div><div>Mao, J., Gan, C., Kohli, P., Tenenbaum, J. B., and Wu, J. (2019a). The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. arXiv preprint arXiv:1904.12584.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Mao, J., Gan, C., Kohli, P., Tenenbaum, J. B., 和 Wu, J. (2019a). 神经符号概念学习者：从自然监督中解释场景、词汇和句子。arXiv 预印本 arXiv:1904.12584。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-24="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-d9490ad3-812f-40cb-97c7-ce4927e2aa03" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-24="0,0"><div style="height: auto;"><div><div><div>Mao, J., Gan, C., Kohli, P., Tenenbaum, J. B., and Wu, J. (2019b). The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. arXiv preprint arXiv:1904.12584.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Mao, J., Gan, C., Kohli, P., Tenenbaum, J. B., 和 Wu, J. (2019b). 神经符号概念学习者：从自然监督中解释场景、词汇和句子。arXiv 预印本 arXiv:1904.12584。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-25="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-25="0,0"><div style="height: auto;"><div><div><div>Mirzaee, R. and Kordjamshidi, P. (2022). Transfer learning with synthetic corpora for spatial role labeling and reasoning. arXiv preprint arXiv:2210.16952.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Mirzaee, R. 和 Kordjamshidi, P. (2022). 使用合成语料库进行空间角色标注和推理的迁移学习。arXiv 预印本 arXiv:2210.16952。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-25="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-25="0,0"><div style="height: auto;"><div><div><div>Mirzaee, R. and Kordjamshidi, P. (2023). Disentangling extraction and reasoning in multi-hop spatial reasoning. arXiv preprint arXiv:2310.16731.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Mirzaee, R. 和 Kordjamshidi, P. (2023). 在多跳空间推理中解开提取与推理的关系。arXiv 预印本 arXiv:2310.16731。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-25="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-25="0,0"><div style="height: auto;"><div><div><div>Pan, L., Albalak, A., Wang, X., and Wang, W. Y. (2023). Logic-lm: Empowering large language models with symbolic solvers for faithful logical reasoning. arXiv preprint arXiv:2305.12295.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Pan, L., Albalak, A., Wang, X., 和 Wang, W. Y. (2023). Logic-lm：通过符号求解器增强大型语言模型以实现忠实的逻辑推理。arXiv 预印本 arXiv:2305.12295。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-25="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-25="0,0"><div style="height: auto;"><div><div><div>Parisi, A., Zhao, Y., and Fiedel, N. (2022). Talm: Tool augmented language models. arXiv preprint arXiv:2205.12255.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Parisi, A., Zhao, Y., 和 Fiedel, N. (2022). Talm: 工具增强的语言模型. arXiv 预印本 arXiv:2205.12255.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-25="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-25="0,0"><div style="height: auto;"><div><div><div>Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., et al. (2021). Learning transferable visual models from natural language supervision. In International Conference on Machine Learning, pages 8748-8763. PMLR.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., 等. (2021). 从自然语言监督中学习可转移的视觉模型. 在国际机器学习会议上, 页码 8748-8763. PMLR.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-25="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-25="0,0"><div style="height: auto;"><div><div><div>Riegel, R., Gray, A., Luus, F., Khan, N., Makondo, N., Akhalwaya, I. Y., Qian, H., Fagin, R., Barahona, F., Sharma, U., et al. (2020). Logical neural networks. arXiv preprint arXiv:2006.13155.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Riegel, R., Gray, A., Luus, F., Khan, N., Makondo, N., Akhalwaya, I. Y., Qian, H., Fagin, R., Barahona, F., Sharma, U., 等. (2020). 逻辑神经网络. arXiv 预印本 arXiv:2006.13155.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-25="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-25="0,0"><div style="height: auto;"><div><div><div>Rozanova, J., Ferreira, D., Dubba, K., Cheng, W., Zhang, D., and Freitas, A. (2021). Grounding natural language instructions: Can large language models capture spatial information? arXiv preprint arXiv:2109.08634.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Rozanova, J., Ferreira, D., Dubba, K., Cheng, W., Zhang, D., 和 Freitas, A. (2021). 基于自然语言指令的基础：大型语言模型能否捕捉空间信息？arXiv 预印本 arXiv:2109.08634.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-25="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-25="0,0"><div style="height: auto;"><div><div><div>Santoro, A., Faulkner, R., Raposo, D., Rae, J., Chrzanowski, M., Weber, T., Wierstra, D., Vinyals, O., Pascanu, R., and Lillicrap, T. (2018). Relational recurrent neural networks. Advances in neural information processing systems, 31.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Santoro, A., Faulkner, R., Raposo, D., Rae, J., Chrzanowski, M., Weber, T., Wierstra, D., Vinyals, O., Pascanu, R., 和 Lillicrap, T. (2018). 关系递归神经网络. 神经信息处理系统进展, 31.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-25="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-25="0,0"><div style="height: auto;"><div><div><div>Schick, T. and Schütze, H. (2021). True few-shot learning with prompts - a real-world perspective. Transactions of the Association for Computational Linguistics, 10:716-731.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Schick, T. 和 Schütze, H. (2021). 真实的少样本学习与提示 - 现实世界的视角. 计算语言学协会会刊, 10:716-731.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-25="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-25="0,0"><div style="height: auto;"><div><div><div>Serafini, L. and Garcez, A. d. (2016). Logic tensor networks: Deep learning and logical reasoning from data and knowledge. arXiv preprint arXiv:1606.04422.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Serafini, L. 和 Garcez, A. d. (2016). 逻辑张量网络：从数据和知识中进行深度学习和逻辑推理。arXiv 预印本 arXiv:1606.04422。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-25="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-d3073410-c0c9-4e0f-ace5-d520b48e1a78" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-25="0,0"><div style="height: auto;"><div><div><div>Sharma, M. (2023). Exploring and improving the spatial reasoning abilities of large language models. arXiv preprint arXiv:2312.01054.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Sharma, M. (2023). 探索和提升大型语言模型的空间推理能力。arXiv 预印本 arXiv:2312.01054。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-26="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-26="0,0"><div style="height: auto;"><div><div><div>Shi, Z., Zhang, Q., and Lipani, A. (2022). Stepgame: A new benchmark for robust multi-hop spatial reasoning in texts. In Proceedings of the AAAI conference on artificial intelligence, volume 36, pages 11321-11329.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Shi, Z., Zhang, Q., 和 Lipani, A. (2022). Stepgame：一个新的文本中稳健多跳空间推理基准。在人工智能协会会议论文集，卷 36，页 11321-11329。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-26="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-26="0,0"><div style="height: auto;"><div><div><div>Smith, S., Patwary, M., Norick, B., LeGresley, P., Rajbhandari, S., Casper, J., Liu, Z., Prabhumoye, S., Zerveas, G., Korthikanti, V., et al. (2022). Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model. arXiv preprint arXiv:2201.11990.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Smith, S., Patwary, M., Norick, B., LeGresley, P., Rajbhandari, S., Casper, J., Liu, Z., Prabhumoye, S., Zerveas, G., Korthikanti, V., 等 (2022). 使用 DeepSpeed 和 Megatron 训练 Megatron-Turing NLG 530B，一个大规模生成语言模型。arXiv 预印本 arXiv:2201.11990。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-26="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-26="0,0"><div style="height: auto;"><div><div><div>Tenbrink, T. and Kuhn, W. (2011). A model of spatial reference frames in language. In Spatial Information Theory: 10th International Conference, COSIT 2011, Belfast, ME, USA, September 12-16, 2011. Proceedings 10, pages 371-390. Springer.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Tenbrink, T. 和 Kuhn, W. (2011). 语言中空间参考框架的模型。在空间信息理论：第十届国际会议，COSIT 2011，贝尔法斯特，ME，美国，2011年9月12-16日。论文集 10，页 371-390。施普林格。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-26="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-26="0,0"><div style="height: auto;"><div><div><div>Wang, J., Liu, Z., Zhao, L., Wu, Z., Ma, C., Yu, S., Dai, H., Yang, Q., Liu, Y.-H., Zhang, S., Shi, E., Pan, Y., Zhang, T., Zhu, D., Li, X., Jiang, X., Ge, B., Yuan, Y., Shen, D., Liu, T., and Zhang, S. (2023). Review of large vision models and visual prompt engineering. ArXiv, abs/2307.00855.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Wang, J., Liu, Z., Zhao, L., Wu, Z., Ma, C., Yu, S., Dai, H., Yang, Q., Liu, Y.-H., Zhang, S., Shi, E., Pan, Y., Zhang, T., Zhu, D., Li, X., Jiang, X., Ge, B., Yuan, Y., Shen, D., Liu, T., 和 Zhang, S. (2023). 大型视觉模型和视觉提示工程的综述. ArXiv, abs/2307.00855.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-26="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-26="0,0"><div style="height: auto;"><div><div><div>Wang, W., Yang, Y., and Wu, F. (2022a). Towards data-and knowledge-driven artificial intelligence: A survey on neuro-symbolic computing. arXiv preprint arXiv:2210.15889.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Wang, W., Yang, Y., 和 Wu, F. (2022a). 朝着数据和知识驱动的人工智能：关于神经符号计算的调查. arXiv 预印本 arXiv:2210.15889.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-26="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-26="0,0"><div style="height: auto;"><div><div><div>Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and Zhou, D. (2022b). Self-consistency improves chain of thought reasoning in language models. ArXiv, abs/2203.11171.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., 和 Zhou, D. (2022b). 自我一致性改善语言模型中的思维链推理. ArXiv, abs/2203.11171.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-26="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-26="0,0"><div style="height: auto;"><div><div><div>Weber, L., Minervini, P., Münchmeyer, J., Leser, U., and Rocktäschel, T. (2019). Nlprolog: Reasoning with weak unification for question answering in natural language. arXiv preprint arXiv:1906.06187.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Weber, L., Minervini, P., Münchmeyer, J., Leser, U., 和 Rocktäschel, T. (2019). Nlprolog：使用弱统一进行自然语言问答推理. arXiv 预印本 arXiv:1906.06187.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-26="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-26="0,0"><div style="height: auto;"><div><div><div>Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Xia, F., Le, Q., and Zhou, D. (2022). Chain of thought prompting elicits reasoning in large language models. ArXiv, abs/2201.11903.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Xia, F., Le, Q., 和 Zhou, D. (2022). 思维链提示在大型语言模型中引发推理. ArXiv, abs/2201.11903.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-26="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-26="0,0"><div style="height: auto;"><div><div><div>Weston, J. E. (2016). Dialog-based language learning. Advances in Neural Information Processing Systems, 29.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Weston, J. E. (2016). 基于对话的语言学习. 神经信息处理系统进展, 29.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-26="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-26="0,0"><div style="height: auto;"><div><div><div>Yang, S., Gribovskaya, E., Kassner, N., Geva, M., and Riedel, S. (2024). Do large language models latently perform multi-hop reasoning? arXiv preprint arXiv:2402.16837.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Yang, S., Gribovskaya, E., Kassner, N., Geva, M., 和 Riedel, S. (2024). 大型语言模型是否在潜在上执行多跳推理？arXiv 预印本 arXiv:2402.16837.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-26="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-ffda205f-8a26-4ad0-81de-e69ff3971391" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-26="0,0"><div style="height: auto;"><div><div><div>Yang, Z., Ishay, A., and Lee, J. (2023). Coupling large language models with logic programming for robust and general reasoning from text. arXiv preprint arXiv:2307.07696.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Yang, Z., Ishay, A., 和 Lee, J. (2023). 将大型语言模型与逻辑编程结合，以实现从文本中进行稳健和通用的推理。arXiv 预印本 arXiv:2307.07696.</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="28" id="mark-455880ef-c279-43e5-9ac3-a723152adcf9" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-27="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="28" id="mark-455880ef-c279-43e5-9ac3-a723152adcf9" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-27="0,0"><div style="height: auto;"><div><div><div>Yi, K., Wu, J., Gan, C., Torralba, A., Kohli, P., and Tenenbaum, J. (2018). Neural-symbolic vqa: Disentangling reasoning from vision and language understanding. Advances in neural information processing systems, 31.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Yi, K., Wu, J., Gan, C., Torralba, A., Kohli, P., 和 Tenenbaum, J. (2018). 神经符号视觉问答：将推理与视觉和语言理解分离。神经信息处理系统进展, 31.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="28" id="mark-455880ef-c279-43e5-9ac3-a723152adcf9" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-27="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="28" id="mark-455880ef-c279-43e5-9ac3-a723152adcf9" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-27="0,0"><div style="height: auto;"><div><div><div>Yu, F., Zhang, H., Tiwari, P., and Wang, B. (2024). Natural language reasoning,a survey. ACM Computing Surveys, 56(12):1-39.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Yu, F., Zhang, H., Tiwari, P., 和 Wang, B. (2024). 自然语言推理：一项调查。ACM 计算机调查, 56(12):1-39.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="28" id="mark-455880ef-c279-43e5-9ac3-a723152adcf9" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-27="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="28" id="mark-455880ef-c279-43e5-9ac3-a723152adcf9" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-27="0,0"><div style="height: auto;"><div><div><div>Zellers, R., Holtzman, A., Peters, M., Mottaghi, R., Kembhavi, A., Farhadi, A., and Choi, Y. (2021). Piglet: Language grounding through neuro-symbolic interaction in a 3d world. arXiv preprint arXiv:2106.00188.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Zellers, R., Holtzman, A., Peters, M., Mottaghi, R., Kembhavi, A., Farhadi, A., 和 Choi, Y. (2021). Piglet：通过神经符号交互在三维世界中实现语言基础。arXiv 预印本 arXiv:2106.00188.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="28" id="mark-455880ef-c279-43e5-9ac3-a723152adcf9" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-27="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="28" id="mark-455880ef-c279-43e5-9ac3-a723152adcf9" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-27="0,0"><div style="height: auto;"><div><div><div>Zhou, D., Scharli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans, D., Bousquet, O., Le, Q., and Chi, E. (2022). Least-to-most prompting enables complex reasoning in large language models. ArXiv, abs/2205.10625.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Zhou, D., Scharli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans, D., Bousquet, O., Le, Q., 和 Chi, E. (2022). 从最少到最多的提示使大型语言模型能够进行复杂推理。ArXiv, abs/2205.10625.</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="28" id="mark-455880ef-c279-43e5-9ac3-a723152adcf9" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-27="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="28" id="mark-455880ef-c279-43e5-9ac3-a723152adcf9" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-27="0,0"><div style="height: auto;"><div><div><div>Zhu, S. and Sun, S. (2024). Exploring knowledge graph-based neural-symbolic system from application perspective. arXiv preprint arXiv:2405.03524.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">Zhu, S. 和 Sun, S. (2024). 从应用角度探索基于知识图谱的神经-符号系统. arXiv 预印本 arXiv:2405.03524.</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-28="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-28="0,0"><div style="height: auto;"><h2><div><div>Appendices<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">附录</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-28="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-28="0,0"><div style="height: auto;"><h2><div><div>Appendix A: Neural-symbolic approaches<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">附录 A: 神经-符号方法</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-28="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-28="0,0"><div style="height: auto;"><div><div><div>To provide a more practical framework, we can consolidate these approaches into four fundamental integration architectures, each capturing a distinct way of combining neural and symbolic capabilities:<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">为了提供一个更实用的框架，我们可以将这些方法整合为四种基本的集成架构，每种架构捕捉到神经能力和符号能力结合的不同方式：</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-28="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-28="0,0"><div style="height: auto;"><div><div><div>a) Neural/ symbolic Sequential Integration:<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">a) 神经/符号顺序集成：</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-28="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-28="0,0"><div style="height: auto;"><div><div><div>In this pipeline architecture, neural networks first process raw input to generate symbolic representations, which are then processed by symbolic reasoners for logical inference. This separation also allows for better interpretability and generalization compared to end-to-end neural approaches. For instance, the Neural-Symbolic VQA system (Yi et al., 2018) demonstrates the effectiveness of sequential integration by first using neural networks to parse visual scenes into structured scene representations, followed by symbolic program execution for reasoning about the scene. Weber et al. (2019) developed NLProlog, which exemplifies the integration of neural networks for processing natural language and Prolog symbolic reasoning for multi-step inference. IBM's neural-vector-symbolic architecture (NVSA) (Hersche et al., 2023) uses an NN as the frontend for perception and semantic parsing, and a symbolic reasoner as the backend for probabilistic abductive reasoning.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在这个管道架构中，神经网络首先处理原始输入以生成符号表示，然后由符号推理器进行逻辑推理。这种分离也使得与端到端神经方法相比，具有更好的可解释性和泛化能力。例如，神经-符号视觉问答系统（Yi et al., 2018）通过首先使用神经网络将视觉场景解析为结构化场景表示，然后进行符号程序执行以推理场景，展示了顺序集成的有效性。Weber 等人（2019）开发的 NLProlog，展示了神经网络处理自然语言与 Prolog 符号推理进行多步推理的集成。IBM 的神经-向量-符号架构（NVSA）（Hersche et al., 2023）使用神经网络作为感知和语义解析的前端，符号推理器作为概率性溯因推理的后端。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-28="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-28="0,0"><div style="height: auto;"><div><div><div>b) Neural-symbolic Iterative Integration: It represents a more sophisticated approach where neural and symbolic components interact in multiple cycles, with each component refining its output based on feedback from the other. This architecture is particularly influenced by cognitive dual-process theories (Evans and Stanovich, 2013; Bellini-Leite, 2022). which posit that human reasoning often involves both intuitive (neural) and analytical (symbolic) processes. The neural-Symbolic Concept Learner (Mao et al., 2019b) exemplifies this integration, showcasing the effectiveness of feedback loops in enhancing reasoning capabilities.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">b) 神经-符号迭代集成：这代表了一种更复杂的方法，其中神经和符号组件在多个循环中相互作用，每个组件根据来自另一个组件的反馈来优化其输出。这种架构特别受到认知双过程理论的影响（Evans 和 Stanovich, 2013; Bellini-Leite, 2022），该理论认为人类推理通常涉及直觉（神经）和分析（符号）过程。神经-符号概念学习器（Mao et al., 2019b）展示了这种集成，展示了反馈循环在增强推理能力方面的有效性。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-28="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-28="0,0"><div style="height: auto;"><div><div><div>c) Symbolic Embedded NN architecture: This approach incorporates symbolic rules within neural network structures for enhancing the model interpretability and simultaneous neural learning and symbolic reasoning. It often involves mapping symbolic logic rules onto embeddings that serve as soft constraints or regularizers on the NN's loss function. For instance, logical NNs (Riegel et al., 2020) encode knowledge or domain expertise as symbolic rules (first-order logic or fuzzy logic) that act as constraints on the NN output. Logical tensor networks (LTNs) (Serafini and Garcez, 2016), for instance, use logical formulas to define constraints on the tensor representations, which has proven successful in knowledge graph completion tasks.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">c) 符号嵌入神经网络架构：该方法在神经网络结构中融入符号规则，以增强模型的可解释性，并实现神经学习与符号推理的同时进行。它通常涉及将符号逻辑规则映射到嵌入上，这些嵌入作为神经网络损失函数的软约束或正则化器。例如，逻辑神经网络（Riegel et al., 2020）将知识或领域专业知识编码为符号规则（第一阶逻辑或模糊逻辑），这些规则作为神经网络输出的约束。逻辑张量网络（LTNs）（Serafini 和 Garcez, 2016）使用逻辑公式来定义对张量表示的约束，这在知识图谱补全任务中取得了成功。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-28="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="29" id="mark-9524358b-efaa-4018-b3b8-e34891fdb2fc" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-28="0,0"><div style="height: auto;"><div><div><div>d) LLM+Tools: The emergence of Large Language Models (LLMs) has given rise to a new neural-symbolic architecture pattern that leverages language models as neural reasoning engines while integrating them with external symbolic tools, APIs, self-defined functions and expert models. This approach represents a significant step forward in combining LLMs' powerful language processing abilities with specialized symbolic reasoning tools, broadening the scope of tasks LLMs can handle. Tool Augmented Language Models (TALM) combine LLMs with non-differentiable tools, demonstrating improved performance on knowledge-heavy and reasoning tasks (Parisi et al., 2022). The LLMs As Tool Makers (LATM) framework introduces a closed-loop system where LLMs create and use their own reusable tools, offering a cost-effective solution for complex reasoning tasks (Cai et al., 2023).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">d) LLM+工具：大型语言模型（LLMs）的出现催生了一种新的神经-符号架构模式，该模式利用语言模型作为神经推理引擎，同时将其与外部符号工具、API、自定义函数和专家模型集成。这种方法在将LLMs强大的语言处理能力与专业的符号推理工具结合方面迈出了重要一步，拓宽了LLMs可以处理的任务范围。工具增强语言模型（TALM）将LLMs与不可微分的工具结合，展示了在知识密集型和推理任务上的改进性能（Parisi et al., 2022）。LLMs作为工具制造者（LATM）框架引入了一个闭环系统，其中LLMs创建并使用自己的可重用工具，为复杂推理任务提供了一种具有成本效益的解决方案（Cai et al., 2023）。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="30" id="mark-383a5eef-004a-47fa-b571-e01715cbf0b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-29="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="30" id="mark-383a5eef-004a-47fa-b571-e01715cbf0b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-29="0,0"><div style="height: auto;"><div><div><div>In the context of spatial reasoning tasks, Cohn (2023) explored integrating LLMs with established QSR calculi, evaluating ChatGPT-4's capabilities in RCC-8 reasoning, while Bhandari et al. (2023) investigated LLMs' geospatial knowledge and reasoning abilities. Alirezaie et al. (2019) proposed a semantic referee framework that uses ontological reasoning to improve geospatial semantic segmentation in satellite imagery. Zellers et al. (2021) introduced PIGLeT, a system that grounds language understanding in a 3D world, combining LLM capabilities with symbolic reasoning about physical interactions.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在空间推理任务的背景下，Cohn（2023）探索了将大型语言模型（LLMs）与已建立的定性空间关系（QSR）计算结合的可能性，评估了ChatGPT-4在RCC-8推理中的能力，而Bhandari等人（2023）则研究了LLMs的地理空间知识和推理能力。Alirezaie等人（2019）提出了一种语义裁判框架，该框架利用本体推理来改善卫星图像中的地理空间语义分割。Zellers等人（2021）介绍了PIGLeT，一个将语言理解与三维世界结合的系统，结合了LLM的能力与关于物理交互的符号推理。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="30" id="mark-383a5eef-004a-47fa-b571-e01715cbf0b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-29="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="30" id="mark-383a5eef-004a-47fa-b571-e01715cbf0b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-29="0,0"><div style="height: auto;"><div><div><div>Despite these advances, challenges remain in integrating neural and symbolic components efficiently. Maintaining the speed and adaptability of LLMs while scaling hybrid systems to address real-world complexities is an active research area, as noted by Besold et al. (2021). Striking a balance between the general capabilities of LLMs and the rule-based precision of symbolic systems is essential to create effective hybrid models. Additionally, addressing uncertain or incomplete information by leveraging both neural and symbolic strengths remains a crucial focus within the field.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">尽管取得了这些进展，但在有效整合神经和符号组件方面仍然存在挑战。正如Besold等人（2021）所指出的，保持LLMs的速度和适应性，同时扩展混合系统以应对现实世界的复杂性，是一个活跃的研究领域。在LLMs的通用能力与符号系统的基于规则的精确性之间取得平衡，对于创建有效的混合模型至关重要。此外，通过利用神经和符号的优势来处理不确定或不完整的信息，仍然是该领域的一个关键关注点。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="30" id="mark-383a5eef-004a-47fa-b571-e01715cbf0b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-29="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="30" id="mark-383a5eef-004a-47fa-b571-e01715cbf0b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-29="0,0"><div style="height: auto;"><h2><div><div>B: Test dataset samples<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">B: 测试数据集样本</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="30" id="mark-383a5eef-004a-47fa-b571-e01715cbf0b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-29="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="30" id="mark-383a5eef-004a-47fa-b571-e01715cbf0b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-29="0,0"><div style="height: auto;"><h2><div><div>B1: Examples in StepGame<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">B1: StepGame中的示例</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="30" id="mark-383a5eef-004a-47fa-b571-e01715cbf0b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-29="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="30" id="mark-383a5eef-004a-47fa-b571-e01715cbf0b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-29="0,0"><div style="height: auto;"><div><div><div>StepGame, developed by Shi et al. (2022), builds upon the foundational concepts of the bAbI dataset (Weston, 2016) to create a benchmark specifically designed for robust multi-hop spatial reasoning. This innovative dataset employs a grid-based system that introduces increased complexity when testing the models' spatial reasoning abilities. StepGame expands the range of directional spatial relations to include eight distinct categories: top (north), down (south), left (west), right (east), top-left (north-west), top-right (north-east), down-left (south-west), and down-right (south-east). Each relation is defined by unique angles and distances, allowing for comprehensive visual representation on a grid. Additionally, the dataset incorporates an "overlap" relation to address scenarios where objects occupy the same location.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">StepGame，由Shi等人（2022）开发，基于bAbI数据集（Weston，2016）的基础概念，创建了一个专门为强健的多跳空间推理设计的基准。这一创新的数据集采用基于网格的系统，在测试模型的空间推理能力时引入了更高的复杂性。StepGame扩展了方向空间关系的范围，包括八个不同的类别：上（北）、下（南）、左（西）、右（东）、左上（西北）、右上（东北）、左下（西南）和右下（东南）。每个关系由独特的角度和距离定义，允许在网格上进行全面的视觉表示。此外，该数据集还包含“重叠”关系，以解决对象占据同一位置的场景。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><div><div><div>The following are examples from StepGame with reasoning hop of 5 and 10 are shown as follows.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">以下是来自StepGame的示例，推理跳数为5和10，如下所示。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><div><div><div>Example 1<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">示例1</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><div><div><div>Story:<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">故事：</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li>A is below <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="700" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c46"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">F</mi></mrow></math></mjx-assistive-mml></mjx-container> with a small gap between them.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>A在<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="701" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c46"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">F</mi></mrow></math></mjx-assistive-mml></mjx-container>的下方，二者之间有一个小间隙。</li></ul></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="702" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c45"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">E</mi></mrow></math></mjx-assistive-mml></mjx-container> is to the right and above <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="703" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c46"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">F</mi></mrow></math></mjx-assistive-mml></mjx-container> at an angle of about 45 degrees.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="704" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c45"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">E</mi></mrow></math></mjx-assistive-mml></mjx-container>在<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="705" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c46"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">F</mi></mrow></math></mjx-assistive-mml></mjx-container>的右上方，角度约为45度。</li></ul></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><div><ul><li>A is sitting at the 3:00 position to W.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>A位于W的3:00位置。</li></ul></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><div><ul><li>W presents lower left to V.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>W位于V的左下方。</li></ul></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="706" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4F"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">O</mi></mrow></math></mjx-assistive-mml></mjx-container> is on the same horizontal plane directly left to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="707" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c56"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">V</mi></mrow></math></mjx-assistive-mml></mjx-container> .</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="708" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4F"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">O</mi></mrow></math></mjx-assistive-mml></mjx-container>与<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="709" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c56"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">V</mi></mrow></math></mjx-assistive-mml></mjx-container>在同一水平面上，直接左侧。</li></ul></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li>G presents lower left to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="710" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4F"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">O</mi></mrow></math></mjx-assistive-mml></mjx-container> .</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li>G位于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="711" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4F"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">O</mi></mrow></math></mjx-assistive-mml></mjx-container>的左下方。</li></ul></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>Question: What is the relation of agent <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="712" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c56"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">V</mi></mrow></math></mjx-assistive-mml></mjx-container> to agent <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="713" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c41"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">A</mi></mrow></math></mjx-assistive-mml></mjx-container> ? Answer: above Example 2<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">问题：代理<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="714" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c56"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">V</mi></mrow></math></mjx-assistive-mml></mjx-container>与代理<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="715" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c41"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">A</mi></mrow></math></mjx-assistive-mml></mjx-container>的关系是什么？答案：在上方 示例2</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><div><div><div>Story:<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">故事：</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="716" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c48"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">H</mi></mrow></math></mjx-assistive-mml></mjx-container> is diagonally left and below <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="717" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c58"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">X</mi></mrow></math></mjx-assistive-mml></mjx-container> .</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="718" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c48"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">H</mi></mrow></math></mjx-assistive-mml></mjx-container> 在 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="719" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c58"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">X</mi></mrow></math></mjx-assistive-mml></mjx-container> 的左下方对角线位置。</li></ul></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="720" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c47"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">G</mi></mrow></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="721" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c56"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">V</mi></mrow></math></mjx-assistive-mml></mjx-container> are in a vertical line with <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="722" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c47"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">G</mi></mrow></math></mjx-assistive-mml></mjx-container> on top.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="723" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c47"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">G</mi></mrow></math></mjx-assistive-mml></mjx-container> 和 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="724" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c56"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">V</mi></mrow></math></mjx-assistive-mml></mjx-container> 在一条垂直线上， <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="725" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c47"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">G</mi></mrow></math></mjx-assistive-mml></mjx-container> 在上方。</li></ul></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="726" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c47"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">G</mi></mrow></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="727" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c50"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">P</mi></mrow></math></mjx-assistive-mml></mjx-container> are vertical and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="728" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c47"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">G</mi></mrow></math></mjx-assistive-mml></mjx-container> is below <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="729" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c50"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">P</mi></mrow></math></mjx-assistive-mml></mjx-container> .</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="730" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c47"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">G</mi></mrow></math></mjx-assistive-mml></mjx-container> 和 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="731" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c50"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">P</mi></mrow></math></mjx-assistive-mml></mjx-container> 是垂直的， <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="732" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c47"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">G</mi></mrow></math></mjx-assistive-mml></mjx-container> 在 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="733" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c50"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">P</mi></mrow></math></mjx-assistive-mml></mjx-container> 的下方。</li></ul></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="734" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c43"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">C</mi></mrow></math></mjx-assistive-mml></mjx-container> is placed in the left direction of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="735" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c42"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">B</mi></mrow></math></mjx-assistive-mml></mjx-container> .</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="736" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c43"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">C</mi></mrow></math></mjx-assistive-mml></mjx-container> 位于 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="737" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c42"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">B</mi></mrow></math></mjx-assistive-mml></mjx-container> 的左侧。</li></ul></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="738" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c5A"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">Z</mi></mrow></math></mjx-assistive-mml></mjx-container> is at the 6 o’clock position relative to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="739" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c42"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">B</mi></mrow></math></mjx-assistive-mml></mjx-container> .</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="740" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c5A"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">Z</mi></mrow></math></mjx-assistive-mml></mjx-container> 在 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="741" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c42"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">B</mi></mrow></math></mjx-assistive-mml></mjx-container> 的 6 点钟位置。</li></ul></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="742" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c50"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">P</mi></mrow></math></mjx-assistive-mml></mjx-container> is diagonally above <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="743" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4D"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">M</mi></mrow></math></mjx-assistive-mml></mjx-container> to the right at a 45 degree.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="744" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c50"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">P</mi></mrow></math></mjx-assistive-mml></mjx-container> 在 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="745" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4D"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">M</mi></mrow></math></mjx-assistive-mml></mjx-container> 的右上方对角线位置，成 45 度角。</li></ul></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="746" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4D"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">M</mi></mrow></math></mjx-assistive-mml></mjx-container> is placed in the left direction of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="747" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c43"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">C</mi></mrow></math></mjx-assistive-mml></mjx-container> .</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="748" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4D"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">M</mi></mrow></math></mjx-assistive-mml></mjx-container> 位于 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="749" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c43"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">C</mi></mrow></math></mjx-assistive-mml></mjx-container> 的左侧。</li></ul></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="750" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c5A"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">Z</mi></mrow></math></mjx-assistive-mml></mjx-container> is above and to the right of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="751" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c54"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">T</mi></mrow></math></mjx-assistive-mml></mjx-container> .</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="752" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c5A"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">Z</mi></mrow></math></mjx-assistive-mml></mjx-container> 在 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="753" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c54"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">T</mi></mrow></math></mjx-assistive-mml></mjx-container> 的上方和右侧。</li></ul></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="754" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c44"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">D</mi></mrow></math></mjx-assistive-mml></mjx-container> is over there and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="755" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c48"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">H</mi></mrow></math></mjx-assistive-mml></mjx-container> is on the top of it.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="756" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c44"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">D</mi></mrow></math></mjx-assistive-mml></mjx-container> 在那里， <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="757" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c48"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">H</mi></mrow></math></mjx-assistive-mml></mjx-container> 在它的顶部。</li></ul></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-30="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="31" id="mark-af54bbca-7f96-4813-97a3-da85accca194" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-30="0,0"><div style="height: auto;"><span style="display: inline;"><div><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="758" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c54"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">T</mi></mrow></math></mjx-assistive-mml></mjx-container> is there and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="759" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c44"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">D</mi></mrow></math></mjx-assistive-mml></mjx-container> is at the 5 position of a clock face.</li></ul><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="760" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c54"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">T</mi></mrow></math></mjx-assistive-mml></mjx-container> 在那里， <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="761" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c44"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">D</mi></mrow></math></mjx-assistive-mml></mjx-container> 在时钟面上的 5 点位置。</li></ul></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-31="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><!-- Media --></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-31="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-31="0,0"><div style="height: auto;"><div><div class="text-center"><img class="max-w-[100%]" draggable="false" src="https://cdn.noedgeai.com/01937d54-d496-7e49-afc6-565908ddfdd3_31.jpg?x=382&amp;y=359&amp;w=887&amp;h=375"></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-31="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-31="0,0"><div style="height: auto;"><div><div><div>Figure 3: An example in the StepGame, adopted by Li et al. (2024b).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">图3：Li等人（2024b）采用的StepGame中的一个示例。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-31="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><!-- Media --></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-31="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-31="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div>Question: What is the relation of the agent <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="762" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c43"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">C</mi></mrow></math></mjx-assistive-mml></mjx-container> to the agent <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="763" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c48"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">H</mi></mrow></math></mjx-assistive-mml></mjx-container> ? Answer: upper-left<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">问题：代理 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="764" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c43"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">C</mi></mrow></math></mjx-assistive-mml></mjx-container> 与代理 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="765" style="font-size: 122.8%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c48"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">H</mi></mrow></math></mjx-assistive-mml></mjx-container> 的关系是什么？答案：左上</div></div></div></div></span></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-31="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-31="0,0"><div style="height: auto;"><div><div><div>The two examples could be visualized by Fig. 3.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">这两个示例可以通过图3进行可视化。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-31="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-31="0,0"><div style="height: auto;"><div><div><div>Although the dataset introduces a range of directional spatial relations and multi-hop reasoning challenges, the single Finding Relation question type may not fully reflect the intricacies of real-world spatial reasoning. Research by Li et al. (2024b) indicates that LLMs often struggle more with constructing object-linking chains from shuffled relations than with the spatial reasoning tasks themselves. Prior research (Yang et al., 2024; Li et al., 2024b) suggests StepGame contains template errors that can distort model performance evaluations. These errors arise from insufficient quality control during the crowdsourcing process, leading to inaccuracies in the relationship mappings used within the dataset. Such flaws can result in misleading assessments of an LLM's spatial reasoning capabilities, as they may perform better or worse if these errors were addressed.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">尽管数据集引入了一系列方向性空间关系和多跳推理挑战，但单一的查找关系问题类型可能无法充分反映现实世界空间推理的复杂性。Li等人（2024b）的研究表明，LLMs在从打乱的关系中构建对象链接链时往往比处理空间推理任务本身更为困难。先前的研究（Yang等，2024；Li等，2024b）表明，StepGame包含模板错误，这些错误可能扭曲模型性能评估。这些错误源于众包过程中的质量控制不足，导致数据集中使用的关系映射不准确。这些缺陷可能导致对LLM空间推理能力的误导性评估，因为如果解决了这些错误，模型的表现可能会更好或更差。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-31="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-31="0,0"><div style="height: auto;"><h2><div><div>B2: Samples in SparQA<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">B2：SparQA中的样本</div></div></div></h2></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-31="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-31="0,0"><div style="height: auto;"><div><div><div>As shown in Fig. 4, SparQA is built upon the NLVR (Natural Language for Visual Reasoning) images, featuring synthetically generated scenes depicting various spatial arrangements. Typically, each scenario consists of three blocks arranged either vertically or horizontally, with each block containing around four objects. Each object is characterized by attributes such as size, color, and shape. In a typical context, there are usually twelve objects distributed across three blocks, along with approximately ten explicitly defined relationships.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">如图4所示，SparQA建立在NLVR（自然语言视觉推理）图像之上，具有合成生成的场景，描绘了各种空间排列。通常，每个场景由三个块垂直或水平排列而成，每个块包含大约四个对象。每个对象的特征包括大小、颜色和形状。在典型情况下，通常有十二个对象分布在三个块中，以及大约十个明确定义的关系。</div></div></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-31="0,0"></paragraphpositioning></div></div></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="32" id="mark-118904df-fd94-48b0-adec-eff9df98b4f4" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-31="0,0"><div style="height: auto;"><div><div><div>The dataset incorporates a wider range of spatial relationships, including 3D spatial reasoning, topological relations and distance relations. For FR questions, the candidate choices include ['left', 'right', 'above', 'below', 'near to', 'far from', 'touching', 'DK'], but there are more synonym relation names involved in the context and question.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">数据集包含更广泛的空间关系，包括3D空间推理、拓扑关系和距离关系。对于FR问题，候选选择包括['左', '右', '上', '下', '靠近', '远离', '接触', '不知道']，但在上下文和问题中涉及更多同义关系名称。</div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-32="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-32="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-32="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-32="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-32="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-32="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-32="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="33" id="mark-fe4af743-7b3c-4379-a540-d5842d41ef3f" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-32="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-33="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-33="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-33="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-33="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-33="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-33="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-33="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-33="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-33="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="34" id="mark-0c2d296e-e85e-4956-a71d-969ba96ff76e" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-33="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="35" id="mark-ccfc2073-0229-4f06-8f4d-14c9cc25d335" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-34="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-35="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-35="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-35="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-35="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-35="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-35="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-35="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-35="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-35="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-35="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-35="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-35="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="36" id="mark-b8b16725-5363-4a5c-b736-ae666e249a30" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-35="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-36="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-36="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-36="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-36="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-36="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-36="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="37" id="mark-7e6b7640-e654-43b3-ace0-2d4c04f75552" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-36="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-37="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-37="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-37="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-37="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-37="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-37="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-37="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-37="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-37="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-37="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-37="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="38" id="mark-adc8f4cc-e94c-4666-8b07-e8718a526040" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-37="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-38="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-38="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-38="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-38="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-38="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-38="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-38="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-38="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="39" id="mark-9be42127-3a69-4b36-a5b7-cb36abd060cf" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-38="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-39="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="40" id="mark-479f5368-6ee1-4c68-9039-96757389d600" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="41" id="mark-6e8d5b0c-4108-441f-b3ce-68000fea9141" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-40="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="42" id="mark-9903f153-81d1-4314-a1f3-eeb63ea02da8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-41="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-42="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="43" id="mark-01774cba-b64b-43d8-ac4b-a64c6582d326" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="44" id="mark-d579e2ce-181e-4e5a-a185-0a116b29fd84" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-43="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-44="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="45" id="mark-7ebac40d-12f3-4b6e-b610-f43ae1618d2a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="46" id="mark-8cb0e10c-67fd-46cc-b3e1-75f026817cc2" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-45="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="46" id="mark-8cb0e10c-67fd-46cc-b3e1-75f026817cc2" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="46" id="mark-8cb0e10c-67fd-46cc-b3e1-75f026817cc2" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-45="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="46" id="mark-8cb0e10c-67fd-46cc-b3e1-75f026817cc2" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="46" id="mark-8cb0e10c-67fd-46cc-b3e1-75f026817cc2" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-45="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="46" id="mark-8cb0e10c-67fd-46cc-b3e1-75f026817cc2" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="46" id="mark-8cb0e10c-67fd-46cc-b3e1-75f026817cc2" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-45="0,0"><div style="height: auto;"></div></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="46" id="mark-8cb0e10c-67fd-46cc-b3e1-75f026817cc2" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"></div></div></div></div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="46" id="mark-8cb0e10c-67fd-46cc-b3e1-75f026817cc2" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-45="0,0"><div style="height: auto;"></div></div></div></div></div></div>
      </body>
    </html>
  