
    <!DOCTYPE html>
    <html lang="en">
      <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>2024-Generalized Out-of-Distribution Detection</title>
        <style>
            * {
              padding: 0;
              margin: 0;
              box-sizing: border-box;
            }
             html {
              line-height: 1.15; /* 1 */
              -webkit-text-size-adjust: 100%; /* 2 */
            }
            body {
              padding: 20px;
              margin: 0;
            }
            main {
              display: block;
            }
            h1 {
              font-size: 2em;
              margin: 0.67em 0;
            }
            hr {
              box-sizing: content-box; /* 1 */
              height: 0; /* 1 */
              overflow: visible; /* 2 */
            }
            pre {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            a {
              background-color: transparent;
            }
            abbr[title] {
              border-bottom: none; /* 1 */
              text-decoration: underline; /* 2 */
              text-decoration: underline dotted; /* 2 */
            }
            b,
            strong {
              font-weight: bolder;
            }
            code,
            kbd,
            samp {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            small {
              font-size: 80%;
            }
            sub,
            sup {
              font-size: 75%;
              line-height: 0;
              position: relative;
              vertical-align: baseline;
            }
            sub {
              bottom: -0.25em;
            }
            sup {
              top: -0.5em;
            }
            img {
              border-style: none;
            }
            button,
            input,
            optgroup,
            select,
            textarea {
              font-family: inherit; /* 1 */
              font-size: 100%; /* 1 */
              line-height: 1.15; /* 1 */
              margin: 0; /* 2 */
            }
            button,
            input { /* 1 */
              overflow: visible;
            }
            button,
            select { /* 1 */
              text-transform: none;
            }
            button,
            [type="button"],
            [type="reset"],
            [type="submit"] {
              -webkit-appearance: button;
            }
            button::-moz-focus-inner,
            [type="button"]::-moz-focus-inner,
            [type="reset"]::-moz-focus-inner,
            [type="submit"]::-moz-focus-inner {
              border-style: none;
              padding: 0;
            }
            button:-moz-focusring,
            [type="button"]:-moz-focusring,
            [type="reset"]:-moz-focusring,
            [type="submit"]:-moz-focusring {
              outline: 1px dotted ButtonText;
            }
            fieldset {
              padding: 0.35em 0.75em 0.625em;
            }
            legend {
              box-sizing: border-box; /* 1 */
              color: inherit; /* 2 */
              display: table; /* 1 */
              max-width: 100%; /* 1 */
              padding: 0; /* 3 */
              white-space: normal; /* 1 */
            }
            progress {
              vertical-align: baseline;
            }
            textarea {
              overflow: auto;
            }
            [type="checkbox"],
            [type="radio"] {
              box-sizing: border-box; /* 1 */
              padding: 0; /* 2 */
            }
            [type="number"]::-webkit-inner-spin-button,
            [type="number"]::-webkit-outer-spin-button {
              height: auto;
            }
            [type="search"] {
              -webkit-appearance: textfield; /* 1 */
              outline-offset: -2px; /* 2 */
            }
            [type="search"]::-webkit-search-decoration {
              -webkit-appearance: none;
            }
            ::-webkit-file-upload-button {
              -webkit-appearance: button; /* 1 */
              font: inherit; /* 2 */
            }
            details {
              display: block;
            }
            summary {
              display: list-item;
            }
            [hidden] {
              display: none;
            }
             table {
                border-collapse: collapse;
                width: 100%;
                margin-top: 20px;
                margin-bottom: 20px;
              }
              table thead {
                background-color: #e5e5e5;
              }
              table td {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              table th {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              h1, h2, h3, h4, h5, h6 {
                margin-bottom: 20px;
              }
              p {
                margin-top: 20px;
                text-indent: 2em;
                margin-bottom: 20px;
              }
        </style>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      </head>
      <body>
        <div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="1" id="mark-cdc80ce3-eb75-4f4b-9964-bd0a8d97cb27" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-0="0,0"><div style="height: auto;"><span style="display: inline;"><h1><div><div>Generalized Out-of-Distribution Detection: A Survey<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">广义分布外检测：综述</div></div></div></h1><div><br></div><div><div><div>Jingkang Yang <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2642" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-texatom texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c4B"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c5A"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c75"></mjx-c></mjx-mtext></mjx-texatom><mjx-script style="vertical-align: 0.421em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msup><mo>⋅</mo><msup><mrow data-mjx-texclass="ORD"><mtext>Kaiyang Zhou</mtext></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msup><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> Yixuan <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2643" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: 0.41em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">Li</mi></mrow></mrow></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msup><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> Ziwei <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2644" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c75"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: 0.41em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c25FB TEX-A"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">Liu</mi></mrow></mrow></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msup><mi>◻</mi></math></mjx-assistive-mml></mjx-container><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">杨景康 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2645" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-texatom texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c4B"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c5A"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c75"></mjx-c></mjx-mtext></mjx-texatom><mjx-script style="vertical-align: 0.421em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msup><mo>⋅</mo><msup><mrow data-mjx-texclass="ORD"><mtext>Kaiyang Zhou</mtext></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msup><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> 李逸轩 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2646" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: 0.41em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">Li</mi></mrow></mrow></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msup><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> 刘子微 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2647" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c75"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-texatom><mjx-script style="vertical-align: 0.41em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c25FB TEX-A"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">Liu</mi></mrow></mrow></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msup><mi>◻</mi></math></mjx-assistive-mml></mjx-container></div></div></div></div><div><br></div><div><div><div>Received: 27 April 2023 / Accepted: 26 April 2024 / Published online: 23 June 2024<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">收稿日期：2023年4月27日 / 录用日期：2024年4月26日 / 在线发表日期：2024年6月23日</div></div></div></div><div><br></div><div><div><div>© The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">© 作者（们），2024年独家授权给施普林格科学商业媒体有限责任公司，施普林格自然旗下一部分</div></div></div></div><div><br></div><h2><div><div>Abstract<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">摘要</div></div></div></h2><div><br></div><div><div><div>Out-of-distribution (OOD) detection is critical to ensuring the reliability and safety of machine learning systems. For instance, in autonomous driving, we would like the driving system to issue an alert and hand over the control to humans when it detects unusual scenes or objects that it has never seen during training time and cannot make a safe decision. The term, OOD detection, first emerged in 2017 and since then has received increasing attention from the research community, leading to a plethora of methods developed, ranging from classification-based to density-based to distance-based ones. Meanwhile, several other problems, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD), are closely related to OOD detection in terms of motivation and methodology. Despite common goals, these topics develop in isolation, and their subtle differences in definition and problem setting often confuse readers and practitioners. In this survey, we first present a unified framework called generalized OOD detection, which encompasses the five aforementioned problems, i.e.,AD, ND, OSR, OOD detection, and OD. Under our framework, these five problems can be seen as special cases or sub-tasks, and are easier to distinguish. Despite comprehensive surveys of related fields, the summarization of OOD detection methods remains incomplete and requires further advancement. This paper specifically addresses the gap in recent technical developments in the field of OOD detection. It also provides a comprehensive discussion of representative methods from other sub-tasks and how they relate to and inspire the development of OOD detection methods. The survey concludes by identifying open challenges and potential research directions.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">分布外（OOD）检测对于确保机器学习系统的可靠性和安全性至关重要。例如，在自动驾驶中，当驾驶系统检测到训练期间从未见过且无法做出安全决策的异常场景或物体时，我们希望它能发出警报并将控制权交给人类。“分布外检测”这一术语于2017年首次出现，此后受到了研究界越来越多的关注，催生了大量的方法，包括基于分类、基于密度和基于距离的方法。同时，其他几个问题，包括异常检测（AD）、新奇检测（ND）、开放集识别（OSR）和离群点检测（OD），在动机和方法上与分布外检测密切相关。尽管目标相似，但这些主题各自独立发展，它们在定义和问题设定上的细微差异常常使读者和从业者感到困惑。在本综述中，我们首先提出了一个名为广义分布外检测的统一框架，该框架涵盖了上述五个问题，即异常检测、新奇检测、开放集识别、分布外检测和离群点检测。在我们的框架下，这五个问题可以被视为特殊情况或子任务，更容易区分。尽管已有相关领域的综合综述，但分布外检测方法的总结仍不完整，需要进一步完善。本文特别填补了分布外检测领域近期技术发展的空白。它还全面讨论了来自其他子任务的代表性方法，以及它们如何与分布外检测方法的发展相关并提供启发。综述最后指出了尚未解决的挑战和潜在的研究方向。</div></div></div></div><div><br></div><div><div><div>Keywords Out-of-distribution detection <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2648" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> AI safety <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2649" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> Model trustworthiness <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2650" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> Open set recognition <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2651" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> Computer vision<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">关键词 分布外检测 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2652" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> 人工智能安全 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2653" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> 模型可信度 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2654" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> 开放集识别 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2655" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>⋅</mo></math></mjx-assistive-mml></mjx-container> 计算机视觉</div></div></div></div><div><br></div><h2><div><div>1 Introduction<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">1 引言</div></div></div></h2><div><br></div><div><div><div>A trustworthy visual recognition system should not only produce accurate predictions on known context, but also detect unknown examples and reject them (or hand them over to human users for safe handling) (Amodei et al., 2016;<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">一个值得信赖的视觉识别系统不仅应在已知环境下做出准确预测，还应检测出未知样本并拒绝它们（或将其交给人类用户安全处理）（阿莫迪等人，2016；</div></div></div></div><div><br></div><div><div><div>Mohseni et al., 2021; Hendrycks et al., 2021; Hendrycks &amp; Mazeika, 2022). For instance, a well-trained food classifier should be able to detect non-food images such as selfies uploaded by users, and reject such input instead of blindly classifying them into existing food categories. In safety-critical applications such as autonomous driving, the driving system must issue a warning and hand over the control to drivers when it detects unusual scenes or objects it has never seen during training (Fig. 1).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">莫赫森尼等人，2021；亨德里克斯等人，2021；亨德里克斯和梅泽卡，2022）。例如，一个训练良好的食物分类器应该能够检测出用户上传的自拍等非食物图像，并拒绝此类输入，而不是盲目地将它们分类到现有的食物类别中。在自动驾驶等安全关键应用中，当驾驶系统检测到训练期间从未见过的异常场景或物体时，必须发出警告并将控制权交给驾驶员（图1）。</div></div></div></div><div><br></div><div><div><div>Most existing machine learning models are trained based on the closed-world assumption (Krizhevsky et al., 2012; He et al., 2015), where the test data is assumed to be drawn i.i.d. from the same distribution as the training data, known as in-distribution (ID). However, when models are deployed in an open-world scenario (Drummond &amp; Shearer, 2006), test samples can be out-of-distribution (OOD) and therefore should be handled with caution. The distributional shifts can be caused by semantic shift (e.g.,OOD samples are drawn from different classes) (Hendrycks &amp; Gimpel, 2017), or covariate shift (e.g.,OOD samples from a different domain) (Ben-David et al., 2010; Li et al., 2017b; Wang &amp; Deng, 2018).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">大多数现有的机器学习模型是基于封闭世界假设进行训练的（克里热夫斯基等人，2012；何等人，2015），即假设测试数据与训练数据来自相同的分布，且是独立同分布的，这被称为分布内（ID）。然而，当模型部署在开放世界场景中时（德拉蒙德和希勒，2006），测试样本可能是分布外（OOD）的，因此需要谨慎处理。分布偏移可能由语义偏移（例如，分布外样本来自不同的类别）（亨德里克斯和金佩尔，2017）或协变量偏移（例如，来自不同领域的分布外样本）（本 - 戴维等人，2010；李等人，2017b；王和邓，2018）引起。</div></div></div></div><div><br><hr></div><div><div><div>Communicated by Hong Liu.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">由刘洪传达。</div></div></div></div><div><br></div><div><div><div>☑ Ziwei Liu<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">☑ 刘子微</div></div></div></div><div><br></div><div><div><div>ziwei.liu@ntu.edu.sgh</div></div></div><div><br></div><div><div><div>Jingkang Yang<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">杨景康</div></div></div></div><div><br></div><div><div><div>jingkang001@ntu.edu.sgh</div></div></div><div><br></div><div><div><div>Kaiyang Zhou<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">周开阳</div></div></div></div><div><br></div><div><div><div>kaiyang.zhou@ntu.edu.sg</div></div></div><div><br></div><div><div><div>Yixuan Li<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">李逸轩</div></div></div></div><div><br></div><div><div><div>sharonli@cs.wisc.edu</div></div></div><div><br></div><div><div><div>1 S-Lab, Nanyang Technological University, Singapore, Singapore<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">1 新加坡南洋理工大学S-Lab</div></div></div></div><div><br></div><div><div><div>2 Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI, USA<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2 美国威斯康星大学麦迪逊分校计算机科学系，威斯康星州麦迪逊市</div></div></div></div><div><br><hr></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="2" id="mark-3b484643-10ec-44fe-9cd2-8e1163ca213c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-1="0,0"><div style="height: auto;"><span style="display: inline;"><div><paragraphpositioning data-position-1="0,0"><!-- Media --><br><!-- figureText: Covariate Shift Detection Semantic Shift Detection Single-Class Multi-Class Semantic Anomaly Detection Novelty Detection One-Class Multi-Class Novelty Novelty Detection Detection Open Set Recognition Out-of-Distribution Detection Outlier Detection *Exception: In OOD Detection, density-based methods do not require ID classification Single/Multi-Class Anomaly Detection Sensory Anomaly Detection Inductive Transductive --><br></paragraphpositioning></div><img src="https://cdn.noedgeai.com/0195d2b3-e92e-7da1-8c3c-990b96d6d818_1.jpg?x=144&amp;y=149&amp;w=710&amp;h=609&amp;r=0" alt="https://cdn.noedgeai.com/0195d2b3-e92e-7da1-8c3c-990b96d6d818_1.jpg?x=144&amp;y=149&amp;w=710&amp;h=609&amp;r=0"><div><br></div><div><div><div>Fig. 1 Taxonomy of generalized OOD detection framework, illustrated by classification tasks. Four bases are used for the task taxonomy: (1) Distribution shift to detect: the task focuses on detecting covariate shift or semantic shift; (2) ID data type: the ID data contains one single class or multiple classes; (3) Whether the task requires ID classification; (4) Transductive learning task requires all observations; inductive tasks follow the train-test scheme. Note that ND is often interchangeable with AD, but ND is more concerned with semantic anomalies. OOD detection is generally interchangeable with OSR for classification tasks<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">图1 广义分布外（OOD）检测框架的分类，以分类任务为例说明。该任务分类使用了四个依据：（1）待检测的分布偏移：任务重点在于检测协变量偏移或语义偏移；（2）分布内（ID）数据类型：ID数据包含单一类别或多个类别；（3）任务是否需要进行ID分类；（4）直推式学习任务需要所有观测值；归纳式任务遵循训练 - 测试方案。请注意，新奇检测（ND）通常可与异常检测（AD）互换使用，但ND更关注语义异常。对于分类任务，OOD检测通常可与开放集识别（OSR）互换使用</div></div></div></div><div><br><!-- Media --><br></div><div><div><div>The detection of semantic distribution shift (e.g.,due to the occurrence of new classes) is the focal point of OOD detection tasks,where the label space <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2656" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> can be different between ID and OOD data and hence the model should not make any prediction. In addition to OOD detection, several problems adopt the "open-world" assumption and have a similar goal of identifying OOD examples. These include outlier detection (OD) (Aggarwal &amp; Yu, 2001; Hodge &amp; Austin, 2004; Ben-Gal, 2005; Wang et al., 2019a), anomaly detection (AD) (Ruff et al., 2021; Pang et al., 2020; Bulusu et al., 2020; Chalapathy &amp; Chawla, 2019), novelty detection (ND) (Pimentel et al., 2014; Miljković, 2010; Markou &amp; Singh, 2003a; Markou &amp; Singh, 2003b), and open set recognition (OSR) (Boult et al., 2019; Huang &amp; Chen, 2020; Mahdavi &amp; Carvalho, 2021). While all these problems are related to each other by sharing similar motivations, subtle differences exist among the sub-topics in terms of the specific definition. However, the lack of a comprehensive understanding of the relationship between the different sub-topics leads to confusion for both researchers and practitioners. Even worse, these sub-topics, which are supposed to be compared and learned from each other, are developing in isolation.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">语义分布偏移的检测（例如，由于新类别的出现）是OOD检测任务的重点，其中ID数据和OOD数据之间的标签空间<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2657" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container>可能不同，因此模型不应进行任何预测。除了OOD检测之外，有几个问题采用了“开放世界”假设，并且具有识别OOD示例的相似目标。这些问题包括离群点检测（OD）（Aggarwal &amp; Yu，2001；Hodge &amp; Austin，2004；Ben - Gal，2005；Wang等人，2019a）、异常检测（AD）（Ruff等人，2021；Pang等人，2020；Bulusu等人，2020；Chalapathy &amp; Chawla，2019）、新奇检测（ND）（Pimentel等人，2014；Miljković，2010；Markou &amp; Singh，2003a；Markou &amp; Singh，2003b）和开放集识别（OSR）（Boult等人，2019；Huang &amp; Chen，2020；Mahdavi &amp; Carvalho，2021）。虽然所有这些问题因具有相似的动机而相互关联，但在具体定义方面，这些子主题之间存在细微差异。然而，对不同子主题之间关系缺乏全面理解，导致研究人员和从业者都感到困惑。更糟糕的是，这些本应相互比较和借鉴的子主题正在孤立地发展。</div></div></div></div><div><br></div><div><div><div>In this survey, we for the first time clarify the similarities and differences between these problems, and present a unified framework termed generalized OOD detection. Under this framework, the five problems (i.e.,AD, ND, OSR, OOD detection, and OD) can be viewed as special cases or sub-topics. While other sub-topics have been extensively surveyed, the summarization of OOD detection methods is still inadequate and requires further exploration. This paper fills this gap by focusing specifically on recent technical developments in OOD detection, analyzing fair experimental comparisons among classical methods on common benchmarks. Our survey concludes by highlighting open challenges and outlining potential avenues for future research.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在本综述中，我们首次阐明了这些问题之间的异同，并提出了一个称为广义OOD检测的统一框架。在这个框架下，这五个问题（即AD、ND、OSR、OOD检测和OD）可以被视为特殊情况或子主题。虽然其他子主题已经得到了广泛的综述，但对OOD检测方法的总结仍然不足，需要进一步探索。本文通过专门关注OOD检测的最新技术发展，分析经典方法在常见基准上的公平实验比较，填补了这一空白。我们的综述最后强调了开放的挑战，并概述了未来研究的潜在途径。</div></div></div></div><div><br></div><div><div><div>We further conduct a literature review for each sub-topic, with a special focus on the OOD detection task. To sum up, we make three contributions to the research community:<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">我们进一步对每个子主题进行了文献综述，特别关注OOD检测任务。综上所述，我们为研究界做出了三点贡献：</div></div></div></div><div><br><ol><li value="1">A Unified Framework For the first time, we systematically review five closely related topics of AD, ND, OSR, OOD detection, and OD, and present a unified framework of generalized OOD detection. Under this framework, the similarities and differences of the five sub-topics can be systematically compared and analyzed. We hope our unification helps the community better understand these problems and correctly position their research in the literature.</li></ol><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ol><li value="1">统一框架 我们首次系统地回顾了异常检测（AD）、新奇检测（ND）、开放集识别（OSR）、分布外检测（OOD检测）和离群点检测（OD）这五个密切相关的主题，并提出了广义OOD检测的统一框架。在这个框架下，可以系统地比较和分析这五个子主题的异同。我们希望我们的统一工作有助于研究界更好地理解这些问题，并在文献中正确定位他们的研究。</li></ol></div><br><ol><li value="2">A Comprehensive Survey for OOD Detection Noticing the existence of comprehensive surveys on AD, ND, OSR, and OD methodologies in recent years (Ruff et al., 2021; Pang et al., 2020; Bulusu et al., 2020; Chalapa-thy &amp; Chawla, 2019; Huang &amp; Chen, 2020), this survey provides a comprehensive overview of OOD detection methods and thus complements existing surveys. By connecting with methodologies of other sub-topics that are also briefly reviewed, as well as sharing the insights from a fair comparison on a standard benchmark, we hope to provide readers with a more holistic understanding of the developments for each problem and their interconnections, especially for OOD detection.</li></ol><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ol><li value="2">OOD检测的全面综述 鉴于近年来已经有关于AD、ND、OSR和OD方法的全面综述（Ruff等人，2021；Pang等人，2020；Bulusu等人，2020；Chalapathy &amp; Chawla，2019；Huang &amp; Chen，2020），本综述提供了OOD检测方法的全面概述，从而补充了现有的综述。通过与其他也进行了简要回顾的子主题的方法相联系，并分享在标准基准上的公平比较所获得的见解，我们希望为读者提供对每个问题的发展及其相互联系的更全面理解，特别是对于OOD检测。</li></ol></div><br><ol><li value="3">Future Research Directions We draw readers' attention to some problems or limitations that remain in the current generalized OOD detection field. We conclude this survey with discussions on open challenges and opportunities for future research.</li></ol><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><ol><li value="3">未来研究方向 我们提请读者注意当前广义OOD检测领域仍然存在的一些问题或局限性。我们在本综述的结尾讨论了开放的挑战和未来研究的机会。</li></ol></div><br></div><div><div><div>Organization of Remaining Sections To match the mentioned contributions, in Sect. 2, we introduce the generalized OOD detection framework and discuss related topics to better position our survey. In Sect. 3, we provide a comprehensive overview of the methodologies for OOD detection, categorizing them into four groups: (1) classification-based methods, which largely rely on classifiers; (2) density-based methods, which detect OOD by modeling data density; (3) distance-based methods, which use distance metrics (usually in the feature space) to identify OODs; and (4) reconstruction-based methods, which are characterized by reconstruction techniques. In Sect. 4, we briefly introduce methodologies for other sub-tasks, including AD, ND, OSR, and OD, to provide readers with a broader understanding of OOD-related problems and inspire the development of more effective methods. To offer readers further insights from an empirical perspective, in Sect. 5 we conduct a thorough analysis that provides a fair comparison between representative OOD detection methods and methods from other sub-tasks. Additionally, we highlight some of the remaining problems and limitations that exist in the current generalized OOD detection field. We conclude this survey with a discussion on the open challenges and opportunities for future research. It is worth noting that a concurrent survey (Salehi et al., 2021) provides a detailed explanation of OOD-related methods, which greatly complements our work.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">剩余章节的组织 为了与上述贡献相匹配，在第2节中，我们介绍广义的分布外（OOD）检测框架，并讨论相关主题，以便更好地定位我们的综述。在第3节中，我们全面概述了OOD检测方法，将其分为四类：（1）基于分类的方法，主要依赖分类器；（2）基于密度的方法，通过对数据密度建模来检测OOD；（3）基于距离的方法，使用距离度量（通常在特征空间中）来识别OOD；（4）基于重构的方法，其特点是采用重构技术。在第4节中，我们简要介绍其他子任务的方法，包括异常检测（AD）、新奇检测（ND）、开放集识别（OSR）和离群点检测（OD），以便让读者更广泛地了解与OOD相关的问题，并启发更有效方法的开发。为了从实证角度为读者提供更多见解，在第5节中，我们进行了全面分析，对有代表性的OOD检测方法和其他子任务的方法进行了公平比较。此外，我们还强调了当前广义OOD检测领域中存在的一些剩余问题和局限性。我们在本综述的结尾讨论了未来研究面临的开放性挑战和机遇。值得注意的是，一项同期综述（Salehi等人，2021年）详细解释了与OOD相关的方法，这对我们的工作起到了很好的补充作用。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="3" id="mark-3cdb0510-739f-48f7-a727-720a5d897537" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-2="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-2="0,0"></paragraphpositioning></div></div></div><div><!-- Media --><br><!-- figureText: Anomaly Detection Generalized Out-of-Distribution Detection Train All Observations are provided dog cat fish Test (d) Open Set Recognition (e) Outlier Detection & Out-of-Distribution Detection* * OOD Detection is generally the same as OSR in classification task, but OOD Detection encompasses a broader spectrum of learning tasks and solution space (ref. Section 2.6) Semantic Anomaly Detection / Novelty Detection Train Train Train dog dog dog Test Test Test (a) Sensory Anomaly Detection (b) One-Class Novelty Detection (c) Multi-Class Novelty Detection --><br></div><img src="https://cdn.noedgeai.com/0195d2b3-e92e-7da1-8c3c-990b96d6d818_2.jpg?x=149&amp;y=159&amp;w=1456&amp;h=475&amp;r=0" alt="https://cdn.noedgeai.com/0195d2b3-e92e-7da1-8c3c-990b96d6d818_2.jpg?x=149&amp;y=159&amp;w=1456&amp;h=475&amp;r=0"><div><br></div><div><div><div>Fig. 2 Illustration of sub-tasks under generalized OOD detection framework with vision tasks. Tags on test images refer to model's expected predictions. a In sensory anomaly detection, test images with covariate shift will be considered as OOD. No semantic shift occurs in this setting. b In one-class novelty detection, normal/ID images belong to one class. Test images with semantic shift will be considered as OOD. c In multi-class novelty detection, ID images belong to multiple classes. Test images with semantic shift will be considered as OOD. Note that <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2658" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D41B TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">b</mi></mrow></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2659" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D41C TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">c</mi></mrow></math></mjx-assistive-mml></mjx-container> compose novelty detection,which is identical to the topic of semantic anomaly detection. d Open set recognition is identical to multi-class novelty detection in the task of detection, with the only difference that open set recognition further requires ID classification. Out-of-distribution detection solves the same problem as open-set recognition. It canonically aims to detect test samples with semantic shift without losing the ID classification accuracy. However, OOD Detection encompasses a broader spectrum of learning tasks and solution space. e Outlier detection does not follow a train-test scheme. All observations are provided. It fits in the generalized OOD detection framework by defining the majority distribution as ID. Outliers can have any distribution shift from the majority<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">图2 具有视觉任务的广义OOD检测框架下子任务的示意图。测试图像上的标签指的是模型的预期预测。a 在感官异常检测中，具有协变量偏移的测试图像将被视为OOD。在此设置中不会发生语义偏移。b 在单类新奇检测中，正常/分布内（ID）图像属于一个类别。具有语义偏移的测试图像将被视为OOD。c 在多类新奇检测中，ID图像属于多个类别。具有语义偏移的测试图像将被视为OOD。请注意，<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2660" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D41B TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">b</mi></mrow></math></mjx-assistive-mml></mjx-container>和<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2661" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D41C TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">c</mi></mrow></math></mjx-assistive-mml></mjx-container>构成了新奇检测，这与语义异常检测的主题相同。d 开放集识别在检测任务上与多类新奇检测相同，唯一的区别是开放集识别还需要进行ID分类。分布外检测解决的问题与开放集识别相同。它通常旨在检测具有语义偏移的测试样本，同时不降低ID分类的准确性。然而，OOD检测涵盖了更广泛的学习任务和解决方案空间。e 离群点检测不遵循训练 - 测试方案。提供了所有观测值。通过将多数分布定义为ID，它适用于广义OOD检测框架。离群点可能与多数分布有任何分布偏移</div></div></div></div><div><br><!-- Media --><br></div><h2><div><div>2 Generalized OOD Detection<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2 广义OOD检测</div></div></div></h2><div><br></div><div><div><div>Framework Overview In this section, we introduce a unified framework termed generalized OOD detection, which encapsulates five related sub-topics: anomaly detection (AD), novelty detection (ND), open set recognition (OSR), out-of-distribution (OOD) detection, and outlier detection (OD). These sub-topics can be similar in the sense that they all define a certain in-distribution, with the common goal of detecting out-of-distribution samples under the open-world assumption. However, subtle differences exist among the sub-topics in terms of the specific definition and properties of ID and OOD data-which are often overlooked by the research community. To this end, we provide a clear introduction and description of each sub-topic in respective subsections (from Sect.2.1 to 2.5). Each subsection details the motivation, background, formal definition, as well as relative position within the unified framework. Applications and benchmarks are also introduced, with concrete examples that facilitate understanding. Figure 2 illustrates the settings for each sub-topic. In the end, we conclude this section by introducing the neighborhood topics to clarify the scope of the generalized OOD detection framework (Sect. 2.6).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">框架概述 在本节中，我们介绍一个统一的框架，称为广义OOD检测，它包含五个相关的子主题：异常检测（AD）、新奇检测（ND）、开放集识别（OSR）、分布外（OOD）检测和离群点检测（OD）。这些子主题在某种意义上可能相似，因为它们都定义了某种分布内情况，共同目标是在开放世界假设下检测分布外样本。然而，这些子主题在ID和OOD数据的具体定义和属性方面存在细微差异，而这些差异往往被研究界所忽视。为此，我们在各个小节（从第2.1节到第2.5节）中对每个子主题进行了清晰的介绍和描述。每个小节详细阐述了动机、背景、正式定义以及在统一框架中的相对位置。还介绍了应用和基准，并给出了便于理解的具体示例。图2展示了每个子主题的设置。最后，我们在本节结尾介绍了相关主题，以明确广义OOD检测框架的范围（第2.6节）。</div></div></div></div><div><br></div><div><div><div>Preliminary: Distribution Shift In our framework, we recognize the complexity and interconnectedness of distribution shifts, which are central to understanding various OOD scenarios. Distribution shifts can be broadly categorized into covariate shift and semantic (label) shift, but it's important to clarify their interdependence. Firstly, let's define the input space as <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2662" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c58 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">X</mi></mrow></math></mjx-assistive-mml></mjx-container> (sensory observations) and the label space as <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2663" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> (semantic categories). The data distribution is represented by the joint distribution <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2664" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>X</mi><mo>,</mo><mi>Y</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> over the space <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2665" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c58 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">X</mi></mrow><mo>×</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> . Distribution shift can occur in either the marginal distribution <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2666" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> , or both <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2667" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2668" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> . Note that shift in <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2669" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> naturally triggers shift in <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2670" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">初步介绍：分布偏移 在我们的框架中，我们认识到分布偏移的复杂性和相互关联性，这对于理解各种分布外（OOD）场景至关重要。分布偏移大致可分为协变量偏移（covariate shift）和语义（标签）偏移（semantic (label) shift），但明确它们之间的相互依赖关系很重要。首先，我们将输入空间定义为<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2671" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c58 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">X</mi></mrow></math></mjx-assistive-mml></mjx-container>（感官观测值），将标签空间定义为<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2672" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container>（语义类别）。数据分布由空间<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2673" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c58 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">X</mi></mrow><mo>×</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container>上的联合分布<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2674" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>X</mi><mo>,</mo><mi>Y</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>表示。分布偏移可能发生在边缘分布<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2675" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>中，或者同时发生在<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2676" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>和<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2677" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>中。请注意，<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2678" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>的偏移自然会引发<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2679" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>的偏移。</div></div></div></div><div><br></div><div><div><div>Covariate Shift This occurs when there is a change in the marginal distribution <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2680" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> ,affecting the input space, while the label space <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2681" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> remains constant. Examples of covariate distribution shift on <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2682" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> include adversarial examples (Goodfellow et al., 2015; Madry et al., 2018), domain shift (Qui nonero-Candela et al., 2009), and style changes (Gatys et al., 2016). Semantic Shift This involves changes in both <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2683" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> and indirectly <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2684" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> . A shift in the label space <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2685" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> implies the introduction of new categories or the alteration of existing ones. This change naturally affects the input space <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2686" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> since the nature of the data being observed or collected is now different.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">协变量偏移 当边缘分布<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2687" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>发生变化，影响输入空间，而标签空间<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2688" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container>保持不变时，就会发生这种情况。<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2689" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>上的协变量分布偏移的例子包括对抗样本（Goodfellow等人，2015年；Madry等人，2018年）、领域偏移（Qui nonero - Candela等人，2009年）和风格变化（Gatys等人，2016年）。语义偏移 这涉及到<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2690" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>的变化以及间接的<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2691" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>的变化。标签空间<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2692" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>的偏移意味着引入了新的类别或改变了现有的类别。这种变化自然会影响输入空间<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2693" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>，因为现在观察或收集的数据的性质不同了。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="4" id="mark-bf4f081c-ffef-4619-bcb1-5bc060eda34d" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-3="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-3="0,0"></paragraphpositioning></div></div></div><div><div><div>Remark Given the interdependence between <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2694" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2695" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> ,it’s crucial to distinguish the intentions behind different types of distribution shifts. We define Covariate Shift as scenarios where changes are intended in the input space <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2696" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> without any deliberate alteration to the label space <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2697" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> . On the other hand,Semantic Shift specifically aims to modify the semantic content, directly impacting the label space <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2698" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> and,consequently,the input space <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2699" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">备注 鉴于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2700" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>和<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2701" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>之间的相互依赖关系，区分不同类型分布偏移背后的意图至关重要。我们将协变量偏移定义为在输入空间<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2702" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>中有意进行改变，而不对标签空间<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2703" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>进行任何刻意改变的场景。另一方面，语义偏移专门旨在修改语义内容，直接影响标签空间<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2704" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>，并因此影响输入空间<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2705" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Importantly, we note that covariate shift is more commonly used to evaluate model generalization and robustness performance,where the label space <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2706" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> remains the same during test time. On the other hand, the detection of semantic distribution shift (e.g.,due to the occurrence of new classes) is the focal point of many detection tasks considered in this framework,where the label space <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2707" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> can be different between ID and OOD data and hence the model should not make any prediction.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">重要的是，我们注意到协变量偏移更常用于评估模型的泛化能力和鲁棒性性能，在测试时标签空间<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2708" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container>保持不变。另一方面，检测语义分布偏移（例如，由于新类别的出现）是本框架中许多检测任务的重点，在这种情况下，分布内（ID）数据和分布外（OOD）数据的标签空间<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2709" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container>可能不同，因此模型不应进行任何预测。</div></div></div></div><div><br></div><div><div><div>With the concept of distribution shift in mind, readers can get a general idea of the differences and connections among sub-topics/tasks in Fig. 1. Notice that different sub-tasks can be easily identified with the following four dichotomies: (1) covariate/semantic shift dichotomy; (2) single/multiple class dichotomy; (3) ID classification needed/non-needed dichotomy; (4) inductive/transductive dichotomy. Next, we proceed with elaborating on each sub-topic.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">考虑到分布偏移的概念，读者可以大致了解图1中各子主题/任务之间的差异和联系。请注意，通过以下四个二分法可以轻松识别不同的子任务：（1）协变量/语义偏移二分法；（2）单类/多类二分法；（3）需要/不需要分布内分类二分法；（4）归纳/直推二分法。接下来，我们将详细阐述每个子主题。</div></div></div></div><div><br></div><h3><div><div>2.1 Anomaly Detection<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2.1 异常检测</div></div></div></h3><div><br></div><div><div><div>Background The notion of "anomaly" stands in contrast with the "normal" defined in advance. The concept of "normal" should be clear and reflect the real task. For example, to create a "not-hotdog detector", the concept of the normal should be clearly defined as the hotdog class, i.e.,a food category, so that objects that violate this definition are identified as anomalies, which include steaks, rice, and non-food objects like cats and dogs. Ideally, "hotdog" would be regarded as a homogeneous concept, regardless of the sub-classes of French or American hotdog.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">背景 “异常”的概念与预先定义的“正常”概念形成对比。“正常”的概念应该清晰明确，并反映实际任务。例如，要创建一个“非热狗检测器”，“正常”的概念应明确定义为热狗类别，即一种食物类别，这样违反该定义的对象就会被识别为异常，包括牛排、米饭以及猫和狗等非食物对象。理想情况下，无论法式热狗还是美式热狗这些子类如何，“热狗”都应被视为一个同质概念。</div></div></div></div><div><br></div><div><div><div>Current anomaly detection settings often restrict the environment of interest to some specific scenarios. For example, the "not-hotdog detector" only focuses on realistic images, assuming the nonexistence of images from other domains such as sketches. Another realistic example is industrial defect detection, which is based on only one set of assembly lines for a specific product. In other words, the "open-world" assumption is usually not completely "open". Nevertheless, "not-hotdog" or "defects" can form a large unknown space that breaks the "closed-world" assumption.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">当前的异常检测设置通常将关注的环境限制在某些特定场景中。例如，“非热狗检测器”仅关注真实图像，假设不存在来自其他领域（如素描）的图像。另一个实际例子是工业缺陷检测，它仅基于特定产品的一组装配线。换句话说，“开放世界”假设通常并非完全“开放”。然而，“非热狗”或“缺陷”可能形成一个巨大的未知空间，打破了“封闭世界”假设。</div></div></div></div><div><br></div><div><div><div>In summary, the key to anomaly detection is to define normal clearly (usually without sub-classes) and detect all possible anomalous samples under some specific scenarios. Definition Anomaly detection (AD) (Chandola et al., 2009) aims to detect any anomalous samples that deviate from the predefined normality during testing. The deviation can happen due to either covariate shift or semantic shift, which leads to two sub-tasks: sensory AD and semantic AD, respectively (Ruff et al., 2021).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">综上所述，异常检测的关键在于清晰地定义正常情况（通常不包含子类），并在某些特定场景下检测所有可能的异常样本。定义 异常检测（AD）（Chandola 等人，2009 年）旨在在测试期间检测任何偏离预定义正常情况的异常样本。这种偏离可能是由于协变量偏移或语义偏移导致的，分别对应两个子任务：感官异常检测和语义异常检测（Ruff 等人，2021 年）。</div></div></div></div><div><br></div><div><div><div>Sensory AD detects test samples with covariate shift, under the assumption that normalities come from the same covariate distribution. No semantic shift takes place in sensory AD settings. On the other hand, semantic AD detects test samples with label shift, assuming that normalities come from the same semantic distribution (category), i.e.,normalities should belong to only one class.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">感官异常检测在假设正常情况来自同一协变量分布的前提下，检测具有协变量偏移的测试样本。在感官异常检测设置中不会发生语义偏移。另一方面，语义异常检测在假设正常情况来自同一语义分布（类别）的前提下，检测具有标签偏移的测试样本，即正常情况应仅属于一个类别。</div></div></div></div><div><br></div><div><div><div>Formally, in sensory AD, normalities are from in-distribution <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2710" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> while anomalies encountered at test time are from out-of-distribution <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2711" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> ,where <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2712" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>≠</mo><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> -only covariate shift occurs. The goal in sensory AD is to detect samples from <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2713" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> . No semantic shift occurs in this setting,i.e., <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2714" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>=</mo><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> . Conversely,for semantic AD,only semantic shift occurs (i.e., <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2715" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>≠</mo><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> ) and the goal is to detect samples that belong to novel classes.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">形式上，在感官异常检测中，正常情况来自分布内 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2716" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>，而测试时遇到的异常来自分布外 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2717" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>，其中 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2718" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>≠</mo><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> - 仅发生协变量偏移。感官异常检测的目标是检测来自 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2719" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 的样本。在这种设置中不会发生语义偏移，即 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2720" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>=</mo><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>。相反，对于语义异常检测，仅发生语义偏移（即 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2721" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>≠</mo><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>），目标是检测属于新类别的样本。</div></div></div></div><div><br></div><div><div><div>Remark: Sensory/Semantic Dichotomy Our sensory/semantic dichotomy for the AD sub-task definition comes from the low-level sensory anomalies and high-level semantic anomalies that are introduced in Ahmed and Courville (2020) and highlighted in the recent AD survey (Ruff et al., 2021), to reflect the rise of deep learning. Note that although most sensory and semantic AD methods are shown to be mutually inclusive due to the common shift on <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2722" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> ,some approaches are specialized in one of the sub-tasks (ref. Sect.4.2). Recent research communities are also trending on subdividing types of anomalies to develop targeted methods, so that practitioners can select the optimal solution for their own practical problem (Ahmed &amp; Courville, 2020; Zhang et al., 2021).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">备注：感官/语义二分法 我们对异常检测子任务定义的感官/语义二分法源自 Ahmed 和 Courville（2020 年）引入并在近期异常检测综述（Ruff 等人，2021 年）中强调的低级感官异常和高级语义异常，以反映深度学习的兴起。请注意，尽管由于 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2723" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 上的共同偏移，大多数感官和语义异常检测方法显示出相互包容的特性，但一些方法专门针对其中一个子任务（参考第 4.2 节）。近期研究界也倾向于细分异常类型以开发有针对性的方法，以便从业者能够为自己的实际问题选择最优解决方案（Ahmed &amp; Courville，2020 年；Zhang 等人，2021 年）。</div></div></div></div><div><br></div><div><div><div>Position in Framework Under the generalized OOD detection framework, the definition of "normality" seamlessly connects to the notion of "in-distribution", and "anomaly" corresponds to "out-of-distribution". Importantly, AD treats ID samples as a whole, which means that regardless of the number of classes (or statistical modalities) in ID data, AD does not require differentiation in the ID samples. This feature is an important distinction between AD and other sub-topics such as OSR and OOD detection.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在框架中的位置 在广义的分布外检测框架下，“正常情况”的定义与“分布内”的概念无缝衔接，“异常”对应“分布外”。重要的是，异常检测将分布内样本视为一个整体，这意味着无论分布内数据中的类别（或统计模式）数量如何，异常检测都不需要对分布内样本进行区分。这一特征是异常检测与其他子主题（如开放集识别和分布外检测）的重要区别。</div></div></div></div><div><br></div><div><div><div>Application and Benchmark Sensory AD only focuses on objects with the same or similar semantics, and identifies the observational differences on their surface. Samples with sensory differences are recognized as sensory anomalies. Example applications include adversarial defense (Akhtar &amp; Mian, 2018), forgery recognition of biometrics and artworks (Patel et al., 2016; Wen et al., 2015; Nixon et al., 2008; Polatkan et al., 2009), image forensics (Dolhansky et al., 2019; Jiang et al., 2021c; Yang et al., 2020c), industrial inspection (Bergmann et al., 2019; Chu &amp; Kitani, 2020; Atha &amp; Jahanshahi, 2018), etc.. The most popular academic AD benchmark is MVTec-AD (Bergmann et al., 2019) for industrial inspection. Beyond academic research, sensory AD has significant potential in various real-world applications, such as detecting counterfeit items in retail and e-commerce and identifying manipulated media in journalism and law enforcement.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">应用与基准 感官异常检测仅关注具有相同或相似语义的对象，并识别其表面的观测差异。具有感官差异的样本被识别为感官异常。示例应用包括对抗防御（Akhtar &amp; Mian，2018 年）、生物特征和艺术品的伪造识别（Patel 等人，2016 年；Wen 等人，2015 年；Nixon 等人，2008 年；Polatkan 等人，2009 年）、图像取证（Dolhansky 等人，2019 年；Jiang 等人，2021c；Yang 等人，2020c）、工业检测（Bergmann 等人，2019 年；Chu &amp; Kitani，2020 年；Atha &amp; Jahanshahi，2018 年）等。最流行的学术异常检测基准是用于工业检测的 MVTec - AD（Bergmann 等人，2019 年）。除了学术研究，感官异常检测在各种现实世界应用中具有巨大潜力，例如在零售和电子商务中检测假冒商品，以及在新闻和执法中识别被篡改的媒体。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="5" id="mark-112e591b-f8b2-44d8-a648-fb579d3b48b6" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-4="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-4="0,0"></paragraphpositioning></div></div></div><div><div><div>In contrast to sensory AD, semantic AD only focuses on the semantic shift. An example of real-world applications is crime surveillance (Idrees et al., 2018; Diehl &amp; Hampshire, 2002). Active image crawlers for a specific category also need semantic AD methods to ensure the purity of the collected images (Li &amp; Fei-Fei, 2010). An example of the academic benchmarks is to recursively use one class from MNIST as ID during training, and ask the model to distinguish it from the rest of the 9 classes during testing.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">与感官异常检测（sensory AD）不同，语义异常检测（semantic AD）仅关注语义变化。现实应用的一个例子是犯罪监控（Idrees等人，2018年；Diehl和Hampshire，2002年）。针对特定类别的主动图像爬虫也需要语义异常检测方法来确保所收集图像的纯度（Li和Fei - Fei，2010年）。学术基准的一个例子是在训练期间递归地使用MNIST中的一个类别作为已知类别（ID），并要求模型在测试期间将其与其余9个类别区分开来。</div></div></div></div><div><br></div><div><div><div>Evaluation In the AD benchmarks, test samples are annotated to be either normal or abnormal. The deployed anomaly detector will produce a confidence score for a test sample, indicating how confident the model considers the sample as normality. Samples below the predefined confidence threshold are considered abnormal. By viewing the anomalies as positive and true normalities as negative, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2724" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msup></math></mjx-assistive-mml></mjx-container> different thresholds will produce a series of true positive rates (TPR) and false-positive rates (FPR)-from which we can calculate the area under the receiver operating characteristic curve (AUROC) (Fawcett, 2006). Similarly, the precision and recall values can be used to compute metrics of F-scores and the area under the precision-recall curve (AUPR) (Powers, 2020). Note that there can be two variants of AUPR values: one treating "normal" as the positive class, and the other treating "abnormal" as the positive class. For AUROC and AUPR, a higher value indicates better detection performance.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">评估 在异常检测基准中，测试样本被标注为正常或异常。部署的异常检测器将为测试样本生成一个置信度分数，表明模型认为该样本为正常的置信程度。低于预定义置信阈值的样本被视为异常。将异常视为阳性，真正的正常样本视为阴性，<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2725" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msup></math></mjx-assistive-mml></mjx-container>不同的阈值将产生一系列真阳性率（TPR）和假阳性率（FPR）——由此我们可以计算受试者工作特征曲线下的面积（AUROC）（Fawcett，2006年）。同样，精确率和召回率值可用于计算F分数和精确率 - 召回率曲线下的面积（AUPR）（Powers，2020年）。请注意，AUPR值有两种变体：一种将“正常”视为正类，另一种将“异常”视为正类。对于AUROC和AUPR，值越高表示检测性能越好。</div></div></div></div><div><br></div><div><div><div>Remark: Alternative Taxonomy on Anomalies Some previous literature considers anomalies types to be three-fold: point anomalies, conditional or contextural anomalies, and group or collective anomalies (Pang et al., 2020; Chalapa-thy &amp; Chawla, 2019; Ruff et al., 2021). In this survey, we mainly focus on point anomalies detection for its popularity in practical applications and its adequacy to elucidate the similarities and differences between sub-tasks. Details of the other two kinds of anomalies, i.e.,contextural anomalies that often occur in time-series tasks, and collective anomalies that are common in the data mining field, are not covered in this survey. We recommend readers to the recent AD survey papers (Ruff et al., 2021) for an in-depth discussion on them. Remark: Taxonomy Based on Supervision We use sensory/semantic dichotomy to subdivide AD at the task level. From the perspective of methodologies, some literature categorizes AD techniques into unsupervised and (semi- ) supervised settings. Note that these two taxonomies are orthogonal as they focus on tasks and methods respectively.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">备注：异常的另一种分类 一些先前的文献认为异常类型可分为三类：点异常、条件或上下文异常以及组或集体异常（Pang等人，2020年；Chalapathy和Chawla，2019年；Ruff等人，2021年）。在本综述中，我们主要关注点异常检测，因为它在实际应用中很流行，并且足以阐明子任务之间的异同。本综述不涵盖其他两种异常的细节，即经常出现在时间序列任务中的上下文异常和数据挖掘领域常见的集体异常。我们建议读者参考最近的异常检测综述论文（Ruff等人，2021年）以深入讨论这些内容。备注：基于监督的分类 我们使用感官/语义二分法在任务层面细分异常检测。从方法学的角度来看，一些文献将异常检测技术分为无监督和（半）监督设置。请注意，这两种分类是正交的，因为它们分别关注任务和方法。</div></div></div></div><div><br></div><h3><div><div>2.2 Novelty Detection<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2.2 新奇性检测</div></div></div></h3><div><br></div><div><div><div>Background The word "novel" generally refers to the unknown, new, and something interesting. While novelty detection (ND) is often interchangeable with AD in the community, strictly speaking, their subtle difference is worth noticing. In terms of motivation, novelty detection usually does not perceive "novel" test samples as erroneous, fraudulent, or malicious as AD does, but cherishes them as learning resources for potential future use with a positive learning attitude (Pang et al., 2020; Ruff et al., 2021). In fact, novelty detection is also known as "novel class detection" (Markou &amp; Singh, 2003a, b), indicating that it is primarily focusing on detecting semantic shift.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">背景 “新奇”一词通常指未知、新颖且有趣的事物。虽然在该领域中，新奇性检测（ND）通常可与异常检测（AD）互换使用，但严格来说，它们之间的细微差异值得注意。在动机方面，新奇性检测通常不会像异常检测那样将“新奇”的测试样本视为错误、欺诈或恶意的，而是以积极的学习态度将它们视为未来潜在用途的学习资源（Pang等人，2020年；Ruff等人，2021年）。实际上，新奇性检测也被称为“新奇类别检测”（Markou和Singh，2003a，b），这表明它主要侧重于检测语义变化。</div></div></div></div><div><br></div><div><div><div>Definition Novelty detection aims to detect any test samples that do not fall into any training category. The detected novel samples are usually prepared for future constructive procedures, such as more specialized analysis, or incremental learning of the model itself. Based on the number of training classes, ND contains two different settings: (1) one-class novelty detection (one-class <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2726" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>N</mi><mi>D</mi></mrow></math></mjx-assistive-mml></mjx-container> ): only one class exists in the training set; (2) multi-class novelty detection (multi-class ND): multiple classes exist in the training set. It is worth noting that despite having many ID classes, the goal of multi-class ND is only to distinguish novel samples from ID. Both one-class and multi-class ND are formulated as binary classification problems.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">定义 新奇性检测旨在检测任何不属于任何训练类别的测试样本。检测到的新奇样本通常为未来的建设性程序做准备，例如更专业的分析或模型本身的增量学习。根据训练类别的数量，新奇性检测包含两种不同的设置：（1）单类新奇性检测（单类<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2727" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>N</mi><mi>D</mi></mrow></math></mjx-assistive-mml></mjx-container>）：训练集中只有一个类别；（2）多类新奇性检测（多类ND）：训练集中存在多个类别。值得注意的是，尽管有多已知类别（ID），但多类新奇性检测的目标只是将新奇样本与已知类别区分开来。单类和多类新奇性检测都被表述为二分类问题。</div></div></div></div><div><br></div><div><div><div>Position in Framework Under the generalized OOD detection framework, ND deals with the setting where OOD samples have semantic shift, without the need for classification in the ID set even if possible. Therefore, ND shares the same problem definition with semantic AD.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在框架中的位置 在广义的分布外（OOD）检测框架下，新奇性检测处理的是分布外样本存在语义变化的情况，即使可能也无需对已知类别（ID）集合进行分类。因此，新奇性检测与语义异常检测具有相同的问题定义。</div></div></div></div><div><br></div><div><div><div>Application and Benchmark Real-world ND application includes video surveillance (Idrees et al., 2018; Diehl &amp; Hampshire, 2002), planetary exploration (Kerner et al., 2019) and incremental learning (Al-Behadili et al., 2015; Pathak et al., 2017). For one-class ND, an example academic benchmark can be identical to that of semantic AD, which considers one class from MNIST as ID and the rest as the novel. The corresponding MNIST benchmark for multi-class ND may use the first 6 classes during training, and test on the remaining 4 classes as OOD. Beyond academic research, ND has significant potential on new drag discovery, new species discovery, etc.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">应用与基准测试 现实世界中的新奇检测（ND）应用包括视频监控（伊德里斯等人，2018年；迪尔和汉普郡，2002年）、行星探索（克纳等人，2019年）和增量学习（阿尔 - 贝哈迪利等人，2015年；帕塔克等人，2017年）。对于单类新奇检测，一个学术基准示例可以与语义异常检测（AD）的基准相同，即把MNIST数据集中的一个类别视为已知类别（ID），其余类别视为新奇类别。多类新奇检测对应的MNIST基准可能在训练时使用前6个类别，并将其余4个类别作为分布外（OOD）数据进行测试。除学术研究外，新奇检测在新药发现、新物种发现等方面具有巨大潜力。</div></div></div></div><div><br><hr></div><div><div><div><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2728" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msup></math></mjx-assistive-mml></mjx-container> Align with MSP (Hendrycks &amp; Gimpel,2017) Check https://github.com/Jingkang50/OpenOOD/issues/206this issue in OpenOOD.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2729" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msup></math></mjx-assistive-mml></mjx-container> 与最大软概率（MSP）方法对齐（亨德里克斯和金佩尔，2017年） 查看OpenOOD中的这个问题：https://github.com/Jingkang50/OpenOOD/issues/206。</div></div></div></div><div><br><hr></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="6" id="mark-c46d177a-fb27-493e-b616-0d94f7b64350" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-5="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-5="0,0">Evaluation The evaluation of ND is identical to AD, which is based on AUROC, AUPR, or F-scores (see details in Sect. 2.1).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">评估 新奇检测的评估与异常检测相同，基于受试者工作特征曲线下面积（AUROC）、精确率 - 召回率曲线下面积（AUPR）或F分数（详见2.1节）。</div></paragraphpositioning></div></div></div><div><br></div><div><div><div>Remark: One-Class/Multi-class Dichotomy Although the ND models do not require the ID classification even with multi-class annotations, the method on multi-class ND can be different from one-class ND, as multi-class ND can make use of the multi-class classifier while one-class ND cannot. Also note that semantic AD can be further split into one-class semantic AD and multi-class semantic AD that matches ND, as semantic AD is equivalent to ND.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">备注：单类/多类二分法 尽管新奇检测模型即使有多类标注也不需要进行已知类别分类，但多类新奇检测的方法可能与单类新奇检测不同，因为多类新奇检测可以利用多类分类器，而单类新奇检测则不能。还需注意，由于语义异常检测等同于新奇检测，因此语义异常检测可进一步分为与新奇检测对应的单类语义异常检测和多类语义异常检测。</div></div></div></div><div><br></div><div><div><div>Remark: Nuance Between AD and ND Apart from the special interest in semantics, some literature (Perera et al., 2019; Xia et al., 2015) also point out that ND is supposed to be fully unsupervised (no novel data in training), while AD might have some abnormal training samples. It's important to note that neither AD nor ND necessitates the classification of ID data. This is a key distinction between OSR and OOD detection, which we will discuss in subsequent sections.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">备注：异常检测与新奇检测的细微差别 除了对语义的特殊关注外，一些文献（佩雷拉等人，2019年；夏等人，2015年）还指出，新奇检测应是完全无监督的（训练中没有新奇数据），而异常检测可能有一些异常训练样本。重要的是要注意，异常检测和新奇检测都不需要对已知类别数据进行分类。这是开放集识别（OSR）和分布外检测的一个关键区别，我们将在后续章节中讨论。</div></div></div></div><div><br></div><h3><div><div>2.3 Open Set Recognition<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2.3 开放集识别</div></div></div></h3><div><br></div><div><div><div>Background Machine learning models trained in the closed-world setting can incorrectly classify test samples from unknown classes as one of the known categories with high confidence (Scheirer et al., 2013). Some literature refers to this notorious overconfident behavior of the model as "arrogance", or "agnostophobia" (Dhamija et al., 2018). Open set recognition (OSR) is proposed to address this problem, with their own terminology of "known known classes" to represent the categories that exist at training, and "unknown unknown classes" for test categories that do not fall into any training category. Some other terms, such as open category detection (Liu et al., 2018a) and open set learning (Fang et al., 2021), are simply different expressions for OSR.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">背景 在封闭世界环境下训练的机器学习模型可能会将来自未知类别的测试样本错误地高置信度分类为已知类别之一（谢勒等人，2013年）。一些文献将模型这种臭名昭著的过度自信行为称为“傲慢”或“未知恐惧”（达米贾等人，2018年）。开放集识别（OSR）就是为解决这个问题而提出的，它使用“已知的已知类别”来表示训练时存在的类别，用“未知的未知类别”来表示不属于任何训练类别的测试类别。其他一些术语，如开放类别检测（刘等人，2018a）和开放集学习（方等人，2021年），只是开放集识别的不同表述。</div></div></div></div><div><br></div><div><div><div>Definition Open set recognition requires the multi-class classifier to simultaneously: (1) accurately classify test samples from "known known classes", and (2) detect test samples from "unknown unknown classes".<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">定义 开放集识别要求多类分类器同时做到：（1）准确分类来自“已知的已知类别”的测试样本；（2）检测来自“未知的未知类别”的测试样本。</div></div></div></div><div><br></div><div><div><div>Position in Framework OSR well aligns with our generalized OOD detection framework, where "known known classes" and "unknown unknown classes" correspond to ID and OOD respectively. Formally, OSR deals with the case where OOD samples during testing have semantic shift, i.e., <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2730" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>≠</mo><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> . The goal of OSR is largely shared with that of multi-class ND-the only difference is that OSR additionally requires accurate classification of ID samples from <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2731" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在框架中的位置 开放集识别与我们的广义分布外检测框架高度契合，其中“已知的已知类别”和“未知的未知类别”分别对应已知类别（ID）和分布外（OOD）。形式上，开放集识别处理的是测试时分布外样本存在语义偏移的情况，即 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2732" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>≠</mo><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 。开放集识别的目标与多类新奇检测基本相同，唯一的区别是开放集识别还要求准确分类来自 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2733" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 的已知类别样本。</div></div></div></div><div><br></div><div><div><div>Application and Benchmark OSR supports the robust deployment of real-world image classifiers in general, which can reject unknown samples in the open world (Sorio et al., 2010; Xu et al., 2019). An example academic benchmark on MNIST can be identical to multi-class ND, which considers the first 6 classes as ID and the remaining 4 classes as OOD. In addition, OSR further requires a good classifier on the 6 ID classes.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">应用与基准测试 一般来说，开放集识别支持现实世界图像分类器的稳健部署，它可以拒绝开放世界中的未知样本（索里奥等人，2010年；徐等人，2019年）。MNIST数据集上的一个学术基准示例可以与多类新奇检测相同，即把前6个类别视为已知类别，其余4个类别视为分布外数据。此外，开放集识别还要求对这6个已知类别有一个良好的分类器。</div></div></div></div><div><br></div><div><div><div>Evaluation Similar to AD and ND, the metrics for OSR include F-scores, AUROC, and AUPR. Beyond them, the classification performance is also evaluated by standard ID accuracy. While the above metrics evaluate the novelty detection and ID classification capabilities independently, some works raise some evaluation criteria for joint evaluation, such as CCR@FPR <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2734" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container> (Dhamija et al.,2018),which calculates the class-wise recall when a certain FPR equal to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2735" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c2C"></mjx-c></mjx-mtext><mjx-msup><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-script style="vertical-align: 0.393em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-texatom><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mtext>e.g.,</mtext><msup><mrow data-mjx-texclass="ORD"><mn>10</mn></mrow><mrow data-mjx-texclass="ORD"><mo>−</mo><mn>1</mn></mrow></msup></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> is achieved.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">评估 与异常检测和新奇检测类似，开放集识别的评估指标包括F分数、受试者工作特征曲线下面积（AUROC）和精确率 - 召回率曲线下面积（AUPR）。除此之外，还通过标准的已知类别准确率来评估分类性能。虽然上述指标分别评估新奇检测和已知类别分类能力，但一些研究提出了一些联合评估的标准，如误报率（FPR）为 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2736" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c2C"></mjx-c></mjx-mtext><mjx-msup><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-script style="vertical-align: 0.393em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-texatom><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mtext>e.g.,</mtext><msup><mrow data-mjx-texclass="ORD"><mn>10</mn></mrow><mrow data-mjx-texclass="ORD"><mo>−</mo><mn>1</mn></mrow></msup></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 时的类别召回率（CCR@FPR <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2737" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container> ）（达米贾等人，2018年）。</div></div></div></div><div><br></div><h3><div><div>2.4 Out-of-Distribution Detection<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2.4 分布外检测</div></div></div></h3><div><br></div><div><div><div>Background With the observation that deep learning models are often inappropriate but in fact overconfident in classifying samples from different semantic distributions in the image classification task and text categorization (Hendrycks &amp; Gimpel, 2017), the field of out-of-distribution detection emerges, requiring the model to reject inputs that are semantically different from the training distribution and therefore should not be predicted by the model.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">背景 有观察表明，在图像分类任务和文本分类中，深度学习模型在对来自不同语义分布的样本进行分类时，往往表现不佳却过度自信（Hendrycks &amp; Gimpel，2017），由此催生了分布外检测（Out-of-distribution detection）领域，该领域要求模型拒绝那些语义与训练分布不同、因而不应由模型进行预测的输入。</div></div></div></div><div><br></div><div><div><div>Definition Out-of-distribution detection, or OOD detection, aims to detect test samples drawn from a distribution that is different from the training distribution, with the definition of distribution to be well-defined according to the application in the target. For most machine learning tasks, the distribution should refer to "label distribution", which means that OOD samples should not have overlapping labels w.r.t.training data. Formally, in the OOD detection, the test samples come from a distribution whose semantics are shifted from ID, i.e., <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2738" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>≠</mo><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> . Note that the training set usually contains multiple classes, and OOD detection should NOT harm the ID classification capability.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">定义 分布外检测（Out-of-distribution detection，简称OOD检测）旨在检测来自与训练分布不同的分布的测试样本，分布的定义应根据目标应用进行明确界定。对于大多数机器学习任务而言，分布应指“标签分布”，这意味着分布外（OOD）样本的标签不应与训练数据的标签有重叠。形式上，在分布外检测中，测试样本来自语义与分布内（ID）不同的分布，即 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2739" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>≠</mo><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> 。请注意，训练集通常包含多个类别，且分布外检测不应损害分布内（ID）分类能力。</div></div></div></div><div><br></div><div><div><div>Position in Framework Out-of-distribution detection can be canonical to OSR in common machine learning tasks like multi-class classification-keeping the classification performance on test samples from ID class space <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2740" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> ,and reject OOD test samples with semantics outside the support of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2741" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> . Also, the multi-class setting and the requirement of ID classification distinguish the task from AD and ND.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在框架中的位置 在多类分类等常见机器学习任务中，分布外检测与开放集识别（OSR）具有相似性——保持对来自分布内（ID）类别空间 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2742" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> 的测试样本的分类性能，并拒绝语义在 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2743" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> 支持范围之外的分布外（OOD）测试样本。此外，多类设置和分布内（ID）分类要求使该任务有别于异常检测（AD）和新奇性检测（ND）。</div></div></div></div><div><br></div><div><div><div>Application and Benchmark The application of OOD detection usually falls into safety-critical situations, such as autonomous driving (Huang et al., 2020b; Geiger et al., 2012). In the context of self-driving vehicles, OOD detection (also OSR) plays a crucial role in identifying novel or unexpected objects and scenarios, allowing the system to take appropriate actions to ensure the safety of passengers and pedestrians. Other potential real-world applications include medical diagnosis, where OOD detection can help flag unusual patient cases that may require further attention from healthcare professionals, and industrial monitoring, where it can identify anomalies in sensor data that could indicate potential equipment failures or safety hazards. An example academic benchmark is to use CIFAR-10 as ID during training and to distinguish CIFAR images from other datasets such as SVHN, etc.. Researchers should pay attention that OOD datasets should NOT have label overlapping with ID datasets when building the benchmark.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">应用与基准 分布外检测的应用通常出现在对安全要求极高的场景中，例如自动驾驶（Huang等人，2020b；Geiger等人，2012）。在自动驾驶车辆的背景下，分布外检测（也即开放集识别）在识别新的或意外的物体和场景方面起着至关重要的作用，使系统能够采取适当的行动，以确保乘客和行人的安全。其他潜在的实际应用包括医学诊断，在医学诊断中，分布外检测可以帮助标记出可能需要医疗专业人员进一步关注的异常患者病例；以及工业监测，在工业监测中，它可以识别传感器数据中的异常，这些异常可能预示着潜在的设备故障或安全隐患。一个学术基准示例是在训练时使用CIFAR - 10作为分布内（ID）数据集，并将CIFAR图像与其他数据集（如SVHN等）区分开来。研究人员在构建基准时应注意，分布外（OOD）数据集的标签不应与分布内（ID）数据集的标签有重叠。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="7" id="mark-9c19fd6b-f45b-41ca-8912-f389745ee402" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-6="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-6="0,0"></paragraphpositioning></div></div></div><div><div><div>Evaluation Apart from F-scores, AUROC, and AUPR, another commonly-used metric is FPR@TPR <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2744" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container> ,which measures the FPR when the TPR is <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2745" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container> (e.g.,0.95). Some works also use an alternative metric,TNR@TPR <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2746" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container> ,which is equivalent to 1-FPR@TPR <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2747" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container> . OOD detection also concerns the performance of ID classification.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">评估 除了F分数、受试者工作特征曲线下面积（AUROC）和精确率 - 召回率曲线下面积（AUPR）之外，另一个常用的指标是真阳性率（TPR）为 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2748" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container> 时的假阳性率（FPR），即FPR@TPR <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2749" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container> （例如，当TPR为0.95时）。一些研究还使用另一个替代指标，即真阴性率（TNR）在TPR为 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2750" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container> 时的值，即TNR@TPR <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2751" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container> ，它等同于1 - FPR@TPR <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2752" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container> 。分布外检测还涉及分布内（ID）分类的性能。</div></div></div></div><div><br></div><div><div><div>Remark: OSR vs OOD Detection The difference between OSR and OOD detection tasks is three-fold.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">备注：开放集识别（OSR）与分布外检测的区别 开放集识别（OSR）和分布外检测任务的区别体现在三个方面。</div></div></div></div><div><br></div><div><div><div>(1) Different Benchmark Setup OSR benchmarks usually split one multi-class classification dataset into ID and OOD parts according to classes, while OOD detection takes one dataset as ID and finds several other datasets as OOD with the guarantee of non-overlapping categories between ID/OOD datasets. However, despite the different benchmark traditions of the two sub-tasks, they are in fact tackling the same problem of semantic shift detection.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">（1）不同的基准设置 开放集识别（OSR）基准通常根据类别将一个多类分类数据集划分为分布内（ID）和分布外（OOD）两部分，而分布外检测则将一个数据集作为分布内（ID）数据集，并找到其他几个数据集作为分布外（OOD）数据集，同时保证分布内/分布外数据集之间的类别不重叠。然而，尽管这两个子任务的基准传统不同，但它们实际上解决的是同一个语义偏移检测问题。</div></div></div></div><div><br></div><div><div><div>(2) No Additional data in OSR Due to the requirement of theoretical open-risk bound guarantee, OSR discourages the usage of additional data during training by design (Boult et al., 2019). This restriction precludes methods that are more focused on effective performance improvements (e.g.,outlier exposures (Hendrycks et al., 2019b; Zhang et al., 2023b)) but may violate OSR constraints.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">（2）开放集识别（OSR）不使用额外数据 由于需要保证理论上的开放风险边界，开放集识别（OSR）在设计上不鼓励在训练过程中使用额外数据（Boult等人，2019）。这一限制排除了那些更注重有效提高性能（例如，异常暴露（Hendrycks等人，2019b；Zhang等人，2023b））但可能违反开放集识别（OSR）约束的方法。</div></div></div></div><div><br></div><div><div><div>(3) Broadness of OOD Detection Compare to OSR, OOD detection encompasses a broader spectrum of learning tasks (e.g.,multi-label classification (Hendrycks et al., 2022a)), wider solution space (to be discussed in Sect. 3).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">（3）分布外检测的广泛性 与开放集识别（OSR）相比，分布外检测涵盖了更广泛的学习任务（例如，多标签分类（Hendrycks等人，2022a））和更广泛的解决方案空间（将在第3节讨论）。</div></div></div></div><div><br></div><div><div><div>Remark: Mainstream OOD Detection Focuses on Semantics While most works in the current community interpret the keyword "out-of-distribution" as "out-of-label/semantic-distribution", some OOD detection works also consider detecting covariate shifts (Hsu et al., 2020), which claim that covariate shift usually leads to a significant drop in model performance and therefore needs to be identified and rejected. However, although detecting covariate shift is reasonable on some specific tasks (usually due to high-risk or privacy reasons) that are to be discussed in the following paragraph,research on this topic remains a controversial task w.r.t OOD generalization tasks (c.f.Sects. 2.6 and 6.2). Detecting semantic shift has been the mainstream of OOD detection tasks.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">备注：主流的分布外（OOD）检测聚焦于语义 虽然当前学界的大多数研究将“分布外”这一关键词解读为“标签/语义分布外”，但也有一些OOD检测研究考虑检测协变量偏移（Hsu等人，2020），这些研究认为协变量偏移通常会导致模型性能显著下降，因此需要识别并排除。然而，尽管检测协变量偏移在一些特定任务（通常出于高风险或隐私原因）中是合理的（将在下一段讨论），但在OOD泛化任务方面，关于这一主题的研究仍然是一个有争议的任务（参见第2.6节和第6.2节）。检测语义偏移一直是OOD检测任务的主流。</div></div></div></div><div><br></div><div><div><div>Remark: To Generalize, or To Detect? We provide another definition from the perspective of generalization: Out-of-distribution detection, or OOD detection, aims to detect test samples to which the model cannot or does not want to generalize (Pleiss et al., 2019). In most of the machine learning tasks, such as image classification, the models are expected to generalize their prediction capability to samples with covariate shift, and they are only unable to generalize when semantic shift occurs. However, for applications where models are by-design nontransferable to other domain, such as many deep reinforcement learning tasks like game AI (Vinyals et al., 2017; Sedlmeier et al., 2019), the key term "distribution" should refer to "data/input distribution", so that the model should refuse to decide the environment that is not the same as the training environment,i.e., <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2753" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>≠</mo><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> . Similar applications are those high-risk tasks such as medical image classification (Zim-merer et al., 2022) or in privacy-sensitive scenario (Tariq et al., 2020), where the models are expected to be very conservative and only make predictions for samples exactly from the training distribution, rejecting any samples that deviate from it. Recent studies (Averly &amp; Chao, 2023) also highlight a model-specific view: a robust model should generalize to examples with covariate shift; a weak model should reject them. Ultimately, an OOD detection task is considered valid when it successfully balances the aspects of "detection" and "generalization", taking into account factors such as meaningfulness and the inherent challenges presented by the task. Nonetheless, detecting semantic shift remains the primary focus of OOD detection tasks and is central to this survey.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">备注：是泛化还是检测？ 我们从泛化的角度给出另一个定义：分布外检测（OOD检测）旨在检测模型无法或不想泛化的测试样本（Pleiss等人，2019）。在大多数机器学习任务中，如图像分类，模型期望将其预测能力泛化到存在协变量偏移的样本上，只有当发生语义偏移时，模型才无法泛化。然而，对于那些设计上不能迁移到其他领域的应用，如许多深度强化学习任务（如游戏AI）（Vinyals等人，2017；Sedlmeier等人，2019），关键术语“分布”应指“数据/输入分布”，这样模型应该拒绝判断与训练环境不同的环境，即<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2754" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2260"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.055em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>≠</mo><msup><mrow data-mjx-texclass="ORD"><mi>P</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>。类似的应用还包括医疗图像分类（Zimmerer等人，2022）等高风险任务或隐私敏感场景（Tariq等人，2020），在这些场景中，模型期望非常保守，只对与训练分布完全相同的样本进行预测，拒绝任何偏离该分布的样本。最近的研究（Averly &amp; Chao，2023）还强调了一种特定于模型的观点：一个鲁棒的模型应该能够泛化到存在协变量偏移的样本；而一个较弱的模型应该拒绝这些样本。最终，当OOD检测任务成功平衡了“检测”和“泛化”两个方面，并考虑到任务的意义和内在挑战等因素时，该任务才被认为是有效的。尽管如此，检测语义偏移仍然是OOD检测任务的主要焦点，也是本综述的核心内容。</div></div></div></div><div><br></div><h3><div><div>2.5 Outlier Detection<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2.5 离群点检测</div></div></div></h3><div><br></div><div><div><div>Background According to Wikipedia (Wikipedia contributors, 2021), an outlier is a data point that differs significantly from other observations. Recall that the problem settings in AD, ND, OSR, and OOD detect unseen test samples that are different from the training data distribution. In contrast, outlier detection directly processes all observations and aims to select outliers from the contaminated dataset (Ben-Gal, 2005; Hodge &amp; Austin, 2004; Aggarwal &amp; Yu, 2001). Since outlier detection does not follow the train-test procedure but has access to all observations, approaches to this problem are usually transductive rather than inductive (Bianchini et al., 2016).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">背景 根据维基百科（维基百科贡献者，2021）的定义，离群点是与其他观测值有显著差异的数据点。回顾一下，异常检测（AD）、新奇检测（ND）、开放集识别（OSR）和分布外检测（OOD）的问题设定是检测与训练数据分布不同的未见测试样本。相比之下，离群点检测直接处理所有观测值，旨在从受污染的数据集中选择离群点（Ben - Gal，2005；Hodge &amp; Austin，2004；Aggarwal &amp; Yu，2001）。由于离群点检测不遵循训练 - 测试流程，而是可以访问所有观测值，因此解决该问题的方法通常是直推式的，而非归纳式的（Bianchini等人，2016）。</div></div></div></div><div><br></div><div><div><div>Definition Outlier detection aims to detect samples that are markedly different from the others in the given observation set, due to either covariate or semantic shift.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">定义 离群点检测旨在检测给定观测集中由于协变量偏移或语义偏移而与其他样本明显不同的样本。</div></div></div></div><div><br></div><div><div><div>Position in Framework Different from all previous subtasks, whose in-distribution is defined during training, the "in-distribution" for outlier detection refers to the majority of the observations. Outliers may exist due to semantic shift on <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2755" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> ,or covariate shift on <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2756" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在框架中的位置 与之前的所有子任务不同，之前子任务的分布内是在训练期间定义的，而离群点检测的“分布内”是指大多数观测值。离群点可能由于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2757" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>Y</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>上的语义偏移或<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2758" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>X</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>上的协变量偏移而存在。</div></div></div></div><div><br></div><div><div><div>Application and Benchmark While mostly applied in data mining tasks (Ben-Gal, 2005; Basu &amp; Meckesheimer, 2007; Dou et al., 2019), outlier detection is also used in real-world computer vision applications such as video surveillance (Xiao et al., 2015) and dataset cleaning (Liu et al., 2004; Loureiro et al., 2004; Van den Broeck et al., 2005). For the application of dataset cleaning, outlier detection is usually used as a pre-processing step for the main tasks such as learning from open-set noisy labels (Wang et al., 2018), webly supervised learning (Chen &amp; Gupta, 2015), and open-set semi-supervised learning (Cao et al., 2021). To construct an outlier detection benchmark on MNIST, one class should be chosen so that all samples that belong to this class are considered as inliers. A small fraction of samples from other classes are introduced as outliers to be detected.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">应用与基准 离群点检测主要应用于数据挖掘任务（Ben - Gal，2005；Basu &amp; Meckesheimer，2007；Dou等人，2019），也用于现实世界的计算机视觉应用，如视频监控（Xiao等人，2015）和数据集清理（Liu等人，2004；Loureiro等人，2004；Van den Broeck等人，2005）。在数据集清理应用中，离群点检测通常作为主要任务的预处理步骤，如从开放集噪声标签中学习（Wang等人，2018）、弱监督学习（Chen &amp; Gupta，2015）和开放集半监督学习（Cao等人，2021）。为了在MNIST数据集上构建离群点检测基准，应选择一个类别，将属于该类别的所有样本视为内点。引入其他类别的一小部分样本作为待检测的离群点。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="8" id="mark-3d2008c8-d869-4d75-978a-7d9ac422b461" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-7="0,0"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-7="0,0"></paragraphpositioning></div></div></div><div><div><div>Evaluation Apart from F-scores, AUROC, and AUPR, the evaluation of outlier detectors can be also evaluated by the performance of the main task it supports. For example, if an outlier detector is used to purify a dataset with noisy labels, the performance of a classifier that is trained on the cleaned dataset can indicate the quality of the outlier detector.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">评估 除了F值、受试者工作特征曲线下面积（AUROC）和精确率-召回率曲线下面积（AUPR）之外，异常值检测器的评估还可以通过其支持的主要任务的性能来进行。例如，如果使用异常值检测器来净化带有噪声标签的数据集，那么在清理后的数据集上训练的分类器的性能可以表明异常值检测器的质量。</div></div></div></div><div><br></div><div><div><div>Remark: On Inclusion of Outlier Detection Interestingly, the outlier detection task can be considered as an outlier in the generalized OOD detection framework, since outlier detectors are operated on the scenario when all observations are given, rather than following the training-test scheme. Also, publications exactly on this topic are rarely seen in the recent deep learning venues. However, we still include outlier detection in our framework, because intuitively speaking, outliers also belong to one type of out-of-distribution, and introducing it can help familiarize readers more with various terms (e.g.,OD, AD, ND, OOD) that have confused the community for a long while.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">备注：关于纳入异常值检测 有趣的是，异常值检测任务可以被视为广义分布外（OOD）检测框架中的一个特例，因为异常值检测器是在所有观测值都已知的场景下运行的，而不是遵循训练 - 测试方案。此外，在最近的深度学习会议中，很少看到专门针对这一主题的出版物。然而，我们仍然将异常值检测纳入我们的框架，因为直观地说，异常值也属于分布外的一种类型，引入它可以帮助读者更熟悉各种让该领域困惑已久的术语（例如，异常检测（OD）、异常值检测（AD）、新奇性检测（ND）、分布外检测（OOD））。</div></div></div></div><div><br></div><h3><div><div>2.6 Related Topics<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">2.6 相关主题</div></div></div></h3><div><br></div><div><div><div>Apart from the five sub-topics that are described in our generalized OOD detection framework (shown in Fig. 1), we further briefly discuss five related topics below, which help clarify the scope of this survey.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">除了我们广义分布外检测框架中描述的五个子主题（如图1所示），我们下面进一步简要讨论五个相关主题，这有助于明确本综述的范围。</div></div></div></div><div><br></div><div><div><div>Learning with Rejection (LWR) LWR (Bartlett &amp; Wegkamp, 2008) can date back to early works on abstention (Chow, 1970; Fumera &amp; Roli, 2002), which considered simple model families such as SVMs (Cortes &amp; Vapnik, 1995). The phenomenon of neural networks' overconfidence in OOD data is first revealed by Nguyen et al. (2015). Despite methodologies differences, subsequent works developed on OOD detection and OSR share the underlying spirit of classification with the rejection option.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">带拒绝选项的学习（LWR） 带拒绝选项的学习（Bartlett &amp; Wegkamp，2008）可以追溯到早期关于弃权的研究（Chow，1970；Fumera &amp; Roli，2002），这些研究考虑了诸如支持向量机（SVMs）（Cortes &amp; Vapnik，1995）等简单的模型族。Nguyen等人（2015）首次揭示了神经网络在分布外数据上过度自信的现象。尽管方法有所不同，但后续在分布外检测和开放集识别（OSR）方面的研究都与带拒绝选项的分类有着相同的内在精神。</div></div></div></div><div><br></div><div><div><div>Domain Adaptation/Generalization Domain Adaptation (DA) (Wang &amp; Deng, 2018) and Domain Generalization (DG) (Zhou et al., 2021b) also follow "open-world" assumption. Different from generalized OOD detection settings, DA/DG expects the existence of covariate shift during testing without any semantic shift and requires classifiers to make accurate predictions into the same set of classes (Liu et al., 2020c). Noticing that OOD detection commonly concerns detecting the semantic shift, which is complementary to DA/DG. In the case when both covariate and semantic shift take place, the model should be able to detect semantic shift while being robust to covariate shift. More discussion on relations between DA/DG and OOD detection is in Sect. 6.2. The difference between DA and DG is that while the former requires extra but few training samples from the target domain, the latter does not.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">领域自适应/泛化 领域自适应（DA）（Wang &amp; Deng，2018）和领域泛化（DG）（Zhou等人，2021b）也遵循“开放世界”假设。与广义分布外检测设置不同，领域自适应/泛化期望在测试期间存在协变量偏移而没有任何语义偏移，并要求分类器对同一组类别进行准确预测（Liu等人，2020c）。值得注意的是，分布外检测通常关注检测语义偏移，这与领域自适应/泛化是互补的。当协变量和语义偏移同时发生时，模型应该能够检测到语义偏移，同时对协变量偏移具有鲁棒性。关于领域自适应/泛化与分布外检测之间关系的更多讨论见第6.2节。领域自适应和领域泛化的区别在于，前者需要来自目标领域的额外但少量的训练样本，而后者则不需要。</div></div></div></div><div><br></div><div><div><div>Novelty Discovery Novelty discovery (Han et al., 2019; Zhao &amp; Han, 2021; Jia et al., 2021; Vaze et al., 2022a; Joseph et al., 2022) requires all observations to be given in advance as outlier detection does. The observations are provided in a semi-supervised manner, and the goal is to explore and discover the new categories and classes in the unlabeled set. Different from outlier detection where outliers are sparse, the unlabeled set in novelty discovery setting can mostly consist of, and even be overwhelmed by unknown classes.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">新奇性发现 新奇性发现（Han等人，2019；Zhao &amp; Han，2021；Jia等人，2021；Vaze等人，2022a；Joseph等人，2022）和异常值检测一样，要求提前给出所有观测值。观测值以半监督的方式提供，目标是探索和发现未标记集中的新类别。与异常值检测中异常值稀疏不同，新奇性发现设置中的未标记集大多可能由未知类别组成，甚至可能被未知类别主导。</div></div></div></div><div><br></div><div><div><div>Zero-Shot Learning Zero-shot learning (Wang et al., 2019b) has a similar goal of novelty discovery but follows the training-testing scheme. The test set is under the "open-world" assumption with unknown classes, which expects classifiers trained only on the known classes to perform classification on unknown testing samples with the help of extra information such as label relationships.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">零样本学习 零样本学习（Wang等人，2019b）与新奇性发现有相似的目标，但遵循训练 - 测试方案。测试集遵循“开放世界”假设，包含未知类别，这期望仅在已知类别上训练的分类器借助额外信息（如标签关系）对未知测试样本进行分类。</div></div></div></div><div><br></div><div><div><div>Open-World Recognition Open-world recognition (Ben-dale &amp; Boult, 2015) aims to build a lifelong learning machine that can actively detect novel images (Liu et al., 2019), label them as new classes, and perform continuous learning. It can be viewed as a combination of novelty detection (or open-set recognition) and incremental learning. More specifically, open-world recognition extends the concept of OSR by adding the ability to incrementally learn new classes over time. In open-world scenarios, the system not only identifies unknown instances but also can update its model to include these new classes as part of the known set. This approach is more dynamic and suited for real-world applications where the environment is not static, and new categories can emerge after the initial training phase (Parmar et al., 2023).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">开放世界识别 开放世界识别（Ben - dale &amp; Boult，2015）旨在构建一个终身学习机器，该机器可以主动检测新奇图像（Liu等人，2019），将它们标记为新类别，并进行持续学习。它可以被视为新奇性检测（或开放集识别）和增量学习的结合。更具体地说，开放世界识别通过增加随时间增量学习新类别的能力扩展了开放集识别的概念。在开放世界场景中，系统不仅能识别未知实例，还能更新其模型，将这些新类别纳入已知类别集合。这种方法更具动态性，适用于环境不是静态的、在初始训练阶段后可能出现新类别的现实应用（Parmar等人，2023）。</div></div></div></div><div><br></div><div><div><div>Conformal Prediction Conformal prediction (CP) stands as a robust statistical framework in machine learning, primarily designed to provide confidence measures for predictions (Shafer &amp; Vovk, 2008; Angelopoulos &amp; Bates, 2021). Distinctively, it yields prediction intervals with specified confidence levels, transcending the limitations of mere point estimates. In scenarios of OOD detection, the conformal prediction framework becomes particularly insightful: wider prediction intervals or lower confidence levels generated by conformal prediction methods can serve as indicators of such OOD data. Although research at the intersection of CP and OOD detection is still emerging (Kaur et al., 2022a, b; Cai et al., 2021), the potential of applying the conformal prediction framework in this domain is significant and warrants further exploration (Table 1; Fig. 3).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">共形预测 共形预测（Conformal Prediction，CP）是机器学习中一个强大的统计框架，主要用于为预测提供置信度度量（Shafer &amp; Vovk，2008；Angelopoulos &amp; Bates，2021）。其独特之处在于，它能生成具有指定置信水平的预测区间，超越了单纯点估计的局限性。在分布外（Out-of-Distribution，OOD）检测场景中，共形预测框架尤其具有启发性：共形预测方法生成的更宽预测区间或更低置信水平可作为此类OOD数据的指标。尽管CP与OOD检测交叉领域的研究仍处于起步阶段（Kaur等人，2022a，b；Cai等人，2021），但在该领域应用共形预测框架的潜力巨大，值得进一步探索（表1；图3）。</div></div></div></div><div><div><div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="9" id="mark-71004abd-58d7-4389-b845-48142d6d34f2" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-8="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-8="0,0"></paragraphpositioning></div></div></div><div><!-- Media --><br></div><div><div><div>Table 1 Paper list for out-of-distribution detection<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">表1 分布外检测相关论文列表</div></div></div></div><div><br><div class="table-container"><table class="fixed-table"><tbody><tr><td>Sections</td><td>References</td></tr><tr><td colspan="2">Section 3.1 Classification</td></tr><tr><td colspan="2">Section 3.1.1 Output-based Methods</td></tr><tr><td>a: Training-free</td><td>Hendrycks and Gimpel (2017), Liang et al. (2018), Lee et al. (2018b), Liu et al. (2020), Sastry and Oore (2020), Wang et al. (2021), Zhang et al. (2023a), Sun et al. (2021b), Dong et al. (2022), Sun and Li (2022), Sun et al. (2022), Lin et al. (2021), Sastry and Oore (2019), Zhang et al. (2023a), Djurisic et al. (2023), Park et al. (2023b), Park et al. (2023a), Jiang et al. (2023b), Liu et al. (2023)</td></tr><tr><td>b: Training-based</td><td>DeVries and Taylor (2018), Wang et al. (2021, 2022b), Vyas et al. (2018), Bitterwolf et al. (2020), Chen et al. (2020b), Hein et al. (2019), Choi and Chung (2020), Chen et al. (2021c), Hein et al. (2019), Thulasidasan et al. (2019), Yun et al. (2019), DeVries and Taylor (2017), Hendrycks et al. (2019c, 2022c), Tack et al. (2020), Meinke and Hein (2019), Bibas et al. (2021), Lin et al. (2021), Dong et al. (2022), Hsu et al. (2020), Wei et al. (2022), Lee et al. (2018c), Huang and Li (2021), Linderman et al. (2023), Shalev et al. (2018), Fort et al. (2021), Gan (2021)</td></tr><tr><td colspan="2">Section 3.1.2 Outlier Exposure</td></tr><tr><td>a: Real Outliers</td><td>Hendrycks et al. (2019b), Dhamija et al. (2018), Yu and Aizawa (2019), Mohseni et al. (2020), Chen et al. (2021c), Thulasidasan et al. (2021), Papadopoulos et al. (2021), Chen et al. (2021c), Ming et al. (2022b), Li and Vasconcelos (2020), Zhang et al. (2023b), Yang et al. (2021), Lu et al. (2023), Shafaei et al. (2019), Katz-Samuels et al. (2022), Wang et al. (2023b)</td></tr><tr><td>b: Data Generation</td><td>Lee et al. (2018a), Vernekar et al. (2019), Sricharan et al. (2018), Jeong and Kim (2020), Du et al. (2022b), Tao et al. (2023), Wang et al. (2023c), Zheng et al. (2023), Du et al. (2022a)</td></tr><tr><td>Section 3.1.3: Gradient-based Methods</td><td>Liang et al. (2018), Huang et al. (2021), Igoe et al. (2022)</td></tr><tr><td>Section 3.1.4: Bayesian Models</td><td>Gal and Ghahramani (2016), Lakshminarayanan et al. (2017), Osawa et al. (2019), Malinin and Gales (2018, 2019), Nandy et al. (2020), Kim et al. (2021)</td></tr><tr><td>Section 3.1.5: OOD for Foundation Models</td><td>Hendrycks et al. (2019a, 2020), Fort et al. (2021), Ming and Li (2023), Miyai et al. (2023a,b), Lu et al. (2023), Esmaeilpour et al. (2022), Ming et al. (2022a), Wang et al. (2023a)</td></tr><tr><td>Section 3.2: Density-based Methods</td><td>Zong et al. (2018), Abati et al. (2019), Pidhorskyi et al. (2018), Deecke et al. (2018), Sabokrou et al. (2018), Lee et al. (2018b), Kobyzev et al. (2020), Zisselman and Tamar (2020), Kingma and Dhariwal (2018), Van Oord et al. (2016), Jiang et al. (2021a), Nalis- nick et al. (2018), Choi et al. (2018), Kirichenko et al. (2020), Ren et al. (2019), Serrà et al. (2020), Xiao et al. (2020), Wang et al. (2022a)</td></tr><tr><td>Section 3.3: Distance-based Methods</td><td>Lee et al. (2018b), Ren et al. (2021), Techapanurak et al. (2020), Chen et al. (2020c), Zaeemzadeh et al. (2021), Van Amersfoort et al. (2020), Huang et al. (2020a), Sun et al. (2022), Ming et al. (2023), Kim et al. (2023)</td></tr><tr><td>Section 3.4: Reconstruction-based Methods</td><td>Denouden et al. (2018), Zhou (2022), Yang et al. (2022c), Jiang et al. (2023a), Li et al. (2023b)</td></tr><tr><td>Section 3.5: Theoretical Analysis</td><td>Zhang et al. (2021), Morteza and Li (2022), Scheirer et al. (2013), Jain et al. (2014), Rudd et al. (2017), Liu et al. (2018a), Fang et al. (2021, 2022)</td></tr></tbody></table></div><div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;"><div class="table-container"><table class="fixed-table"><tbody><tr><td>章节</td><td>参考文献</td></tr><tr><td colspan="2">3.1节 分类</td></tr><tr><td colspan="2">3.1.1节 基于输出的方法</td></tr><tr><td>a: 免训练</td><td>亨德里克斯和金佩尔（Hendrycks and Gimpel，2017年）、梁等人（Liang et al.，2018年）、李等人（Lee et al.，2018b年）、刘等人（Liu et al.，2020年）、萨斯特里和奥雷（Sastry and Oore，2020年）、王等人（Wang et al.，2021年）、张等人（Zhang et al.，2023a年）、孙等人（Sun et al.，2021b年）、董等人（Dong et al.，2022年）、孙和李（Sun and Li，2022年）、孙等人（Sun et al.，2022年）、林等人（Lin et al.，2021年）、萨斯特里和奥雷（Sastry and Oore，2019年）、张等人（Zhang et al.，2023a年）、久里西奇等人（Djurisic et al.，2023年）、朴等人（Park et al.，2023b年）、朴等人（Park et al.，2023a年）、江等人（Jiang et al.，2023b年）、刘等人（Liu et al.，2023年）</td></tr><tr><td>b: 基于训练</td><td>德弗里斯和泰勒（DeVries and Taylor，2018年）、王等人（Wang et al.，2021年、2022b年）、维亚斯等人（Vyas et al.，2018年）、比特沃尔夫等人（Bitterwolf et al.，2020年）、陈等人（Chen et al.，2020b年）、海因等人（Hein et al.，2019年）、崔和钟（Choi and Chung，2020年）、陈等人（Chen et al.，2021c年）、海因等人（Hein et al.，2019年）、图拉萨迪桑等人（Thulasidasan et al.，2019年）、尹等人（Yun et al.，2019年）、德弗里斯和泰勒（DeVries and Taylor，2017年）、亨德里克斯等人（Hendrycks et al.，2019c年、2022c年）、塔克等人（Tack et al.，2020年）、迈因克和海因（Meinke and Hein，2019年）、比巴斯等人（Bibas et al.，2021年）、林等人（Lin et al.，2021年）、董等人（Dong et al.，2022年）、许等人（Hsu et al.，2020年）、魏等人（Wei et al.，2022年）、李等人（Lee et al.，2018c年）、黄和李（Huang and Li，2021年）、林德曼等人（Linderman et al.，2023年）、沙莱夫等人（Shalev et al.，2018年）、福特等人（Fort et al.，2021年）、甘（Gan，2021年）</td></tr><tr><td colspan="2">3.1.2节 异常值暴露</td></tr><tr><td>a: 真实异常值</td><td>亨德里克斯等人（Hendrycks et al.，2019b年）、达米贾等人（Dhamija et al.，2018年）、余和相泽（Yu and Aizawa，2019年）、莫赫森尼等人（Mohseni et al.，2020年）、陈等人（Chen et al.，2021c年）、图拉萨迪桑等人（Thulasidasan et al.，2021年）、帕帕多普洛斯等人（Papadopoulos et al.，2021年）、陈等人（Chen et al.，2021c年）、明等人（Ming et al.，2022b年）、李和瓦斯康塞洛斯（Li and Vasconcelos，2020年）、张等人（Zhang et al.，2023b年）、杨等人（Yang et al.，2021年）、陆等人（Lu et al.，2023年）、沙法伊等人（Shafaei et al.，2019年）、卡茨 - 塞缪尔斯等人（Katz - Samuels et al.，2022年）、王等人（Wang et al.，2023b年）</td></tr><tr><td>b: 数据生成</td><td>李等人（Lee et al.，2018a年）、韦尔内卡尔等人（Vernekar et al.，2019年）、斯里查兰等人（Sricharan et al.，2018年）、郑和平和金（Jeong and Kim，2020年）、杜等人（Du et al.，2022b年）、陶等人（Tao et al.，2023年）、王等人（Wang et al.，2023c年）、郑等人（Zheng et al.，2023年）、杜等人（Du et al.，2022a年）</td></tr><tr><td>3.1.3节：基于梯度的方法</td><td>梁等人（Liang et al.，2018年）、黄等人（Huang et al.，2021年）、伊戈等人（Igoe et al.，2022年）</td></tr><tr><td>3.1.4节：贝叶斯模型</td><td>加尔和加哈拉马尼（Gal and Ghahramani，2016年）、拉克什米纳拉亚南等人（Lakshminarayanan et al.，2017年）、大泽等人（Osawa et al.，2019年）、马利宁和盖尔斯（Malinin and Gales，2018年、2019年）、南迪等人（Nandy et al.，2020年）、金等人（Kim et al.，2021年）</td></tr><tr><td>3.1.5节：基础模型的分布外检测</td><td>亨德里克斯等人（Hendrycks et al.，2019a年、2020年）、福特等人（Fort et al.，2021年）、明和李（Ming and Li，2023年）、宫井等人（Miyai et al.，2023a年、b年）、陆等人（Lu et al.，2023年）、埃斯迈尔普尔等人（Esmaeilpour et al.，2022年）、明等人（Ming et al.，2022a年）、王等人（Wang et al.，2023a年）</td></tr><tr><td>3.2节：基于密度的方法</td><td>宗等人（2018年）、阿巴蒂等人（2019年）、皮德霍尔斯基等人（2018年）、迪克等人（2018年）、萨博克罗等人（2018年）、李等人（2018b）、科比泽夫等人（2020年）、齐塞尔曼和塔马尔（2020年）、金马和达里瓦尔（2018年）、范·奥尔德等人（2016年）、江等人（2021a）、纳利斯尼克等人（2018年）、崔等人（2018年）、基里琴科等人（2020年）、任等人（2019年）、塞拉等人（2020年）、肖等人（2020年）、王等人（2022a）</td></tr><tr><td>3.3节：基于距离的方法</td><td>李等人（2018b）、任等人（2021年）、泰查帕努拉克等人（2020年）、陈等人（2020c）、扎伊姆扎德等人（2021年）、范·阿默斯福特等人（2020年）、黄等人（2020a）、孙等人（2022年）、明等人（2023年）、金等人（2023年）</td></tr><tr><td>3.4节：基于重建的方法</td><td>德努登等人（2018年）、周（2022年）、杨等人（2022c）、江等人（2023a）、李等人（2023b）</td></tr><tr><td>3.5节：理论分析</td><td>张等人（2021年）、莫尔塔扎和李（2022年）、谢勒等人（2013年）、贾恩等人（2014年）、鲁德等人（2017年）、刘等人（2018a）、方等人（2021年，2022年）</td></tr></tbody></table></div></div><br><!-- Media --><br></div><h2><div><div>3 OOD Detection: Methodology<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3 分布外（OOD）检测：方法</div></div></div></h2><div><br></div><div><div><div>In this section, we introduce the methodology for OOD detection. Initially, we explore classification-based models in Sect. 3.1. These models primarily utilize the model's output, such as softmax scores, to identify OOD instances. We further examine outlier exposure-based methods that leverage external data sources and other types of methods. The later section is followed by density-based methods in Sect.3.2. Distance-based methods will be introduced in Sect.3.3. A brief discussion will be included at the end.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在本节中，我们将介绍分布外（OOD）检测的方法。首先，我们将在3.1节中探讨基于分类的模型。这些模型主要利用模型的输出，如softmax分数，来识别分布外（OOD）实例。我们还将进一步研究基于异常值暴露的方法，这些方法利用外部数据源，以及其他类型的方法。随后，我们将在3.2节中介绍基于密度的方法。基于距离的方法将在3.3节中介绍。最后将进行简要讨论。</div></div></div></div><div><br></div><h3><div><div>3.1 Classification-Based Methods<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.1 基于分类的方法</div></div></div></h3><div><br></div><div><div><div>Research on OOD detection originated from a simple baseline, that is, using the maximum softmax probability as the indicator score of ID-ness (Hendrycks &amp; Gimpel, 2017). Early OOD detection methods focus on deriving improved OOD scores based on the output of neural networks.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">分布外（OOD）检测的研究源于一个简单的基线，即使用最大softmax概率作为分布内（ID）程度的指标分数（亨德里克斯和金佩尔，2017年）。早期的分布外（OOD）检测方法侧重于根据神经网络的输出来推导改进的分布外（OOD）分数。</div></div></div></div><div><br></div><h4><div><div>3.1.1 Output-Based Methods<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.1.1 基于输出的方法</div></div></div></h4><div><br></div><div><div><div>a. Post-Hoc Detection Post-hoc methods have the advantage of being easy to use without modifying the training procedure and objective. The property can be important for the adoption of OOD detection methods in real-world production environments, where the overhead cost of retraining can be prohibitive. Early work ODIN (Liang et al., 2018) is a post-hoc method that uses temperature scaling and input perturbation to amplify the ID/OOD separability. Key to the method, a sufficiently large temperature has a strong smoothing effect that transforms the softmax score back to the logit space-which effectively distinguishes ID vs. OOD. Note that this is different from confidence calibration, where a much milder <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2759" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math></mjx-assistive-mml></mjx-container> is employed. While calibration focuses on representing the true correctness likelihood of ID data only, the ODIN score is designed to maximize the gap between ID and OOD data and may no longer be meaningful from a predictive confidence standpoint. Built on the insights, recent work (Liu et al., 2020; Lin et al., 2021) proposed using an energy score for OOD detection, which enjoys theoretical interpretation from a likelihood perspective (Morteza &amp; Li, 2022). Test samples with lower energy are considered ID and vice versa. JointEnergy score (Wang et al., 2021) is then proposed to perform OOD detection for multi-label classification networks. The most recent work SHE (Zhang et al., 2023a) uses stored patterns that represent classes to measure the discrepancy of unseen data for OOD detection, which is hyperparameter-free and computationally efficient compared to classic energy methods. Techniques such as layer-wise Mahalanobis distance (Lee et al., 2018b) and Gram Matrix (Sastry &amp; Oore, 2020) are implemented for better-hidden feature quality to perform density estimation.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">a. 事后检测 事后检测方法的优点是易于使用，无需修改训练过程和目标。这一特性对于在现实生产环境中采用分布外（OOD）检测方法至关重要，因为在这些环境中，重新训练的开销可能过高。早期的工作ODIN（梁等人，2018年）是一种事后检测方法，它使用温度缩放和输入扰动来增强分布内（ID）/分布外（OOD）的可分离性。该方法的关键在于，足够大的温度具有很强的平滑效果，能将softmax分数转换回对数几率空间，从而有效区分分布内（ID）和分布外（OOD）。请注意，这与置信度校准不同，置信度校准采用的是温和得多的<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2760" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math></mjx-assistive-mml></mjx-container>。虽然校准仅关注表示分布内（ID）数据的真实正确可能性，但ODIN分数旨在最大化分布内（ID）和分布外（OOD）数据之间的差距，从预测置信度的角度来看，它可能不再有意义。基于这些见解，近期的工作（刘等人，2020年；林等人，2021年）提出使用能量分数进行分布外（OOD）检测，从似然性的角度来看，该方法具有理论解释（莫尔塔扎和李，2022年）。能量较低的测试样本被视为分布内（ID）样本，反之则为分布外（OOD）样本。随后，联合能量分数（王等人，2021年）被提出用于多标签分类网络的分布外（OOD）检测。最新的工作SHE（张等人，2023a）使用表示类别的存储模式来衡量未见数据的差异，以进行分布外（OOD）检测，与经典的能量方法相比，该方法无需超参数且计算效率高。为了获得更好的隐藏特征质量以进行密度估计，还采用了诸如逐层马氏距离（李等人，2018b）和格拉姆矩阵（萨斯特里和奥雷，2020年）等技术。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="10" id="mark-80fbf8b4-3710-4766-b876-90968714626c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-9="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-9="0,0"></paragraphpositioning></div></div></div><div><!-- Media --><br><!-- figureText: Classification-based Density-based Distance-based Reconstruction-based MCD GRAM G-ODIN GradNorm MOS LLR DUQ CSI EBO ReACT UDG 2019 2020 2021 SHE CIDER GEN MixOE Relation NPOS ASH \( \mathbf{{MCM}} \) NNGUIDE LoCoOp 2023 2008 Learning with Reject Option ODIN MDS OE Anomaly Detection Survey MSP 2014 Novelty Detection Survey ConfBranch 2016 Open Set Recognition Precursor Studies 2017 2018 VOS STUD VIM KNN DICE READ MLS KLM Watermarking LogitNorm MOOD 2022 --><br></div><img src="https://cdn.noedgeai.com/0195d2b3-e92e-7da1-8c3c-990b96d6d818_9.jpg?x=147&amp;y=146&amp;w=1461&amp;h=478&amp;r=0" alt="https://cdn.noedgeai.com/0195d2b3-e92e-7da1-8c3c-990b96d6d818_9.jpg?x=147&amp;y=146&amp;w=1461&amp;h=478&amp;r=0"><div><br></div><div><div><div>Fig. 3 Timeline for representative OOD detection methodologies. Different colors indicate different categories of methodologies. Each method has its corresponding reference (inconspicuous white) in the lower right corner. Methods with high citations and open-source code are prioritized for inclusion in this figure (Color figure online)<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">图3 代表性分布外（OOD）检测方法的时间线。不同颜色表示不同类别的方法。每种方法在右下角都有其相应的参考文献（不显眼的白色）。本图优先纳入引用次数高且有开源代码的方法（彩色图见在线版本）</div></div></div></div><div><br><!-- Media --><br></div><div><div><div>Recently, one fundamental cause of the overconfidence issue on OOD data has been revealed that using mismatched BatchNorm statistics-that are estimated on ID data yet blindly applied to the OOD data in testing-can trigger abnormally high unit activations and model output accordingly (Sun et al., 2021b). Therefore, ReAct (Sun et al., 2021b) proposes truncating the high activations, which establishes strong post-hoc detection performance and further boosts the performance of existing scoring functions. Similarly, NMD (Dong et al., 2022) uses the activation means from BatchNorm layers for ID/OOD discrepancy. While ReAct considers activation space, (Sun &amp; Li, 2022) proposes a weight sparsification-based OOD detection framework termed DICE. DICE ranks weights based on a measure of contribution and selectively uses the most salient weights to derive the output for OOD detection. By pruning away noisy signals, DICE provably reduces the output variance for OOD data, resulting in a sharper output distribution and stronger separability from ID data. In a similar vein, ASH (Djurisic et al., 2023) also targets the activation space but adopts a different strategy. It removes a significant portion (e.g., 90%) of an input's feature representations from a late layer based on a top-K criterion, followed by adjusting the remaining activations (e.g., 10%) either by scaling or assigning constant values, yielding surprisingly effective results.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">最近，研究揭示了在分布外（OOD）数据上出现过度自信问题的一个根本原因，即使用不匹配的批量归一化（BatchNorm）统计量——这些统计量是在分布内（ID）数据上估计的，但在测试时盲目应用于分布外（OOD）数据——会相应地引发异常高的单元激活和模型输出（孙等人，2021b）。因此，ReAct（孙等人，2021b）提出截断高激活值，这建立了强大的事后检测性能，并进一步提升了现有评分函数的性能。同样，NMD（董等人，2022年）使用批量归一化（BatchNorm）层的激活均值来衡量分布内（ID）/分布外（OOD）的差异。当ReAct考虑激活空间时，（孙和李，2022年）提出了一个基于权重稀疏化的分布外（OOD）检测框架，称为DICE。DICE根据贡献度量对权重进行排序，并选择性地使用最显著的权重来推导用于分布外（OOD）检测的输出。通过去除噪声信号，DICE可证明地降低了分布外（OOD）数据的输出方差，从而产生更尖锐的输出分布，并增强了与分布内（ID）数据的可分离性。同样，ASH（久里西奇等人，2023年）也针对激活空间，但采用了不同的策略。它根据前K准则从较深的层中移除输入特征表示的很大一部分（例如90%），然后通过缩放或赋予常数值来调整剩余的激活值（例如10%），从而产生了惊人的有效结果。</div></div></div></div><div><br></div><div><div><div>b. Training-Based Methods With the training phase, confidence can be developed via designing a confidence-estimating branch (DeVries &amp; Taylor, 2018) or class (Wang et al., 2021), ensembling with leaving-out strategy (Vyas et al., 2018), adversarial training (Bitterwolf et al., 2020; Chen et al., 2020b; Hein et al., 2019; Choi &amp; Chung, 2020; Chen et al., 2021c), stronger data augmentation (Hein et al., 2019; Thulasidasan et al., 2019; Yun et al., 2019; DeVries &amp; Taylor, 2017; Hendrycks et al., 2019c, 2022c), pretext training (Tack et al., 2020), better uncertainty modeling (Meinke &amp; Hein, 2019; Bibas et al., 2021), input-level manipulation (Liang et al., 2018; Wang et al., 2022b), and utilizing feature or statistics from the intermediate-layer features (Lin et al., 2021; Dong et al., 2022). Especially, to enhance the sensitivity to covariate shift, some methods focus on the hidden representations in the middle layers of neural networks. Generalized ODIN, or G-ODIN (Hsu et al., 2020) extended ODIN (Liang et al., 2018) by using a specialized training objective termed DeConf-C and choosing hyperparameters such as perturbation magnitude on ID data. Note that we do not categorize G-ODIN as post-hoc method as it requires model retraining. Recent work (Wei et al., 2022) shows that the overconfidence issue can be mitigated through Logit Normalization (Logit-Norm), a simple fix to the common cross-entropy loss by enforcing a constant vector norm on the logits in training. Trained with LogitNorm, neural networks produce highly distinguishable confidence scores between in- and out-of-distribution data.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">b. 基于训练的方法 在训练阶段，可以通过设计一个置信度估计分支（DeVries &amp; Taylor，2018）或类别（Wang 等人，2021）、采用留一策略进行集成（Vyas 等人，2018）、对抗训练（Bitterwolf 等人，2020；Chen 等人，2020b；Hein 等人，2019；Choi &amp; Chung，2020；Chen 等人，2021c）、更强的数据增强（Hein 等人，2019；Thulasidasan 等人，2019；Yun 等人，2019；DeVries &amp; Taylor，2017；Hendrycks 等人，2019c，2022c）、前置训练（Tack 等人，2020）、更好的不确定性建模（Meinke &amp; Hein，2019；Bibas 等人，2021）、输入级操作（Liang 等人，2018；Wang 等人，2022b）以及利用中间层特征的特征或统计信息（Lin 等人，2021；Dong 等人，2022）来提高置信度。特别是，为了增强对协变量偏移的敏感性，一些方法专注于神经网络中间层的隐藏表示。广义 ODIN 或 G - ODIN（Hsu 等人，2020）通过使用一种称为 DeConf - C 的专门训练目标，并在内部数据（ID data）上选择诸如扰动幅度等超参数，对 ODIN（Liang 等人，2018）进行了扩展。请注意，我们不将 G - ODIN 归类为事后方法，因为它需要重新训练模型。最近的工作（Wei 等人，2022）表明，通过对数归一化（Logit - Norm）可以缓解过度自信问题，这是一种通过在训练中对对数进行恒定向量归一化来对常见交叉熵损失进行的简单修正。使用对数归一化训练的神经网络在分布内和分布外数据之间产生高度可区分的置信度分数。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="11" id="mark-bfdb163c-867e-43e1-8328-490e3a024595" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-10="0,0"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-10="0,0"></paragraphpositioning></div></div></div><div><div><div>Some works redesign the label space to achieve good OOD detection performance. While commonly used to encode categorical information for classification, the one-hot encoding ignores the inherent relationship among labels. For example, it is unreasonable to have a uniform distance between dog and cat vs. dog and car. To this end, several works attempt to use information in the label space for OOD detection. Some works arrange the large semantic space into a hierarchical taxonomy of known classes (Lee et al., 2018c; Huang et al., 2021; Linderman et al., 2023). Under the redesigned label architecture, top-down classification strategy (Lee et al., 2018c; Linderman et al., 2023) and group softmax training (Huang et al., 2021) are demonstrated effective. Another set of works uses word embeddings to automatically construct the label space. In Shalev et al. (2018), the sparse one-hot labels are replaced with several dense word embeddings from different NLP models, forming multiple regression heads for robust training. When testing, the label, which has the minimal distance to all the embedding vectors from different heads, will be considered as the prediction. If the minimal distance crosses above the threshold, the sample would be classified as "novel". Recent works further take the image features from language-image pre-training models (Radford et al., 2021) to better detect novel classes, where the image encoding space also contains rich information from the language space (Fort et al., 2021; Gan, 2021).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">一些工作重新设计标签空间以实现良好的分布外（OOD）检测性能。虽然独热编码（one - hot encoding）通常用于对分类的类别信息进行编码，但它忽略了标签之间的内在关系。例如，狗和猫之间的距离与狗和汽车之间的距离相同是不合理的。为此，一些工作尝试利用标签空间中的信息进行 OOD 检测。一些工作将大的语义空间安排成已知类别的层次分类法（Lee 等人，2018c；Huang 等人，2021；Linderman 等人，2023）。在重新设计的标签架构下，自上而下的分类策略（Lee 等人，2018c；Linderman 等人，2023）和分组 softmax 训练（Huang 等人，2021）被证明是有效的。另一组工作使用词嵌入来自动构建标签空间。在 Shalev 等人（2018）的研究中，稀疏的独热标签被来自不同自然语言处理（NLP）模型的几个密集词嵌入所取代，形成多个回归头以进行稳健训练。在测试时，与来自不同头的所有嵌入向量距离最小的标签将被视为预测结果。如果最小距离超过阈值，则该样本将被分类为“新类别”。最近的工作进一步利用语言 - 图像预训练模型（Radford 等人，2021）的图像特征来更好地检测新类别，其中图像编码空间也包含来自语言空间的丰富信息（Fort 等人，2021；Gan，2021）。</div></div></div></div><div><br></div><h4><div><div>3.1.2 Methods with Outlier Exposure<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.1.2 带有离群值暴露的方法</div></div></div></h4><div><br></div><div><div><div>a. Real Outliers Another branch of OOD detection methods makes use of a set of collected OOD samples, or "outlier", during training to help models learn ID/OOD discrepancy. Starting from the concurrent baselines that encourage a flat/high-entropic prediction on given OOD samples (Hendrycks et al., 2019b; Dhamija et al., 2018) and suppressing OOD feature magnitudes (Dhamija et al., 2018), a follow-up work, MCD (Yu &amp; Aizawa, 2019) uses a network with two branches, between which entropy discrepancy is enlarged for OOD training data. Another straightforward approach with outlier exposure spares an extra abstention (or rejection class) and considers all the given OOD samples in this class (Mohseni et al., 2020; Chen et al., 2021c; Thulasi-dasan et al., 2021). A later work OECC (Papadopoulos et al., 2021) noticed that an extra regularization for confidence calibration introduces additional improvement for OE. To effectively utilize the given, usually massive, OOD samples, some work use outlier mining (Chen et al., 2021c; Ming et al., 2022b) and adversarial resampling (Li &amp; Vasconcelos, 2020) approaches to obtain a compact yet representative set. In cases where the meaningful "near"-OOD images are not available, MixOE (Zhang et al., 2023b) proposes to interpolate between ID and "far"-OOD images to obtain informative outliers for better regularization. Other works consider a more practical scenario where given OOD samples contain ID samples, therefore using pseudo-labeling (Mohseni et al., 2020) or ID filtering methods (Yang et al., 2021) with optimal transport scheme (Lu et al., 2023) to reduce the interference of ID data. In general, OOD detection with outlier exposure can reach a much better performance.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">a. 真实离群值 另一类分布外（OOD）检测方法在训练过程中利用一组收集到的OOD样本，即“离群值”，来帮助模型学习分布内（ID）/OOD的差异。从鼓励对给定OOD样本进行平坦/高熵预测（亨德里克斯等人，2019b；达米贾等人，2018）并抑制OOD特征幅度（达米贾等人，2018）的同期基线方法开始，后续工作MCD（于和相泽，2019）使用了一个具有两个分支的网络，在这两个分支之间扩大OOD训练数据的熵差异。另一种直接的离群值暴露方法预留了一个额外的弃权（或拒绝类别），并将所有给定的OOD样本归为该类别（莫赫塞尼等人，2020；陈等人，2021c；图拉西 - 达桑等人，2021）。后来的工作OECC（帕帕多普洛斯等人，2021）注意到，用于置信度校准的额外正则化对离群值暴露（OE）方法有额外的改进。为了有效利用通常数量庞大的给定OOD样本，一些工作采用离群值挖掘（陈等人，2021c；明等人，2022b）和对抗性重采样（李和瓦斯康塞洛斯，2020）方法来获得一个紧凑但具有代表性的集合。在没有有意义的“近”OOD图像的情况下，MixOE（张等人，2023b）提出在ID和“远”OOD图像之间进行插值，以获得信息丰富的离群值，从而实现更好的正则化。其他工作考虑了一种更实际的场景，即给定的OOD样本中包含ID样本，因此使用伪标签法（莫赫塞尼等人，2020）或ID过滤方法（杨等人，2021）以及最优传输方案（陆等人，2023）来减少ID数据的干扰。一般来说，使用离群值暴露的OOD检测可以达到更好的性能。</div></div></div></div><div><br></div><div><div><div>In typical outlier exposure setups, the auxiliary outlier data used during training is assumed to be representative of the true OOD data encountered at test time. However, research shows that the performance can be largely affected by the correlations between given and real OOD samples (Shafaei et al., 2019). Wang et al. (2023c) and Katz-Samuels et al. (2022) both highlight that the discrepancy between surrogate and test-time OOD distributions can hinder the effectiveness of outlier exposure methods. To address the issue, recent work (Katz-Samuels et al., 2022) proposes a novel framework that enables effectively exploiting unlabeled in-the-wild data for OOD detection. Unlabeled wild data is frequently available since it is produced essentially for free whenever deploying an existing classifier in a real-world system. This setting can be viewed as training OOD detectors in their natural habitats, which provide a much better match to the true test time distribution than data collected offline. Wang et al. (2023b) propose an approach to craft an augmented set of OOD distributions around the training outliers to mitigate this distribution shift. Accounting for potential shifts in the OOD data distribution, in addition to shifts in the ID data, is an important consideration for developing robust OOD detectors that can handle the complexities of real-world settings.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在典型的离群值暴露设置中，训练期间使用的辅助离群值数据被假定能够代表测试时遇到的真实OOD数据。然而，研究表明，给定的OOD样本与真实OOD样本之间的相关性会在很大程度上影响检测性能（沙法伊等人，2019）。王等人（2023c）和卡茨 - 塞缪尔斯等人（2022）都强调，替代OOD分布与测试时OOD分布之间的差异会阻碍离群值暴露方法的有效性。为了解决这个问题，近期的工作（卡茨 - 塞缪尔斯等人，2022）提出了一个新颖的框架，该框架能够有效利用未标记的自然数据进行OOD检测。未标记的自然数据通常很容易获取，因为在现实世界系统中部署现有分类器时，这些数据本质上是免费产生的。这种设置可以看作是在自然环境中训练OOD检测器，与离线收集的数据相比，它能更好地匹配真实测试时的分布。王等人（2023b）提出了一种方法，在训练离群值周围构建一组增强的OOD分布，以减轻这种分布偏移。除了考虑ID数据的潜在偏移外，考虑OOD数据分布的潜在偏移对于开发能够处理现实世界复杂情况的鲁棒OOD检测器是一个重要的考量因素。</div></div></div></div><div><br></div><div><div><div>b. Outlier Data Generation The outlier exposure approaches impose a strong assumption on the availability of OOD training data, which can be infeasible in practice. When no OOD sample is available, some methods attempt to synthesize OOD samples to enable ID/OOD separability. Existing works leverage GANs to generate OOD training samples and force the model predictions to be uniform (Lee et al., 2018a), generate boundary samples in the low-density region (Vernekar et al., 2019), or similarly, high-confidence OOD samples (Sricharan et al., 2018), or using meta-learning the update sample generation (Jeong &amp; Kim, 2020). However, synthesizing images in the high-dimensional pixel space can be difficult to optimize. Recent work VOS (Du et al., 2022b) proposed synthesizing virtual outliers from the low-likelihood region in the feature space, which is more tractable given lower dimensionality. While VOS (Du et al., 2022b) is a parametric approach that models the feature space as a class-conditional Gaussian distribution, NPOS (Tao et al., 2023) also generates outlier ID data but in a nonparametric approach. Noticing the generated OOD data could be incorrect or irrelevant, DOE (Wang et al., 2023c) synthesizes hard OOD data that leads to worst judgments to train the OOD detector with a min-max learning scheme, and ATOL (Zheng et al., 2023) uses auxiliary task to relieve the mistaken OOD generation. In object detection, (Du et al., 2022a) proposes synthesizing unknown objects from videos in the wild using spatial-temporal unknown distillation.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">b. 离群数据生成 离群暴露方法对分布外（OOD）训练数据的可用性提出了很强的假设，而这在实践中可能并不可行。当没有可用的OOD样本时，一些方法试图合成OOD样本以实现分布内（ID）/OOD的可分离性。现有工作利用生成对抗网络（GANs）来生成OOD训练样本，并迫使模型预测具有均匀性（Lee等人，2018a），在低密度区域生成边界样本（Vernekar等人，2019），或者类似地，生成高置信度的OOD样本（Sricharan等人，2018），或者使用元学习来更新样本生成（Jeong和Kim，2020）。然而，在高维像素空间中合成图像可能难以优化。近期的工作VOS（Du等人，2022b）提出从特征空间中的低似然区域合成虚拟离群点，鉴于其维度较低，这种方法更易于处理。虽然VOS（Du等人，2022b）是一种将特征空间建模为类别条件高斯分布的参数化方法，但NPOS（Tao等人，2023）也生成离群ID数据，不过采用的是非参数化方法。考虑到生成的OOD数据可能不正确或不相关，DOE（Wang等人，2023c）合成会导致最差判断的难OOD数据，以通过最小 - 最大学习方案训练OOD检测器，而ATOL（Zheng等人，2023）使用辅助任务来缓解错误的OOD生成。在目标检测中，（Du等人，2022a）提出使用时空未知蒸馏从野外视频中合成未知目标。</div></div></div></div><div><div><div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="12" id="mark-fae7e727-87fb-4944-bea3-2282b09dd83c" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-11="0,0"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-11="0,0"></paragraphpositioning></div></div></div><h4><div><div>3.1.3 Gradient-Based Methods<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.1.3 基于梯度的方法</div></div></div></h4><div><br></div><div><div><div>Existing OOD detection approaches primarily rely on the output (Sect.3.1) or feature space for deriving OOD scores, while overlooking information from the gradient space. ODIN (Liang et al., 2018) first explored using gradient information for OOD detection. In particular, ODIN proposed using input pre-processing by adding small perturbations obtained from the input gradients. The goal of ODIN perturbations is to increase the softmax score of any given input by reinforcing the model's belief in the predicted label. Ultimately the perturbations have been found to create a greater gap between the softmax scores of ID and OOD inputs, thus making them more separable and improving the performance of OOD detection. While ODIN only uses gradients implicitly through input perturbation, recent work proposed GradNorm (Huang et al., 2021) which explicitly derives a scoring function from the gradient space. GradNorm employs the vector norm of gradients, backpropagated from the KL divergence between the softmax output and a uniform probability distribution. A recent research (Igoe et al., 2022) demonstrates that while gradient-based methods are effective, their success does not necessarily depend on gradients, but rather on the magnitude of learned feature embeddings and predicted output distribution.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">现有的OOD检测方法主要依赖输出（3.1节）或特征空间来推导OOD分数，而忽略了梯度空间的信息。ODIN（Liang等人，2018）首次探索了使用梯度信息进行OOD检测。具体而言，ODIN提出通过添加从输入梯度获得的小扰动来进行输入预处理。ODIN扰动的目标是通过强化模型对预测标签的置信度来提高任何给定输入的softmax分数。最终发现，这些扰动能够在ID和OOD输入的softmax分数之间产生更大的差距，从而使它们更易于分离，并提高OOD检测的性能。虽然ODIN仅通过输入扰动隐式地使用梯度，但近期的工作提出了GradNorm（Huang等人，2021），它从梯度空间显式地推导了一个评分函数。GradNorm采用从softmax输出和均匀概率分布之间的KL散度反向传播得到的梯度向量范数。最近的一项研究（Igoe等人，2022）表明，虽然基于梯度的方法是有效的，但它们的成功并不一定依赖于梯度，而是依赖于学习到的特征嵌入的大小和预测输出分布。</div></div></div></div><div><br></div><h4><div><div>3.1.4 Bayesian Models<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.1.4 贝叶斯模型</div></div></div></h4><div><br></div><div><div><div>A Bayesian model is a statistical model that implements Bayes' rule to infer all uncertainty within the model (Jaynes, 1986). The most representative method is the Bayesian neural network (Neal, 2012), which draws samples from the posterior distribution of the model via MCMC (Gamer-man &amp; Lopes, 2006), Laplace methods (Mackay, 1992; Foong et al., 2020) and variational inference (Peterson &amp; Hartman, 1989), forming the epistemic uncertainty of the model prediction. However, their obvious shortcomings of inaccurate predictions (Wenzel et al., 2020) and high computational costs (Gelman, 2008) prevent them from wide adoption in practice. Recent works attempt several less principled approximations including MC-dropout (Gal &amp; Ghahramani, 2016) and deep ensembles (Dietterich, 2000; Lakshminarayanan et al., 2017; Maddox et al., 2019) for faster and better estimates of uncertainty. These methods are less competitive for OOD uncertainty estimation. Further exploration takes natural-gradient variational inference and enables practical and affordable modern deep learning training while preserving the benefits of Bayesian principles (Osawa et al., 2019). Dirichlet Prior Network (DPN) is also used for OOD detection with an uncertainty modeling of three different sources of uncertainty: model uncertainty, data uncertainty, and distributional uncertainty, and form a line of works (Malinin &amp; Gales, 2018, 2019; Nandy et al., 2020). Recently, the Bayesian hypothesis test has been used to formulate OOD detection, with upweighting method and Hessian approximation for scalability (Kim et al., 2021).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">贝叶斯模型是一种应用贝叶斯规则来推断模型内所有不确定性的统计模型（Jaynes，1986）。最具代表性的方法是贝叶斯神经网络（Neal，2012），它通过马尔可夫链蒙特卡罗（MCMC）方法（Gamerman和Lopes，2006）、拉普拉斯方法（Mackay，1992；Foong等人，2020）和变分推断（Peterson和Hartman，1989）从模型的后验分布中抽取样本，形成模型预测的认知不确定性。然而，它们明显的缺点，如预测不准确（Wenzel等人，2020）和计算成本高（Gelman，2008），阻碍了它们在实践中的广泛应用。近期的工作尝试了几种不太严谨的近似方法，包括蒙特卡罗随机失活（MC - dropout）（Gal和Ghahramani，2016）和深度集成（Dietterich，2000；Lakshminarayanan等人，2017；Maddox等人，2019），以更快、更好地估计不确定性。这些方法在OOD不确定性估计方面竞争力较弱。进一步的探索采用自然梯度变分推断，在保留贝叶斯原理优势的同时，实现了实用且经济的现代深度学习训练（Osawa等人，2019）。狄利克雷先验网络（DPN）也用于OOD检测，它对三种不同来源的不确定性进行建模：模型不确定性、数据不确定性和分布不确定性，并形成了一系列相关工作（Malinin和Gales，2018，2019；Nandy等人，2020）。最近，贝叶斯假设检验已被用于制定OOD检测方法，并采用加权方法和海森矩阵近似以提高可扩展性（Kim等人，2021）。</div></div></div></div><div><br></div><h4><div><div>3.1.5 OOD Detection for Foundation Models<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.1.5 基础模型的OOD检测</div></div></div></h4><div><br></div><div><div><div>Foundation models (Bommasani et al., 2021), notably large-scale vision-language models (Radford et al., 2021), have demonstrated exceptional performance in a variety of downstream tasks. Their success is largely attributed to extensive pre-training on large-scale datasets. Several works (Hendrycks et al., 2019a; Fort et al., 2021; Hendrycks et al., 2020) reveal that well-pretrained models can significantly enhance OOD detection, particularly in challenging scenarios.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基础模型（Bommasani等人，2021年），尤其是大规模视觉语言模型（Radford等人，2021年），在各种下游任务中表现出了卓越的性能。它们的成功在很大程度上归功于在大规模数据集上进行的广泛预训练。多项研究（Hendrycks等人，2019a；Fort等人，2021年；Hendrycks等人，2020年）表明，经过良好预训练的模型可以显著增强分布外（OOD）检测能力，特别是在具有挑战性的场景中。</div></div></div></div><div><br></div><div><div><div>However, adapting (tuning) these models for downstream tasks with specific semantic (label) space in the training data remains a challenge, as simple approaches such as linear probing, prompt tuning (Zhou et al., 2022a, b; Jia et al., 2022), and adaptor-style fine-tuning methods (Gao et al., 2023) do not have good results on OOD detection. Dong et al. (2023) establish a comprehensive few-shot OOD detection benchmark, demonstrating the superiority of parameter-efficient fine-tuning strategies over conventional techniques. They propose a novel method called Domain-Specific and General Knowledge Fusion (DSGF) to strengthen fine-tuned features with original pre-trained features, significantly enhancing few-shot OOD detection capabilities. To advance the problem, a thorough investigation (Ming &amp; Li, 2023) examines how fine-tuned vision-language models are performed. Additionally, recent research (Miyai et al., 2023a) highlights the impact of large-scale pretraining data and provides a systematic study on pretraining strategies on OOD detection performance. On a technical front, LoCoOp (Miyai et al., 2023b) introduces OOD regularization to a subset of CLIP’s local features identified as OOD, enhancing prompt learning for better ID and OOD differentiation, and LSA (Lu et al., 2023) uses a bidirectional prompt customization mechanism to enhance the image-text alignment.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">然而，要使这些模型适应（微调）训练数据中具有特定语义（标签）空间的下游任务仍然是一项挑战，因为诸如线性探测、提示微调（Zhou等人，2022a，b；Jia等人，2022年）和适配器式微调方法（Gao等人，2023年）等简单方法在OOD检测方面效果不佳。Dong等人（2023年）建立了一个全面的少样本OOD检测基准，证明了参数高效微调策略优于传统技术。他们提出了一种名为特定领域与通用知识融合（DSGF）的新方法，用原始预训练特征强化微调后的特征，显著增强了少样本OOD检测能力。为了推进这一问题的研究，一项深入调查（Ming和Li，2023年）研究了微调后的视觉语言模型的性能。此外，近期研究（Miyai等人，2023a）强调了大规模预训练数据的影响，并对预训练策略对OOD检测性能的影响进行了系统研究。在技术方面，LoCoOp（Miyai等人，2023b）将OOD正则化引入到被识别为OOD的CLIP局部特征子集中，增强了提示学习，以便更好地区分分布内（ID）和OOD样本，而LSA（Lu等人，2023年）则使用双向提示定制机制来增强图像 - 文本对齐。</div></div></div></div><div><div><div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="13" id="mark-cf936e42-4632-419e-b5bb-a72d54f15344" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-12="0,0"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-12="0,0"></paragraphpositioning></div></div></div><div><div><div>The strong zero-shot learning capabilities of models like CLIP (Radford et al., 2021) also open avenues for zero-shot OOD detection. This new setting aims to categorize known class samples and detect samples that do not belong to any of the known classes, where known classes are represented solely through textual descriptions or class names, eliminating the need for explicit training on these classes. Addressing this, ZOC (Esmaeilpour et al., 2022) trains a decoder based on CLIP's visual encoder to create candidate labels for OOD detection. While ZOC is computationally intensive and data-demanding, MCM (Ming et al., 2022a) opts for soft-max scaling to align visual features with textual concepts for OOD detection. Jiang et al. (2023c) propose NegLabel, which introduces massive negative labels exhibiting significant semantic differences from ID labels, determining whether an image is OOD by comparing its affinity towards ID and negative labels. Bai et al. (2023) construct ID-like outliers using CLIP and propose an ID-like prompt learning framework to identify challenging OOD samples. Nie et al. (2023) propose to learn a set of negative prompts for each class, which are leveraged along with learned positive prompts to measure similarity and dissimilarity in the feature space simultaneously, enabling more accurate detection of OOD samples. A recent advancement, CLIPN (Wang et al., 2023a), innovatively integrates a "no" logic in OOD detection. Utilizing new prompts and a text encoder, along with novel opposite loss functions, CLIPN effectively tackles the challenge of identifying hard-to-distinguish OOD samples. This development marks a significant stride in enhancing the precision of OOD detection in complex scenarios.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">像CLIP（Radford等人，2021年）这样的模型强大的零样本学习能力也为零样本OOD检测开辟了新途径。这种新的设置旨在对已知类别样本进行分类，并检测不属于任何已知类别的样本，其中已知类别仅通过文本描述或类别名称来表示，无需对这些类别进行显式训练。针对这一问题，ZOC（Esmaeilpour等人，2022年）基于CLIP的视觉编码器训练了一个解码器，以创建用于OOD检测的候选标签。虽然ZOC计算量大且对数据要求高，但MCM（Ming等人，2022a）选择使用soft - max缩放来使视觉特征与文本概念对齐，以进行OOD检测。Jiang等人（2023c）提出了NegLabel方法，该方法引入了与ID标签具有显著语义差异的大量负标签，通过比较图像与ID标签和负标签的亲和度来确定图像是否为OOD。Bai等人（2023年）使用CLIP构建类似ID的离群值，并提出了一个类似ID的提示学习框架来识别具有挑战性的OOD样本。Nie等人（2023年）提议为每个类别学习一组负提示，并将其与学习到的正提示一起用于同时测量特征空间中的相似性和差异性，从而能够更准确地检测OOD样本。最近的一项进展，CLIPN（Wang等人，2023a）在OOD检测中创新性地集成了“否”逻辑。CLIPN利用新的提示和文本编码器，以及新颖的对立损失函数，有效地解决了识别难以区分的OOD样本这一难题。这一进展标志着在复杂场景中提高OOD检测精度方面迈出了重要一步。</div></div></div></div><div><br></div><h3><div><div>3.2 Density-Based Methods<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.2 基于密度的方法</div></div></div></h3><div><br></div><div><div><div>Density-based methods in OOD detection explicitly model the in-distribution with some probabilistic models, and flag test data in low-density regions as OOD. Although OOD detection can be different from AD in that multiple classes exist in the in-distribution, density estimation methods used for AD in Sect.4.2 can be directly adapted to OOD detection by unifying the ID data as a whole (Zong et al., 2018; Abati et al., 2019; Pidhorskyi et al., 2018; Deecke et al., 2018; Sabokrou et al., 2018). When the ID contains multiple classes, class-conditional Gaussian distribution can explicitly model the in-distribution so that the OOD samples can be identified based on their likelihoods (Lee et al., 2018b). Flow-based methods (Kobyzev et al., 2020; Zisselman &amp; Tamar, 2020; Kingma &amp; Dhariwal, 2018; Van Oord et al., 2016; Jiang et al., 2021a) can also be used for probabilistic modeling. While directly estimating the likelihood seems like a natural approach, some works (Nalisnick et al., 2018; Choi et al., 2018; Kirichenko et al., 2020) find that probabilistic models sometimes assign a higher likelihood for the OOD sample. Several works attempt to solve the problems using likelihood ratio (Ren et al., 2019). Serrà et al. (2020) finds that the likelihood exhibits a strong bias towards the input complexity and proposes a likelihood ratio-based method to compensate for the influence of input complexity. Recent methods turn to new scores such as likelihood regret (Xiao et al., 2020) or an ensemble of multiple density models (Choi et al., 2018). To directly model the density of semantic space, SEM score is used with a simple combination of density estimation in the low-level and high-level space (Yang et al., 2022b). Overall, generative models can be prohibitively challenging to train and optimize, and the performance can often lag behind the classification-based approaches (Sect. 3.1).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在离群分布（OOD）检测中，基于密度的方法使用一些概率模型对分布内数据进行显式建模，并将低密度区域的测试数据标记为离群分布数据。尽管OOD检测与异常检测（AD）有所不同，因为分布内存在多个类别，但第4.2节中用于AD的密度估计方法可以通过将分布内（ID）数据作为一个整体进行统一，直接应用于OOD检测（宗等人，2018年；阿巴蒂等人，2019年；皮德霍尔斯基等人，2018年；迪克等人，2018年；萨博克罗等人，2018年）。当ID包含多个类别时，类条件高斯分布可以对分布内数据进行显式建模，从而可以根据离群样本的似然性来识别它们（李等人，2018b）。基于流的方法（科比泽夫等人，2020年；齐塞尔曼和塔马尔，2020年；金玛和达里瓦尔，2018年；范·奥尔德等人，2016年；江等人，2021a）也可用于概率建模。虽然直接估计似然性似乎是一种自然的方法，但一些研究（纳利斯尼克等人，2018年；崔等人，2018年；基里琴科等人，2020年）发现，概率模型有时会为离群样本分配更高的似然性。一些研究试图使用似然比来解决这些问题（任等人，2019年）。塞拉等人（2020年）发现，似然性对输入复杂度表现出强烈的偏差，并提出了一种基于似然比的方法来补偿输入复杂度的影响。最近的方法转向了新的得分，如似然遗憾（肖等人，2020年）或多个密度模型的集成（崔等人，2018年）。为了直接对语义空间的密度进行建模，SEM得分与低层次和高层次空间中的密度估计进行简单组合使用（杨等人，2022b）。总体而言，生成模型的训练和优化可能极具挑战性，并且其性能通常落后于基于分类的方法（第3.1节）。</div></div></div></div><div><br></div><h3><div><div>3.3 Distance-Based Methods<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.3 基于距离的方法</div></div></div></h3><div><br></div><div><div><div>The basic idea of distance-based methods is that the testing OOD samples should be relatively far away from the centroids or prototypes of in-distribution classes. (Lee et al., 2018b) uses the minimum Mahalanobis distance to all class centroids for detection. A subsequent work splits the images into foreground and background and then calculates the Mahalanobis distance ratio between the two spaces (Ren et al., 2021). In contrast to the parametric approach, recent work (Sun et al., 2022) shows strong promise of nonparametric nearest-neighbor distance for OOD detection. Unlike Mahalanobis, the non-parametric approach does not impose any distributional assumption about the underlying feature space, hence providing stronger simplicity, flexibility, and generality.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于距离的方法的基本思想是，测试的离群分布样本应该相对远离分布内类别的质心或原型。（李等人，2018b）使用到所有类质心的最小马氏距离进行检测。后续的一项工作将图像分为前景和背景，然后计算两个空间之间的马氏距离比（任等人，2021年）。与参数化方法不同，最近的研究（孙等人，2022年）表明，非参数最近邻距离在OOD检测中具有很大的潜力。与马氏距离不同，非参数方法不对底层特征空间施加任何分布假设，因此具有更强的简单性、灵活性和通用性。</div></div></div></div><div><br></div><div><div><div>For distance functions, some works use cosine similarity between test sample features and class features to determine OOD samples (Techapanurak et al., 2020; Chen et al., 2020c). The one-dimensional subspace spanned by the first singular vector of the training features is shown to be more suitable for cosine similarity-based detection (Zaeemzadeh et al., 2021). Moreover, other works leverage distances with radial basis function kernel (Van Amersfoort et al., 2020), Euclidean distance (Huang et al., 2020a), and geodesic distance (Gomes et al., 2022) between the input's embedding and the class centroids. Apart from calculating the distance between samples and class centroids, the feature norm in the orthogonal complement space of the principal space is shown effective on OOD detection (Wang et al., 2022a). Recent work CIDER (Ming et al., 2023) explores the usability of the embeddings in the hyperspherical space, where inter-class dispersion and inner-class compactness can be encouraged.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">对于距离函数，一些研究使用测试样本特征与类特征之间的余弦相似度来确定离群分布样本（特查帕努拉克等人，2020年；陈等人，2020c）。研究表明，由训练特征的第一个奇异向量所张成的一维子空间更适合基于余弦相似度的检测（扎伊姆扎德等人，2021年）。此外，其他研究利用输入嵌入与类质心之间的径向基函数核距离（范·阿默斯福特等人，2020年）、欧几里得距离（黄等人，2020a）和测地距离（戈麦斯等人，2022年）。除了计算样本与类质心之间的距离外，主空间正交补空间中的特征范数在OOD检测中也被证明是有效的（王等人，2022a）。最近的研究CIDER（明等人，2023年）探索了超球面空间中嵌入的可用性，在该空间中可以促进类间分散和类内紧凑性。</div></div></div></div><div><br></div><h3><div><div>3.4 Reconstruction-Based Methods<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.4 基于重建的方法</div></div></div></h3><div><br></div><div><div><div>The core idea of reconstruction-based methods is that the encoder-decoder framework trained on the ID data usually yields different outcomes for ID and OOD samples. The difference in model performance can be utilized as an indicator for detecting anomalies. For example, reconstruction models that are only trained by ID data cannot well recover the OOD data (Denouden et al., 2018), and therefore the OOD can be identified. While reconstruction-based models with pixel-level comparison seem not a popular solution in OOD detection for its expensive training cost, reconstructing with hidden features is shown as a promising alternative (Zhou, 2022). Rather than reconstructing the entire image, recent work MoodCat (Yang et al., 2022c) masks a random portion of the input image and identifies OOD samples using the quality of the classification-based reconstruction results. READ (Jiang et al., 2023a) combines inconsistencies from a classifier and an autoencoder by transforming the reconstruction error of raw pixels to the latent space of the classifier. MOOD (Li et al., 2023b) shows that masked image modeling for pretraining is beneficial to OOD detection tasks compared to contrastive training and classic classifier training.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于重建的方法的核心思想是，在分布内（ID）数据上训练的编码器 - 解码器框架通常会对分布内和分布外（OOD）样本产生不同的结果。模型性能的差异可以作为检测异常的指标。例如，仅由分布内数据训练的重建模型无法很好地恢复分布外数据（Denouden 等人，2018 年），因此可以识别出分布外数据。虽然基于像素级比较的重建模型由于其高昂的训练成本，在分布外检测中似乎不是一个流行的解决方案，但使用隐藏特征进行重建被证明是一种有前途的替代方法（周，2022 年）。近期的 MoodCat 工作（杨等人，2022c）不是重建整个图像，而是对输入图像的随机部分进行掩码处理，并使用基于分类的重建结果的质量来识别分布外样本。READ（江等人，2023a）通过将原始像素的重建误差转换到分类器的潜在空间，结合了分类器和自动编码器的不一致性。MOOD（李等人，2023b）表明，与对比训练和经典分类器训练相比，用于预训练的掩码图像建模有利于分布外检测任务。</div></div></div></div><div><div><div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="14" id="mark-d694d930-d62b-4cb5-810c-8f439157d44a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-13="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-13="0,0"></paragraphpositioning></div></div></div><h3><div><div>3.5 Theoretical Analysis<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.5 理论分析</div></div></div></h3><div><br></div><div><div><div>Early theoretical research on OOD detection (Zhang et al., 2021) delves into the limitations of Deep Generative Models (DGMs) in OOD contexts. This work uncovers a critical flaw where DGMs frequently assign greater probabilities to OOD data compared to training data, attributing this issue primarily to model misestimation rather than the typical set hypothesis. This hypothesis posits that relevant out-distributions might be located in high-likelihood areas of the data distribution. The study concludes that any generalized OOD task must restrict the set of distributions that are considered out-of-distribution, as without any restrictions, the task is impossible. Later work (Morteza &amp; Li, 2022) advances the field by developing a comprehensive analytical framework aimed at enhancing theoretical understanding and practical performance of OOD detection methods in neural networks. Their innovative approach culminates in a novel OOD detection method that surpasses existing techniques in both theoretical robustness and empirical performance.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">早期关于分布外检测的理论研究（张等人，2021 年）深入探讨了深度生成模型（DGMs）在分布外场景中的局限性。这项工作揭示了一个关键缺陷，即深度生成模型通常会比训练数据更大概率地分配给分布外数据，主要将此问题归因于模型的错误估计，而非典型的集合假设。该假设认为相关的分布外数据可能位于数据分布的高似然区域。研究得出结论，任何广义的分布外任务都必须限制被视为分布外的分布集合，因为如果没有任何限制，该任务是不可能完成的。后来的工作（Morteza 和李，2022 年）通过开发一个全面的分析框架推动了该领域的发展，旨在增强对神经网络中分布外检测方法的理论理解和实际性能。他们的创新方法最终形成了一种新的分布外检测方法，在理论鲁棒性和实证性能方面都超越了现有技术。</div></div></div></div><div><br></div><div><div><div>Another series of studies has been focused on Open-Set Learning (OSL). The seminal work in this domain (Scheirer et al., 2013) conceptualizes open-space risk for recognizing samples from unknown classes. The following research applies extreme value theory to OSL (Jain et al., 2014; Rudd et al., 2017). While probably approximately correct (PAC) theory is applied for OSR (Liu et al., 2018a), their method required test samples during training. Therefore, an investigation of the generalization error bound is conducted and proves the existence of a low-error OSL algorithm under certain assumptions (Fang et al., 2021). Still, under the PAC theory, a later study establishes necessary and sufficient conditions for the learnability of OOD detection in various scenarios (Fang et al., 2022), including cases with overlapping and non-overlapping ID and OOD data. Their work also offers theoretical support for existing OOD detection algorithms and suggests that OOD detection is possible under certain practical conditions.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">另一系列研究集中在开放集学习（OSL）上。该领域的开创性工作（Scheirer 等人，2013 年）为识别来自未知类别的样本概念化了开放空间风险。后续研究将极值理论应用于开放集学习（Jain 等人，2014 年；Rudd 等人，2017 年）。虽然大概近似正确（PAC）理论被应用于开放集识别（OSR）（刘等人，2018a），但他们的方法在训练期间需要测试样本。因此，对泛化误差界进行了研究，并证明了在某些假设下存在低误差的开放集学习算法（方等人，2021 年）。尽管如此，在大概近似正确理论下，后来的一项研究为各种场景下分布外检测的可学习性建立了充分必要条件（方等人，2022 年），包括分布内和分布外数据有重叠和无重叠的情况。他们的工作还为现有的分布外检测算法提供了理论支持，并表明在某些实际条件下分布外检测是可行的。</div></div></div></div><div><br></div><div><div><div>Despite these theoretical advancements, the field eagerly anticipates further research addressing aspects such as generalization in OOD detection, the explainability of these models, the integration of deep learning theory specific to OOD detection, and the exploration of foundation model theories pertinent to this area.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">尽管有这些理论进展，但该领域迫切期待进一步的研究来解决诸如分布外检测中的泛化问题、这些模型的可解释性、专门针对分布外检测的深度学习理论的整合，以及探索与该领域相关的基础模型理论等方面的问题。</div></div></div></div><div><br></div><h3><div><div>3.6 Discussion<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">3.6 讨论</div></div></div></h3><div><br></div><div><div><div>The field of OOD detection has enjoyed rapid development since its emergence, with a large space of solutions. In the multi-class setting, the problem can be canonical to OSR (Sect.4.1)—accurately classify test samples from ID within the class space <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2761" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> ,and reject test samples with semantics outside the support of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2762" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> . The difference often lies in the evaluation protocol. OSR splits a dataset into two halves: one set as ID and another set as OOD. In contrast, OOD allows a more general and flexible evaluation by considering test samples from different datasets or domains. Moreover, OOD detection encompasses a broader spectrum of learning tasks (e.g.,multi-label classification (Wang et al., 2021), object detection (Du et al., 2022b, a)) and solution space. Apart from the methodology development, theoretical understanding has also received attention in the community (Morteza &amp; Li, 2022), providing provable guarantees and empirical analysis to understand how OOD detection performance changes with respect to data distributions.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">分布外检测领域自出现以来发展迅速，有大量的解决方案。在多类设置中，该问题可以规范为开放集识别（OSR）（4.1 节）——在类别空间 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2763" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> 内准确分类来自分布内的测试样本，并拒绝语义在 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2764" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c59 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">Y</mi></mrow></math></mjx-assistive-mml></mjx-container> 支持范围之外的测试样本。差异通常在于评估协议。开放集识别将数据集分成两半：一组作为分布内数据，另一组作为分布外数据。相比之下，分布外检测通过考虑来自不同数据集或领域的测试样本，允许更通用和灵活的评估。此外，分布外检测涵盖了更广泛的学习任务（例如，多标签分类（王等人，2021 年）、目标检测（杜等人，2022b，a））和解决方案空间。除了方法开发之外，理论理解也受到了该领域的关注（Morteza 和李，2022 年），为理解分布外检测性能如何随数据分布变化提供了可证明的保证和实证分析。</div></div></div></div><div><br></div><h2><div><div>4 Methodologies from Other Sub-tasks<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">4 来自其他子任务的方法</div></div></div></h2><div><br></div><div><div><div>In this section, we briefly introduce methodologies for subtasks under the generalized OOD detection framework, including AD, ND, OSR, and OD, in hope that the methods from other sub-tasks can inspire more ideas for OOD detection community.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在本节中，我们简要介绍广义分布外检测框架下子任务的方法，包括异常检测（AD）、新奇性检测（ND）、开放集识别（OSR）和离群点检测（OD），希望来自其他子任务的方法能为分布外检测领域带来更多的思路。</div></div></div></div><div><br></div><h3><div><div>4.1 Open Set Recognition<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">4.1 开放集识别</div></div></div></h3><div><br></div><div><div><div>The concept of OSR was first introduced in (Scheirer et al., 2013), which showed the validity of 1-class SVM and binary SVM for solving the OSR problem. In particular, (Scheirer et al., 2013) proposes the 1-vs-Set SVM to manage the open-set risk by solving a two-plane optimization problem instead of the classic half-space of a binary linear classifier. This paper highlighted that the open-set space should also be bounded, in addition to bounding the ID risk.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">开放集识别（OSR）的概念最早由（Scheirer等人，2013）提出，该研究展示了单类支持向量机（1-class SVM）和二分类支持向量机（binary SVM）解决开放集识别问题的有效性。具体而言，（Scheirer等人，2013）提出了一对多集支持向量机（1-vs-Set SVM），通过解决一个双平面优化问题而非经典二分类线性分类器的半空间问题来管理开放集风险。该论文强调，除了限制已知类别（ID）风险外，开放集空间也应该有界。</div></div></div></div><div><br></div><div><div><div>Classification-Based Methods Early works focused on logits redistribution using the compact abating probability (CAP) (Scheirer et al., 2014) and extreme value theory (EVT) (Smith, 1990; Castillo, 2012; Jain et al., 2014). In particular, classic probabilistic models lack the consideration of open-set space. CAP explicitly models the probability of class membership abating from ID points to OOD points, and EVT focuses on modeling the tail distribution with extreme high/low values. In the context of deep learning, OpenMax (Bendale &amp; Boult, 2016) first implements EVT for neural networks. OpenMax replaces the softmax layer with an OpenMax layer, which calibrates the logits with a per-class EVT probabilistic model such as Weibull distribution.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于分类的方法 早期的工作集中于使用紧凑衰减概率（CAP）（Scheirer等人，2014）和极值理论（EVT）（Smith，1990；Castillo，2012；Jain等人，2014）进行对数几率（logits）重新分配。具体来说，经典概率模型缺乏对开放集空间的考虑。紧凑衰减概率（CAP）明确地对从已知类别（ID）点到未知类别（OOD）点的类别隶属概率衰减进行建模，而极值理论（EVT）则专注于对具有极高/极低值的尾部分布进行建模。在深度学习的背景下，OpenMax（Bendale &amp; Boult，2016）首次将极值理论（EVT）应用于神经网络。OpenMax用OpenMax层取代了softmax层，该层使用基于每个类别的极值理论概率模型（如威布尔分布）来校准对数几率（logits）。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="15" id="mark-6a165198-f4a0-4f04-bf31-142416feafb8" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-14="0,0"><div style="height: auto;"><div><div><div><paragraphpositioning data-position-14="0,0"></paragraphpositioning></div></div></div><div><div><div>To bypass open-set risk construction, some works attained good results without EVT. For example, some work uses a membership loss to encourage high activations for known classes, and uses large-scale external datasets to learn globally negative filters that can reduce the activations of novel images (Perera &amp; Patel, 2019). Apart from explicitly forcing discrepancy between known/unknown classes, other methods extract stronger features through an auxiliary task of transformation classification (Perera et al., 2020), or mutual information maximization between the input image and its latent features (Sun et al., 2021a), etc..<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">为了绕过开放集风险构建，一些工作在不使用极值理论（EVT）的情况下取得了良好的效果。例如，一些工作使用隶属损失来鼓励已知类别的高激活值，并使用大规模外部数据集来学习全局负滤波器，以降低新图像的激活值（Perera &amp; Patel，2019）。除了明确强制已知/未知类别之间的差异外，其他方法通过变换分类的辅助任务（Perera等人，2020）或输入图像与其潜在特征之间的互信息最大化（Sun等人，2021a）等方式提取更强的特征。</div></div></div></div><div><br></div><div><div><div>Image generation techniques have been utilized to synthesize unknown samples from known classes, which helps distinguish between known vs. unknown samples (Ge et al., 2017; Neal et al., 2018; Zhou et al., 2021a; Kong &amp; Ramanan, 2021). While these methods are promising on simple images such as handwritten characters, they do not scale to complex natural image datasets due to the difficulty in generating high-quality images in high-dimensional space. Another solution is to successively choose random categories in the training set and treat them as unknown, which helps the classifier to shrink the boundaries and gain the ability to identify unknown classes (Geng &amp; Chen, 2020; Jang &amp; Kim, 2020). Moreover, Schlachter et al. (2019) splits the training data into typical and atypical subsets, which also helps learn compact classification boundaries.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">图像生成技术已被用于从已知类别合成未知样本，这有助于区分已知和未知样本（Ge等人，2017；Neal等人，2018；Zhou等人，2021a；Kong &amp; Ramanan，2021）。虽然这些方法在手写字符等简单图像上很有前景，但由于在高维空间中生成高质量图像的困难，它们无法扩展到复杂的自然图像数据集。另一种解决方案是在训练集中依次选择随机类别并将其视为未知类别，这有助于分类器缩小边界并获得识别未知类别的能力（Geng &amp; Chen，2020；Jang &amp; Kim，2020）。此外，Schlachter等人（2019）将训练数据分为典型和非典型子集，这也有助于学习紧凑的分类边界。</div></div></div></div><div><br></div><div><div><div>Distance-Based Methods Distance-based methods for OSR require the prototypes to be class-conditional, which allows maintaining the ID classification performance. Category-based clustering and prototyping are performed based on the visual features extracted from the classifiers. OOD samples can be detected by computing the distance w.r.t. clusters (Masana et al., 2018; Shu et al., 2020). Some methods also leveraged contrastive learning to learn more compact clusters for known classes (Liu et al., 2020a; Chen et al., 2020a), which enlarge the distance between ID and OOD. CROSR (Yoshihashi et al., 2019) enhances the features by concatenating visual embeddings from both the classifier and reconstruction model for distance computation in the extended feature space. Besides using features from classifiers, GMVAE (Cao et al., 2020) extracts features using a reconstruction VAE, and models the embeddings of the training set as a Gaussian mixture with multiple centroids for the following distance-based operations. Classifiers using nearest neighbors are also adapted for OSR problem (Júnior et al., 2017). By storing the training samples, the nearest neighbor distance ratio is used for identifying unknown samples in testing.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于距离的方法 开放集识别（OSR）的基于距离的方法要求原型具有类别条件性，这有助于保持已知类别（ID）的分类性能。基于从分类器中提取的视觉特征进行基于类别的聚类和原型构建。可以通过计算与聚类的距离来检测未知类别（OOD）样本（Masana等人，2018；Shu等人，2020）。一些方法还利用对比学习为已知类别学习更紧凑的聚类（Liu等人，2020a；Chen等人，2020a），这扩大了已知类别（ID）和未知类别（OOD）之间的距离。CROSR（Yoshihashi等人，2019）通过连接来自分类器和重建模型的视觉嵌入来增强特征，以便在扩展特征空间中进行距离计算。除了使用分类器的特征外，GMVAE（Cao等人，2020）使用重建变分自编码器（VAE）提取特征，并将训练集的嵌入建模为具有多个质心的高斯混合模型，以便进行后续的基于距离的操作。使用最近邻的分类器也适用于开放集识别（OSR）问题（Júnior等人，2017）。通过存储训练样本，最近邻距离比用于在测试中识别未知样本。</div></div></div></div><div><br></div><div><div><div>Reconstruction-Based Methods With similar motivations as Sect. 3.4, reconstruction-based methods expect different reconstruction behavior for ID vs. OOD samples. The difference can be captured in the latent feature space or the pixel space of reconstructed images.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于重建的方法 与3.4节的动机类似，基于重建的方法期望已知类别（ID）和未知类别（OOD）样本具有不同的重建行为。这种差异可以在潜在特征空间或重建图像的像素空间中被捕捉到。</div></div></div></div><div><br></div><div><div><div>By sparsely encoding images from the known classes, open-set samples can be identified based on their dense representation. Techniques such as sparsity concentration index (Zhang &amp; Patel, 2016) and kernel null space methods (Bodesheim et al., 2013; Liu et al., 2017) are used for sparse encoding.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">通过对已知类别的图像进行稀疏编码，可以根据开放集样本的密集表示来识别它们。诸如稀疏集中指数（Zhang &amp; Patel，2016）和核零空间方法（Bodesheim等人，2013；Liu等人，2017）等技术被用于稀疏编码。</div></div></div></div><div><br></div><div><div><div>By fixing the visual encoder obtained from standard multi-class training to maintain ID classification performance, C2AE trains a decoder conditioned on label vectors and estimates the reconstructed images using EVT to distinguish unknown classes (Oza &amp; Patel, 2019). Subsequent works use conditional Gaussian distributions by forcing different latent features to approximate class-wise Gaussian models, which enables classifying known samples as well as rejecting unknown samples (Sun et al., 2020). Other methods generate counterfactual images, which help the model focus more on semantics (Yue et al., 2021). Adversarial defense is also considered in Shao et al. (2020) to enhance model robustness.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">通过固定从标准多类训练中获得的视觉编码器以保持身份（ID）分类性能，C2AE训练一个以标签向量为条件的解码器，并使用极值理论（EVT）估计重建图像，以区分未知类别（Oza &amp; Patel，2019）。后续工作通过迫使不同的潜在特征逼近按类别划分的高斯模型来使用条件高斯分布，这使得模型既能对已知样本进行分类，又能拒绝未知样本（Sun等人，2020）。其他方法生成反事实图像，这有助于模型更多地关注语义（Yue等人，2021）。Shao等人（2020）还考虑了对抗防御，以增强模型的鲁棒性。</div></div></div></div><div><br></div><div><div><div>Discussion Although there is not an independent section for density-based methods, these methods can play an important role and are fused as a critical step in some classification-based methods such as OpenMax (Bendale &amp; Boult, 2016). The density estimation on visual embeddings can effectively detect unknown classes without influencing the classification performance. A hybrid model also uses a flow-based density estimator to detect unknown samples (Zhang et al., 2020).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">讨论 尽管没有独立的章节介绍基于密度的方法，但这些方法可以发挥重要作用，并且在一些基于分类的方法（如OpenMax（Bendale &amp; Boult，2016））中作为关键步骤被融合。对视觉嵌入进行密度估计可以在不影响分类性能的情况下有效检测未知类别。一个混合模型还使用基于流的密度估计器来检测未知样本（Zhang等人，2020）。</div></div></div></div><div><br></div><div><div><div>As introduced in Sect.2.4, the general goal of OSR and OOD detection is aligned, that is to detect semantic shift from the training data. Therefore, we encourage methods from these two field should learn more from each other. For example, apart from novel methods, OSR research also shows that a good classifier (Vaze et al., 2022b) in the close-set is critical to OSR performance, which should also applicable to OOD detection tasks.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">正如第2.4节所介绍的，开放集识别（OSR）和分布外（OOD）检测的总体目标是一致的，即检测与训练数据的语义偏移。因此，我们鼓励这两个领域的方法相互学习。例如，除了新颖的方法之外，OSR研究还表明，封闭集内的优秀分类器（Vaze等人，2022b）对OSR性能至关重要，这也应该适用于OOD检测任务。</div></div></div></div><div><br></div><h3><div><div>4.2 Anomaly Detection and Novelty Detection<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">4.2 异常检测和新奇性检测</div></div></div></h3><div><br></div><div><div><div>This section reviews methodologies for sensory and semantic AD and one-class ND. Notice that multi-classes ND is covered in the previous. Given homogeneous in-distribution data, approaches include density-based, reconstruction-based, distance-based, and hybrid methods. We also discuss theoretical works.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">本节回顾了感官和语义异常检测（AD）以及单类新奇性检测（ND）的方法。请注意，多类ND已在前面介绍过。对于同质的分布内数据，方法包括基于密度的方法、基于重建的方法、基于距离的方法和混合方法。我们还将讨论理论方面的工作。</div></div></div></div><div><div><div></div></div></div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="16" id="mark-e783b7ff-7fad-41ec-ae2a-a3e51f9d4376" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-15="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-15="0,0"></paragraphpositioning></div></div></div><div><div><div>Density-Based Methods Density-based methods model normal data (ID) distributions, assuming anomalous test data has low likelihood while normal data has higher likelihood. Techniques include classic density estimation, density estimation with deep generative models, energy-based models, and frequency-based methods.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于密度的方法 基于密度的方法对正常数据（分布内，ID）的分布进行建模，假设异常测试数据的似然较低，而正常数据的似然较高。技术包括经典密度估计、使用深度生成模型的密度估计、基于能量的模型和基于频率的方法。</div></div></div></div><div><br></div><div><div><div>Parametric density estimation assumes pre-defined distributions (Danuser &amp; Stricker, 1998). Methods involve multivariate Gaussian distribution (De Maesschalck et al., 2000; Leys et al., 2018), mixed Gaussian distribution (Red-ner &amp; Walker, 1984; Eskin, 2000), and Poisson distribution (Turcotte et al., 2016). Non-parametric density estimation handles more complex scenarios (Izenman, 1991) with histograms (Van Ryzin, 1973; Xie et al., 2012; Kind et al., 2009; Goldstein &amp; Dengel, 2012) and kernel density estimation (KDE) (Parzen, 1962; Desforges et al., 1998; Hu et al., 2018).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">参数密度估计假设数据符合预定义的分布（Danuser &amp; Stricker，1998）。方法包括多元高斯分布（De Maesschalck等人，2000；Leys等人，2018）、混合高斯分布（Redner &amp; Walker，1984；Eskin，2000）和泊松分布（Turcotte等人，2016）。非参数密度估计使用直方图（Van Ryzin，1973；Xie等人，2012；Kind等人，2009；Goldstein &amp; Dengel，2012）和核密度估计（KDE）（Parzen，1962；Desforges等人，1998；Hu等人，2018）来处理更复杂的场景（Izenman，1991）。</div></div></div></div><div><br></div><div><div><div>Neural networks generate high-quality features to enhance classic density estimation. Techniques include autoencoder (AE) (Kramer, 1991) and variational autoencoder (VAE) (Kingma &amp; Welling, 2013)-based models, generative adversarial networks (GANs) (Goodfellow et al., 2014), flow-based models (Rezende &amp; Mohamed, 2015; Kobyzev et al., 2020), and representation enhancement strategies.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">神经网络生成高质量的特征以增强经典密度估计。技术包括基于自编码器（AE）（Kramer，1991）和变分自编码器（VAE）（Kingma &amp; Welling，2013）的模型、生成对抗网络（GANs）（Goodfellow等人，2014）、基于流的模型（Rezende &amp; Mohamed，2015；Kobyzev等人，2020）以及表示增强策略。</div></div></div></div><div><br></div><div><div><div>EBMs use scalar energy scores to express probability density (Ngiam et al., 2011) and provide a solution for AD (Zhai et al., 2016). Training EBMs can be computationally expensive, but score matching (Hyvärinen &amp; Dayan, 2005) and stochastic gradient Langevin dynamics (Welling &amp; Teh, 2011) enable efficient training.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于能量的模型（EBMs）使用标量能量分数来表示概率密度（Ngiam等人，2011），并为异常检测（AD）提供了一种解决方案（Zhai等人，2016）。训练EBMs的计算成本可能很高，但得分匹配（Hyvärinen &amp; Dayan，2005）和随机梯度朗之万动力学（Welling &amp; Teh，2011）可以实现高效训练。</div></div></div></div><div><br></div><div><div><div>Frequency domain analysis for AD includes methods like CNN kernel smoothing (Wang et al., 2020), spectrum-oriented data augmentation (Chen et al., 2021a), and phase spectrum targeting (Liu et al., 2021). These mainly focus on sensory AD.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">用于异常检测的频域分析方法包括卷积神经网络（CNN）核平滑（Wang等人，2020）、面向频谱的数据增强（Chen等人，2021a）和相位谱靶向（Liu等人，2021）等。这些方法主要关注感官异常检测。</div></div></div></div><div><br></div><div><div><div>Reconstruction-Based Methods These AD methods leverage model performance differences on normal and abnormal data in feature space or by reconstruction error.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于重建的方法 这些异常检测方法利用模型在特征空间中对正常和异常数据的性能差异，或者通过重建误差来进行检测。</div></div></div></div><div><br></div><div><div><div>Sparse reconstruction assumes normal samples can be accurately reconstructed using a limited set of basis functions, while anomalies have larger reconstruction costs and a dense representation (Adler et al., 2015; Li et al., 2017a; Mo et al.,2013). Techniques include <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2765" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>L</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub></math></mjx-assistive-mml></mjx-container> norm-based kernel PCA (Xiao et al., 2013) and low-rank embedded networks (Jiang et al., 2021b).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">稀疏重建假设正常样本可以使用有限的一组基函数进行准确重建，而异常样本的重建成本更高，并且具有密集表示（Adler等人，2015；Li等人，2017a；Mo等人，2013）。技术包括基于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2766" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi>L</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub></math></mjx-assistive-mml></mjx-container>范数的核主成分分析（PCA）（Xiao等人，2013）和低秩嵌入网络（Jiang等人，2021b）。</div></div></div></div><div><br></div><div><div><div>Reconstruction-error methods assume a model trained on normal data will produce better reconstructions for normal test samples than anomalies. Deep models include AEs (Chen et al., 2018), VAEs (An &amp; Cho, 2015), GANs (Zenati et al., 2018), and U-Net (Liu et al., 2018b).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">重建误差方法假定，在正常数据上训练的模型对正常测试样本的重建效果会比对异常样本的更好。深度模型包括自动编码器（AE，Chen等人，2018）、变分自动编码器（VAE，An和Cho，2015）、生成对抗网络（GAN，Zenati等人，2018）和U型网络（U-Net，Liu等人，2018b）。</div></div></div></div><div><br></div><div><div><div>AE/VAE-based models combine reconstruction-error with AE/VAE models (Chen et al., 2018; An &amp; Cho, 2015) and use strategies like reconstructing by memorized normality (Gong et al., 2019; Park et al., 2020), adapting model architectures (Lai et al., 2020), and partial/conditional reconstruction (Yan et al., 2021; Pidhorskyi et al., 2018; Nguyen et al., 2019). In semi-supervised AD, CoRA (Tian et al., 2019) trains two AEs on inliers and outliers, using reconstruction errors for anomaly detection. Reconstruction-error methods using GANs leverage the discriminator to calculate reconstruction error for anomaly detection (Zenati et al., 2018). Variants like denoising GANs (Sabokrou et al., 2018), class-conditional GANs (Perera et al., 2019), and ensembling (Han et al., 2020) further improve performance. Gradient-based methods observe different patterns on training gradient between normalities and anomalies in a reconstruction task, using gradient-based representation to characterize anomalies (Kwon et al., 2020).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于自动编码器/变分自动编码器（AE/VAE）的模型将重建误差与AE/VAE模型相结合（Chen等人，2018；An和Cho，2015），并采用诸如通过记忆正常模式进行重建（Gong等人，2019；Park等人，2020）、调整模型架构（Lai等人，2020）以及部分/条件重建（Yan等人，2021；Pidhorskyi等人，2018；Nguyen等人，2019）等策略。在半监督异常检测（AD）中，对比重建自动编码器（CoRA，Tian等人，2019）在正常样本和异常样本上训练两个自动编码器，利用重建误差进行异常检测。使用生成对抗网络的重建误差方法利用判别器计算重建误差以进行异常检测（Zenati等人，2018）。去噪生成对抗网络（Sabokrou等人，2018）、类别条件生成对抗网络（Perera等人，2019）和集成方法（Han等人，2020）等变体进一步提高了性能。基于梯度的方法在重建任务中观察正常样本和异常样本在训练梯度上的不同模式，利用基于梯度的表示来表征异常（Kwon等人，2020）。</div></div></div></div><div><br></div><div><div><div>Distance-Based Methods These methods detect anomalies by calculating the distance between samples and prototypes (Wettschereck, 1994), requiring training data in memory. Methods include K-nearest Neighbors (Tian et al., 2014) and prototype-based methods (Münz et al., 2007; Syarif et al., 2012).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于距离的方法 这些方法通过计算样本与原型之间的距离来检测异常（Wettschereck，1994），需要在内存中存储训练数据。方法包括K近邻法（Tian等人，2014）和基于原型的方法（Münz等人，2007；Syarif等人，2012）。</div></div></div></div><div><br></div><div><div><div>Classification-Based Methods AD and one-class ND are often formulated as unsupervised learning problems, but there are some supervised and semi-supervised methods as well. One-class classification (OCC) directly learns a decision boundary that corresponds to a desired density level set of the normal data distribution (Tax, 2002). DeepSVDD (Ruff et al., 2018) introduced classic OCC to the deep learning community. PU learning (Zhang &amp; Zuo, 2008; Bekker &amp; Davis, 2020; Jaskie &amp; Spanias, 2019; Ruff et al., 2020) is proposed for the semi-supervised AD setting where unlabeled data is available in addition to the normal data. Self-supervised learning methods use pretext tasks such as contrastive learning (Tack et al., 2020), image transformation prediction (Bergman &amp; Hoshen, 2020; Golan &amp; El-Yaniv, 2018), and future frame prediction (Georgescu et al., 2021), where anomalies are more likely to make mistakes on the designed task.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于分类的方法 异常检测和单类新奇检测（ND）通常被表述为无监督学习问题，但也有一些有监督和半监督方法。单类分类（OCC）直接学习一个决策边界，该边界对应于正常数据分布的期望密度水平集（Tax，2002）。深度支持向量数据描述（DeepSVDD，Ruff等人，2018）将经典的单类分类引入到深度学习领域。正例和无标签学习（PU学习，Zhang和Zuo，2008；Bekker和Davis，2020；Jaskie和Spanias，2019；Ruff等人，2020）是为半监督异常检测场景提出的，在该场景中，除了正常数据外还有无标签数据。自监督学习方法使用前置任务，如对比学习（Tack等人，2020）、图像变换预测（Bergman和Hoshen，2020；Golan和El-Yaniv，2018）和未来帧预测（Georgescu等人，2021），在这些任务中，异常样本更有可能在设计的任务上出错。</div></div></div></div><div><br></div><div><div><div>One-class classification learns a decision boundary that corresponds to a desired density level set of the normal data distribution, which DeepSVDD (Ruff et al., 2018) introduced to the deep learning community. PU learning (Zhang &amp; Zuo, 2008; Bekker &amp; Davis, 2020; Jaskie &amp; Spanias, 2019; Ruff et al., 2020) is a popular method for the semi-supervised AD setting. Self-supervised learning methods use pretext tasks such as contrastive learning (Tack et al., 2020), image transformation prediction (Bergman &amp; Hoshen, 2020; Golan &amp; El-Yaniv, 2018), and future frame prediction (Georgescu et al., 2021), where anomalies are more likely to make mistakes on the designed task.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">单类分类学习一个决策边界，该边界对应于正常数据分布的期望密度水平集，深度支持向量数据描述（DeepSVDD，Ruff等人，2018）将其引入到深度学习领域。正例和无标签学习（PU学习，Zhang和Zuo，2008；Bekker和Davis，2020；Jaskie和Spanias，2019；Ruff等人，2020）是半监督异常检测场景中一种流行的方法。自监督学习方法使用前置任务，如对比学习（Tack等人，2020）、图像变换预测（Bergman和Hoshen，2020；Golan和El-Yaniv，2018）和未来帧预测（Georgescu等人，2021），在这些任务中，异常样本更有可能在设计的任务上出错。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="17" id="mark-2930789c-c355-4075-a340-c4699ad50596" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-16="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-16="0,0"></paragraphpositioning></div></div></div><div><div><div>Discussion: Sensory vs Semantic AD Sensory and semantic AD approaches assume the normal data as homogeneous, despite the presence of multiple categories within it. While semantic AD methods are mainly applicable to sensory AD problems, the latter can benefit from techniques that focus on lower-level features (e.g., flow-based and hidden feature-based), local representations, and frequency-based methods. Although current OOD detection tasks mostly focus on semantic shift, the method for Sensory AD might be especially helpful for far OOD detection, like ImageNet vs Texture dataset.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">讨论：感官异常检测与语义异常检测 感官和语义异常检测方法都假定正常数据是同质的，尽管其中存在多个类别。虽然语义异常检测方法主要适用于感官异常检测问题，但感官异常检测可以从专注于低级特征（如基于流和基于隐藏特征的方法）、局部表示和基于频率的方法等技术中受益。尽管当前的分布外（OOD）检测任务大多关注语义偏移，但感官异常检测方法可能对远距离分布外检测特别有用，如图像网（ImageNet）与纹理数据集的对比。</div></div></div></div><div><br></div><div><div><div>Discussion: Theoretical Analysis In addition to algorithmic development, theoretical analysis of AD and one-class ND has also been provided in some works. For instance, (Liu et al., 2018a) constructs a clean set of ID and a mixed set of ID/OOD with identical sample sizes, achieving a PAC-style finite sample guarantee for detecting a certain portion of anomalies with the minimum number of false alarms. All these works could be beneficial to the theoretical works of OOD detection.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">讨论：理论分析 除了算法开发，一些研究还对异常检测和单类新奇检测进行了理论分析。例如，（Liu等人，2018a）构建了一个样本大小相同的干净的分布内（ID）集合和一个混合的ID/OOD集合，为以最少的误报检测出一定比例的异常提供了PAC风格的有限样本保证。所有这些研究都可能对分布外检测的理论研究有益。</div></div></div></div><div><br></div><h3><div><div>4.3 Outlier Detection<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">4.3 离群值检测</div></div></div></h3><div><br></div><div><div><div>Outlier detection (OD) observes all samples to identify significant deviations from the majority distribution. Though mostly studied in data mining, deep learning-based OD methods are used for data cleaning in open-set noisy data (Wang et al., 2018; Chen &amp; Gupta, 2015) and open-set semi-supervised learning (Cao et al., 2021).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">离群值检测（Outlier Detection，OD）会观察所有样本，以识别与多数分布存在显著偏差的样本。尽管离群值检测大多在数据挖掘领域进行研究，但基于深度学习的离群值检测方法可用于开放集噪声数据的数据清洗（Wang等人，2018；Chen和Gupta，2015）以及开放集半监督学习（Cao等人，2021）。</div></div></div></div><div><br></div><div><div><div>Density-Based Methods OD methods include Gaussian distribution (Altman &amp; Bland, 2005; Leys et al., 2013), Mahalanobis distance (De Maesschalck et al., 2000), Gaussian mixtures (Yang et al., 2009), and Local outlier factor (LOF) (Breunig et al., 2000). RANSAC (Fischler &amp; Bolles, 1981) estimates parameters for a mathematical model. Classic density methods and NN-based density methods can also be applied.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于密度的方法 离群值检测方法包括高斯分布（Altman和Bland，2005；Leys等人，2013）、马氏距离（De Maesschalck等人，2000）、高斯混合模型（Yang等人，2009）以及局部离群因子（Local Outlier Factor，LOF）（Breunig等人，2000）。随机抽样一致性算法（Random Sample Consensus，RANSAC）（Fischler和Bolles，1981）用于估计数学模型的参数。经典密度方法和基于神经网络的密度方法也可以应用。</div></div></div></div><div><br></div><div><div><div>Distance-Based Methods Outliers can be detected by neighbor counting (Sugiyama &amp; Borgwardt, 2013; Orair et al., 2010), DBSCAN clustering (Ester et al., 1996), and graph-based methods (Hautamaki et al., 2004; Muhlenbach et al., 2004; Liu et al., 2010; Akoglu et al., 2015; Noble &amp; Cook, 2003; Kou et al., 2007; Mingqiang et al., 2012; Wu et al., 2021; Yang et al., 2020a).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于距离的方法 可以通过邻居计数（Sugiyama和Borgwardt，2013；Orair等人，2010）、基于密度的空间聚类应用（Density-Based Spatial Clustering of Applications with Noise，DBSCAN）（Ester等人，1996）以及基于图的方法（Hautamaki等人，2004；Muhlenbach等人，2004；Liu等人，2010；Akoglu等人，2015；Noble和Cook，2003；Kou等人，2007；Mingqiang等人，2012；Wu等人，2021；Yang等人，2020a）来检测离群值。</div></div></div></div><div><br></div><div><div><div>Classification-Based Methods AD methods like Isolation Forest (Liu et al., 2008) and OC-SVM (Tax, 2002; Ruff et al., 2018) can be applied to OD. Deep learning models can identify outliers (Li et al., 2017). Techniques for robustness and feature generalizability include ensembling (Nguyen et al., 2020), co-training (Han et al., 2018), and distillation (Li et al., 2017; Yang et al., 2020b).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基于分类的方法 像孤立森林（Isolation Forest，Liu等人，2008）和单类支持向量机（One-Class Support Vector Machine，OC - SVM）（Tax，2002；Ruff等人，2018）等异常检测（Anomaly Detection，AD）方法可以应用于离群值检测。深度学习模型可以识别离群值（Li等人，2017）。提高鲁棒性和特征泛化能力的技术包括集成学习（Nguyen等人，2020）、协同训练（Han等人，2018）和知识蒸馏（Li等人，2017；Yang等人，2020b）。</div></div></div></div><div><br></div><div><div><div>Discussion OD techniques are valuable for open-set semi-supervised learning, learning with open-set noisy labels, and novelty discovery. All these solutions can be applied especially when OOD samples are exposed during the training stage (Yang et al., 2021).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">讨论 离群值检测技术对于开放集半监督学习、带有开放集噪声标签的学习以及新奇事物发现具有重要价值。当在训练阶段出现分布外（Out-of-Distribution，OOD）样本时，所有这些解决方案都可以应用（Yang等人，2021）。</div></div></div></div><div><br></div><h2><div><div>5 Benchmarks and Experiments<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">5 基准测试与实验</div></div></div></h2><div><br></div><div><div><div>In this section, we report the fair comparison of methodologies that from different categories on the CIFAR (Krizhevsky et al., 2009) benchmark. The report originated from OpenOOD benchmarks (Yang et al., 2022a). We selected several popular AD methods, OOD detection methods (post-hot, training-required, and extra-data-required), and model robustness methods.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">在本节中，我们报告了在CIFAR（Krizhevsky等人，2009）基准测试上不同类别的方法的公平比较结果。该报告源自OpenOOD基准测试（Yang等人，2022a）。我们选择了几种流行的异常检测方法、分布外检测方法（事后处理、需要训练和需要额外数据的方法）以及模型鲁棒性方法。</div></div></div></div><div><br></div><h3><div><div>5.1 Benchmarks and Metrics<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">5.1 基准测试与指标</div></div></div></h3><div><br></div><div><div><div>The common practice for building OOD detection benchmarks is to consider an entire dataset as in-distribution (ID), and then collect several datasets that are disconnected from any ID categories as OOD datasets. In this part, we show the results from two popular OOD benchmarks with ID datasets of CIFAR-10 (Krizhevsky et al., 2009), CIFAR- 100 (Krizhevsky et al., 2009) from OpenOOD (c.f.Fig. 4), with each benchmark designing near-OOD and far-OOD datasets to facilitate detailed analysis of the OOD detectors. Near-OOD datasets only have semantic shift compared with ID datasets, while far-OOD further contains obvious covariate (domain) shift.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">构建分布外检测基准测试的常见做法是将整个数据集视为分布内（In - Distribution，ID）数据集，然后收集几个与任何分布内类别无关的数据集作为分布外数据集。在这部分，我们展示了来自两个流行的分布外基准测试的结果，这些基准测试使用OpenOOD中的CIFAR - 10（Krizhevsky等人，2009）和CIFAR - 100（Krizhevsky等人，2009）作为分布内数据集（参见图4），每个基准测试都设计了近分布外和远分布外数据集，以便对分布外检测器进行详细分析。近分布外数据集与分布内数据集相比仅存在语义偏移，而远分布外数据集还包含明显的协变量（领域）偏移。</div></div></div></div><div><br></div><div><div><div>CIFAR-10 CIFAR-10 (Krizhevsky et al., 2009) is a 10-class dataset for general object classification, which contains <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2767" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c6B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>50</mn></mrow><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">k</mi></mrow></math></mjx-assistive-mml></mjx-container> training images and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2768" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c6B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>10</mn></mrow><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">k</mi></mrow></math></mjx-assistive-mml></mjx-container> test images. As for the OOD dataset, we construct near-OOD with CIFAR- 100 (Krizhevsky et al., 2009) and TinyImageNet (Krizhevsky et al., 2012). Notice that 1,207 images are removed from TinyImageNet since they actually belong to CIFAR-10 classes (Yang et al., 2021). Far-OOD is built by MNIST (LeCun &amp; Cortes, 2005), SVHN (Netzer et al., 2011), Texture (Kyl-berg, 2011), and Places365 (Zhou et al., 2017) with 1,305 images are removed due to semantic overlaps.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">CIFAR - 10 CIFAR - 10（Krizhevsky等人，2009）是一个用于通用目标分类的10类数据集，包含<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2769" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c6B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>50</mn></mrow><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">k</mi></mrow></math></mjx-assistive-mml></mjx-container>张训练图像和<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2770" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c6B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>10</mn></mrow><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">k</mi></mrow></math></mjx-assistive-mml></mjx-container>张测试图像。至于分布外数据集，我们使用CIFAR - 100（Krizhevsky等人，2009）和TinyImageNet（Krizhevsky等人，2012）构建近分布外数据集。请注意，由于TinyImageNet中有1207张图像实际上属于CIFAR - 10类别，因此将其移除（Yang等人，2021）。远分布外数据集由MNIST（LeCun和Cortes，2005）、街景门牌号（Street View House Numbers，SVHN）（Netzer等人，2011）、纹理数据集（Texture，Kylberg，2011）和Places365（Zhou等人，2017）构建，由于语义重叠移除了1305张图像。</div></div></div></div><div><br></div><div><div><div>CIFAR-100 Another OOD detection benchmark uses CIFAR-100 (Krizhevsky et al., 2009) as an in-distribution, which contains <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2771" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c6B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>50</mn></mrow><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">k</mi></mrow></math></mjx-assistive-mml></mjx-container> training images and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2772" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c6B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>10</mn></mrow><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">k</mi></mrow></math></mjx-assistive-mml></mjx-container> test images with 100 classes. For OOD dataset, near-OOD includes CIFAR- 10 (Krizhevsky et al., 2009) and TinyImageNet (Torralba et al., 2008). Similar to the CIFAR-10 benchmark, 2,502 images are removed from TinyImageNet due to the overlapping semantics with CIFAR-100 classes (Yang et al., 2021). Far-OOD consists of MNIST (LeCun &amp; Cortes, 2005), SVHN (Netzer et al., 2011), Texture (Kylberg, 2011), and Places365 (Zhou et al., 2017) with 1,305 images removed.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">CIFAR - 100 另一个离群分布（OOD）检测基准使用 CIFAR - 100（克里兹夫斯基等人，2009 年）作为分布内数据集，它包含 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2773" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c6B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>50</mn></mrow><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">k</mi></mrow></math></mjx-assistive-mml></mjx-container> 张训练图像和 <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2774" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c6B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>10</mn></mrow><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">k</mi></mrow></math></mjx-assistive-mml></mjx-container> 张测试图像，共 100 个类别。对于 OOD 数据集，近 OOD 数据集包括 CIFAR - 10（克里兹夫斯基等人，2009 年）和 TinyImageNet（托拉尔巴等人，2008 年）。与 CIFAR - 10 基准类似，由于与 CIFAR - 100 类别存在语义重叠，从 TinyImageNet 中移除了 2502 张图像（杨等人，2021 年）。远 OOD 数据集由 MNIST（勒昆和科尔特斯，2005 年）、SVHN（内策尔等人，2011 年）、Texture（基尔贝里，2011 年）和 Places365（周等人，2017 年）组成，移除了 1305 张图像。</div></div></div></div><div><br></div><div><div><div>Metrics We only report the AUROC scores, which measure the area under the Receiver Operating Characteristic (ROC) curve.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">指标 我们仅报告受试者工作特征曲线下面积（AUROC）分数，该分数衡量的是受试者工作特征（ROC）曲线下的面积。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="18" id="mark-ec6a316a-5d31-47e4-89c6-c6247b0e5fa1" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-17="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="19" id="mark-dd086d11-34c4-49b7-9cab-da0d4f92f024" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-18="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="20" id="mark-a865081c-ccf5-44c4-85c4-e6b05a520cf2" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-19="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="21" id="mark-ffa0f228-ce39-4607-8d46-0b73fc813462" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-20="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="22" id="mark-ebf3e990-62d1-4088-86e1-c987d8eacd4a" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-21="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="23" id="mark-ce10eca3-ae09-4251-9dcd-004dbe0f9310" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-22="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="24" id="mark-420103b3-3c04-486d-af0e-3b5598f58891" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-23="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="25" id="mark-95f7dbf1-77a1-4d59-99be-23969b46162e" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-24="0,0"><div style="height: auto;"></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="26" id="mark-411a902e-20f7-4185-bebd-cf32ccab3731" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-25="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-25="0,0">Nixon, K. A., Aimale, V., &amp; Rowe, R. K. (2008). Spoof detection schemes. In Handbook of biometrics.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">尼克松（Nixon），K. A.，艾马勒（Aimale），V.，&amp; 罗（Rowe），R. K.（2008）。欺骗检测方案。见《生物识别手册》。</div></paragraphpositioning></div></div></div><div><br></div><div><div><div>Noble, C. C., &amp; Cook, D. J. (2003). Graph-based anomaly detection. In<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">诺布尔（Noble），C. C.，&amp; 库克（Cook），D. J.（2003）。基于图的异常检测。见</div></div></div></div><div><br></div><div><div><div>SIGKDD.</div></div></div><div><br></div><div><div><div>Orair, G. H., Teixeira, C. H., Meira, W., Jr., Wang, Y., &amp; Parthasarathy, S. (2010). Distance-based outlier detection: consolidation and renewed bearing. In Proceedings of the VLDB endowment.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">奥拉伊尔（Orair, G. H.）、特谢拉（Teixeira, C. H.）、小梅拉（Meira, W., Jr.）、王（Wang, Y.）和帕塔萨拉蒂（Parthasarathy, S.）（2010 年）。基于距离的离群点检测：整合与新视角。收录于《VLDB 捐赠会议论文集》。</div></div></div></div><div><br></div><div><div><div>Osawa, K., Swaroop, S., Jain, A., Eschenhagen, R., Turner, R. E., Yokota, R., &amp; Khan, M. E. (2019). Practical deep learning with Bayesian principles. In NeurIPS.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">大泽（Osawa, K.）、斯瓦鲁普（Swaroop, S.）、贾因（Jain, A.）、埃申哈根（Eschenhagen, R.）、特纳（Turner, R. E.）、横田（Yokota, R.）和汗（Khan, M. E.）（2019 年）。基于贝叶斯原理的实用深度学习。收录于神经信息处理系统大会（NeurIPS）。</div></div></div></div><div><br></div><div><div><div>Oza, P., &amp; Patel, V. M. (2019). C2ae: Class conditioned auto-encoder for open-set recognition. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2582" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">奥扎（Oza, P.）和帕特尔（Patel, V. M.）（2019 年）。C2ae：用于开放集识别的类别条件自编码器。收录于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2583" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Panareda Busto, P., &amp; Gall, J. (2017). Open set domain adaptation. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2584" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">帕纳雷达·布斯托（Panareda Busto, P.）和加尔（Gall, J.）（2017 年）。开放集领域自适应。收录于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2585" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Pang, G., Shen, C., Cao, L., &amp; Hengel, A. V. D. (2020). Deep learning for anomaly detection: A review, arXiv preprint arXiv:2007.02500<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">庞（Pang, G.）、沈（Shen, C.）、曹（Cao, L.）和范登·亨格尔（Hengel, A. V. D.）（2020 年）。用于异常检测的深度学习：综述，预印本 arXiv:2007.02500</div></div></div></div><div><br></div><div><div><div>Papadopoulos, A.-A., Rajati, M. R., Shaikh, N., &amp; Wang, J. (2021). Outlier exposure with confidence control for out-of-distribution detection. Neurocomputing, 441, 138-150.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">帕帕多普洛斯（Papadopoulos, A.-A.）、拉贾蒂（Rajati, M. R.）、谢赫（Shaikh, N.）和王（Wang, J.）（2021 年）。用于分布外检测的带置信度控制的离群点暴露。《神经计算》，441 卷，138 - 150 页。</div></div></div></div><div><br></div><div><div><div>Park, H., Noh, J., &amp; Ham, B. (2020). Learning memory-guided normality for anomaly detection. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2586" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">朴（Park, H.）、诺（Noh, J.）和哈姆（Ham, B.）（2020 年）。为异常检测学习记忆引导的正常性。收录于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2587" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Park, J., Chai, J. C. L., Yoon, J., &amp; Teoh, A. B. J. (2023a). Understanding the feature norm for out-of-distribution detection. In Proceedings of the IEEE/CVF international conference on computer vision (pp. 1557-1567).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">朴（Park, J.）、柴（Chai, J. C. L.）、尹（Yoon, J.）和张（Teoh, A. B. J.）（2023a）。理解用于分布外检测的特征范数。收录于电气与电子工程师协会/计算机视觉基金会国际计算机视觉会议论文集（第 1557 - 1567 页）。</div></div></div></div><div><br></div><div><div><div>Park, J., Jung, Y. G., &amp; Teoh, A. B. J. (2023b). Nearest neighbor guidance for out-of-distribution detection. In Proceedings of the IEEE/CVF international conference on computer vision (pp. 1686-1695).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">朴（Park, J.）、郑（Jung, Y. G.）和张（Teoh, A. B. J.）（2023b）。用于分布外检测的最近邻引导。收录于电气与电子工程师协会/计算机视觉基金会国际计算机视觉会议论文集（第 1686 - 1695 页）。</div></div></div></div><div><br></div><div><div><div>Parmar, J., Chouhan, S., Raychoudhury, V., &amp; Rathore, S. (2023). Open-world machine learning: Applications, challenges, and opportunities. ACM Computing Surveys, 55(10), 1-37.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">帕尔马（Parmar, J.）、乔汉（Chouhan, S.）、雷乔杜里（Raychoudhury, V.）和拉托雷（Rathore, S.）（2023 年）。开放世界机器学习：应用、挑战与机遇。《ACM 计算调查》，55(10)，1 - 37 页。</div></div></div></div><div><br></div><div><div><div>Parzen, E. (1962). On estimation of a probability density function and mode. The Annals of Mathematical Statistics, 33, 1065-1076.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">帕尔森（Parzen, E.）（1962 年）。关于概率密度函数和众数的估计。《数理统计年鉴》，33 卷，1065 - 1076 页。</div></div></div></div><div><br></div><div><div><div>Patel, K., Han, H., &amp; Jain, A. K. (2016). Secure face unlock: Spoof detection on smartphones. IEEE Transactions on Information Forensics and Security, 11, 2268-2283.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">帕特尔（Patel, K.）、韩（Han, H.）和贾因（Jain, A. K.）（2016 年）。安全面部解锁：智能手机上的欺骗检测。《电气与电子工程师协会信息取证与安全汇刊》，11 卷，2268 - 2283 页。</div></div></div></div><div><br></div><div><div><div>Pathak, D., Agrawal, P., Efros, A. A., &amp; Darrell, T. (2017). Curiosity-driven exploration by self-supervised prediction. In ICML.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">帕塔克（Pathak, D.）、阿格拉瓦尔（Agrawal, P.）、埃弗罗斯（Efros, A. A.）和达雷尔（Darrell, T.）（2017 年）。通过自监督预测进行好奇心驱动的探索。收录于国际机器学习会议（ICML）。</div></div></div></div><div><br></div><div><div><div>Perera, P., Morariu, V. I., Jain, R., Manjunatha, V., Wigington, C., Ordonez, V., &amp; Patel, V. M. (2020). Generative-discriminative feature representations for open-set recognition. In CVPR.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">佩雷拉（Perera, P.）、莫拉里乌（Morariu, V. I.）、贾因（Jain, R.）、曼朱纳塔（Manjunatha, V.）、威金顿（Wigington, C.）、奥尔多涅斯（Ordonez, V.）和帕特尔（Patel, V. M.）（2020 年）。用于开放集识别的生成 - 判别特征表示。收录于计算机视觉与模式识别会议（CVPR）。</div></div></div></div><div><br></div><div><div><div>Perera, P., Nallapati, R., &amp; Xiang, B. (2019). Ocgan: One-class novelty detection using gans with constrained latent representations. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2588" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">佩雷拉（Perera, P.）、纳拉帕蒂（Nallapati, R.）和向（Xiang, B.）（2019 年）。Ocgan：使用具有受限潜在表示的生成对抗网络进行单类新奇检测。收录于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2589" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Perera, P., &amp; Patel, V. M. (2019). Deep transfer learning for multiple class novelty detection. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2590" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">佩雷拉（Perera, P.）和帕特尔（Patel, V. M.）（2019 年）。用于多类新奇检测的深度迁移学习。收录于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2591" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Peterson, C., &amp; Hartman, E. (1989). Explorations of the mean field theory learning algorithm. Neural Networks, 2, 475-494.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">彼得森（Peterson），C.，&amp; 哈特曼（Hartman），E.（1989）。对平均场理论学习算法的探索。《神经网络》（Neural Networks），2，475 - 494。</div></div></div></div><div><br></div><div><div><div>Pidhorskyi, S., Almohsen, R., Adjeroh, D. A., &amp; Doretto, G. (2018). Generative probabilistic novelty detection with adversarial autoen-coders. In NeurIPS.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">皮德霍尔斯基（Pidhorskyi），S.，阿尔莫森（Almohsen），R.，阿杰罗（Adjeroh），D. A.，&amp; 多雷托（Doretto），G.（2018）。使用对抗自编码器进行生成概率新奇检测。发表于神经信息处理系统大会（NeurIPS）。</div></div></div></div><div><br></div><div><div><div>Pimentel, M. A., Clifton, D. A., Clifton, L., &amp; Tarassenko, L. (2014). A review of novelty detection. Signal Processing, 99, 215-249.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">皮门特尔（Pimentel），M. A.，克利夫顿（Clifton），D. A.，克利夫顿（Clifton），L.，&amp; 塔拉森科（Tarassenko），L.（2014）。新奇检测综述。《信号处理》（Signal Processing），99，215 - 249。</div></div></div></div><div><br></div><div><div><div>Pleiss, G., Souza, A., Kim, J., Li, B., &amp; Weinberger, K. Q. (2019). Neural network out-of-distribution detection for regression tasks.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">普莱斯（Pleiss），G.，苏扎（Souza），A.，金（Kim），J.，李（Li），B.，&amp; 温伯格（Weinberger），K. Q.（2019）。用于回归任务的神经网络分布外检测。</div></div></div></div><div><br></div><div><div><div>Polatkan, G., Jafarpour, S., Brasoveanu, A., Hughes, S., &amp; Daubechies, I. (2009). Detection of forgery in paintings using supervised learning. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2592" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>I</mi><mi>P</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">波拉坎（Polatkan），G.，贾法普尔（Jafarpour），S.，布拉索韦亚努（Brasoveanu），A.，休斯（Hughes），S.，&amp; 多贝西（Daubechies），I.（2009）。使用监督学习检测绘画伪造。发表于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2593" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>I</mi><mi>P</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Powers, D. M. (2020). Evaluation: From precision, recall and f-measure to roc, informedness, markedness and correlation. In JMLT.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">鲍尔斯（Powers），D. M.（2020）。评估：从精确率、召回率和F值到受试者工作特征曲线（ROC）、信息性、显著性和相关性。发表于《机器学习技术杂志》（JMLT）。</div></div></div></div><div><br></div><div><div><div>Qui nonero-Candela, J., Sugiyama, M., Lawrence, N. D., &amp; Schwaighofer, A. (2009). Dataset shift in machine learning. MIT Press.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">基诺内罗 - 坎德拉（Qui nonero - Candela），J.，杉山（Sugiyama），M.，劳伦斯（Lawrence），N. D.，&amp; 施韦格霍费尔（Schwaighofer），A.（2009）。机器学习中的数据集偏移。麻省理工学院出版社（MIT Press）。</div></div></div></div><div><br></div><div><div><div>Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., &amp; Krueger, G.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">拉德福德（Radford），A.，金（Kim），J. W.，哈拉西（Hallacy），C.，拉梅什（Ramesh），A.，戈（Goh），G.，阿加瓦尔（Agarwal），S.，萨斯特里（Sastry），G.，阿斯凯尔（Askell），A.，米什金（Mishkin），P.，克拉克（Clark），J.，&amp; 克鲁格（Krueger），G.</div></div></div></div><div><br></div><div><div><div>(2021). Learning transferable visual models from natural language supervision. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2594" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">(2021). 从自然语言监督中学习可迁移的视觉模型。发表于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2595" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Redner, R. A., &amp; Walker, H. F. (1984). Mixture densities, maximum likelihood and the em algorithm. SIAM Review, 26(2), 195-239.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">雷德纳（Redner），R. A.，&amp; 沃克（Walker），H. F.（1984）。混合密度、最大似然和期望最大化（EM）算法。《工业与应用数学学会评论》（SIAM Review），26(2)，195 - 239。</div></div></div></div><div><br></div><div><div><div>Ren, J., Fort, S., Liu, J., Roy, A. G., Padhy, S., &amp; Lakshminarayanan, B. (2021). A simple fix to Mahalanobis distance for improving near-ood detection, arXiv preprint arXiv:2106.09022<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">任（Ren），J.，福特（Fort），S.，刘（Liu），J.，罗伊（Roy），A. G.，帕迪（Padhy），S.，&amp; 拉克什米纳拉亚南（Lakshminarayanan），B.（2021）。对马氏距离的一个简单修正以改进近分布外检测，预印本arXiv:2106.09022</div></div></div></div><div><br></div><div><div><div>Ren, J., Liu, P.J., Fertig, E., Snoek, J., Poplin, R., DePristo, M. A., Dillon, J. V., &amp; Lakshminarayanan, B. (2019). Likelihood ratios for out-of-distribution detection. In NeurIPS.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">任（Ren），J.，刘（Liu），P. J.，费蒂格（Fertig），E.，斯诺克（Snoek），J.，波普林（Poplin），R.，德普里斯特（DePristo），M. A.，狄龙（Dillon），J. V.，&amp; 拉克什米纳拉亚南（Lakshminarayanan），B.（2019）。用于分布外检测的似然比。发表于神经信息处理系统大会（NeurIPS）。</div></div></div></div><div><br></div><div><div><div>Rezende, D., &amp; Mohamed, S. (2015). Variational inference with normalizing flows. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2596" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">雷曾德（Rezende），D.，&amp; 穆罕默德（Mohamed），S.（2015）。使用归一化流的变分推断。发表于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2597" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Rudd, E. M., Jain, L. P., Scheirer, W. J., &amp; Boult, T. E. (2017). The extreme value machine. IEEE Transactions on Pattern Analysis and Machine Intelligence, 40(3), 762-768.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">鲁德（Rudd），E. M.，贾因（Jain），L. P.，谢勒（Scheirer），W. J.，&amp; 博尔特（Boult），T. E.（2017）。极值机。《电气与电子工程师协会模式分析与机器智能汇刊》（IEEE Transactions on Pattern Analysis and Machine Intelligence），40(3)，762 - 768。</div></div></div></div><div><br></div><div><div><div>Ruff, L., Kauffmann, J. R., Vandermeulen, R. A., Montavon, G., Samek, W., Kloft, M., Dietterich, T. G., &amp; Müller, K.-R. (2021). A unifying review of deep and shallow anomaly detection. In Proceedings of the IEEE.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">鲁夫（Ruff），L.，考夫曼（Kauffmann），J. R.，范德梅伦（Vandermeulen），R. A.，蒙塔冯（Montavon），G.，萨梅克（Samek），W.，克洛夫特（Kloft），M.，迪特里希（Dietterich），T. G.，&amp; 米勒（Müller），K. - R.（2021）。深度和浅层异常检测的统一综述。发表于电气与电子工程师协会会议论文集（Proceedings of the IEEE）。</div></div></div></div><div><br></div><div><div><div>Ruff, L., Vandermeulen, R., Goernitz, N., Deecke, L., Siddiqui, S. A., Binder, A., Müller, E., &amp; Kloft, M. (2018). Deep one-class classification. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2598" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">鲁夫（Ruff），L.，范德梅伦（Vandermeulen），R.，戈尔尼茨（Goernitz），N.，德克（Deecke），L.，西迪基（Siddiqui），S. A.，宾德（Binder），A.，米勒（Müller），E.，&amp; 克洛夫特（Kloft），M.（2018）。深度一类分类。发表于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2599" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Ruff, L., Vandermeulen, R. A., Görnitz, N., Binder, A., Müller, K.-R. Müller, E., &amp; Kloft, M. (2020). Deep semi-supervised anomaly detection. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2600" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>L</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">鲁夫（Ruff, L.）、范德梅伦（Vandermeulen, R. A.）、戈尔尼茨（Görnitz, N.）、宾德（Binder, A.）、米勒（Müller, K.-R.）、米勒（Müller, E.）和克洛夫特（Kloft, M.）（2020 年）。深度半监督异常检测。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2601" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>L</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Sabokrou, M., Khalooei, M., Fathy, M., &amp; Adeli, E. (2018). Adversar-ially learned one-class classifier for novelty detection. In CVPR.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">萨博克罗（Sabokrou, M.）、哈洛埃（Khalooei, M.）、法西（Fathy, M.）和阿德利（Adeli, E.）（2018 年）。用于新奇检测的对抗学习单类分类器。见计算机视觉与模式识别会议（CVPR）。</div></div></div></div><div><br></div><div><div><div>Salehi, M., Mirzaei, H., Hendrycks, D., Li, Y., Rohban, M. H., &amp; Sabokrou, M. (2021). A unified survey on anomaly, novelty, open-set, and out-of-distribution detection: Solutions and future challenges, arXiv preprint arXiv:2110.14051<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">萨利希（Salehi, M.）、米尔扎伊（Mirzaei, H.）、亨德里克斯（Hendrycks, D.）、李（Li, Y.）、罗汉（Rohban, M. H.）和萨博克罗（Sabokrou, M.）（2021 年）。异常、新奇、开放集和分布外检测的统一综述：解决方案和未来挑战，预印本 arXiv:2110.14051</div></div></div></div><div><br></div><div><div><div>Sastry, C. S., &amp; Oore, S. (2019). Detecting out-of-distribution examples with in-distribution examples and gram matrices. In NeurIPS-W.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">萨斯特里（Sastry, C. S.）和奥雷（Oore, S.）（2019 年）。使用分布内示例和格拉姆矩阵检测分布外示例。见神经信息处理系统研讨会（NeurIPS - W）。</div></div></div></div><div><br></div><div><div><div>Sastry, C. S., &amp; Oore, S. (2020). Detecting out-of-distribution examples with gram matrices. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2602" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">萨斯特里（Sastry, C. S.）和奥雷（Oore, S.）（2020 年）。使用格拉姆矩阵检测分布外示例。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2603" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Scheirer, W. J., de Rezende Rocha, A., Sapkota, A., &amp; Boult, T. E. (2013). Toward open set recognition. In TPAMI.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">谢勒（Scheirer, W. J.）、德雷森德·罗查（de Rezende Rocha, A.）、萨普科塔（Sapkota, A.）和博尔特（Boult, T. E.）（2013 年）。迈向开放集识别。见《模式分析与机器智能汇刊》（TPAMI）。</div></div></div></div><div><br></div><div><div><div>Scheirer, W. J., Jain, L. P., &amp; Boult, T. E. (2014). Probability models for open set recognition. In TPAMI.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">谢勒（Scheirer, W. J.）、贾因（Jain, L. P.）和博尔特（Boult, T. E.）（2014 年）。开放集识别的概率模型。见《模式分析与机器智能汇刊》（TPAMI）。</div></div></div></div><div><br></div><div><div><div>Schlachter, P., Liao, Y., &amp; Yang, B. (2019). Open-set recognition using intra-class splitting. In EUSIPCO.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">施拉赫特（Schlachter, P.）、廖（Liao, Y.）和杨（Yang, B.）（2019 年）。使用类内分割的开放集识别。见欧洲信号处理会议（EUSIPCO）。</div></div></div></div><div><br></div><div><div><div>Sedlmeier, A., Gabor, T., Phan, T., Belzner, L., &amp; Linnhoff-Popien, C. (2019). Uncertainty-based out-of-distribution detection in deep reinforcement learning, arXiv preprint arXiv:1901.02219<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">塞德迈尔（Sedlmeier, A.）、加博尔（Gabor, T.）、潘（Phan, T.）、贝尔兹纳（Belzner, L.）和林霍夫 - 波皮恩（Linnhoff - Popien, C.）（2019 年）。深度强化学习中基于不确定性的分布外检测，预印本 arXiv:1901.02219</div></div></div></div><div><br></div><div><div><div>Serrà, J., Álvarez, D., Gómez, V., Slizovskaia, O., Núnez, J. F., &amp; Luque, J. (2020). Input complexity and out-of-distribution detection with likelihood-based generative models.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">塞拉（Serrà, J.）、阿尔瓦雷斯（Álvarez, D.）、戈麦斯（Gómez, V.）、斯利佐夫斯卡娅（Slizovskaia, O.）、努涅斯（Núnez, J. F.）和卢克（Luque, J.）（2020 年）。基于似然的生成模型的输入复杂度和分布外检测。</div></div></div></div><div><br></div><div><div><div>Shafaei, A., Schmidt, M., &amp; Little, J. J. (2019). A less biased evaluation of out-of-distribution sample detectors. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2604" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>B</mi><mi>M</mi><mi>V</mi><mi>C</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">沙法伊（Shafaei, A.）、施密特（Schmidt, M.）和利特尔（Little, J. J.）（2019 年）。对分布外样本检测器的偏差较小的评估。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2605" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>B</mi><mi>M</mi><mi>V</mi><mi>C</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Shafer, G., &amp; Vovk, V. (2008). A tutorial on conformal prediction. Journal of Machine Learning Research, 9(3), 66.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">谢弗（Shafer, G.）和沃夫克（Vovk, V.）（2008 年）。共形预测教程。《机器学习研究杂志》，9(3)，66。</div></div></div></div><div><br></div><div><div><div>Shalev, G., Adi, Y., &amp; Keshet, J. (2018). Out-of-distribution detection using multiple semantic label representations. In NeurIPS.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">沙莱夫（Shalev, G.）、阿迪（Adi, Y.）和凯舍特（Keshet, J.）（2018 年）。使用多种语义标签表示进行分布外检测。见神经信息处理系统大会（NeurIPS）。</div></div></div></div><div><br></div><div><div><div>Shalev, G., Shalev, G.-L., &amp; Keshet, J. (2022). A baseline for detecting out-of-distribution examples in image captioning. arXiv preprint, arXiv:2207.05418<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">沙莱夫（Shalev, G.）、沙莱夫（Shalev, G.-L.）和凯舍特（Keshet, J.）（2022 年）。图像描述中检测分布外示例的基线。预印本，arXiv:2207.05418</div></div></div></div><div><br></div><div><div><div>Shao, R., Perera, P., Yuen, P. C., &amp; Patel, V. M. (2020). Open-set adversarial defense. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2606" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>E</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">邵（Shao, R.）、佩雷拉（Perera, P.）、袁（Yuen, P. C.）和帕特尔（Patel, V. M.）（2020 年）。开放集对抗防御。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2607" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>E</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Shu, Y., Cao, Z., Wang, C., Wang, J., &amp; Long, M. (2021). Open domain generalization with domain-augmented meta-learning. In CVPR.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">舒（Shu, Y.）、曹（Cao, Z.）、王（Wang, C.）、王（Wang, J.）和龙（Long, M.）（2021 年）。使用域增强元学习的开放域泛化。见计算机视觉与模式识别会议（CVPR）。</div></div></div></div><div><br></div><div><div><div>Shu, Y., Shi, Y., Wang, Y., Huang, T., &amp; Tian, Y. (2020). p-odn: Prototype-based open deep network for open set recognition. Scientific Reports, 10, 7146.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">舒，Y.，施，Y.，王，Y.，黄，T.，&amp; 田，Y.（2020）。p - odn：用于开放集识别的基于原型的开放深度网络。《科学报告》，10，7146。</div></div></div></div><div><br></div><div><div><div>Smith, R. L. (1990). Extreme value theory. Handbook of Applicable Mathematics, 7, 18.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">史密斯，R. L.（1990）。极值理论。《应用数学手册》，7，18。</div></div></div></div><div><br></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div><div data-page="27" id="mark-5aabaab3-3665-4dda-9148-df460080f130" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate" data-positiontag-26="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-26="0,0">Sorio, E., Bartoli, A., Davanzo, G., &amp; Medvet, E. (2010). Open world<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">索里奥，E.，巴尔托利，A.，达万佐，G.，&amp; 梅德韦特，E.（2010）。开放世界</div></paragraphpositioning></div></div></div><div><br></div><div><div><div>classification of printed invoices. In Proceedings of the 10th ACM symposium on document engineering.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">印刷发票的分类。见第10届ACM文档工程研讨会会议记录。</div></div></div></div><div><br></div><div><div><div>Sricharan, K., &amp; Srivastava, A. (2018). Building robust classifiers through generation of confident out of distribution examples. In NeurIPS-W.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">斯里查兰，K.，&amp; 斯里瓦斯塔瓦，A.（2018）。通过生成可信的分布外示例构建鲁棒分类器。见神经信息处理系统研讨会（NeurIPS - W）。</div></div></div></div><div><br></div><div><div><div>Sugiyama, M., &amp; Borgwardt, K. (2013). Rapid distance-based outlier detection via sampling. In NIPS.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">杉山，M.，&amp; 博格瓦尔特，K.（2013）。通过采样实现基于距离的快速离群点检测。见神经信息处理系统大会（NIPS）。</div></div></div></div><div><br></div><div><div><div>Sun, X., Ding, H., Zhang, C., Lin, G., &amp; Ling, K.-V. (2021a). M2iosr: Maximal mutual information open set recognition, arXiv preprint arXiv:2108.02373<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">孙，X.，丁，H.，张，C.，林，G.，&amp; 凌，K. - V.（2021a）。M2iosr：最大互信息开放集识别，预印本arXiv：2108.02373</div></div></div></div><div><br></div><div><div><div>Sun, X., Yang, Z., Zhang, C., Ling, K.-V., &amp; Peng, G. (2020). Conditional Gaussian distribution learning for open set recognition. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2608" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">孙，X.，杨，Z.，张，C.，凌，K. - V.，&amp; 彭，G.（2020）。用于开放集识别的条件高斯分布学习。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2609" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Sun, Y., Guo, C., &amp; Li, Y. (2021b). React: Out-of-distribution detection with rectified activations. In NeurIPS.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">孙，Y.，郭，C.，&amp; 李，Y.（2021b）。React：使用校正激活进行分布外检测。见神经信息处理系统大会（NeurIPS）。</div></div></div></div><div><br></div><div><div><div>Sun, Y., &amp; Li, Y. (2022). Dice: Leveraging sparsification for out-of-distribution detection. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2610" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>E</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">孙，Y.，&amp; 李，Y.（2022）。Dice：利用稀疏化进行分布外检测。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2611" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>E</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Sun, Y., Ming, Y., Zhu, X., &amp; Li, Y. (2022). Out-of-distribution detection with deep nearest neighbors. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2612" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">孙，Y.，明，Y.，朱，X.，&amp; 李，Y.（2022）。使用深度最近邻进行分布外检测。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2613" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Syarif, I., Prugel-Bennett, A., &amp; Wills, G. (2012). Unsupervised clustering approach for network anomaly detection. In International conference on networked digital technologies.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">西亚里夫，I.，普鲁格尔 - 贝内特，A.，&amp; 威尔斯，G.（2012）。用于网络异常检测的无监督聚类方法。见网络数字技术国际会议。</div></div></div></div><div><br></div><div><div><div>Tack, J., Mo, S., Jeong, J., &amp; Shin, J. (2020). Csi: Novelty detection via contrastive learning on distributionally shifted instances. In NeurIPS.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">塔克，J.，莫，S.，郑，J.，&amp; 申，J.（2020）。Csi：通过对分布偏移实例进行对比学习进行新奇性检测。见神经信息处理系统大会（NeurIPS）。</div></div></div></div><div><br></div><div><div><div>Tao, L., Du, X., Zhu, X., &amp; Li, Y. (2023). Non-parametric outlier synthesis. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2614" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>L</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">陶，L.，杜，X.，朱，X.，&amp; 李，Y.（2023）。非参数离群点合成。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2615" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>L</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Tariq, M. I., Memon, N. A., Ahmed, S., Tayyaba, S., Mushtaq, M. T., Mian, N. A., Imran, M., &amp; Ashraf, M. W. (2020). A review of deep learning security and privacy defensive techniques. Mobile Information Systems, 2020, 1-8.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">塔里格，M. I.，梅蒙，N. A.，艾哈迈德，S.，泰亚巴，S.，穆什塔克，M. T.，米安，N. A.，伊姆兰，M.，&amp; 阿什拉夫，M. W.（2020）。深度学习安全与隐私防御技术综述。《移动信息系统》，2020，1 - 8。</div></div></div></div><div><br></div><div><div><div>Tax, D. M. J. (2002). One-class classification: Concept learning in the absence of counter-examples.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">塔克斯，D. M. J.（2002）。一类分类：在没有反例的情况下进行概念学习。</div></div></div></div><div><br></div><div><div><div>Techapanurak, E., Suganuma, M., &amp; Okatani, T. (2020). Hyperparameter-free out-of-distribution detection using cosine similarity. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2616" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>A</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">泰查帕努拉克（Techapanurak），E.，菅沼（Suganuma），M.，及冈谷（Okatani），T.（2020）。使用余弦相似度的无超参数分布外检测。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2617" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>A</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Thulasidasan, S., Chennupati, G., Bilmes, J., Bhattacharya, T., &amp; Michalak, S. (2019). On mixup training: Improved calibration and predictive uncertainty for deep neural networks. In NeurIPS.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">图拉萨迪桑（Thulasidasan），S.，钱努帕蒂（Chennupati），G.，比尔梅斯（Bilmes），J.，巴塔查里亚（Bhattacharya），T.，及米查拉克（Michalak），S.（2019）。关于混合训练：提高深度神经网络的校准和预测不确定性。见神经信息处理系统大会（NeurIPS）。</div></div></div></div><div><br></div><div><div><div>Thulasidasan, S., Thapa, S., Dhaubhadel, S., Chennupati, G., Bhat-tacharya, T., &amp; Bilmes, J. (2021). An effective baseline for robustness to distributional shift, arXiv preprint arXiv:2105.07107<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">图拉萨迪桑（Thulasidasan），S.，塔帕（Thapa），S.，多布哈德尔（Dhaubhadel），S.，钱努帕蒂（Chennupati），G.，巴塔查里亚（Bhat - tacharya），T.，及比尔梅斯（Bilmes），J.（2021）。应对分布偏移鲁棒性的有效基线，预印本arXiv:2105.07107</div></div></div></div><div><br></div><div><div><div>Tian, J., Azarian, M. H., &amp; Pecht, M. (2014). Anomaly detection using self-organizing maps-based k-nearest neighbor algorithm. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2618" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>P</mi><mi>H</mi><mi>M</mi></mrow></math></mjx-assistive-mml></mjx-container> society European conference.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">田（Tian），J.，阿扎里安（Azarian），M. H.，及佩希特（Pecht），M.（2014）。使用基于自组织映射的k近邻算法进行异常检测。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2619" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>P</mi><mi>H</mi><mi>M</mi></mrow></math></mjx-assistive-mml></mjx-container>协会欧洲会议。</div></div></div></div><div><br></div><div><div><div>Tian, K., Zhou, S., Fan, J., &amp; Guan, J. (2019). Learning competitive and discriminative reconstructions for anomaly detection. In AAAI.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">田（Tian），K.，周（Zhou），S.，范（Fan），J.，及关（Guan），J.（2019）。学习用于异常检测的竞争性和判别性重建。见美国人工智能协会会议（AAAI）。</div></div></div></div><div><br></div><div><div><div>Torralba, A., Fergus, R., &amp; Freeman, W. T. (2008). 80 million tiny images: A large data set for nonparametric object and scene recognition. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2620" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>T</mi><mi>P</mi><mi>A</mi><mi>M</mi><mi>I</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">托拉尔巴（Torralba），A.，弗格斯（Fergus），R.，及弗里曼（Freeman），W. T.（2008）。八千万张小图像：用于非参数对象和场景识别的大型数据集。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2621" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>T</mi><mi>P</mi><mi>A</mi><mi>M</mi><mi>I</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Turcotte, M., Moore, J., Heard, N., &amp; McPhall, A. (2016). Poisson factorization for peer-based anomaly detection. In IEEE conference on intelligence and security informatics (ISI).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">图尔科特（Turcotte），M.，摩尔（Moore），J.，赫德（Heard），N.，及麦克法尔（McPhall），A.（2016）。基于同行的异常检测的泊松因子分解。见电气与电子工程师协会智能与安全信息学会议（IEEE ISI）。</div></div></div></div><div><br></div><div><div><div>Van Amersfoort, J., Smith, L., Teh, Y. W., &amp; Gal, Y. (2020). Uncertainty estimation using a single deep deterministic neural network. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2622" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">范·阿默斯福特（Van Amersfoort），J.，史密斯（Smith），L.， Teh，Y. W.，及加尔（Gal），Y.（2020）。使用单个深度确定性神经网络进行不确定性估计。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2623" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Van den Broeck, J., Argeseanu Cunningham, S., Eeckels, R., &amp; Herbst, K. (2005). Data cleaning: Detecting, diagnosing, and editing data abnormalities. PLoS Medicine, 2, 267.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">范登·布罗克（Van den Broeck），J.，阿格塞亚努·坎宁安（Argeseanu Cunningham），S.，埃克尔斯（Eeckels），R.，及赫布斯特（Herbst），K.（2005）。数据清理：检测、诊断和编辑数据异常。《公共科学图书馆·医学》，2，267。</div></div></div></div><div><br></div><div><div><div>Van Oord, A., Kalchbrenner, N., &amp; Kavukcuoglu, K. (2016). Pixel recurrent neural networks. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2624" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">范·奥尔德（Van Oord），A.，卡尔赫布伦纳（Kalchbrenner），N.，及卡武库奥卢（Kavukcuoglu），K.（2016）。像素循环神经网络。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2625" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Van Ryzin, J. (1973). A histogram method of density estimation. Communications in Statistics-Theory and Methods, 2,493-506.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">范·赖津（Van Ryzin），J.（1973）。一种密度估计的直方图方法。《统计学通讯 - 理论与方法》，2，493 - 506。</div></div></div></div><div><br></div><div><div><div>Vaze, S., Han, K., Vedaldi, A., &amp; Zisserman, A. (2022a). Generalized category discovery. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2626" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">瓦兹（Vaze），S.，韩（Han），K.，韦尔迪耶（Vedaldi），A.，及齐斯曼（Zisserman），A.（2022a）。广义类别发现。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2627" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Vaze, S., Han, K., Vedaldi, A., &amp; Zisserman, A. (2022b). Open-set recognition: A good closed-set classifier is all you need. In ICLR.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">瓦兹（Vaze），S.，韩（Han），K.，韦尔迪耶（Vedaldi），A.，及齐斯曼（Zisserman），A.（2022b）。开放集识别：你只需要一个好的封闭集分类器。见国际学习表征会议（ICLR）。</div></div></div></div><div><br></div><div><div><div>Vernekar, S., Gaurav, A., Abdelzad, V., Denouden, T., Salay, R., &amp; Czarnecki, K. (2019). Out-of-distribution detection in classifiers<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">韦尔内卡尔（Vernekar），S.，高拉夫（Gaurav），A.，阿卜杜勒扎德（Abdelzad），V.，德努登（Denouden），T.，萨莱（Salay），R.，及恰尔内茨基（Czarnecki），K.（2019）。分类器中的分布外检测</div></div></div></div><div><br></div><div><div><div>via generation. In NeurIPS-W.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">通过生成方法。见神经信息处理系统大会研讨会（NeurIPS - W）。</div></div></div></div><div><br></div><div><div><div>Vinyals, O., Ewalds, T., Bartunov, S., Georgiev, P., Vezhnevets, A. S., Yeo, M., Makhzani, A., Küttler, H., Agapiou, J., Schrittwieser, J., &amp; Quan, J. (2017). Starcraft II: A new challenge for reinforcement learning, arXiv preprint arXiv:1708.04782<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">维尼亚尔斯（Vinyals），O.，埃瓦尔德斯（Ewalds），T.，巴尔图诺夫（Bartunov），S.，格奥尔基耶夫（Georgiev），P.，韦日涅韦茨（Vezhnevets），A. S.，杨（Yeo），M.，马赫扎尼（Makhzani），A.，库特勒（Küttler），H.，阿加皮乌（Agapiou），J.，施里特维泽（Schrittwieser），J.，及权（Quan），J.（2017）。《星际争霸II》：强化学习的新挑战，预印本arXiv:1708.04782</div></div></div></div><div><br></div><div><div><div>Vyas, A., Jammalamadaka, N., Zhu, X., Das, D., Kaul, B., &amp; Willke, T. L. (2018). Out-of-distribution detection using an ensemble of self supervised leave-out classifiers. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2628" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>E</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">维亚斯（Vyas），A.，贾马拉马德卡（Jammalamadaka），N.，朱（Zhu），X.，达斯（Das），D.，考尔（Kaul），B.，&amp; 威尔克（Willke），T. L.（2018）。使用自监督留一分类器集成进行分布外检测。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2629" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>E</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Wang, H., Bah, M. J., &amp; Hammad, M. (2019a). Progress in outlier detection techniques: A survey. IEEE Access, 7, 107964-108000.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">王（Wang），H.，巴赫（Bah），M. J.，&amp; 哈马德（Hammad），M.（2019a）。离群值检测技术的进展：综述。《IEEE接入》，7，107964 - 108000。</div></div></div></div><div><br></div><div><div><div>Wang, H., Li, Y., Yao, H., &amp; Li, X. (2023a). Clipn for zero-shot ood detection: Teaching clip to say no. In Proceedings of the IEEE/CVF international conference on computer vision (pp. 1802-1812).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">王（Wang），H.，李（Li），Y.，姚（Yao），H.，&amp; 李（Li），X.（2023a）。用于零样本分布外检测的Clipn：教会Clip说“不”。见《IEEE/CVF国际计算机视觉会议论文集》（第1802 - 1812页）。</div></div></div></div><div><br></div><div><div><div>Wang, H., Li, Z., Feng, L., &amp; Zhang, W. (2022a). Vim: Out-of-distribution with virtual-logit matching. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">王（Wang），H.，李（Li），Z.，冯（Feng），L.，&amp; 张（Zhang），W.（2022a）。Vim：基于虚拟对数匹配的分布外检测。见《IEEE/CVF计算机视觉与模式识别会议论文集》。</div></div></div></div><div><br></div><div><div><div>Wang, H., Liu, W., Bocchieri, A., &amp; Li, Y. (2021). Can multi-label classification networks know what they don't know? NeurIPS, 34, 29074-29087.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">王（Wang），H.，刘（Liu），W.，博基耶里（Bocchieri），A.，&amp; 李（Li），Y.（2021）。多标签分类网络能知道它们不知道的东西吗？《神经信息处理系统大会》，34，29074 - 29087。</div></div></div></div><div><br></div><div><div><div>Wang, H., Wu, X., Huang, Z., &amp; Xing, E. P. (2020). High-frequency component helps explain the generalization of convolutional neural networks. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2630" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">王（Wang），H.，吴（Wu），X.，黄（Huang），Z.，&amp; 邢（Xing），E. P.（2020）。高频分量有助于解释卷积神经网络的泛化能力。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2631" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Wang, M., &amp; Deng, W. (2018). Deep visual domain adaptation: A survey. Neurocomputing, 312, 135-153.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">王（Wang），M.，&amp; 邓（Deng），W.（2018）。深度视觉领域自适应：综述。《神经计算》，312，135 - 153。</div></div></div></div><div><br></div><div><div><div>Wang, Q., Fang, Z., Zhang, Y., Liu, F., Li, Y., &amp; Han, B. (2023b). Learning to augment distributions for out-of-distribution detection. Advances in Neural Information Processing Systems, 36, 66.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">王（Wang），Q.，方（Fang），Z.，张（Zhang），Y.，刘（Liu），F.，李（Li），Y.，&amp; 韩（Han），B.（2023b）。为分布外检测学习增强分布。《神经信息处理系统进展》，36，66。</div></div></div></div><div><br></div><div><div><div>Wang, Q., Liu, F., Zhang, Y., Zhang, J., Gong, C., Liu, T., &amp; Han, B. (2022b). Watermarking for out-of-distribution detection. In NeurIPS.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">王（Wang），Q.，刘（Liu），F.，张（Zhang），Y.，张（Zhang），J.，龚（Gong），C.，刘（Liu），T.，&amp; 韩（Han），B.（2022b）。用于分布外检测的水印技术。见《神经信息处理系统大会》。</div></div></div></div><div><br></div><div><div><div>Wang, Q., Ye, J., Liu, F., Dai, Q., Kalander, M., Liu, T., Hao, J., &amp; Han, B. (2023c). Out-of-distribution detection with implicit outlier transformation.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">王（Wang），Q.，叶（Ye），J.，刘（Liu），F.，戴（Dai），Q.，卡兰德（Kalander），M.，刘（Liu），T.，郝（Hao），J.，&amp; 韩（Han），B.（2023c）。基于隐式离群值变换的分布外检测。</div></div></div></div><div><br></div><div><div><div>Wang, W., Zheng, V. W., Yu, H., &amp; Miao, C. (2019b). A survey of zero-shot learning: Settings, methods, and applications. In TIST.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">王（Wang），W.，郑（Zheng），V. W.，余（Yu），H.，&amp; 苗（Miao），C.（2019b）。零样本学习综述：设置、方法和应用。见《ACM智能系统与技术汇刊》（TIST）。</div></div></div></div><div><br></div><div><div><div>Wang, Y., Li, B., Che, T., Zhou, K., Liu, Z., &amp; Li, D. (2021). Energy-based open-world uncertainty modeling for confidence calibration. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2632" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">王（Wang），Y.，李（Li），B.，车（Che），T.，周（Zhou），K.，刘（Liu），Z.，&amp; 李（Li），D.（2021）。基于能量的开放世界不确定性建模用于置信度校准。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2633" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Wang, Y., Liu, W., Ma, X., Bailey, J., Zha, H., Song, L., &amp; Xia, S.-T. (2018). Iterative learning with open-set noisy labels. In CVPR.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">王（Wang），Y.，刘（Liu），W.，马（Ma），X.，贝利（Bailey），J.，查（Zha），H.，宋（Song），L.，&amp; 夏（Xia），S.-T.（2018）。使用开放集噪声标签进行迭代学习。见《计算机视觉与模式识别会议》（CVPR）。</div></div></div></div><div><br></div><div><div><div>Wei, H., Xie, R., Cheng, H., Feng, L., An, B., &amp; Li, Y. (2022). Mitigating neural network overconfidence with logit normalization. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2634" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">魏（Wei），H.，谢（Xie），R.，程（Cheng），H.，冯（Feng），L.，安（An），B.，&amp; 李（Li），Y.（2022）。通过对数归一化减轻神经网络的过度自信。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2635" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Welling, M., &amp; Teh, Y. W. (2011). Bayesian learning via stochastic gradient Langevin dynamics. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2636" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">韦林（Welling），M.，&amp;  Teh，Y. W.（2011）。通过随机梯度朗之万动力学进行贝叶斯学习。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2637" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Wen, D., Han, H., &amp; Jain, A. K. (2015). Face spoof detection with image distortion analysis. IEEE Transactions on Information Forensics and Security, 10, 746-761.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">温（Wen），D.，韩（Han），H.，&amp; 贾因（Jain），A. K.（2015）。基于图像失真分析的人脸欺骗检测。《IEEE信息取证与安全汇刊》，10，746 - 761。</div></div></div></div><div><br></div><div><div><div>Wenzel, F., Roth, K., Veeling, B. S., Swiatkowski, J., Tran, L., Mandt, S., Snoek, J., Salimans, T., Jenatton, R., &amp; Nowozin, S. (2020). How good is the Bayes posterior in deep neural networks really? In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2638" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">温泽尔（Wenzel, F.）、罗斯（Roth, K.）、维林（Veeling, B. S.）、斯维亚托夫斯基（Swiatkowski, J.）、陈（Tran, L.）、曼特（Mandt, S.）、斯诺克（Snoek, J.）、萨利曼斯（Salimans, T.）、热纳通（Jenatton, R.）和诺沃津（Nowozin, S.）（2020 年）。深度神经网络中的贝叶斯后验到底有多好？见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2639" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Wettschereck, D. (1994). A study of distance-based machine learning algorithms.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">韦特舍雷克（Wettschereck, D.）（1994 年）。基于距离的机器学习算法研究。</div></div></div></div><div><br></div><div><div><div>Wikipedia contributors. (2021). Outlier from Wikipedia, the free encyclopedia. Retrieved August 12, 2021<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">维基百科贡献者（2021 年）。来自免费百科全书维基百科的离群值。2021 年 8 月 12 日检索</div></div></div></div><div><br></div><div><div><div>Wu, X., Lu, J., Fang, Z., &amp; Zhang, G. (2023). Meta ood learning for continuously adaptive ood detection. In Proceedings of the IEEE/CVF international conference on computer vision (pp. 19353-19364).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">吴（Wu, X.）、陆（Lu, J.）、方（Fang, Z.）和张（Zhang, G.）（2023 年）。用于连续自适应分布外检测的元分布外学习。见《电气与电子工程师协会/计算机视觉基金会国际计算机视觉会议论文集》（第 19353 - 19364 页）。</div></div></div></div><div><br></div><div><div><div>Wu, Z.-F., Wei, T., Jiang, J., Mao, C., Tang, M., &amp; Li, Y.-F. (2021). Ngc: A unified framework for learning with open-world noisy data. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2640" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">吴（Wu, Z.-F.）、魏（Wei, T.）、江（Jiang, J.）、毛（Mao, C.）、唐（Tang, M.）和李（Li, Y.-F.）（2021 年）。Ngc：一个用于开放世界噪声数据学习的统一框架。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2641" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div></div></div></div></span></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"></div><div><div data-page="28" id="mark-947ab0b6-d0d4-4856-98be-ef5ff672dcfd" class="markdown-parser-view mb-5 relative cursor-pointer"><div class="locator-translate alive_postion_page_md" data-positiontag-27="0,0"><div style="height: auto;"><span style="display: inline;"><div><div><div><paragraphpositioning data-position-27="0,0">Xia, Y., Cao, X., Wen, F., Hua, G., &amp; Sun, J. (2015). Learning discriminative reconstructions for unsupervised outlier removal. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2550" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">夏（Xia, Y.）、曹（Cao, X.）、文（Wen, F.）、华（Hua, G.）和孙（Sun, J.）（2015 年）。学习用于无监督离群值去除的判别性重建。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2551" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></paragraphpositioning></div></div></div><div><br></div><div><div><div>Xiao, T., Zhang, C., &amp; Zha, H. (2015). Learning to detect anomalies in surveillance video. IEEE Signal Processing Letters, 22, 1477- 1481.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">肖（Xiao, T.）、张（Zhang, C.）和查（Zha, H.）（2015 年）。学习检测监控视频中的异常。《电气与电子工程师协会信号处理快报》，22 卷，1477 - 1481 页。</div></div></div></div><div><br></div><div><div><div>Xiao, Y., Wang, H., Xu, W., &amp; Zhou, J. (2013). L1 norm based kpca for novelty detection. Pattern Recognition, 46, 389-396.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">肖（Xiao, Y.）、王（Wang, H.）、徐（Xu, W.）和周（Zhou, J.）（2013 年）。基于 L1 范数的核主成分分析用于新奇性检测。《模式识别》，46 卷，389 - 396 页。</div></div></div></div><div><br></div><div><div><div>Xiao, Z., Yan, Q., &amp; Amit, Y. (2020). Likelihood regret: An out-of-distribution detection score for variational auto-encoder. In NeurIPS.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">肖（Xiao, Z.）、严（Yan, Q.）和阿米特（Amit, Y.）（2020 年）。似然遗憾：变分自编码器的分布外检测分数。见神经信息处理系统大会（NeurIPS）。</div></div></div></div><div><br></div><div><div><div>Xie, M., Hu, J., &amp; Tian, B. (2012). Histogram-based online anomaly detection in hierarchical wireless sensor networks. In ICTSPCC.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">谢（Xie, M.）、胡（Hu, J.）和田（Tian, B.）（2012 年）。分层无线传感器网络中基于直方图的在线异常检测。见信息与通信技术系统与产品控制会议（ICTSPCC）。</div></div></div></div><div><br></div><div><div><div>Xu, H., Liu, B., Shu, L., &amp; Yu, P. (2019). Open-world learning and application to product classification. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2552" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>W</mi><mi>W</mi><mi>W</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">徐（Xu, H.）、刘（Liu, B.）、舒（Shu, L.）和余（Yu, P.）（2019 年）。开放世界学习及其在产品分类中的应用。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2553" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>W</mi><mi>W</mi><mi>W</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Yan, X., Zhang, H., Xu, X., Hu, X., &amp; Heng, P.-A. (2021). Learning semantic context from normal samples for unsupervised anomaly detection. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2554" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>A</mi><mi>A</mi><mi>A</mi><mi>I</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">严（Yan, X.）、张（Zhang, H.）、徐（Xu, X.）、胡（Hu, X.）和亨（Heng, P.-A.）（2021 年）。从正常样本中学习语义上下文用于无监督异常检测。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2555" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>A</mi><mi>A</mi><mi>A</mi><mi>I</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Yang, J., Chen, W., Feng, L., Yan, X., Zheng, H., &amp; Zhang, W. (2020a). Webly supervised image classification with metadata: Automatic noisy label correction via visual-semantic graph. In ACM multimedia.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">杨（Yang, J.）、陈（Chen, W.）、冯（Feng, L.）、严（Yan, X.）、郑（Zheng, H.）和张（Zhang, W.）（2020a）。利用元数据进行网络监督图像分类：通过视觉 - 语义图自动纠正噪声标签。见美国计算机协会多媒体会议（ACM multimedia）。</div></div></div></div><div><br></div><div><div><div>Yang, J., Feng, L., Chen, W., Yan, X., Zheng, H., Luo, P., &amp; Zhang, W. (2020b). Webly supervised image classification with self-contained confidence. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2556" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>E</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">杨（Yang, J.）、冯（Feng, L.）、陈（Chen, W.）、严（Yan, X.）、郑（Zheng, H.）、罗（Luo, P.）和张（Zhang, W.）（2020b）。具有自包含置信度的网络监督图像分类。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2557" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>E</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Yang, J., Wang, H., Feng, L., Yan, X., Zheng, H., Zhang, W., &amp; Liu, Z. (2021). Semantically coherent out-of-distribution detection. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2558" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">杨（Yang, J.）、王（Wang, H.）、冯（Feng, L.）、严（Yan, X.）、郑（Zheng, H.）、张（Zhang, W.）和刘（Liu, Z.）（2021 年）。语义连贯的分布外检测。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2559" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Yang, J., Wang, P., Zou, D., Zhou, Z., Ding, K., Peng, W., Wang, H., Chen, G., Li, B., Sun, Y., Du, X., Zhou, K., Zhang, W., Hendrycks, D., Li, Y., &amp; Liu, Z. (2022a). Openood: Benchmarking generalized out-of-distribution detection. In NeurIPS.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">杨（Yang, J.）、王（Wang, P.）、邹（Zou, D.）、周（Zhou, Z.）、丁（Ding, K.）、彭（Peng, W.）、王（Wang, H.）、陈（Chen, G.）、李（Li, B.）、孙（Sun, Y.）、杜（Du, X.）、周（Zhou, K.）、张（Zhang, W.）、亨德里克斯（Hendrycks, D.）、李（Li, Y.）和刘（Liu, Z.）（2022a）。Openood：广义分布外检测基准测试。见神经信息处理系统大会（NeurIPS）。</div></div></div></div><div><br></div><div><div><div>Yang, J., Zhou, K., &amp; Liu, Z. (2022b). Full-spectrum out-of-distribution detection, arXiv preprint arXiv:2204.05306<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">杨（Yang）、周（Zhou）和刘（Liu）（2022b）。全谱分布外检测，arXiv预印本arXiv:2204.05306</div></div></div></div><div><br></div><div><div><div>Yang, P., Baracchi, D., Ni, R., Zhao, Y., Argenti, F., &amp; Piva, A. (2020c). A survey of deep learning-based source image forensics. Journal of Imaging, 6, 66.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">杨（Yang）、巴拉奇（Baracchi）、倪（Ni）、赵（Zhao）、阿尔真蒂（Argenti）和皮瓦（Piva）（2020c）。基于深度学习的源图像取证综述。《成像杂志》，6，66。</div></div></div></div><div><br></div><div><div><div>Yang, X., Latecki, L. J., &amp; Pokrajac, D. (2009). Outlier detection with globally optimal exemplar-based gmm. In SIAM.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">杨（Yang）、拉特茨基（Latecki）和波克拉亚茨（Pokrajac）（2009）。基于全局最优范例的高斯混合模型的离群点检测。发表于美国工业与应用数学学会（SIAM）会议。</div></div></div></div><div><br></div><div><div><div>Yang, Y., Gao, R., &amp; Xu, Q. (2022c). Out-of-distribution detection with semantic mismatch under masking. In ECCV.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">杨（Yang）、高（Gao）和徐（Xu）（2022c）。掩码下基于语义不匹配的分布外检测。发表于欧洲计算机视觉会议（ECCV）。</div></div></div></div><div><br></div><div><div><div>Yang, Z., Li, L., Lin, K., Wang, J., Lin, C.-C., Liu, Z., &amp; Wang, L. (2023). The dawn of lmms Preliminary explorations with gpt-4v (ision). arXiv preprint, arXiv:2309.17421<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">杨（Yang）、李（Li）、林（Lin）、王（Wang）、林（Lin）、刘（Liu）和王（Wang）（2023）。大型多模态模型（LMMs）的曙光——基于GPT - 4V（ision）的初步探索。arXiv预印本，arXiv:2309.17421</div></div></div></div><div><br></div><div><div><div>Yoshihashi, R., Shao, W., Kawakami, R., You, S., Iida, M., &amp; Nae-mura, T. (2019). Classification-reconstruction learning for open-set recognition. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2560" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">吉桥（Yoshihashi）、邵（Shao）、川上（Kawakami）、尤（You）、饭田（Iida）和中村（Nae - mura）（2019）。用于开放集识别的分类 - 重建学习。发表于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2561" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Yu, Q., &amp; Aizawa, K. (2019). Unsupervised out-of-distribution detection by maximum classifier discrepancy. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2562" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">余（Yu）和相泽（Aizawa）（2019）。基于最大分类器差异的无监督分布外检测。发表于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2563" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Yue, Z., Wang, T., Sun, Q., Hua, X.-S., &amp; Zhang, H. (2021). Counterfactual zero-shot and open-set visual recognition. In CVPR.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">岳（Yue）、王（Wang）、孙（Sun）、华（Hua）和张（Zhang）（2021）。反事实零样本和开放集视觉识别。发表于计算机视觉与模式识别会议（CVPR）。</div></div></div></div><div><br></div><div><div><div>Yun, S., Han, D., Oh, S. J., Chun, S., Choe, J., &amp; Yoo, Y. (2019). Cutmix: Regularization strategy to train strong classifiers with localizable features. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2564" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">尹（Yun）、韩（Han）、吴（Oh）、春（Chun）、崔（Choe）和柳（Yoo）（2019）。Cutmix：一种使用可定位特征训练强分类器的正则化策略。发表于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2565" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Zaeemzadeh, A., Bisagno, N., Sambugaro, Z., Conci, N., Rahnavard, N., &amp; Shah, M. (2021). Out-of-distribution detection using union of 1-dimensional subspaces. In CVPR.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">扎伊姆扎德（Zaeemzadeh）、比萨尼奥（Bisagno）、桑布加罗（Sambugaro）、孔奇（Conci）、拉赫纳瓦尔（Rahnavard）和沙阿（Shah）（2021）。使用一维子空间并集的分布外检测。发表于计算机视觉与模式识别会议（CVPR）。</div></div></div></div><div><br></div><div><div><div>Zenati, H., Foo, C. S., Lecouat, B., Manek, G., &amp; Chandrasekhar, V. R. (2018). Efficient gan-based anomaly detection. In ICLR-W.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">泽纳蒂（Zenati）、傅（Foo）、勒库阿（Lecouat）、马内克（Manek）和钱德拉塞卡尔（Chandrasekhar）（2018）。基于生成对抗网络（GAN）的高效异常检测。发表于国际学习表征会议研讨会（ICLR - W）。</div></div></div></div><div><br></div><div><div><div>Zhai, S., Cheng, Y., Lu, W., &amp; Zhang, Z. (2016). Deep structured energy based models for anomaly detection. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2566" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">翟（Zhai）、程（Cheng）、陆（Lu）和张（Zhang）（2016）。基于深度结构化能量模型的异常检测。发表于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2567" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Zhang, B., &amp; Zuo, W. (2008). Learning from positive and unlabeled examples: A survey. In International symposiums on information processing.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">张（Zhang）和左（Zuo）（2008）。从正例和无标签示例中学习：综述。发表于国际信息处理研讨会。</div></div></div></div><div><br></div><div><div><div>Zhang, H., Li, A., Guo, J., &amp; Guo, Y. (2020). Hybrid models for open set recognition. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2568" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>E</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">张（Zhang）、李（Li）、郭（Guo）和郭（Guo）（2020）。用于开放集识别的混合模型。发表于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2569" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>E</mi><mi>C</mi><mi>C</mi><mi>V</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Zhang, H., &amp; Patel, V. M. (2016). Sparse representation-based open set recognition. In TPAMI.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">张（Zhang）和帕特尔（Patel）（2016）。基于稀疏表示的开放集识别。发表于《模式分析与机器智能汇刊》（TPAMI）。</div></div></div></div><div><br></div><div><div><div>Zhang, J., Fu, Q., Chen, X., Du, L., Li, Z., Wang, G., Han, S., &amp; Zhang, D. (2023a). Out-of-distribution detection based on in-distribution data patterns memorization with modern Hopfield energy. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2570" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>L</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">张（Zhang）、傅（Fu）、陈（Chen）、杜（Du）、李（Li）、王（Wang）、韩（Han）和张（Zhang）（2023a）。基于现代霍普菲尔德能量的分布内数据模式记忆的分布外检测。发表于<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2571" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>L</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Zhang, J., Inkawhich, N., Linderman, R., Chen, Y., &amp; Li, H. (2023b). Mixture outlier exposure: Towards out-of-distribution detection in fine-grained environments. In Proceedings of the IEEE/CVF winter conference on applications of computer vision (WACV) (pp. 5531-5540).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">张（Zhang）、英卡维奇（Inkawhich）、林德曼（Linderman）、陈（Chen）和李（Li）（2023b）。混合离群值暴露：实现细粒度环境中的分布外检测。见《电气与电子工程师协会/计算机视觉基金会冬季计算机视觉应用会议（WACV）论文集》（第5531 - 5540页）。</div></div></div></div><div><br></div><div><div><div>Zhang, J., Yang, J., Wang, P., Wang, H., Lin, Y., Zhang, H., Sun, Y., Du, X., Zhou, K., Zhang, W., Li, Y., Liu, Z., Chen, Y., &amp; Li, H. (2023c). Openood v1.5: Enhanced benchmark for out-of-distribution detection. arXiv preprint, arXiv:2306.09301<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">张（Zhang）、杨（Yang）、王（Wang）、王（Wang）、林（Lin）、张（Zhang）、孙（Sun）、杜（Du）、周（Zhou）、张（Zhang）、李（Li）、刘（Liu）、陈（Chen）和李（Li）（2023c）。Openood v1.5：增强的分布外检测基准。预印本，arXiv:2306.09301</div></div></div></div><div><br></div><div><div><div>Zhang, L., Goldstein, M., &amp; Ranganath, R. (2021). Understanding failures in out-of-distribution detection with deep generative models. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2572" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">张（Zhang）、戈尔茨坦（Goldstein）和兰加纳特（Ranganath）（2021）。理解深度生成模型在分布外检测中的失败原因。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2573" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>M</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Zhao, B., &amp; Han, K. (2021). Novel visual category discovery with dual ranking statistics and mutual knowledge distillation. In NeurIPS.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">赵（Zhao）和韩（Han）（2021）。利用双重排序统计和相互知识蒸馏进行新型视觉类别发现。见《神经信息处理系统大会（NeurIPS）》。</div></div></div></div><div><br></div><div><div><div>Zheng, H., Wang, Q., Fang, Z., Xia, X., Liu, F., Liu, T., &amp; Han, B. (2023). Out-of-distribution detection learning with unreliable out-of-distribution sources. In NeurIPS.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">郑（Zheng）、王（Wang）、方（Fang）、夏（Xia）、刘（Liu）、刘（Liu）和韩（Han）（2023）。利用不可靠的分布外源进行分布外检测学习。见《神经信息处理系统大会（NeurIPS）》。</div></div></div></div><div><br></div><div><div><div>Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., &amp; Torralba, A. (2017). Places: A 10 million image database for scene recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 40, 1452-1464.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">周（Zhou）、拉佩德里萨（Lapedriza）、科斯拉（Khosla）、奥利瓦（Oliva）和托拉尔巴（Torralba）（2017）。Places：用于场景识别的千万图像数据库。《电气与电子工程师协会模式分析与机器智能汇刊》，40，1452 - 1464。</div></div></div></div><div><br></div><div><div><div>Zhou, C., Neubig, G., Gu, J., Diab, M., Guzman, P., Zettlemoyer, L., &amp; Ghazvininejad, M. (2020). Detecting hallucinated content in conditional neural sequence generation. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2574" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>A</mi><mi>C</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">周（Zhou）、纽比格（Neubig）、顾（Gu）、迪亚布（Diab）、古兹曼（Guzman）、泽特尔莫耶（Zettlemoyer）和加兹维尼内贾德（Ghazvininejad）（2020）。检测条件神经序列生成中的幻觉内容。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2575" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>A</mi><mi>C</mi><mi>L</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Zhou, D.-W., Ye, H.-J., &amp; Zhan, D.-C. (2021a). Learning placeholders for open-set recognition. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2576" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">周（Zhou）、叶（Ye）和詹（Zhan）（2021a）。学习用于开放集识别的占位符。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2577" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Zhou, K., Liu, Z., Qiao, Y., Xiang, T., &amp; Loy, C. C. (2021b). Domain generalization: A survey, arXiv preprint arXiv:2103.02503<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">周（Zhou）、刘（Liu）、乔（Qiao）、向（Xiang）和洛伊（Loy）（2021b）。领域泛化：综述，预印本arXiv:2103.02503</div></div></div></div><div><br></div><div><div><div>Zhou, K., Yang, J., Loy, C. C., &amp; Liu, Z. (2022a). Learning to prompt for vision-language models. In International Journal of Computer Vision (IJCV).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">周（Zhou）、杨（Yang）、洛伊（Loy）和刘（Liu）（2022a）。学习为视觉 - 语言模型设置提示。见《国际计算机视觉杂志（IJCV）》。</div></div></div></div><div><br></div><div><div><div>Zhou, K., Yang, J., Loy, C. C., &amp; Liu, Z. (2022b). Conditional prompt learning for vision-language models. In IEEE/CVF conference on computer vision and pattern recognition (CVPR).<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">周（Zhou）、杨（Yang）、洛伊（Loy）和刘（Liu）（2022b）。视觉 - 语言模型的条件提示学习。见《电气与电子工程师协会/计算机视觉基金会计算机视觉与模式识别会议（CVPR）》。</div></div></div></div><div><br></div><div><div><div>Zhou, Y. (2022). Rethinking reconstruction autoencoder-based out-of-distribution detection. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2578" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">周（Zhou）（2022）。重新思考基于重构自编码器的分布外检测。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2579" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Zimmerer, D., Full, P. M., Isensee, F., Jäger, P., Adler, T., Petersen, J., Köhler, G., Ross, T., Reinke, A., Kascenas, A., &amp; Jensen, B. S. (2022). Mood 2020: A public benchmark for out-of-distribution detection and localization on medical images. IEEE Transactions on Medical Imaging, 41, 2728-2738.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">齐默勒（Zimmerer）、富尔（Full）、伊森塞（Isensee）、耶格（Jäger）、阿德勒（Adler）、彼得森（Petersen）、克勒（Köhler）、罗斯（Ross）、赖因克（Reinke）、卡斯塞纳斯（Kascenas）和詹森（Jensen）（2022）。Mood 2020：医学图像分布外检测和定位的公共基准。《电气与电子工程师协会医学成像汇刊》，41，2728 - 2738。</div></div></div></div><div><br></div><div><div><div>Zisselman, E., &amp; Tamar, A. (2020). Deep residual flow for out of distribution detection. In <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2580" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container> .<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">齐塞尔曼（Zisselman）和塔马尔（Tamar）（2020）。用于分布外检测的深度残差流。见<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2581" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>V</mi><mi>P</mi><mi>R</mi></mrow></math></mjx-assistive-mml></mjx-container>。</div></div></div></div><div><br></div><div><div><div>Zong, B., Song, Q., Min, M. R., Cheng, W., Lumezanu, C., Cho, D., &amp; Chen, H. (2018). Deep autoencoding Gaussian mixture model for unsupervised anomaly detection. In ICLR.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">宗（Zong）、宋（Song）、闵（Min）、程（Cheng）、卢梅扎努（Lumezanu）、赵（Cho）和陈（Chen）（2018）。用于无监督异常检测的深度自编码高斯混合模型。见《国际学习表征会议（ICLR）》。</div></div></div></div><div><br></div><div><div><div>Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">出版者说明：施普林格·自然在已发表地图的管辖权主张和机构隶属关系方面保持中立。</div></div></div></div><div><br></div><div><div><div>Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.<div style="background-color: #e3e4e588;border-radius: 4px;margin: 8px 0;padding: 12px;">施普林格·自然集团（Springer Nature）或其授权方（如某个学会或其他合作伙伴）根据与作者或其他版权持有者签订的出版协议，对本文享有独家权利；作者自行存档本文的录用稿件版本仅受该出版协议条款和适用法律的约束。</div></div></div></div><div><div><div></div></div></div></span></div></div></div></div></div></div>
      </body>
    </html>
  