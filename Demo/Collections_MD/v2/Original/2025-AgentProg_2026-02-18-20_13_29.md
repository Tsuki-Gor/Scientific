# AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context Management
# AgentProg: 使用程序引导上下文管理的长时窗 GUI 代理


Shizuo Tian
Shizuo Tian


Tsinghua University
清华大学


Beijing, China
中国北京


Hao Wen
Hao Wen


Tsinghua University
清华大学


Beijing, China
中国北京


Yuxuan Chen
Yuxuan Chen


Tsinghua University
清华大学


Beijing, China
中国北京


Jiacheng Liu
Jiacheng Liu


Peking University
北京大学


Beijing, China
中国北京


Shanhui Zhao
Shanhui Zhao


Tsinghua University
清华大学


Beijing, China
中国北京


Guohong Liu
郭宏 刘


Tsinghua University
清华大学


Beijing, China
中国，北京


Ju Ren
如仁


Tsinghua University
清华大学


Beijing, China
中国，北京


Yunxin Liu
云欣 刘


Tsinghua University
清华大学


Beijing, China
中国，北京


Yuanchun Li
元春 李


Tsinghua University
清华大学


Beijing, China
中国，北京


## Abstract
## 摘要


The rapid development of mobile GUI agents has stimulated growing research interest in long-horizon task automation. However, building agents for these tasks faces a critical bottleneck: the reliance on ever-expanding interaction history incurs substantial context overhead. Existing context management and compression techniques often fail to preserve vital semantic information, leading to degraded task performance. We propose AgentProg, a program-guided approach for agent context management that reframes the interaction history as a program with variables and control flow. By organizing information according to the structure of program, this structure provides a principled mechanism to determine which information should be retained and which can be discarded. We further integrate a global belief state mechanism inspired by Belief MDP framework to handle partial observability and adapt to unexpected environmental changes. Experiments on AndroidWorld and our extended long-horizon task suite demonstrate that AgentProg has achieved the state-of-the-art success rates on these benchmarks. More importantly, it maintains robust performance on long-horizon tasks while baseline methods experience catastrophic degradation. Our system is open-sourced at https://github.com/MobileLLM/AgentProg.
移动GUI代理的快速发展推动了对长时间任务自动化的研究兴趣。然而，为这些任务构建代理面临一个关键瓶颈：对日益扩展的交互历史的依赖会带来巨大的上下文开销。现有的上下文管理与压缩技术往往难以保留关键语义信息，导致任务性能下降。我们提出 AgentProg，一种用于代理上下文管理的程序引导方法，将交互历史重新表述为带变量和控制流的程序。通过按程序结构组织信息，这一结构提供了一个原则性机制来判定哪些信息应被保留，哪些可以舍弃。我们进一步整合受 Belief MDP 框架启发的全局信念状态机制，以应对部分可观测性并适应意外的环境变化。在 AndroidWorld 的实验与我们扩展的长时任务集合上，AgentProg 显示出在这些基准测试中的最新状态的成功率。更重要的是，它在长时任务中保持稳健表现，而基线方法则出现灾难性退化。我们的系统开源，地址为 https://github.com/MobileLLM/AgentProg。


## 1 Introduction
## 1 引言


Building intelligent assistants that can operate mobile devices by following natural language instructions has long been a central goal of mobile systems $\left\lbrack  {3,{18},{40}}\right\rbrack$ and artificial intelligence researchers [19, 21, 32]. Graphical User Interface (GUI) agents aim to simulate human user operations on graphical interfaces (e.g. such as clicking, scrolling, and inputting text, etc.) to interact with devices and complete complex tasks within existing software ecosystems. Recent advances in large language models (LLMs) and vision-language models (VLMs) have shown promising results in this domain. Building upon these foundation models, researchers have developed rich agent frameworks that enable agents to successfully complete relatively simple tasks through interactive decision-making processes [7, 17, 41, 45, 49, 51, 53].
设计能够通过自然语言指令在移动设备上操作的智能助手，一直是移动系统 $\left\lbrack  {3,{18},{40}}\right\rbrack$ 与人工智能研究者的核心目标之一 [19, 21, 32]。图形用户界面（GUI）代理旨在模拟人类用户在图形界面上的操作（如点击、滚动、输入文本等），以在现有软件生态系统中与设备交互并完成复杂任务。近期大型语言模型（LLMs）与视觉-语言模型（VLMs）的进展在该领域展现出良好前景。在这些基础模型的基础上，研究者开发了丰富的代理框架，使代理能够通过交互式决策过程成功完成相对简单的任务 [7, 17, 41, 45, 49, 51, 53]。


However, despite their success on simple tasks, existing methods face significant challenges when scaling to long-horizon scenarios-tasks that require dozens or even hundreds of steps to complete. The ability to complete such long tasks is usually more desirable, as they are often cumbersome and difficult for human users. For instance, an example long task is to review all events on today's calendar (including sending messages, creating notes, etc.) and generate followup steps on all scheduled items, or to navigate between multiple shopping and note apps to compare and record product prices. These challenges manifest in two critical dimensions. First, model performance degrades significantly on extended tasks, as language models struggle to maintain coherence and task-relevant reasoning over protracted sequences [2, 22]. Second, the computational cost grows substantially as the interaction history increases, with each decision requiring to process an increasingly long context.
然而，尽管他们在简单任务上取得了成功，现有方法在扩展到长时域情景时面临显著挑战——这些任务通常需要几十甚至上百步才能完成。完成如此长的任务的能力通常更令人向往，因为它们往往繁琐且难以被人类用户完成。例如，一个长任务的示例是查看日历上今天的所有事件（包括发送消息、创建笔记等）并对所有已安排事项生成后续步骤，或在多个购物与笔记应用之间切换以比较并记录产品价格。这些挑战在两个关键维度上表现出来。首先，随着任务扩展，模型性能显著下降，因为语言模型难以在漫长序列中维持连贯性和与任务相关的推理[2, 22]。其次，随着交互历史的增加，计算成本显著提高，每次决策都需要处理越来越长的上下文。


Existing approaches attempt to address the context management problem through various techniques, such as context window [26], summarization [27, 49] or hierarchical planning [1, 16]. While these methods partially alleviate the computational burden, they face a fundamental limitation: they lack a principled framework for determining which information is essential for future steps and which can be safely discarded. This often results in the loss of crucial state information, leading to task failure [28, 52, 55]. Moreover, existing methods demonstrate a critical gap in generalization-an agent's ability to solve individual atomic tasks does not directly transfer to solving compositional or iterative long-horizon tasks, revealing deeper limitations in their reasoning capabilities [23]. The core challenge in long-horizon task execution lies in effective context management during task execution. An agent must maintain a comprehensive understanding of the task progress and dynamically assess the evolving environment to make informed decisions. This requires task-aware context management to preserve the essential state while discarding irrelevant details.
现有方法通过多种技术来解决上下文管理问题，如上下文窗口[26]、摘要[27, 49]或分层规划[1, 16]。虽然这些方法在一定程度上减轻了计算负担，但它们面临一个根本性限制：缺乏一个 principled 的框架来决定哪些信息对未来步骤是必需的，哪些信息可以安全丢弃。 这常常导致关键状态信息的丢失，进而导致任务失败[28, 52, 55]。此外，现有方法在泛化能力方面存在关键差距——一个代理能解决的单一原子任务并不能直接转化为解决组合性或迭代性的长时任务，暴露出它们在推理能力方面的更深层次局限[23]。长时任务执行的核心挑战在于在任务执行过程中实现有效的上下文管理。代理必须对任务进展有全面的理解，并动态评估不断变化的环境，以做出明智的决策。这需要以任务为导向的上下文管理，在保留关键状态的同时丢弃不相关的细节。


---



Corresponding Author: liyuanchun@air.tsinghua.edu.cn.
通讯作者： liyuanchun@air.tsinghua.edu.cn。


---



Based on a pilot test of mobile GUI agents on long-horizon tasks (detailed in Section 2.3), we observed three key difficulties that hinder more accurate and robust task execution.
基于对移动GUI代理在长时任务上的初步测试（详见第2.3节），我们观察到三个关键困难，阻碍更高准确性和鲁棒性的任务执行。


(1) Task Planning and Decomposition. Long-horizon tasks often involve composition, repetition, and recursion of multiple subtasks. Existing methods typically decompose tasks into sequences or trees [39, 48], but these structures are overly simplistic for complex scenarios, necessitating frequent replanning that introduces overhead and instability. For instance, tasks like "read today's todo list and complete each item" cannot be fully planned upfront since the items are unknown initially, leading to repeated replanning that increases error risks.
(1) 任务规划与分解。长时任务通常涉及对多个子任务的组合、重复和递归。现有方法通常将任务分解为序列或树形结构[39, 48]，但对于复杂场景，这些结构过于简化，需要频繁重新规划，增加开销和不稳定性。例如，“读取今天的待办事项并逐项完成”这类任务在初始阶段无法完全事先规划，因为待办项最初未知，导致重复重新规划，增加错误风险。


(2) Interaction History Management. Due to the limited context length of LLMs, agents must determine what information to retain or forget in the task execution process. Current approaches lack task-aware context management, struggling to preserve critical intermediate results (e.g., restaurant details across a reservation task) while discarding irrelevant navigation history.
(2) 交互历史管理。由于大型语言模型的上下文长度有限，代理在任务执行过程中必须决定保留或遗忘哪些信息。当前方法缺乏任务感知的上下文管理，在保持关键中间结果（例如在预订任务中记录的餐厅详情）的同时，难以保留无关的导航历史。


(3) Environment State Comprehension. Agents must maintain accurate understanding about environment states throughout execution. Software environments are usually dynamic and partially-observable with hidden UI elements, unexpected state changes, and transient failures, which are hard to handle for agents in the long task process. For instance, without proper environment understanding, agents may incorrectly believe tasks are complete when operations actually failed, causing workflow derailment that becomes critical in long-horizon scenarios.
(3) 环境状态理解。代理在执行过程中必须对环境状态保持准确理解。软件环境通常是动态且部分可观测的，存在隐藏的用户界面元素、意外的状态变化以及短暂的故障，这些都对长时任务过程中的代理较难处理。例如，如果没有对环境有正确理解，代理可能错误地认为任务已完成，而实际操作却失败，导致工作流偏离，在长时情景中会变得十分关键。


Our inspiration to address these challenges stems from traditional programs, which are capable to execute extremely long tasks with limited memory capacity. A program is naturally a representation of task decomposition. Its "context management" strategy is the program itself, which seamlessly handles information retaining/discarding in the system heap and stack through the mechanisms of functions, threads, global/local variables, etc. In principle, the task execution process of a GUI agent can also be represented as a program, and the agent context can be maintained in the same way as the CPU memory during program execution.
我们解决这些挑战的灵感来自传统程序，它们能够在有限内存容量下执行极其长的任务。程序本质上就是任务分解的表现形式。其“上下文管理”策略就是程序本身，借助函数、线程、全局/局部变量等机制在系统堆和栈中无缝处理信息的保留与丢弃。原则上，GUI代理的任务执行过程也可以表示为一个程序，代理上下文可以像程序执行时的CPU内存那样进行维护。


Therefore, we propose AgentProg, a program-guided context management approach for long-horizon GUI agent tasks. AgentProg reframes the agent's interaction history-traditionally represented as a flat, ever-expanding sequence - as a program with variables and control flow. This program structure, generated based on the task requirements, provides a principled and task-aware mechanism for context management. By organizing information according to the program's structure, AgentProg can systematically determine which information to retain and which to discard at each step, enabling task-specific context management that preserves crucial details.
因此，我们提出 AgentProg，一种用于长时域 GUI 代理任务的程序引导上下文管理方法。AgentProg 将代理的交互历史——传统上表现为一个平坦、不断扩展的序列——重新表述为一个具有变量和控制流的程序。这个基于任务需求生成的程序结构，为上下文管理提供了一个原则性且任务感知的机制。通过按照程序结构组织信息，AgentProg 可以在每一步系统地确定需要保留哪些信息、应丢弃哪些信息，从而实现保留关键细节的任务特定上下文管理。


A key question in our agent-program analogy is how to handle environment dynamicity. Letting the agent follow a program in the task process may lead to poor adaptivity, since the programs are generated before observing the actual environment at each step. We introduce a domain-specific language named Semantic Task Program (STP) to handle this problem. Unlike traditional programs that are based on precise symbolic instructions (e.g. name = getElement('user Name').text), STP uses fuzzy, natural-language-style instructions (e.g. get user name as \{name\}) to construct the program. The STP instructions capture necessary information for interaction context management, while they are interpreted adaptively at runtime based on the actual environment state. Furthermore, we incorporate a Global Belief State module into the STP execution process to address the inherent partial observability of GUI environments, a characteristic absent in traditional programming paradigms.
一个关键问题在于如何处理环境的动态性。让智能体在任务处理中依照一个程序执行可能导致适应性差，因为在每一步观察实际环境之前就生成了程序。为了解决这个问题，我们引入了一个领域特定语言，称为语义任务程序（STP）。与基于精确符号指令（例如 name = getElement('user Name').text）的传统程序不同，STP 使用模糊、自然语言风格的指令（例如 get user name as {name}）来构造程序。STP 指令捕捉了交互上下文管理所需的信息，同时在运行时根据实际环境状态进行自适应解释。此外，我们在 STP 执行过程中引入全局信念状态模块，以应对 GUI 环境固有的部分可观测性，这点是传统编程范式所不具备的。


We evaluate AgentProg on AndroidWorld [27], a challenging and widely-used benchmark for mobile device-control agents, and introduce an extended task suite that we construct based on AndroidWorld to specifically test agent performance on long-horizon scenarios. Our experiments reveal that while existing methods perform well on the original An-droidWorld benchmark, they exhibit substantial performance degradation on our extended task suite, highlighting their fundamental limitations in handling long-horizon reasoning. In contrast, our program-guided approach demonstrates robust performance across both benchmarks. The context organization ability of AgentProg also helps it achieve the new state of the art on AndroidWorld.
我们在 AndroidWorld [27] 上评估 AgentProg，这是一项具有挑战性且被广泛使用的移动设备控制代理基准，并基于 AndroidWorld 构建扩展任务套件，专门用于测试代理在长时域场景中的表现。实验表明，现有方法在原始的 AndroidWorld 基准上表现良好，但在我们扩展的任务套件上表现显著下降，凸显它们在处理长时域推理方面的基本局限性。相比之下，我们的程序引导方法在两个基准测试上都显示出稳健的性能。AgentProg 的上下文组织能力也帮助其在 AndroidWorld 上达到新的状态最优。


Our main contributions are summarized as follows:
我们的主要贡献概括如下：


(1) We identify three key challenges for GUI agents on long-horizon tasks, and propose program-guided context management as a principled approach to address these challenges.
(1) 我们识别了长时域任务中 GUI 代理的三个关键挑战，并提出以程序引导的上下文管理作为解决这些挑战的原理性方法。


(2) We design and implement AgentProg, a mobile GUI agent based on program-guided context management. We introduce Semantic Task Program and global belief state to address the dynamicity and partial observability problems in program-driven task execution.
(2) 我们设计并实现 AgentProg，这是一种基于程序引导的上下文管理的移动 GUI 代理。我们引入语义任务程序和全局信念状态，以应对程序驱动任务执行中的动态性和部分可观测性问题。


(3) AgentProg has been evaluated on AndroidWorld and AW-Extend and achieved the new state of the art.
(3) AgentProg 已在 AndroidWorld 和 AW-Extend 上进行了评估并达到新的状态最优。


## 2 Related Work and Motivation
## 2 相关工作与动机


### 2.1 GUI Agent
### 2.1 GUI 代理


Graphical User Interface (GUI) agents are autonomous systems designed to interact with software applications through their visual interfaces, mimicking human user behavior to accomplish complex tasks. A GUI agent typically takes as input a natural language task instruction (e.g., "Send an email to John about the meeting") and the current screen state, which includes visual information (screenshots) and optionally structural information (UI element hierarchies such as accessibility trees or HTML DOMs) [25]. The agent outputs a sequence of actions such as clicking on specific UI elements, scrolling, typing text, or navigating between applications to accomplish the specified task within existing software ecosystems.
图形用户界面（GUI）代理是自主系统，设计用于通过可视界面与软件应用交互，模仿人类用户行为以完成复杂任务。一个 GUI 代理通常以自然语言任务指令（例如“给 John 发送一封关于会议的邮件”）以及当前屏幕状态（包括视觉信息（截图）以及可选的结构信息（UI 元素层次结构，如辅助性树或 HTML DOM））作为输入 [25]。代理输出一系列操作，如点击特定 UI 元素、滚动、输入文本，或在应用之间导航，以在现有软件生态中完成指定任务。


The decision-making process of a GUI agent can be formalized as a partially observable Markov decision process (POMDP) [30]. At each timestep $t$ ,the agent observes the current screen state ${o}_{t}$ and selects an action ${a}_{t}$ based on the task goal $g$ and the interaction history ${h}_{ < t} = \left\{  \left( {{o}_{0},{a}_{0}}\right) \right.$ , $\left. {\left( {{o}_{1},{a}_{1}}\right) ,\ldots ,\left( {{o}_{t - 1},{a}_{t - 1}}\right) }\right\}$ . The environment then transitions to a new state,providing observation ${o}_{t + 1}$ . This process continues until the task is completed or a maximum number of steps is reached. The core challenge lies in how agents manage the ever-growing interaction history ${h}_{ < t}$ while maintaining accurate understanding of the current environment state.
GUI 代理的决策过程可以形式化为部分可观测的马尔可夫决策过程（POMDP）[30]。在每个时间步 $t$，代理观察当前屏幕状态 ${o}_{t}$，并基于任务目标 $g$、交互历史 ${h}_{ < t} = \left\{  \left( {{o}_{0},{a}_{0}}\right) \right.$、$\left. {\left( {{o}_{1},{a}_{1}}\right) ,\ldots ,\left( {{o}_{t - 1},{a}_{t - 1}}\right) }\right\}$ 选择一个动作 ${a}_{t}$。环境随后转移到新状态，提供观测 ${o}_{t + 1}$。这个过程一直持续，直到任务完成或达到最大步数。核心挑战在于代理如何在不断增长的交互历史 ${h}_{ < t}$ 中保持对当前环境状态的准确理解。


### 2.2 Related Work
### 2.2 相关工作


GUI Agents with Foundation Models. Recent advances in large language models and multimodal large language models have significantly enhanced their capabilities in language understanding and cognitive processing, enabling effective interpretation of human instructions, detailed planning, and complex task execution [44]. Early approaches combined LLMs with domain-specific knowledge to achieve smartphone automation [40, 51], while subsequent methods introduced refined control mechanisms for mobile applications through visual perception and multimodal reasoning [47, 50, 51]. Vision-centric approaches have been proposed that identify and locate UI elements directly from visual inputs without relying on XML metadata or system accessibility trees $\left\lbrack  {4,9,{16},{17},{34},{35},{43},{54}}\right\rbrack$ .
基于基础模型的 GUI 代理。近年来，大型语言模型和多模态大语言模型的进展显著提升了其语言理解与认知处理能力，使其能够有效理解人类指令、进行详细规划并执行复杂任务 [44]。早期方法将 LLM 与领域知识结合，以实现智能手机自动化 [40, 51]，随后的方法通过视觉感知和多模态推理引入了对移动应用的更 refined 控制机制 [47, 50, 51]。也有视觉为核心的方法被提出，直接从视觉输入识别和定位 UI 元素，而不依赖 XML 元数据或系统辅助树 $\left\lbrack  {4,9,{16},{17},{34},{35},{43},{54}}\right\rbrack$。


Context Management for GUI Agents. Managing interaction history is crucial for GUI agents to maintain task progress within token budget constraints. Existing approaches include sliding window methods that retain only the most recent $N$ observations [26],summarization methods that condense each step into minimal tokens [6, 27, 33], and hierarchical planning methods that decompose tasks into subtask sequences $\left\lbrack  {7,{17},{24},{49},{50}}\right\rbrack$ . However,these methods face limitations: sliding window incurs increasing context, summarization lacks explicit planning for complex tasks and may lose critical early information, and hierarchical planning introduces overhead requiring multiple replanning rounds and also faces with the challenge of forgetting important information.
GUI 代理的上下文管理。管理交互历史对于 GUI 代理在令牌预算约束内维持任务进度至关重要。现有方法包括保留最近 $N$ 条观测的滑动窗口方法 [26]、将每一步浓缩为最少令牌的摘要方法 [6, 27, 33]，以及将任务分解为子任务序列的分层规划方法 $\left\lbrack  {7,{17},{24},{49},{50}}\right\rbrack$ 。然而，这些方法存在局限性：滑动窗口会带来持续增加的上下文负担，摘要缺乏对复杂任务的显式规划，可能丢失早期关键信息，分层规划则需要额外开销并需多轮重新规划，同时也面临遗忘重要信息的挑战。


Program-Based GUI Agents. While standard GUI agents utilize a fixed set of programmatic APIs (e.g., click, type, scroll) as their action space, they typically treat these low-level APIs merely as atomic tool invocations. Recently, A distinct paradigm of LLM agents shift has emerged from using rigid, discrete tool calls to employing executable code as the unified action space for agents [15, 20, 29, 37]. To bridge the gap between low-level actions and high-level code generation, recent GUI agents have empowered agents to proac-tively construct high-level functions, encapsulating primitive operations into meaningful skills [38, 42]. Other approaches establish a persistent program context or terminal environment, enabling the agent to engage in continuous interaction through script synthesizing [11, 31, 41]. However, current task script generation methods [41] typically require precise API calls and strict syntax adherence, relying heavily on extensive exploration of mobile apps to build application documentation. Consequently, these scripts are prone to failure when encountering unseen applications or when dealing with out-of-distribution scenarios where documentation is unavailable.
基于程序的 GUI 代理。尽管标准 GUI 代理使用固定的一组编程 API（如点击、输入、滚动）作为行动空间，但它们通常仅将这些低层 API 视为原子工具调用。最近，一种从使用僵硬、离散工具调用转向将可执行代码作为代理统一行动空间的新范式已出现 [15, 20, 29, 37]。为弥合低层行动与高层代码生成之间的差距，最近的 GUI 代理已使代理能够主动构建高层函数，将原始操作封装为有意义的技能 [38, 42]。其他方法建立持久的程序上下文或终端环境，使代理能够通过脚本合成进行持续交互 [11, 31, 41]。然而，当前的任务脚本生成方法 [41] 通常需要精确的 API 调用和严格的语法遵循， heavily 依赖于对移动应用程序的广泛探索以构建应用文档。因此，这些脚本在遇到未见应用或处于分布外场景且文档不可用时容易失败。


### 2.3 Motivation and Challenges
### 2.3 动机与挑战


Despite the progress in GUI agents, existing methods face fundamental limitations when handling long-horizon tasks, which require dozens or hundreds of sequential steps to complete. To better understand these challenges, we construct AW-Extend, an extended task suite based on Android-World [27] that specifically tests agent performance on compositional and iterative tasks. Our extended suite comprises 19 tasks that are possibly common in realistic scenarios across two categories: Compositional Tasks that combine sub-tasks into a compositional task requiring critical information maintenance across applications, and Iterative Tasks that scale sub-task counts to $n = {10}$ or $n = {20}$ to test robustness and memory filtering capabilities. The detail of this task suite is illustrated in Section 4.
尽管在 GUI 代理方面取得了进展，现有方法在处理需要几十甚至上百步才能完成的长程任务时仍面临根本性限制。为了更好地理解这些挑战，我们构建 AW-Extend，一个基于 Android-World [27] 的扩展任务集，专门测试代理在组成性与迭代性任务上的表现。我们的扩展集包含 19 个任务，可能在现实场景中常见，分为两类：组成性任务，将子任务组合成一个需要跨应用维护关键信息的综合任务；迭代性任务，将子任务数量扩展到 $n = {10}$ 或 $n = {20}$ 以测试鲁棒性与记忆筛选能力。该任务集的细节将在第 4 章中说明。


<img src="https://cdn.noedgeai.com/bo_d6aqlu77aajc739are4g_3.jpg?x=151&y=235&w=722&h=370&r=0"/>



Figure 1: Performance Comparison on AndroidWorld vs. AW-Extend. a11y refers to the Accessibility Tree observation space; SoM denotes Set-of-Mark; Mobile-Ag-v3 denotes Mobile-Agent-v3.
图 1：AndroidWorld 与 AW-Extend 的性能对比。a11y 指可访问性树观测空间；SoM 表示 Set-of-Mark；Mobile-Ag-v3 表示 Mobile-Agent-v3。


<img src="https://cdn.noedgeai.com/bo_d6aqlu77aajc739are4g_3.jpg?x=147&y=793&w=727&h=1121&r=0"/>



Figure 2: Failure mode in existing methods (Mobile-Agent-v3 [49], UI-TARS [26], M3A [27]) on AW-Extend.
图 2：现有方法（Mobile-Agent-v3 [49]、UI-TARS [26]、M3A [27]）在 AW-Extend 上的失败模式。


Our preliminary analysis reveals critical failure reasons in existing methods, as illustrated in Figure 1:
我们的初步分析揭示了现有方法中的关键失败原因，如图 1 所示：


Lack of Overall Planning. In the "MarkorTodoList" task, Mobile-Agent-v3 prematurely terminates after completing only the first two sub-tasks, mistakenly believing all three items from the note have been addressed, as shown in Figure 2. This indicates a fundamental deficiency in holistic task planning and progress tracking.
缺乏整体规划。在“MarkorTodoList”任务中，Mobile-Agent-v3 在完成前两个子任务后提前终止，错误地认为笔记中的三个条目都已处理，如图 2 所示。这表明在整体任务规划与进度跟踪方面存在根本性缺陷。


Failure to Remember Critical Information. Despite employing context management schemes, existing agents fail to preserve task-relevant information at critical moments. In our tests, agents consistently pass incorrect parameters during sub-task execution because they do not retain all task items when initially opening the note, as shown in Figure 2. Their context management mechanisms lack sensitivity to task-critical information.
未能记住关键信息。尽管采用了上下文管理方案，现有代理在关键时刻仍未能保留与任务相关的信息。在我们的测试中，代理在子任务执行时始终传递错误的参数，因为在最初打开笔记时并未保留所有任务条目，如图 2 所示。它们的上下文管理机制对任务关键性信息缺乏敏感性。


Poor Understanding of Dynamic Environments. Our iterative tasks involving 10-20 sub-tasks expose fragility in handling unexpected situations-accidental app closures, dialog popups, or wrong operations. Moreover, due to the partial observability of GUI environments, changes in phone data are sometimes implicit, such as system settings, date and time, and in-app data. Existing methods struggle with such environmental variations, resulting in poor robustness during extended task execution. In our tests, the agent was tasked with deleting all events on this Saturday, but failed to correctly understand the date in the phone environment. Consequently, it deleted all Saturday events across different weeks, leading to task failure.
对动态环境理解不足。我们涉及 10-20 个子任务的迭代任务暴露了对突发情况的脆弱性——应用意外关闭、对话弹窗或错误操作等。此外，由于 GUI 环境的部分可观测性，手机数据的变化有时是隐含的，例如系统设置、日期时间及应用内数据。现有方法难以应对这类环境变化，导致在长时间执行任务时鲁棒性差。在我们的测试中，代理的任务是删除本周六的所有事件，但未能正确理解手机环境中的日期，因此它跨不同周删除了所有周六的事件，导致任务失败。


## 3 Our Approach: AgentProg
## 3 我们的方法：AgentProg


We present AgentProg, a program-guided framework for long-horizon task execution, as shown in Figure 3. It addresses three fundamental challenges in agent-environment interaction. First, to tackle the challenge of planning and decomposing complex long-horizon tasks, we introduce Semantic Task Program (STP), a domain-specific language that extends natural language instructions with structured control flow (loops, branches, functions) and explicit variable operations. Second, to provide agents with appropriate context without redundancy, we develop a program-guided context management approach that operates along control flow-based pruning and data flow management. Third, to maintain accurate environment understanding despite partial observability and outdated beliefs, we propose a Global Belief State mechanism that continuously validates and updates the agent's hypotheses about environment mechanisms and hidden variables throughout execution.
我们提出 AgentProg，一个用于长时程任务执行的程序引导框架，如图 3所示。它解决了代理与环境交互中的三个基本挑战。第一，为应对规划与分解复杂长时程任务的挑战，我们引入语义任务程序（STP），这是一种领域特定语言，在自然语言指令的基础上扩展了结构化控制流（循环、分支、函数）和显式变量操作。第二，为向代理提供恰当的上下文且不过度冗余，我们开发了一种沿控制流剪枝与数据流管理的程序引导上下文管理方法。第三，为在部分可观测性和陈旧信念的环境理解下仍能保持准确，我们提出全局信念状态机制，在执行全过程中持续验证并更新代理对环境机制与隐藏变量的假设。


Together, these components form a two-stage framework: Semantic Task Program Generation, where the agent performs global planning to create a structured program with identified critical variables, followed by Semantic Task Program Execution, where the agent incrementally interprets the program while maintaining belief state consistency and managing context efficiently. This design enables stable, efficient execution of long-horizon tasks without the context overflow and information loss problems that plague conventional approaches.
这些组件共同构成一个两阶段框架：语义任务程序生成阶段，代理进行全局规划以创建具有关键变量的结构化程序；以及语义任务程序执行阶段，代理在维持信念状态一致性并高效管理上下文的同时，增量地解释程序。这一设计实现了对长时程任务的稳定、高效执行，避免了常规方法常见的上下文溢出和信息丢失问题。


### 3.1 Semantic Task Program: A DSL for Long-Horizon Task Planning
### 3.1 语义任务程序：用于长时程任务规划的DSL


We design Semantic Task Program (STP), a domain-specific language (DSL) that represents long-horizon tasks. Unlike rigid programming languages, STP balances expressiveness with semantic tolerance. It enables agents to plan and execute complex tasks effectively. More details and examples of STP are listed in Section A.
我们设计了语义任务程序（STP），一种表示长时程任务的领域特定语言（DSL）。与僵硬的编程语言不同，STP 在表达能力与语义容错之间取得平衡，使代理能够高效地规划与执行复杂任务。STP 的更多细节与示例请见第 A 节。


Design Principles. STP is built on three core principles: (1) Natural Language Foundation: Each program step is primarily expressed in natural language instructions, ensuring readability and maintaining generality across different environments; (2) Structured Control Flow: The language incorporates essential programming constructs including loops, conditionals, and functions to express iterative and recursive task patterns concisely; (3) Explicit Data Flow: Variables are used to explicitly pass information between steps, allowing the agent to identify and preserve critical information throughout task execution.
设计原则。STP 基于三大核心原则：（1）自然语言基础：每个程序步骤主要以自然语言指令表达，确保可读性并在不同环境中保持通用性；（2）结构化控制流：语言包含循环、条件分支和函数等基本编程构件，以简洁地表达迭代和递归任务模式；（3）显式数据流：变量用于在步骤之间显式传递信息，帮助代理在任务执行过程中识别并保留关键信息。


Syntax and Constructs. An STP consists of a sequence of steps, where each step can be: (1) Action Step: A natural language instruction describing what should be accomplished, such as "Open the note 'todo_list.md' in the Markor application"; (2) Variable Declaration and Assignment: Explicit recording of critical information using variables enclosed in braces, e.g., "record them as \{task_list\}"; (3) Control Flow Statements: Loop constructs, conditional branches, and function definitions that organize execution flow, e.g., "Iterate over \{task_list\}"; (4) Variable References: Using declared variables in subsequent steps, e.g., "for each \{task_item\}, ...".
语法与构造。STP 由一系列步骤组成，每个步骤可以是：（1）动作步骤：描述应完成的自然语言指令，例如“在 Markor 应用中打开笔记 ‘todo_list.md’”；（2）变量声明与赋值：使用大括号括起的变量显式记录关键信息，例如“将它们记为 {task_list}”；（3）控制流语句：循环、条件分支和函数定义，用以组织执行流程，例如“遍历 {task_list}”；（4）变量引用：在后续步骤中使用已声明的变量，例如“对每个 {task_item}，……”。


Semantic Tolerance. A key distinguishing feature of STP is its semantic tolerance. Current task script generation methods [41] require precise API calls and strict syntax. Consequently, they are highly sensitive to environment dynamics and software updates. Semantic Task Program allows for variations in execution details. The natural language instructions provide high-level guidance without being tightly coupled to specific environment implementations. This tolerance enables the agent to adapt to different environments and handle unexpected situations during execution, while the structured control flow ensures the overall task logic remains intact.
语义容错。STP 的一个关键区别特征是其语义容错性。目前的任务脚本生成方法 [41] 需要精确的 API 调用和严格的语法，因此对环境动态和软件更新高度敏感。语义任务程序允许在执行细节上有所变动。自然语言指令提供了高层次的引导，而不与具体环境实现紧密耦合。这种容错性使代理能够适应不同环境并在执行过程中处理意外情况，同时结构化控制流确保整体任务逻辑保持完整。


### 3.2 STP Generation and Execution
### 3.2 STP 生成与执行


AgentProg aims to enhance agent performance in long-horizon tasks through a two-stage framework for memory management as Figure 3 shows: 1) Semantic Task Program Generation: The agent generates a globally planned Semantic Task Program based on task requirements, where the program extends natural language with support for control flow constructs (e.g., branching, loops) and variable operations (declaration, assignment); 2) Semantic Task Program Execution: The agent incrementally interprets and executes the Semantic Task Program, taking environment state and current program state as input, and producing actions while updating the program state.
AgentProg 旨在通过如图 3 所示的两阶段内存管理框架提升长时程任务中的代理性能：1) 语义任务程序生成阶段：代理基于任务要求生成全局规划的语义任务程序，程序在自然语言基础上扩展对控制流构造（如分支、循环）和变量操作（声明、赋值）的支持；2) 语义任务程序执行阶段：代理在输入环境状态与当前程序状态的前提下，增量解释并执行语义任务程序，同时更新程序状态并输出行动。


Generation Phase. The agent plans a feasible program according to specifications. It uses control flow to orchestrate execution and identifies critical variables for preservation. The natural language components ensure the program remains general and robust.
生成阶段。代理根据规格规划可行程序。它使用控制流来编排执行，并识别需要保留的关键变量。自然语言组件确保程序保持通用性与鲁棒性。


## Execution Phase.
## 执行阶段。


Instead of rigidly executing pre-defined scripts, Agent-Prog adopts a dynamic instruction grounding paradigm. The Semantic Task Program serves as a high-level guide, where AgentProg acts as a runtime interpreter that translates the current high-level program instruction into executable low-level actions based on the real-time environment state. This mechanism decouples the task logic from specific execution details, preventing context overflow while maintaining flexibility.
Agent-Prog 不再局限于执行预定义脚本，而是采用动态指令落地范式。语义任务程序作为高级指引，AgentProg 充当运行时解释器，将当前高级程序指令依据实时环境状态转化为可执行的低级动作。这一机制将任务逻辑与具体执行细节解耦，防止上下文溢出，同时保持灵活性。


Specifically, AgentProg operates in two alternating modes:
具体来说，AgentProg 以两种交替模式运行：


1) Action Generation. In this mode, the agent focuses on instantiating the high-level intent of the current program step into concrete execution logic. Based on the instruction pointed to by the Program Counter (PC) and the current GUI observation, the agent generates a snippet of low-level Python code to interact with the environment. AgentProg utilizes LLM to ground abstract natural language instructions into a sequence of atomic Python APIs (e.g., start_app(<app>, click(<element>), input(<text>), swipe_down()). Crucially, this allows the agent to dynamically adapt the low-level operations (e.g., handling pop-ups or layout changes) while adhering to the high-level plan. The agent records these executed Python scripts to track data flow, while repetitive execution histories (e.g. , inside loops) are folded to save context.
1) 动作生成。该模式下，智能体侧重将当前程序步骤的高层意图落实为具体执行逻辑。根据程序计数器（PC）指向的指令以及当前 GUI 观察，生成可与环境交互的低级 Python 代码片段。AgentProg 使用大语言模型将抽象自然语言指令落地为原子 Python API 序列（如 start_app(<app>, click(<element>), input(<text>), swipe_down())）。关键在于，这使智能体在遵循高层计划的同时，能够动态适配低级操作（如处理弹窗或布局变化）。智能体会记录这些已执行的 Python 脚本以追踪数据流，而重复的执行历史（例如在循环内）会被折叠以节省上下文。


2) Program Counter Update. After the generated Python code is executed and the environment updates, the agent switches to this mode to manage the control flow. It decides how to move the Program Counter-whether to advance to the next step, iterate a loop, or jump to a branch-based on the execution result of the previous step.
2) 程序计数器更新。生成的 Python 代码执行并更新环境后，智能体切换到此模式以管理控制流。它决定如何移动 PC—是推进到下一步、循环迭代，还是基于上一步执行结果跳转到分支。


<img src="https://cdn.noedgeai.com/bo_d6aqlu77aajc739are4g_5.jpg?x=238&y=259&w=1314&h=699&r=0"/>



Figure 3: The workflow of AgentProg.
图3：AgentProg 的工作流程。


These two modes alternate strictly: AgentProg translates the current instruction into Python code (Action Generation), executes it, and then decides where to go next in the program (PC Update). Throughout this process, AgentProg maintains a structured context containing the static program plan and the dynamic variables and low-level history, ensuring all decisions are globally consistent yet locally adaptive.
这两种模式严格交替：AgentProg 将当前指令翻译为 Python 代码（动作生成），执行后再决定程序接下来去哪里（PC 更新）。在整个过程中，AgentProg 维持一个结构化上下文，包含静态程序计划与动态变量及低级历史，确保所有决策在全局上保持一致而在局部上具备自适应性。


### 3.3 Program-Guided Context Management
### 3.3 程序引导的上下文管理


During the Semantic Task Program Execution phase, Agent-Prog adopts a program-guided approach to manage the context input for the agent. This mechanism addresses the tradeoff between information retention and context length. By leveraging the explicit structure of the STP, AgentProg acts as a filter: it retains execution-critical information while systematically discarding redundant history. This management operates along two dimensions: control flow pruning and data flow persistence.
在语义任务程序执行阶段，Agent-Prog 采取以程序为导向的上下文输入管理方法。该机制在信息保留与上下文长度之间权衡。利用 STP 的显式结构，AgentProg 充当过滤器：保留对执行关键的信息，同时系统性地舍弃冗余历史。该管理在两个维度上运作：控制流裁剪与数据流持久化。


3.3.1 Execution Tree-Guided Context Pruning. To manage the control flow context, we organize the STP execution history into a dynamic tree structure. As illustrated in Figure 4, each executed step expands a corresponding node in this tree.
3.3.1 基于执行树的上下文裁剪。为管理控制流上下文，我们将 STP 的执行历史组织成一个动态树结构。如图4所示，每执行一步都会扩展树中的一个相应节点。


Tree Construction Rules. The node expansion logic is strictly bound to the program structure. We categorize nodes into three types:
树构建规则。节点扩展逻辑严格绑定于程序结构。我们将节点分为三类：


- Sequential Nodes: If a step follows a linear sequence, it becomes a direct child of the previously executed node.
- 顺序节点：若一步跟随线性序列，则成为前一步所执行节点的直接子节点。


- Conditional Nodes: For branching statements (e.g., if-else), only the node corresponding to the actually executed branch becomes a child of the condition node. Unexecuted branches are never added.
- 条件节点：对于分支语句（如 if-else），只有实际执行分支对应的节点成为条件节点的子节点。未执行的分支不会被添加。


- Loop Nodes: For loop structures, each iteration expands a new loop statement node. These are added as children of the loop entry point, preserving the iteration history hierarchically.
- 循环节点：对于循环结构，每次迭代扩展一个新的循环语句节点。它们作为循环入口点的子节点添加，按层级保留迭代历史。


Path-Based Pruning. During inference, the agent does not see the entire raw history. Instead, we compute the active path from the root node to the currently executing node. Only the step information and observations along this active path are retained in the context; all other branches and completed loop iterations that are no longer relevant to the current state are discarded.
基于路径的裁剪。在推理过程中，智能体并不能看到整个原始历史。相反，我们从根节点到当前执行节点计算活动路径。仅在该活动路径上的步骤信息与观测被保留在上下文中；所有其他分支和已完成但与当前状态不再相关的循环迭代将被丢弃。


This approach significantly reduces context overhead, especially in tasks involving complex logic. It prevents the agent from being confused by redundant information (e.g., stale states from a previous loop iteration or irrelevant actions from a non-taken branch), allowing it to focus solely on the current logical path.
这种方法显著降低了上下文开销，尤其适用于包含复杂逻辑的任务。它防止智能体被冗余信息（例如来自上一次循环迭代的陈旧状态或来自未被选取的分支的无关动作）所困扰，使其只关注当前的逻辑路径。


3.3.2 Program-based Historical Step Retrieval. While pruning removes irrelevant context, AgentProg also employs a retrieval mechanism to enhance stability for iterative tasks.
3.3.2 基于程序的历史步骤检索。尽管裁剪移除了不相关的上下文，AgentProg 也采用检索机制以提升对迭代性任务的稳定性。


<img src="https://cdn.noedgeai.com/bo_d6aqlu77aajc739are4g_6.jpg?x=183&y=267&w=1430&h=756&r=0"/>



Figure 4: Program-guided context management with context pruning, history retrival and variable management.
图4：带有上下文裁剪、历史检索与变量管理的程序引导上下文管理。


When the execution revisits a specific program step-a common scenario in loops or recursive segments-AgentProg activates a retrieval mechanism. Unlike generic similarity search, this mechanism uses the unique program step ID to precisely identify preceding executions of the exact same step. The operational outcomes of these past iterations-including actions taken and resulting state changes-are selectively injected into the current context as references. This allows the agent to "remember" its own recent success or failure patterns. By providing this structured historical awareness, AgentProg significantly improves consistency in long-horizon repetitive tasks, mitigating the risks of oscillation or repeated errors that often plague agents lacking step-specific memory.
当执行回访特定程序步骤——这是循环或递归段中的常见场景时，AgentProg 会激活检索机制。与通用相似性搜索不同，这一机制利用唯一的程序步骤 ID 精确识别此前恰好相同步骤的执行。过去迭代的操作结果与状态变化会被选择性地以引用形式注入当前上下文中。这使智能体能够“记住”自身最近的成功或失败模式。通过提供这种结构化的历史意识，AgentProg 在长期的重复任务中显著提升一致性，降低因缺乏步骤特定记忆而导致的振荡或重复错误的风险。


3.3.3 Data Flow and Variable Management. Beyond control flow, AgentProg ensures the persistence of critical information through explicit variable management. This addresses the challenge where purely context-based agents often lose track of key data (e.g., a phone number retrieved 50 steps ago). During the Semantic Task Program Generation phase, the agent explicitly identifies and declares essential variables. These variables-such as extracted todo items, reservation times, or user preferences-act as "anchors". They are mandated to persist throughout the execution, ensuring that task-critical data is never inadvertently discarded by the pruning mechanism.
3.3.3 数据流与变量管理。超越控制流，AgentProg 通过显式变量管理确保关键信息的持久性。这解决了纯基于上下文的代理常常丢失关键数据的问题（例如，在50步前获取的电话号码）。在语义任务程序生成阶段，代理明确识别并声明关键变量。这些变量——如提取的待办事项、预订时间或用户偏好——充当“锚点”。它们被要求在执行过程中持续存在，确保任务关键数据不会被剪枝机制误删。


During the Execution phase, the agent retains the flexibility to define auxiliary variables via Python code. This programmatic manipulation compensates for the limitations of raw LLM reasoning. For instance, an agent can extract multiple items into a list variable, iterate through them systematically, and use counters to track progress. This combination of declarative planning and imperative execution ensures robust information flow: critical data remains accessible, while the internal state adapts dynamically to evolving task requirements.
在执行阶段，代理保留通过 Python 代码定义辅助变量的灵活性。这种编程化操作弥补了原始大模型推理的局限性。例如，代理可以将多项内容提取到一个列表变量中，系统性地遍历它们，并使用计数器跟踪进度。这种陈述性规划与命令式执行的结合，确保信息流的鲁棒性：关键数据保持可访问，内部状态能够动态适应不断变化的任务需求。


3.3.4 Advantages of program-guided context management. AgentProg binds context directly to the program's execution structure, effectively addressing these limitations. From a control flow perspective, the STP captures repetition and branching patterns upfront. This allows the agent to systematically prune irrelevant branches and loop iterations without the need for error-prone replanning cycles. From a data flow perspective, explicit variable declaration serves as an information anchor, ensuring that critical data (e.g., user preferences or extracted items) persists throughout execution regardless of context length. This dual mechanism enables AgentProg to maintain a compact, noise-free context while guaranteeing the persistence of task-critical information.
3.3.4 程序引导的上下文管理优势。AgentProg 将上下文直接绑定到程序的执行结构，有效解决这些局限性。从控制流角度看，STP 事先捕捉重复与分支模式。这使代理能够系统性地剪除无关分支和循环迭代，而无需易出错的重新规划循环。从数据流角度看，显式变量声明作为信息锚点，确保关键数据（如用户偏好或提取项）在执行过程中保持持久，无论上下文长度如何变化。这一双重机制使 AgentProg 能维持紧凑、无噪声的上下文，同时保证任务关键性信息的持续存在。


<img src="https://cdn.noedgeai.com/bo_d6aqlu77aajc739are4g_7.jpg?x=149&y=244&w=722&h=481&r=0"/>



Figure 5: Dynamic global belief state management in partially observable environments.
图5：部分可观测环境中的全局信念状态动态管理。


### 3.4 Global Belief State
### 3.4 全局信念状态


While the Action Generation phase produces executable Python scripts, ensuring their faithful execution requires active monitoring. The Global Belief State integrates directly into this low-level execution loop, acting as a runtime verifier that checks if the assumptions made during code generation remain valid as each atomic command executes. This validation is critical because mobile GUI environments are inherently partially observable. Critical system states-such as clipboard content, navigation back-stack, or off-screen selected items, etc.-are often invisible in the current screenshot but decisive for future actions.
虽然行动生成阶段会生成可执行的 Python 脚本，但要确保其忠实执行需要主动监控。全局信念状态直接集成到这个低级执行循环中，充当运行时验证器，在每个原子命令执行时检查代码生成时的假设是否仍然有效。这种验证至关重要，因为移动 GUI 环境本质上是部分可观测的。关键系统状态——如剪贴板内容、导航返回栈或屏幕外的选中项等——在当前截图中往往不可见，但对将来操作具有决定性作用。


Inspired by the Belief MDP framework [13], we introduce a Global Belief State mechanism to bridge this gap. It operates as a runtime monitor through a continuous Predict-Verify-Align cycle: 1) Maintain Hypothesis (Predict): Unlike passive memory, the agent maintains an active set of hypotheses about the current environment status, including the UI context and data validity. 2) Runtime Verification (Verify): During the execution of low-level Python codes, AgentProg continuously compares the real-time visual observation against its belief state. 3) Anomaly Correction (Align): If the observation contradicts the belief, AgentProg identifies a Belief-Reality Gap. It immediately marks the previous state as invalid (e.g., "Context Lost"), and switches from execution mode to a recovery routine (e.g., navigating back to the target app) to realign its belief with reality.
受 Belief MDP 框架[13]的启发，我们引入一个全局信念状态机制，以弥合这一差距。它以持续的“预测-验证-对齐”循环作为运行时监控：1) 维持假设（预测）：与被动记忆不同，智能体维护一组关于当前环境状态的主动假设集，包括 UI 情境和数据有效性。2) 运行时验证（验证）：在低级 Python 代码执行期间，AgentProg 不断将实时视觉观测与其信念状态进行比较。3) 异常校正（对齐）：若观测与信念相矛盾，AgentProg 识别信念-现实差距。它立即将前一状态标记为无效（如“上下文丢失”），并从执行模式切换到恢复例程（如返回目标应用）以使信念与现实重新对齐。


Case Study. Consider a scenario where an agent is filling out a contact form. Initial Belief: "Editing contact 'John Doe'; Name and Email fields are filled." Event: Due to an accidental touch or crash, the app exits to the home screen. Without Belief State: A traditional agent might hallucinate that the step succeeded and attempt to click a "Save" button that no longer exists, leading to a cascade of errors. With Belief State: AgentProg detects the conflict: the visual observation (Home Screen) refutes the belief hypothesis (Editing View). It immediately invalidates the "Name/Email filled" status, updates the belief to "Form Context Lost," and generates a corrective plan to restart the app and re-fill the information. This mechanism ensures that the agent never proceeds on false premises.
案例研究。设想一个智能体正在填写联系表单的场景。初始信念：“正在编辑联系人 ‘John Doe’；姓名和邮箱字段已填好。” 事件：由于意外触摸或崩溃，应用返回到主屏幕。若没有信念状态：传统智能体可能会错觉地认为步骤已成功并尝试点击不再存在的“保存”按钮，导致一系列错误。若有信念状态：AgentProg 检测到冲突：视觉观测（主屏幕）推翻了信念假设（正在编辑视图）。它立即使“姓名/邮箱已填”状态失效，更新信念为“表单上下文丢失”，并生成纠错计划以重启应用并重新填写信息。此机制确保智能体在错误前提下绝不推进。


## 4 AW-Extend Benchmark
## 4 AW-Extend 基准测试


To systematically evaluate agent performance on the long-horizon challenges identified above, we constructed AW-Extend, an extended task suite that builds upon the original AndroidWorld benchmark. By adapting the existing Android-World evaluation and verification system, we ensure our extended tasks maintain the same rigorous automated assessment standards while specifically targeting long-horizon scenarios.
为系统地评估智能体在上述长期任务中的表现，我们构建了 AW-Extend，一套扩展任务集，基于原始 AndroidWorld 基准进行扩展。通过改编现有的 AndroidWorld 评估与验证系统，确保扩展任务维持相同严格的自动化评估标准，同时专门面向长期情景。


Existing mobile GUI operation benchmarks [27, 36, 46] primarily focus on evaluating isolated functionalities within individual applications. They lack adequate coverage of realistic complex scenarios that involve coordinating multiple applications, integrating diverse functionalities across apps, or executing extended sequences of operations within a single application. However, such long-horizon tasks are common in real-world usage, necessitating a dedicated benchmark to assess agent capabilities in these dimensions. Our extended suite comprises 19 tasks covering two categories:
现有的移动 GUI 操作基准测试 [27, 36, 46] 主要关注对单一应用中独立功能的评估。它们对涉及协调多应用、跨应用整合多种功能，或在单一应用内执行较长操作序列等现实复杂场景的覆盖不足。然而，在现实使用中，这些长期任务很常见，因此需要专门的基准来评估智能体在这些维度上的能力。我们的扩展套件包含 19 个任务，覆盖两大类：


Compositional Tasks combine multiple atomic operations into realistic workflows that require maintaining task context across different applications. These tasks are characterized by strong dependencies between subtasks, demanding that agents retain and effectively utilize critical information throughout the execution process. Representative examples include: processing a To-Do List from notes by completing each item sequentially (creating calendar events, adding contacts, managing expenses); batch operations such as creating multiple contacts and messaging each one; and cross-application interactions like querying note content via text message and replying accordingly.
组合任务（Compositional Tasks）将多个原子操作组合成需要跨应用维持任务上下文的现实工作流。这些任务的子任务之间存在强依赖，要求智能体在执行过程中保持并有效利用关键信息。典型示例包括：从笔记中处理待办列表，逐项完成（创建日历事件、添加联系人、管理开支）；批量操作，如创建多位联系人并逐一发送信息；以及跨应用交互，如通过短信查询笔记内容并据此回复等。


Iterative Tasks systematically scale the sub-task count from the standard $n = 3$ in AndroidWorld to $n = {10}$ and $n = {20}$ ,testing both agent robustness and the ability to filter irrelevant information from context. Unlike compositional tasks where subtasks are interdependent, iterative tasks involve weakly-correlated operations, making them particularly effective for evaluating an agent's capacity to suppress interference from irrelevant historical context while maintaining consistent task execution. These tasks encompass managing expense records, calendar events, menu items, and note operations.
迭代任务（Iterative Tasks）将子任务数量从 AndroidWorld 的标准 $n = 3$ 逐步扩展到 $n = {10}$ 和 $n = {20}$，测试智能体的鲁棒性以及从上下文中过滤不相关信息的能力。不同于子任务相互依赖的组合任务，迭代任务涉及弱相关的操作，使其在评估智能体在抑制无关历史上下文干扰，同时保持任务执行的一致性方面尤为有效。这些任务包括管理费用记录、日历事件、菜单项和笔记操作。


We adapted AndroidWorld's environment configuration and evaluation code to create these tasks, enabling assessment through AndroidWorld's standard interface, including environment setup, automated evaluation based on emulator state, and trajectory recording.
我们对 AndroidWorld 的环境配置与评估代码进行了改造，以创建这些任务，能够通过 AndroidWorld 的标准界面进行评估，包括环境搭建、基于模拟器状态的自动评估以及轨迹记录。


## 5 Experiments
## 5 实验


### 5.1 Experimental Settings
### 5.1 实验设置


Benchmarks. We conduct experiments on AndroidWorld [27] and AW-Extend (AW-Extend). AndroidWorld is a comprehensive and widely used benchmark for evaluating Android GUI agents across diverse real-world mobile applications with 116 tasks. AW-Extend is an extension we construct with 19 additional long horizon tasks described in Section 4.
基准测试。我们在 AndroidWorld [27] 与 AW-Extend（AW-Extend）上进行实验。AndroidWorld 是一个全面且广泛使用的基准，用于在多样化真实世界移动应用中评估 Android GUI 智能体，包含 116 个任务。AW-Extend 是我们在第 4 节描述的新增 19 个长期任务的扩展集合。


Baselines. We compare our method with several state-of-the-art approaches on two benchmarks. On Android-World benchmark, as shown in Table 1, we include a wide range of methods from related work. We re-evaluated M3A method [27], for both its a11y tree and SoM variants, using Gemini-2.5-Pro, as the original work reported results based on GPT-4-turbo. All other baseline scores on AndroidWorld are cited from their respective original publications. On AW-Extend benchmark, we select a focused set of baselines, each employing a distinct context management strategy to handle long-horizon tasks. As detailed in Table 2, these include:
基线。我们在两个基准上将我们的方法与若干最先进的方法进行比较。在 Android-World 基准上，如表 1 所示，我们包含了来自相关工作的广泛方法。我们用 Gemini-2.5-Pro 重新评估 M3A 方法 [27]，针对其 a11y tree 与 SoM 变体，因为原工作基于 GPT-4-turbo 汇报了结果。AndroidWorld 的所有其他基线分数均来自各自的原始出版物。在 AW-Extend 基准上，我们选择了一组聚焦的基线，每个基线采用不同的上下文管理策略来处理长时间任务。如下表 2 所述，这些包括：


- M3A [27], which generates a textual summary after each step to manage its context.
- M3A [27]，每一步后生成文本摘要以管理上下文。


- UI-TARS [26], which uses a sliding window approach, discarding the oldest screenshots in a first-in-first-out (FIFO) manner when the context exceeds a limit. We follow its official setting, retaining a maximum of five screenshots.
- UI-TARS [26]，采用滑动窗口方法，在上下文超过限制时按照先进先出（FIFO）方式丢弃最旧的截图。我们遵循其官方设置，最多保留五张截图。


- Mobile-Agent-v3 [49], which employs hierarchical planning method. A planner first decomposes the main task into a list of sub-tasks, and an executor then completes them sequentially. The planner maintains the list of sub-tasks continuously during the task execution.
- Mobile-Agent-v3 [49]，采用分层规划方法。规划者先将主要任务分解为若干子任务清单，执行者再按顺序完成它们。规划者在任务执行过程中持续维护子任务清单。


For baselines on AW-Extend benchmark, we use Gemini- 2.5-Pro [8] as the backbone model for M3A [27], UI-TARS- 1.5-API for UI-TARS [26], and both GUI-Owl-32B and GUI-Owl-7B for Mobile-Agent-v3 [49].
在 AW-Extend 基准上的基线，我们将 Gemini-2.5-Pro [8] 作为 M3A [27] 的骨干模型，UI-TARS-1.5-API 作为 UI-TARS [26]，以及 GUI-Owl-32B 与 GUI-Owl-7B 作为 Mobile-Agent-v3 [49] 的两种模型。


Metrics. We adapt the official AndroidWorld evaluation metric (Success Rate) to measure task completion performance. For AW-Extend, we adapt AndroidWorld's evaluation codebase to support assessment of our custom task set.
评估指标。我们采用官方的 AndroidWorld 评估指标（成功率）来衡量任务完成表现。对于 AW-Extend，我们改编 AndroidWorld 的评测代码库以支持对我们自定义任务集的评估。


Implementation Details. We implement AgentProg using Gemini-2.5-Pro [8] as the backbone planning model, and leverage UI-TARS-1.5-API [26] to locate the UI elements.
实现细节。我们使用 Gemini-2.5-Pro [8] 作为骨干规划模型实现 AgentProg，并借助 UI-TARS-1.5-API [26] 来定位 UI 元素。


### 5.2 Analysis of Success Rate
### 5.2 成功率分析


Table 1: Success Rate (%) on AndroidWorld.
表 1：AndroidWorld 上的成功率 (%)。


<table><tr><td>Method</td><td>AndroidWorld (%)</td></tr><tr><td>MobileGPT [14]</td><td>23.0</td></tr><tr><td>AutoDroid-V2 [41]</td><td>26.0</td></tr><tr><td>M3A (a11y, GPT-4-Turbo) [27]</td><td>30.6</td></tr><tr><td>M3A (a11y, Gemini-2.5-Pro) [27]</td><td>31.0</td></tr><tr><td>M3A (SoM, GPT-4-Turbo) [27]</td><td>25.4</td></tr><tr><td>M3A (SoM, Gemini-2.5-Pro) [27]</td><td>39.7</td></tr><tr><td>GLM-4.1V-9B-Thinking [12]</td><td>41.7</td></tr><tr><td>UI-TARS (UI-TARS-7B) [26]</td><td>33.0</td></tr><tr><td>UI-TARS (UI-TARS-1.5-API) [26]</td><td>64.2</td></tr><tr><td>V-Droid [5]</td><td>59.5</td></tr><tr><td>MobileUse [17]</td><td>62.9</td></tr><tr><td>UI-Venus [10]</td><td>65.9</td></tr><tr><td>Agent S3 [7]</td><td>68.1</td></tr><tr><td>Mobile-Agent-v3 (GUI-Owl-7B) [49]</td><td>66.4</td></tr><tr><td>Mobile-Agent-v3 (GUI-Owl-32B) [49]</td><td>73.3</td></tr><tr><td>AgentProg</td><td>78.0</td></tr></table>
<table><tbody><tr><td>方法</td><td>AndroidWorld (%)</td></tr><tr><td>MobileGPT [14]</td><td>23.0</td></tr><tr><td>AutoDroid-V2 [41]</td><td>26.0</td></tr><tr><td>M3A (无障碍, GPT-4-Turbo) [27]</td><td>30.6</td></tr><tr><td>M3A (无障碍, Gemini-2.5-Pro) [27]</td><td>31.0</td></tr><tr><td>M3A (SoM, GPT-4-Turbo) [27]</td><td>25.4</td></tr><tr><td>M3A (SoM, Gemini-2.5-Pro) [27]</td><td>39.7</td></tr><tr><td>GLM-4.1V-9B-思考型 [12]</td><td>41.7</td></tr><tr><td>UI-TARS (UI-TARS-7B) [26]</td><td>33.0</td></tr><tr><td>UI-TARS (UI-TARS-1.5-API) [26]</td><td>64.2</td></tr><tr><td>V-Droid [5]</td><td>59.5</td></tr><tr><td>MobileUse [17]</td><td>62.9</td></tr><tr><td>UI-Venus [10]</td><td>65.9</td></tr><tr><td>Agent S3 [7]</td><td>68.1</td></tr><tr><td>Mobile-Agent-v3 (GUI-Owl-7B) [49]</td><td>66.4</td></tr><tr><td>Mobile-Agent-v3 (GUI-Owl-32B) [49]</td><td>73.3</td></tr><tr><td>AgentProg</td><td>78.0</td></tr></tbody></table>


Table 2: Success Rate (%) on AW-Extend.
Table 2: 成功率 (%) 在 AW-Extend 上。


<table><tr><td>Method</td><td>AW-Extend (%)</td></tr><tr><td>M3A (a11y)</td><td>23.7</td></tr><tr><td>M3A (SoM)</td><td>28.9</td></tr><tr><td>Mobile-Agent-v3 (GUI-Owl-7B)</td><td>26.3</td></tr><tr><td>Mobile-Agent-v3 (GUI-Owl-32B)</td><td>28.9</td></tr><tr><td>UI-TARS (UI-TARS-1.5-API)</td><td>36.8</td></tr><tr><td>AgentProg</td><td>68.4</td></tr></table>
<table><tbody><tr><td>方法</td><td>AW-扩展 (%)</td></tr><tr><td>M3A (无障碍)</td><td>23.7</td></tr><tr><td>M3A (SoM)</td><td>28.9</td></tr><tr><td>Mobile-Agent-v3 (GUI-Owl-7B)</td><td>26.3</td></tr><tr><td>Mobile-Agent-v3 (GUI-Owl-32B)</td><td>28.9</td></tr><tr><td>UI-TARS (UI-TARS-1.5-API)</td><td>36.8</td></tr><tr><td>AgentProg</td><td>68.4</td></tr></tbody></table>


Overall Results. As shown in Table 1, our method achieves a success rate of 78.0% on the AndroidWorld benchmark, surpassing the previous state-of-the-art Mobile-Agent-v3 by 4.7%. This demonstrates significant advantages in general mobile automation tasks. On AW-Extend benchmark shown in Table 2, we compare our program-guided context management approach against three representative baseline context management strategies: Summarization (M3A), sliding window (UI-TARS), and hierarchical planning (Mobile-Agent-v3). Our method achieves a success rate of 68.4%, substantially outperforming all baseline approaches. These results demonstrate that our program-guided context management framework offers substantial advantages over existing methods, particularly for long-horizon tasks that require maintaining context effectively over extended interaction sequences.
总体结果。如表1所示，我们的方法在 AndroidWorld 基准测试上实现78.0% 的成功率，比上一代最先进的 Mobile-Agent-v3 高出4.7%，这在一般移动自动化任务中显示出显著优势。在 AW-Extend 基准测试如表2所示，我们将我们基于程序引导的上下文管理方法与三种代表性的基线上下文管理策略进行比较：摘要（M3A）、滑动窗口（UI-TARS）以及分层规划（Mobile-Agent-v3）。我们的方法达到68.4%的成功率，显著超越所有基线方法。这些结果表明，我们的基于程序的上下文管理框架相对于现有方法具有实质性优势，尤其适用于需要在较长交互序列中有效维持上下文的长时任务。


Performance Across Task Difficulty Levels. Figure 6 presents the success rates of different methods stratified by task difficulty levels on AndroidWorld. In Figure 6, M3A uses SoM as input and Gemini-2.5-Pro as backbone model. Mo-bileUse results are reported from the original paper, while M3A and AgentProg results are from our evaluation. Other existing methods have not reported performance across different difficulty levels on AndroidWorld. We observe that success rates decline progressively as task difficulty increases across all methods. Notably, AgentProg consistently outperforms baselines at every difficulty level. Besides, the magnitude of improvement is most pronounced for medium tasks (25.0% over MobileUse), followed by hard tasks (13.1% improvement), with the smallest gain on easy tasks (9.8% improvement). This pattern suggests that existing methods can handle simple tasks reasonably well, but face substantial challenges with medium and hard tasks. AgentProg effectively addresses this gap, particularly excelling where current methods struggle most. This demonstrates that the program-driven framework with belief state tracking in AgentProg is particularly effective for complex tasks that demand advanced planning capabilities, robust memory of critical information, and sophisticated environment understanding. The widening performance gap at higher difficulty levels validates that these capabilities become increasingly critical as task complexity grows.
按任务难度等级的性能。图6 展示了在 AndroidWorld 上按任务难度分层的不同方法的成功率。在图6中，M3A 以 SoM 作为输入，Gemini-2.5-Pro 作为骨干模型。Mo-bileUse 的结果来自原论文，而 M3A 与 AgentProg 的结果来自我们的评估。其他现有方法尚未在 AndroidWorld 的不同难度等级上给出性能报告。我们观察到随着任务难度的增加，所有方法的成功率逐步下降。值得注意的是，AgentProg 在每个难度等级上始终优于基线。此外，提升幅度在中等难度任务（比 MobileUse 提升 25.0%）最为显著，其次是困难任务（提升 13.1%），在简单任务上的提升最小（提升 9.8%）。这一模式表明，现有方法在处理简单任务时相对较好，但在中等和困难任务上面临实质性挑战。AgentProg 有效弥补了这一差距，尤其是在当前方法最难以应付的领域表现突出。这表明 AgentProg 的基于程序驱动、带有信念状态跟踪的框架对于需要高级规划能力、对关键信息的稳健记忆以及对复杂环境的理解的任务尤为有效。随着任务难度的提升，性能差距的扩大证实了这些能力在任务复杂性增长时变得日益关键。


<img src="https://cdn.noedgeai.com/bo_d6aqlu77aajc739are4g_9.jpg?x=153&y=242&w=717&h=420&r=0"/>



Figure 6: Success Rate (%) across difficulty levels on AndroidWorld.
图6：在 AndroidWorld 上不同难度水平的成功率（%）。


Performance Across Different Task Types. AW-Extend benchmark comprises two distinct task categories: iterative tasks and compositional tasks. We analyze the performance of different methods across these categories, as illustrated in Figure 7. Compositional tasks combine multiple related subtasks, requiring agents to retain information from one subtask while executing another, thereby testing their ability to preserve critical memory. In contrast, iterative tasks involve executing similar operations multiple times with weak intertask dependencies, primarily challenging capability of agents to filter out irrelevant memory interference while maintaining robust task completion. Among only baseline methods, UI-TARS achieves the best overall performance, primarily due to its strong results on compositional tasks. This advantage stems from its sliding window approach, which avoids summarizing historical information, allowing the model to access information from previous subtasks when executing the current one. However, both UI-TARS and Mobile-Agent-v3 underperform M3A on iterative tasks. For UI-TARS, this may be attributed to the sliding window accumulating substantial irrelevant memory in the context, which interferes with model performance. The more complex architecture of Mobile-Agent-v3 compared to M3A introduces greater instability in context management during task execution, reducing robustness for iterative operations. M3A outperforms other baselines on iterative tasks, likely because its summary-based context management offers a simpler, more stable architecture that maintains lower failure rates when executing similar operations repeatedly. AgentProg surpasses all baseline methods, demonstrating significant advantages on both iterative and compositional tasks. The program-guided context management approach enables robust completion of both task types: it effectively preserves important information through program variables while eliminating redundant and irrelevant memory by parsing program structure. This dual capability allows AgentProg to excel where existing methods face trade-offs between memory retention and interference reduction.
跨不同任务类型的性能。AW-Extend 基准测试包含两类不同的任务：迭代任务与组合法任务。我们如图7所示分析不同方法在这两类任务上的性能。组合法任务结合了多个相关子任务，要求代理在执行一个子任务时保留来自另一个子任务的信息，从而测试其保持关键记忆的能力。相对而言，迭代任务涉及多次执行相似操作，任务间依赖较弱，主要挑战是代理在保持稳健完成任务的同时过滤掉无关记忆干扰。在仅有的基线方法中，UI-TARS 在整体性能上表现最好，主要得益于其在组合法任务上的强势表现。这一优势源于其滑动窗口方法，避免对历史信息进行摘要，允许模型在执行当前任务时访问先前子任务的信息。然而，UI-TARS 和 Mobile-Agent-v3 在迭代任务上的表现均不及 M3A。对于 UI-TARS，这可能归因于滑动窗口在上下文中积累了大量无关记忆，干扰模型性能。相比之下，Mobile-Agent-v3 的更复杂架构在任务执行期间带来更大的上下文管理不稳定性，降低了对迭代操作的鲁棒性。M3A 在迭代任务上优于其他基线，可能是因为其基于摘要的上下文管理提供了更简单、更加稳定的体系结构，在重复执行相似操作时保持较低的失败率。AgentProg 超越所有基线方法，在迭代和组合法任务上都展现出显著优势。基于程序的上下文管理方法能够在两类任务中实现稳健完成：通过程序变量有效保留关键信息，同时在解析程序结构时消除冗余和无关记忆。这种双重能力使 AgentProg 能在现有方法在记忆保留与干扰降低之间取舍时脱颖而出。


<img src="https://cdn.noedgeai.com/bo_d6aqlu77aajc739are4g_9.jpg?x=930&y=244&w=718&h=420&r=0"/>



Figure 7: Success Rate (%) across difficulty task types on AW-Extend.
图7：AW-Extend 上不同难度任务类型的成功率（%）。


Impact of Global Belief State. We further investigate the contribution of the global belief state component by comparing AgentProg with a variant that removes this module. The results reveal substantial performance improvements achieved by incorporating belief state tracking: the success rate improves from 53.9% to 78.0% on AndroidWorld (increased by 24.1%), and from 35.1% to 68.4% on AW-Extend (increased by 33.3%). These significant gains underscore the critical role of global belief state in long-horizon tasks. The global belief state mechanism enhances the agent's understanding of environmental states, enabling it to detect and recover from unexpected situations immediately. This capability is particularly valuable for maintaining execution stability, which becomes increasingly crucial as task horizons extend. The more pronounced performance improvement on AW-Extend further validates that belief state tracking becomes even more essential for complex, multi-step tasks. By maintaining a structured representation of the current environment state, the global belief state allows AgentProg to make more informed decisions, reduce cascading errors, and ultimately achieve more robust task completion across diverse scenarios.
全球信念状态的影响。我们通过将 AgentProg 与移除此模块的变体进行对比，进一步研究全球信念状态组件的贡献。结果显示，纳入信念状态跟踪可带来显著的性能提升：在 AndroidWorld 上成功率从 53.9% 提升至 78.0%（提升 24.1%），在 AW-Extend 上从 35.1% 提升至 68.4%（提升 33.3%）。这些显著的提升强调了全球信念状态在长时程任务中的关键作用。全球信念状态机制提升了智能体对环境状态的理解，使其能够立即检测并从意外情境中恢复。这一能力对维持执行稳定性尤为重要，随着任务时程的延展变得愈发关键。AW-Extend 上更为显著的性能提升进一步验证了信念状态跟踪在复杂的多步骤任务中变得更加必要。通过维护对当前环境状态的结构化表示，全球信念状态使 AgentProg 能做出更明智的决策，减少级联错误，并最终在各种情境中实现更稳健的任务完成。


### 5.3 Analysis of Latency and Cost
### 5.3 延迟与成本分析


Token Consumption and Latency. As shown in Table 3, we compare the token consumption and latency per task across AgentProg and two baseline methods: Mobile-Agent-v3 and UI-TARS, which outperform other baselines in An-droidWorld and AW-Extend respectively. First, We analyze token consumption by distinguishing between static prefix and dynamic prompt tokens since AgentProg is based on prompt engineering with substantial system prompts, a large portion of the prefix can be cached to reduce cost and improve efficiency. This distinction provides meaningful insights into the true efficiency of different approaches. Second, we compare only tasks where all three methods succeeded, as failed tasks exhibit inconsistent token patterns-some fail due to premature termination, leading to low token counts, while others fail after excessive iterative trial-and-error operations, leading to high token counts. Including failed tasks would obscure the true efficiency characteristics of each method.
令牌消耗与延迟。正如表 3 所示，我们比较 AgentProg 与两种基线方法：Mobile-Agent-v3 与 UI-TARS，在 AndroidWorld 与 AW-Extend 的表现分别优于其他基线。首先，我们通过区分静态前缀与动态提示令牌来分析令牌消耗，因为 AgentProg 基于大量系统提示的提示工程，前缀的很大一部分可以缓存以降低成本并提高效率。此区分为不同方法的真实效率提供了有意义的洞察。其次，我们仅比较三种方法都成功的任务，因为失败的任务会呈现不一致的令牌模式——有些因提前终止导致令牌数量偏低，而有些在大量迭代试错后失败导致令牌数量偏高。包含失败任务会掩盖各方法的真实效率特征。


Table 3 shows that UI-TARS demonstrates the lowest latency and minimal token consumption because its backbone model trained on extensive data with short static prompts and performs no additional context processing (e.g., summarization), resulting in minimal output tokens and the fastest execution speed. In contrast, Mobile-Agent-v3, while also using a trained model with relatively short static prefix (53 tokens per call), requires more tokens than UI-TARS due to its summarization and reflection process. Since AgentProg is implemented through prompt engineering, it contains a substantial static prompt prefix (12.5k tokens per call), resulting in a much higher proportion of cached tokens in the input, which reduces the cost of input tokens. Notably, AgentProg achieves significantly lower dynamic token counts compared to Mobile-Agent-v3, with performance comparable to UI-TARS. This demonstrates the effectiveness of AgentProg's context management approach over hierarchical planning method in maintaining compact context. However, Agent-Prog generates significantly more output tokens compared to both baselines, as it produces extensive intermediate content for context management including belief state, and many operations involve program counter update and variable manipulations. In terms of latency, AgentProg exhibits longer execution time than Mobile-Agent-v3, primarily attributable to the increased output token generation. All three methods exhibit consistent trends across task categories: iterative tasks involve numerous repeated subtasks and thus require higher token consumption, while compositional tasks contain fewer combined subtasks and consequently demand fewer tokens.
表 3 显示 UI-TARS 展现出最低的延迟和最小的令牌消耗，因为其骨干模型在大量数据上训练，静态提示简短且不进行额外上下文处理（如摘要），因此输出令牌最少且执行速度最快。相较之下，Mobile-Agent-v3 虽然同样使用经过训练的模型且静态前缀相对较短（每次调用 53 个令牌），但由于其摘要与反思过程需要更多令牌。由于 AgentProg 通过提示工程实现，包含大量静态提示前缀（每次调用 12.5k 令牌），导致输入中缓存令牌比例更高，降低了输入令牌的成本。值得注意的是，AgentProg 的动态令牌数量显著低于 Mobile-Agent-v3，与 UI-TARS 的性能相当。这充分证明了 AgentProg 的上下文管理方法在维持紧凑上下文方面优于分层规划方法。然而，与两基线相比，AgentProg 产生的输出令牌显著更多，因为它为上下文管理包括信念状态在内的中间内容，以及许多操作涉及程序计数器更新与变量操作。在延迟方面，AgentProg 的执行时间长于 Mobile-Agent-v3，主要归因于输出令牌生成增加。三种方法在各任务类别中都呈现出一致的趋势：迭代任务包含大量重复子任务，因此需要更高的令牌消耗；而组合任务包含的子任务较少，因此需要的令牌也更少。


<img src="https://cdn.noedgeai.com/bo_d6aqlu77aajc739are4g_10.jpg?x=933&y=748&w=708&h=437&r=0"/>



Figure 8: Dynamic context tokens in 50 steps.
图 8：50 步的动态上下文令牌。


Context Tokens Over Steps. As shown in Figure 8, we analyze the dynamic context growth patterns of different methods over extended task execution in 50 steps. We compute the average dynamic tokens at each step across all agent trajectories on the AW-Extend benchmark. UI-TARS performs minimal processing of historical information, only discarding excess screenshots when necessary. Consequently, a notable drawback of this approach is the continuous growth of context length over time. UI-TARS exhibits rapid dynamic context growth in the first 5 steps, primarily because each step adds a new screenshot to the context. From step 6 onwards, the growth rate slows as UI-TARS begins discarding the oldest screenshot while adding a new one, with context expansion mainly driven by the textual portion of historical information.
按步的上下文令牌。正如图 8 所示，我们分析在 50 步的扩展任务执行中，不同方法的动态上下文增长模式。我们计算 AW-Extend 基准上所有智能体轨迹在每一步的平均动态令牌。UI-TARS 对历史信息处理最少，只在必要时丢弃多余的截图。因此，该方法的一个显著缺点是在时间推移中上下文长度持续增长。UI-TARS 在前 5 步呈现出快速的动态上下文增长，主要是因为每一步都向上下文中添加一个新的截图。从第 6 步起，增长速度放缓，因为 UI-TARS 开始丢弃最旧的截图并添加新截图，上下文扩展主要由历史信息的文本部分驱动。


Mobile-Agent-v3 also achieves relatively slow dynamic token growth thanks to its hierarchical planning mechanism, which decomposes complex tasks into subtasks and progressively removes information during execution. However, Mobile-Agent-v3 maintains dynamic tokens at a consistently high level (approximately 17k tokens) throughout task execution. In contrast, AgentProg consistently maintains dynamic tokens at a lower level (approximately $9\mathrm{k}$ tokens),demonstrating advantages over both baselines. During 50 steps, the dynamic context token count in AgentProg remains nearly constant, indicating the effectiveness of our program-guided management in maintaining a compact representation of context. This stability is achieved through our approach's ability to represent critical information in program variables and global belief state, while systematically pruning redundant and irrelevant historical details by parsing program structure. AgentProg scales efficiently to long-horizon tasks, ensuring consistent performance even as task complexity and duration increase, while requiring much fewer dynamic tokens than existing methods.
Mobile-Agent-v3 也通过分层规划机制实现相对缓慢的动态令牌增长，将复杂任务分解为子任务并在执行过程中逐步去除信息。然而，Mobile-Agent-v3 在任务执行过程中始终维持较高水平的动态令牌（约 17k 令牌）。相比之下，AgentProg 始终将动态令牌维持在较低水平（约 $9\mathrm{k}$ 令牌），显示出相对于两个基线的优势。在 50 步中，AgentProg 的动态上下文令牌数量几乎保持不变，表明我们通过程序引导管理来维持紧凑的上下文表示的有效性。这一稳定性通过我们的方法将关键信息表示在程序变量和全局信念状态中实现，并通过解析程序结构系统性地裁剪冗余和不相关的历史细节来实现。AgentProg 能高效扩展到长时程任务，即使任务复杂性和时长增加也能保持稳定性能，同时需要比现有方法少得多的动态令牌。


Table 3: Per-Task Token Consumption and Latency for Successful Attempts on AW-Extend. "Static Prefix" represents the static prefix prompt tokens that remain constant across invocations, "Dynamic" represents the prompt tokens that continuously change during task execution, and "Output" represents the total number of tokens generated during task execution.
表 3：AW-Extend 成功尝试的每任务令牌消耗与延迟。“静态前缀”表示在调用之间保持不变的静态前缀提示令牌，“动态”表示在任务执行期间持续变化的提示令牌，“输出”表示任务执行中生成的总令牌数。


<table><tr><td>Agent</td><td>Task Set</td><td>Static Prefix (k)</td><td>Dynamic (k)</td><td>Output (k)</td><td>Latency (s)</td></tr><tr><td rowspan="3">UI-TARS</td><td>Overall</td><td>8.1</td><td>315.5</td><td>3.2</td><td>312</td></tr><tr><td>Iterative</td><td>8.5</td><td>329.6</td><td>3.3</td><td>344</td></tr><tr><td>Compositional</td><td>7.6</td><td>294.3</td><td>3.0</td><td>263</td></tr><tr><td rowspan="3">Mobile-Agent-v3</td><td>Overall</td><td>7.9</td><td>809.4</td><td>22.1</td><td>1604</td></tr><tr><td>Iterative</td><td>8.9</td><td>917.6</td><td>26.1</td><td>2033</td></tr><tr><td>Compositional</td><td>5.8</td><td>592.9</td><td>14.2</td><td>746</td></tr><tr><td rowspan="3">AgentProg</td><td>Overall</td><td>1026.4</td><td>301.3</td><td>179.7</td><td>2662</td></tr><tr><td>Iterative</td><td>1275.3</td><td>370.3</td><td>225.1</td><td>2910</td></tr><tr><td>Compositional</td><td>777.4</td><td>232.4</td><td>134.3</td><td>2164</td></tr></table>
<table><tbody><tr><td>代理</td><td>任务集</td><td>静态前缀 (k)</td><td>动态 (k)</td><td>输出 (k)</td><td>延迟 (s)</td></tr><tr><td rowspan="3">UI-TARS</td><td>总体</td><td>8.1</td><td>315.5</td><td>3.2</td><td>312</td></tr><tr><td>迭代的</td><td>8.5</td><td>329.6</td><td>3.3</td><td>344</td></tr><tr><td>组成的</td><td>7.6</td><td>294.3</td><td>3.0</td><td>263</td></tr><tr><td rowspan="3">Mobile-Agent-v3</td><td>总体</td><td>7.9</td><td>809.4</td><td>22.1</td><td>1604</td></tr><tr><td>迭代的</td><td>8.9</td><td>917.6</td><td>26.1</td><td>2033</td></tr><tr><td>组成的</td><td>5.8</td><td>592.9</td><td>14.2</td><td>746</td></tr><tr><td rowspan="3">AgentProg</td><td>总体</td><td>1026.4</td><td>301.3</td><td>179.7</td><td>2662</td></tr><tr><td>迭代的</td><td>1275.3</td><td>370.3</td><td>225.1</td><td>2910</td></tr><tr><td>组成的</td><td>777.4</td><td>232.4</td><td>134.3</td><td>2164</td></tr></tbody></table>


Table 4: Per-Task Average Steps on AW-Extend.
Table 4: AW-Extend 上的每任务平均步数。


<table><tr><td>Task Set</td><td>AgentProg</td><td>Mobile-Agent-v3</td><td>UI-TARS</td></tr><tr><td colspan="4">All Attempts</td></tr><tr><td>Overall</td><td>129.6</td><td>134.0</td><td>225.5</td></tr><tr><td>Iterative</td><td>138.5</td><td>169.1</td><td>224.9</td></tr><tr><td>Compositional</td><td>104.6</td><td>34.0</td><td>227.0</td></tr><tr><td colspan="4">Successful Attempts Only</td></tr><tr><td>Overall</td><td>37.7</td><td>51.2</td><td>43.6</td></tr><tr><td>Iterative</td><td>36.8</td><td>57.8</td><td>50.0</td></tr><tr><td>Compositional</td><td>39.5</td><td>38.0</td><td>34.0</td></tr></table>
<table><tbody><tr><td>任务集</td><td>代理程序</td><td>移动代理-v3</td><td>用户界面-TARS</td></tr><tr><td colspan="4">所有尝试</td></tr><tr><td>总体</td><td>129.6</td><td>134.0</td><td>225.5</td></tr><tr><td>迭代</td><td>138.5</td><td>169.1</td><td>224.9</td></tr><tr><td>组合式</td><td>104.6</td><td>34.0</td><td>227.0</td></tr><tr><td colspan="4">仅成功尝试</td></tr><tr><td>总体</td><td>37.7</td><td>51.2</td><td>43.6</td></tr><tr><td>迭代</td><td>36.8</td><td>57.8</td><td>50.0</td></tr><tr><td>组合式</td><td>39.5</td><td>38.0</td><td>34.0</td></tr></tbody></table>


Average Steps per Task. Table 4 presents the average number of steps required per task for AgentProg and baselines on the AW-Extend dataset. Step counts should be interpreted with caution, as different methods require varying numbers of model queries per step: Mobile-Agent-v3 queries the language model three times per step and UI-TARS queries once per step while AgentProg uses two queries per step.
每步任务的平均步骤数。表4给出AW-Extend数据集上 AgentProg 与基线在每个任务上所需的平均步骤数。应谨慎解读步骤计数，因为不同方法每步所需的模型查询次数不同：Mobile-Agent-v3 每步查询语言模型三次，UI-TARS 每步查询一次，而 AgentProg 每步使用两次查询。


The trends in step counts largely match those observed in token consumption as shown in Table 3. When considering all attempts, the compositional task results show an anomalous pattern where Mobile-Agent-v3 uses very few steps, attributable to premature task termination due to forgotten subtasks. When examining only successful attempts, AgentProg requires fewer steps than baselines across the overall tasks and iterative tasks, with comparable performance on composition tasks. This demonstrates that AgentProg achieves better performance while maintaining step efficiency. The higher step counts in "All Attempts" group compared to "Successful Attempts Only" group can be attributed to two factors: first, tasks requiring fewer steps are inherently easier to complete successfully; second, failed attempts in "All Attempts" involve substantial iterative trial-and-error operations that inflate the step count.
步骤计数的趋势在很大程度上与表3所示的代币消耗趋势一致。考虑所有尝试时，组合任务的结果显示出异常模式：Mobile-Agent-v3 使用的步骤极少，原因在于子任务被遗忘导致的任务提前终止。仅在成功尝试的情况下，AgentProg 在整体任务与迭代任务中所需的步骤更少，与组合任务的性能相当。这表明 AgentProg 在保持步骤效率的同时实现了更好的性能。与“仅成功尝试”组相比，“所有尝试”组的较高步骤数可归因于两点：一是需要较少步骤的任务本身更易于成功完成；二是“All Attempts”中的失败尝试包含大量迭代性试错操作，从而抬高了步骤计数。


## 6 Conclusion
## 6 结论


In this work, we introduce AgentProg to address the context bottleneck in long-horizon tasks. By reframing interaction history into a structured Semantic Task Program, Agent-Prog enables principled context pruning and critical variable retention. Additionally, our Global Belief State mechanism maintains an active mental model to handle partial observability and environmental dynamics. Experiments on An-droidWorld and our AW-Extend benchmark demonstrate that AgentProg significantly outperforms state-of-the-art baselines. Ultimately, our work establishes a scalable foundation for robust agent deployment in complex real-world scenarios.
本文提出 AgentProg，旨在解决长时间任务中的上下文瓶颈。通过将交互历史重构为结构化的语义任务程序，AgentProg 实现了原理性的上下文裁剪和关键变量保留。此外，我们的全局信念状态机制维持一个活跃的心理模型，以处理部分可观测性和环境动态。在 AndroidWorld 和 AW-Extend 基准测试中的实验表明，AgentProg 显著优于现有最先进的基线。最终，我们的工作为在复杂现实场景中实现鲁棒代理部署提供了可扩展的基础。


## References
## 参考文献


[1] Saaket Agashe, Kyle Wong, Vincent Tu, Jiachen Yang, Ang Li, and Xin Eric Wang. 2025. Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents. arXiv:2504.00906 [cs.AI] https: //arxiv.org/abs/2504.00906
[1] Saaket Agashe, Kyle Wong, Vincent Tu, Jiachen Yang, Ang Li, and Xin Eric Wang. 2025. Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents. arXiv:2504.00906 [cs.AI] https: //arxiv.org/abs/2504.00906


[2] Chenxin An, Jun Zhang, Ming Zhong, Lei Li, Shansan Gong, Yao Luo, Jingjing Xu, and Lingpeng Kong. 2024. Why does the effective context length of LLMs fall short? arXiv preprint arXiv:2410.18745 (2024).
[2] Chenxin An, Jun Zhang, Ming Zhong, Lei Li, Shansan Gong, Yao Luo, Jingjing Xu, and Lingpeng Kong. 2024. Why does the effective context length of LLMs fall short? arXiv preprint arXiv:2410.18745 (2024).


[3] Tanzirul Azim, Oriana Riva, and Suman Nath. 2016. ULink: Enabling User-Defined Deep Linking to App Content. In Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services (Singapore, Singapore) (MobiSys '16). Association for Computing Machinery, New York, NY, USA, 305-318. doi:10.1145/2906388.2906416
[3] Tanzirul Azim, Oriana Riva, and Suman Nath. 2016. ULink: Enabling User-Defined Deep Linking to App Content. In Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services (Singapore, Singapore) (MobiSys '16). Association for Computing Machinery, New York, NY, USA, 305-318. doi:10.1145/2906388.2906416


[4] Kanzhi Cheng, Qiushi Sun, Yougang Chu, Fangzhi Xu, Yantao Li, Jian-bing Zhang, and Zhiyong Wu. 2024. SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents. arXiv:2401.10935 [cs.HC]
[4] Kanzhi Cheng, Qiushi Sun, Yougang Chu, Fangzhi Xu, Yantao Li, Jian-bing Zhang, and Zhiyong Wu. 2024. SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents. arXiv:2401.10935 [cs.HC]


[5] Gaole Dai, Shiqi Jiang, Ting Cao, Yuanchun Li, Yuqing Yang, Rui Tan, Mo Li, and Lili Qiu. 2025. Advancing mobile gui agents: A verifier-driven approach to practical deployment. arXiv preprint arXiv:2503.15937 (2025).
[5] Gaole Dai, Shiqi Jiang, Ting Cao, Yuanchun Li, Yuqing Yang, Rui Tan, Mo Li, and Lili Qiu. 2025. Advancing mobile gui agents: A verifier-driven approach to practical deployment. arXiv preprint arXiv:2503.15937 (2025).


[6] Xinzge Gao, Chuanrui Hu, Bin Chen, and Teng Li. 2025. Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation. arXiv:2506.18158 [cs.AI] https://arxiv.org/abs/2506.18158
[6] Xinzge Gao, Chuanrui Hu, Bin Chen, and Teng Li. 2025. Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation. arXiv:2506.18158 [cs.AI] https://arxiv.org/abs/2506.18158


[7] Gonzalo Gonzalez-Pumariega, Vincent Tu, Chih-Lun Lee, Jiachen Yang, Ang Li, and Xin Eric Wang. 2025. The Unreasonable Effectiveness of Scaling Agents for Computer Use. arXiv:2510.02250 [cs.AI] https: //arxiv.org/abs/2510.02250
[7] Gonzalo Gonzalez-Pumariega, Vincent Tu, Chih-Lun Lee, Jiachen Yang, Ang Li, and Xin Eric Wang. 2025. The Unreasonable Effectiveness of Scaling Agents for Computer Use. arXiv:2510.02250 [cs.AI] https: //arxiv.org/abs/2510.02250


[8] Google. 2025. Gemini 2.5 Pro - Google DeepMind. https://deepmind.google/models/gemini/pro/.
[8] Google. 2025. Gemini 2.5 Pro - Google DeepMind. https://deepmind.google/models/gemini/pro/.


[9] Boyu Gou, Ruohan Wang, Boyuan Zheng, Yanan Xie, Cheng Chang, Yiheng Shu, Huan Sun, and Yu Su. 2025. Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents. In The Thirteenth International Conference on Learning Representations. https: //openreview.net/forum?id=kxnoqaisCT
[9] Boyu Gou, Ruohan Wang, Boyuan Zheng, Yanan Xie, Cheng Chang, Yiheng Shu, Huan Sun, and Yu Su. 2025. Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents. In The Thirteenth International Conference on Learning Representations. https: //openreview.net/forum?id=kxnoqaisCT


[10] Zhangxuan Gu, Zhengwen Zeng, Zhenyu Xu, Xingran Zhou, Shuheng Shen, Yunfei Liu, Beitong Zhou, Changhua Meng, Tianyu Xia, Weizhi Chen, et al. 2025. Ui-venus technical report: Building high-performance ui agents with rft. arXiv preprint arXiv:2508.10833 (2025).
[10] 张煊顾, 曾正闻, 徐振宇, 周星然, 沈书恒, 刘云飞, 周北同, 孟长华, 夏天羽, 陈伟志, 等. 2025. Ui-venus 技术报告：构建具有高性能 UI 代理的 rft。arXiv 预印本 arXiv:2508.10833 (2025).


[11] Izzeddin Gur, Hiroki Furuta, Austin V Huang, Mustafa Safdari, Yutaka Matsuo, Douglas Eck, and Aleksandra Faust. 2024. A Real-World We-bAgent with Planning, Long Context Understanding, and Program Synthesis. In The Twelfth International Conference on Learning Representations. https://openreview.net/forum?id=9JQtrumvg8
[11] Izzeddin Gur, Hiroki Furuta, Austin V Huang, Mustafa Safdari, Yutaka Matsuo, Douglas Eck, 和 Aleksandra Faust. 2024. 一个带计划、长上下文理解与程序合成的真实世界 WebAgent。收录于 第十二届学习表征国际会议。https://openreview.net/forum?id=9JQtrumvg8


[12] Wenyi Hong, Wenmeng Yu, Xiaotao Gu, Guo Wang, Guobing Gan, Haomiao Tang, Jiale Cheng, Ji Qi, Junhui Ji, Lihang Pan, et al. 2025. GLM-4.1 V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning. arXiv preprint arXiv:2507.01006 (2025).
[12] 温毅宏, 温猛瑜, 小涛 固, 郭 王, 郭炳 干, 浩苗 唐, 嘉乐 程, Ji Qi, Junhui Ji, 李航 潘, 等. 2025. GLM-4.1 V-Thinking：面向可扩展强化学习的多模态推理的多样化能力。arXiv 预印本 arXiv:2507.01006 (2025).


[13] Leslie Pack Kaelbling, Michael L. Littman, and Anthony R. Cassandra. 1998. Planning and acting in partially observable stochastic domains. Artif. Intell. 101, 1-2 (May 1998), 99-134.
[13] Leslie Pack Kaelbling, Michael L. Littman, and Anthony R. Cassandra. 1998. 在部分可观测的随机域中的规划与行动。人工智能 101(1-2)，1998年5月，99-134。


[14] Sunjae Lee, Junyoung Choi, Jungjae Lee, Munim Hasan Wasi, Ho-jun Choi, Steve Ko, Sangeun Oh, and Insik Shin. 2024. MobileGPT: Augmenting LLM with Human-like App Memory for Mobile Task Automation. In Proceedings of the 30th Annual International Conference on Mobile Computing and Networking (Washington D.C., DC, USA) (ACM MobiCom '24). Association for Computing Machinery, New York, NY, USA, 1119-1133. doi:10.1145/3636534.3690682
[14] Sunjae Lee, Junyoung Choi, Jungjae Lee, Munim Hasan Wasi, Ho-jun Choi, Steve Ko, Sangeun Oh, and Insik Shin. 2024. MobileGPT：用类似人类的应用记忆来增强 LLM 的移动任务自动化。收录于 第三十届国际移动计算与网络大会（华盛顿特区，美国）（ACM MobiCom '24）。计算机协会，纽约，纽约，美国，1119-1133。doi:10.1145/3636534.3690682


[15] Kuan Li, Zhongwang Zhang, Huifeng Yin, Rui Ye, Yida Zhao, Li-wen Zhang, Litu Ou, Dingchu Zhang, Xixi Wu, Jialong Wu, et al. 2025. Websailor-v2: Bridging the chasm to proprietary agents via synthetic data and scalable reinforcement learning. arXiv preprint arXiv:2509.13305 (2025).
[15] Kuan Li, Zhongwang Zhang, Huifeng Yin, Rui Ye, Yida Zhao, Li-wen Zhang, Litu Ou, Dingchu Zhang, Xixi Wu, Jialong Wu, 等. 2025. Websailor-v2：通过合成数据与可扩展强化学习弥合专有代理的鸿沟。arXiv 预印本 arXiv:2509.13305 (2025).


[16] Ning Li, Qiqiang Lin, Zheng Wu, Xiaoyun Mo, Weiming Zhang, Yin Zhao, Xiangmou Qu, Jiamu Zhou, Jun Wang, Congmin Zheng, et al. 2025. ColorAgent: Building A Robust, Personalized, and Interactive OS Agent. arXiv preprint arXiv:2510.19386 (2025).
[16] Ning Li, Qiqiang Lin, Zheng Wu, Xiaoyun Mo, Weiming Zhang, Yin Zhao, Xiangmou Qu, Jiamu Zhou, Jun Wang, Congmin Zheng, 等. 2025. ColorAgent：构建一个稳健、个性化、可交互的操作系统代理。arXiv 预印本 arXiv:2510.19386 (2025).


[17] Ning Li, Xiangmou Qu, Jiamu Zhou, Jun Wang, Muning Wen, Kou-nianhua Du, Xingyu Lou, Qiuying Peng, and Weinan Zhang. 2025. MobileUse: A GUI Agent with Hierarchical Reflection for Autonomous Mobile Operation. arXiv preprint arXiv:2507.16853 (2025).
[17] Ning Li, Xiangmou Qu, Jiamu Zhou, Jun Wang, Muning Wen, Kou-nianhua Du, Xingyu Lou, Qiuying Peng, and Weinan Zhang. 2025. MobileUse：具层次反思的 GUI 代理，用于自主移动操作。arXiv 预印本 arXiv:2507.16853 (2025).


[18] Toby Jia-Jun Li and Oriana Riva. 2018. Kite: Building Conversational Bots from Mobile Apps. In Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services (Munich, Germany) (MobiSys '18). Association for Computing Machinery, New York, NY, USA, 96-109. doi:10.1145/3210240.3210339
[18] Toby Jia-Jun Li and Oriana Riva. 2018. Kite：从移动应用构建对话机器人。收录于 第十六届国际移动系统、应用与服务会议（慕尼黑，德国）（MobiSys '18）。 ACM，纽约，美国，96-109。doi:10.1145/3210240.3210339


[19] Yang Li, Jiacong He, Xin Zhou, Yuan Zhang, and Jason Baldridge. 2020. Mapping Natural Language Instructions to Mobile UI Action Sequences. In Annual Conference of the Association for Computational Linguistics (ACL 2020). https://www.aclweb.org/anthology/2020.acl-main.729.pdf
[19] Yang Li, Jiacong He, Xin Zhou, Yuan Zhang, and Jason Baldridge. 2020. 将自然语言指令映射到移动 UI 动作序列。计算语言学协会年会（ACL 2020）。https://www.aclweb.org/anthology/2020.acl-main.729.pdf


[20] Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Brian Ichter, Pete Florence, and Andy Zeng. 2023. Code as Policies: Language Model Programs for Embodied Control. In 2023 IEEE International Conference on Robotics and Automation (ICRA). 9493-9500. doi:10. 1109/ICRA48891.2023.10160591
[20] Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Brian Ichter, Pete Florence, and Andy Zeng. 2023. 代码即策略：用于具身控制的语言模型程序。2023 IEEE 国际机器人与自动化会议（ICRA）。9493-9500。doi:10. 1109/ICRA48891.2023.10160591


[21] Evan Zheran Liu, Kelvin Guu, Panupong Pasupat, Tianlin Shi, and Percy Liang. 2018. Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration. In International Conference on Learning Representations (ICLR). https://arxiv.org/abs/1802.08802
[21] Evan Zheran Liu, Kelvin Guu, Panupong Pasupat, Tianlin Shi, and Percy Liang. 2018. 使用工作流引导探索的网页界面强化学习。In International Conference on Learning Representations (ICLR). https://arxiv.org/abs/1802.08802


[22] Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2024. Lost in the Middle: How Language Models Use Long Contexts. Transactions of the Association for Computational Linguistics 12 (2024), 157-173. doi:10.1162/ tacl_a_00638
[22] Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2024. Lost in the Middle: How Language Models Use Long Contexts. Transactions of the Association for Computational Linguistics 12 (2024), 157-173. doi:10.1162/ tacl_a_00638


[23] Shunyu Liu, Minghao Liu, Huichi Zhou, Zhenyu Cui, Yang Zhou, Yuhao Zhou, Wendong Fan, Ge Zhang, Jiajun Shi, Weihao Xuan, et al. 2025. Verigui: Verifiable long-chain gui dataset. arXiv preprint arXiv:2508.04026 (2025).
[23] Shunyu Liu, Minghao Liu, Huichi Zhou, Zhenyu Cui, Yang Zhou, Yuhao Zhou, Wendong Fan, Ge Zhang, Jiajun Shi, Weihao Xuan, et al. 2025. Verigui: Verifiable long-chain gui dataset. arXiv preprint arXiv:2508.04026 (2025).


[24] Hussein Mozannar, Gagan Bansal, Cheng Tan, Adam Fourney, Victor Dibia, Jingya Chen, Jack Gerrits, Tyler Payne, Matheus Kunzler Maldaner, Madeleine Grunde-McLaughlin, et al. 2025. Magentic-UI: Towards Human-in-the-loop Agentic Systems. arXiv preprint arXiv:2507.22358 (2025).
[24] Hussein Mozannar, Gagan Bansal, Cheng Tan, Adam Fourney, Victor Dibia, Jingya Chen, Jack Gerrits, Tyler Payne, Matheus Kunzler Maldaner, Madeleine Grunde-McLaughlin, et al. 2025. Magentic-UI: Towards Human-in-the-loop Agentic Systems. arXiv preprint arXiv:2507.22358 (2025).


[25] Dang Nguyen, Jian Chen, Yu Wang, Gang Wu, Namyong Park, Zheng-mian Hu, Hanjia Lyu, Junda Wu, Ryan Aponte, Yu Xia, Xintong Li, Jing Shi, Hongjie Chen, Viet Dac Lai, Zhouhang Xie, Sungchul Kim, Ruiyi Zhang, Tong Yu, Mehrab Tanjim, Nesreen K. Ahmed, Puneet Mathur, Seunghyun Yoon, Lina Yao, Branislav Kveton, Jihyung Kil, Thien Huu Nguyen, Trung Bui, Tianyi Zhou, Ryan A. Rossi, and Franck Dernoncourt. 2025. GUI Agents: A Survey. arXiv:2412.13501 [cs.AI] https://arxiv.org/abs/2412.13501
[25] Dang Nguyen, Jian Chen, Yu Wang, Gang Wu, Namyong Park, Zheng-mian Hu, Hanjia Lyu, Junda Wu, Ryan Aponte, Yu Xia, Xintong Li, Jing Shi, Hongjie Chen, Viet Dac Lai, Zhouhang Xie, Sungchul Kim, Ruiyi Zhang, Tong Yu, Mehrab Tanjim, Nesreen K. Ahmed, Puneet Mathur, Seunghyun Yoon, Lina Yao, Branislav Kveton, Jihyung Kil, Thien Huu Nguyen, Trung Bui, Tianyi Zhou, Ryan A. Rossi, and Franck Dernoncourt. 2025. GUI Agents: A Survey. arXiv:2412.13501 [cs.AI] https://arxiv.org/abs/2412.13501


[26] Yujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin Li, Shijue Huang, et al. 2025. Ui-tars: Pioneering automated gui interaction with native agents. arXiv preprint arXiv:2501.12326 (2025).
[26] Yujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin Li, Shijue Huang, et al. 2025. Ui-tars: Pioneering automated gui interaction with native agents. arXiv preprint arXiv:2501.12326 (2025).


[27] Christopher Rawles, Sarah Clinckemaillie, Yifan Chang, Jonathan Waltz, Gabrielle Lau, Marybeth Fair, Alice Li, William Bishop, Wei Li, Folawiyo Campbell-Ajala, Daniel Toyama, Robert Berry, Divya Tyama-gundlu, Timothy Lillicrap, and Oriana Riva. 2024. AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents. arXiv:2405.14573 [cs.AI] https://arxiv.org/abs/2405.14573
[27] Christopher Rawles, Sarah Clinckemaillie, Yifan Chang, Jonathan Waltz, Gabrielle Lau, Marybeth Fair, Alice Li, William Bishop, Wei Li, Folawiyo Campbell-Ajala, Daniel Toyama, Robert Berry, Divya Tyama-gundlu, Timothy Lillicrap, and Oriana Riva. 2024. AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents. arXiv:2405.14573 [cs.AI] https://arxiv.org/abs/2405.14573


[28] Philip Schroeder, Nathaniel W Morgan, Hongyin Luo, and James Glass. 2025. Thread: Thinking deeper with recursive spawning. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). 8418-8442.
[28] Philip Schroeder, Nathaniel W Morgan, Hongyin Luo, and James Glass. 2025. Thread: Thinking deeper with recursive spawning. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). 8418-8442.


[29] Leming Shen, Qiang Yang, Yuanqing Zheng, and Mo Li. 2025. Au-toIOT: LLM-Driven Automated Natural Language Programming for AIoT Applications. In Proceedings of the 31st Annual International Conference on Mobile Computing and Networking (Kerry Hotel, Hong Kong, Hong Kong, China) (ACM MOBICOM '25). Association for Computing Machinery, New York, NY, USA, 468-482. doi:10.1145/3680207.3723486
[29] Leming Shen, Qiang Yang, Yuanqing Zheng, and Mo Li. 2025. Au-toIOT: LLM-Driven Automated Natural Language Programming for AIoT Applications. In Proceedings of the 31st Annual International Conference on Mobile Computing and Networking (Kerry Hotel, Hong Kong, Hong Kong, China) (ACM MOBICOM '25). Association for Computing Machinery, New York, NY, USA, 468-482. doi:10.1145/3680207.3723486


[30] Edward J. Sondik. 1978. The Optimal Control of Partially Observable Markov Processes Over the Infinite Horizon: Discounted Costs. Operations Research 26, 2 (1978), 282-304. https://doi.org/10.1287/opre.26.2.282
[30] Edward J. Sondik. 1978. The Optimal Control of Partially Observable Markov Processes Over the Infinite Horizon: Discounted Costs. Operations Research 26, 2 (1978), 282-304. https://doi.org/10.1287/opre.26.2.282


[31] Linxin Song, Yutong Dai, Viraj Prabhu, Jieyu Zhang, Taiwei Shi, Li Li, Junnan Li, Silvio Savarese, Zeyuan Chen, Jieyu Zhao, et al. 2025. Coact-1: Computer-using agents with coding as actions. arXiv preprint arXiv:2508.03923 (2025).
[31] Linxin Song, Yutong Dai, Viraj Prabhu, Jieyu Zhang, Taiwei Shi, Li Li, Junnan Li, Silvio Savarese, Zeyuan Chen, Jieyu Zhao, et al. 2025. Coact-1: 使用计算机的代理将编码作为行动。 arXiv 预印本 arXiv:2508.03923 (2025).


[32] Liangtai Sun, Xingyu Chen, Lu Chen, Tianle Dai, Zichen Zhu, and Kai Yu. 2022. META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI. arXiv preprint arXiv:2205.11029 (2022).
[32] Liangtai Sun, Xingyu Chen, Lu Chen, Tianle Dai, Zichen Zhu, and Kai Yu. 2022. META-GUI: 面向移动 GUI 的多模态对话代理。 arXiv 预印本 arXiv:2205.11029 (2022).


[33] Weihao Tan, Wentao Zhang, Xinrun Xu, Haochong Xia, Ziluo Ding, Boyu Li, Bohan Zhou, Junpeng Yue, Jiechuan Jiang, Yewen Li, Ruyi An, Molei Qin, Chuqiao Zong, Longtao Zheng, Yujie Wu, Xiaoqiang Chai, Yifei Bi, Tianbao Xie, Pengjie Gu, Xiyun Li, Ceyao Zhang, Long Tian, Chaojie Wang, Xinrun Wang, Börje F. Karlsson, Bo An, Shuicheng Yan, and Zongqing Lu. 2024. Cradle: Empowering Foundation Agents Towards General Computer Control. arXiv:2403.03186 [cs.AI] https: //arxiv.org/abs/2403.03186
[33] Weihao Tan, Wentao Zhang, Xinrun Xu, Haochong Xia, Ziluo Ding, Boyu Li, Bohan Zhou, Junpeng Yue, Jiechuan Jiang, Yewen Li, Ruyi An, Molei Qin, Chuqiao Zong, Longtao Zheng, Yujie Wu, Xiaoqiang Chai, Yifei Bi, Tianbao Xie, Pengjie Gu, Xiyun Li, Ceyao Zhang, Long Tian, Chaojie Wang, Xinrun Wang, Börje F. Karlsson, Bo An, Shuicheng Yan, and Zongqing Lu. 2024. Cradle: 赋能基础代理实现通用计算机控制。 arXiv:2403.03186 [cs.AI] https: //arxiv.org/abs/2403.03186


[34] Haoming Wang, Haoyang Zou, Huatong Song, Jiazhan Feng, Junjie Fang, Junting Lu, Longxiang Liu, Qinyu Luo, Shihao Liang, Shijue Huang, Wanjun Zhong, Yining Ye, Yujia Qin, Yuwen Xiong, Yuxin Song, Zhiyong Wu, Aoyan Li, Bo Li, Chen Dun, Chong Liu, Daoguang Zan, Fuxing Leng, Hanbin Wang, Hao Yu, Haobin Chen, Hongyi Guo, Jing Su, Jingjia Huang, Kai Shen, Kaiyu Shi, Lin Yan, Peiyao Zhao, Pengfei Liu, Qinghao Ye, Renjie Zheng, Shulin Xin, Wayne Xin Zhao, Wen Heng, Wenhao Huang, Wenqian Wang, Xiaobo Qin, Yi Lin, Youbin Wu, Zehui Chen, Zihao Wang, Baoquan Zhong, Xinchun Zhang, Xujing Li, Yuanfan Li, Zhongkai Zhao, Chengquan Jiang, Faming Wu, Haotian Zhou, Jinlin Pang, Li Han, Qi Liu, Qianli Ma, Siyao Liu, Songhua Cai, Wenqi Fu, Xin Liu, Yaohui Wang, Zhi Zhang, Bo Zhou, Guoliang Li, Jiajun Shi, Jiale Yang, Jie Tang, Li Li, Qihua Han, Taoran Lu, Woyu Lin, Xiaokang Tong, Xinyao Li, Yichi Zhang, Yu Miao, Zhengxuan Jiang, Zili Li, Ziyuan Zhao, Chenxin Li, Dehua Ma, Feng Lin, Ge Zhang, Haihua Yang, Hangyu Guo, Hongda Zhu, Jiaheng Liu, Junda Du, Kai Cai, Kuanye Li, Lichen Yuan, Meilan Han, Minchao Wang, Shuyue Guo, Tianhao Cheng, Xiaobo Ma, Xiaojun Xiao, Xiaolong Huang, Xin-jie Chen, Yidi Du, Yilin Chen, Yiwen Wang, Zhaojian Li, Zhenzhu Yang, Zhiyuan Zeng, Chaolin Jin, Chen Li, Hao Chen, Haoli Chen, Jian Chen, Qinghao Zhao, and Guang Shi. 2025. UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning. arXiv:2509.02544 [cs.AI] https://arxiv.org/abs/2509.02544
[34] Haoming Wang, Haoyang Zou, Huatong Song, Jiazhan Feng, Junjie Fang, Junting Lu, Longxiang Liu, Qinyu Luo, Shihao Liang, Shijue Huang, Wanjun Zhong, Yining Ye, Yujia Qin, Yuwen Xiong, Yuxin Song, Zhiyong Wu, Aoyan Li, Bo Li, Chen Dun, Chong Liu, Daoguang Zan, Fuxing Leng, Hanbin Wang, Hao Yu, Haobin Chen, Hongyi Guo, Jing Su, Jingjia Huang, Kai Shen, Kaiyu Shi, Lin Yan, Peiyao Zhao, Pengfei Liu, Qinghao Ye, Renjie Zheng, Shulin Xin, Wayne Xin Zhao, Wen Heng, Wenhao Huang, Wenqian Wang, Xiaobo Qin, Yi Lin, Youbin Wu, Zehui Chen, Zihao Wang, Baoquan Zhong, Xinchun Zhang, Xujing Li, Yuanfan Li, Zhongkai Zhao, Chengquan Jiang, Faming Wu, Haotian Zhou, Jinlin Pang, Li Han, Qi Liu, Qianli Ma, Siyao Liu, Songhua Cai, Wenqi Fu, Xin Liu, Yaohui Wang, Zhi Zhang, Bo Zhou, Guoliang Li, Jiajun Shi, Jiale Yang, Jie Tang, Li Li, Qihua Han, Taoran Lu, Woyu Lin, Xiaokang Tong, Xinyao Li, Yichi Zhang, Yu Miao, Zhengxuan Jiang, Zili Li, Ziyuan Zhao, Chenxin Li, Dehua Ma, Feng Lin, Ge Zhang, Haihua Yang, Hangyu Guo, Hongda Zhu, Jiaheng Liu, Junda Du, Kai Cai, Kuanye Li, Lichen Yuan, Meilan Han, Minchao Wang, Shuyue Guo, Tianhao Cheng, Xiaobo Ma, Xiaojun Xiao, Xiaolong Huang, Xin-jie Chen, Yidi Du, Yilin Chen, Yiwen Wang, Zhaojian Li, Zhenzhu Yang, Zhiyuan Zeng, Chaolin Jin, Chen Li, Hao Chen, Haoli Chen, Jian Chen, Qinghao Zhao, and Guang Shi. 2025. UI-TARS-2 技术报告：通过多轮强化学习推进 GUI 代理。 arXiv:2509.02544 [cs.AI] https://arxiv.org/abs/2509.02544


[35] Junyang Wang, Haiyang Xu, Jiabo Ye, Ming Yan, Weizhou Shen, Ji Zhang, Fei Huang, and Jitao Sang. 2024. Mobile-agent: Autonomous multi-modal mobile device agent with visual perception. arXiv preprint arXiv:2401.16158 (2024).
[35] Junyang Wang, Haiyang Xu, Jiabo Ye, Ming Yan, Weizhou Shen, Ji Zhang, Fei Huang, and Jitao Sang. 2024. Mobile-agent: 具备视觉感知的自主多模态移动设备代理。 arXiv 预印本 arXiv:2401.16158 (2024).


[36] Luyuan Wang, Yongyu Deng, Yiwei Zha, Guodong Mao, Qinmin Wang, Tianchen Min, Wei Chen, and Shoufa Chen. 2024. MobileAgentBench: An Efficient and User-Friendly Benchmark for Mobile LLM Agents. arXiv preprint arXiv:2406.08184 (2024).
[36] 王路源、邓永瑜、查逸炜、毛国栋、王勤敏、闵天辰、陈伟、陈守发。2024。MobileAgentBench：一个高效且易用的移动端LLM代理基准。arXiv 预印本 arXiv:2406.08184 (2024)。


[37] Xingyao Wang, Yangyi Chen, Lifan Yuan, Yizhe Zhang, Yunzhu Li, Hao Peng, and Heng Ji. 2024. Executable Code Actions Elicit Better LLM Agents. In ICML. arXiv:2402.01030
[37] Wang Xingyao, Chen Yangyi, Yuan Lifan, Zhang Yizhe, Li Yunzhu, Peng Hao, and Ji Heng. 2024. 可执行代码动作能更好地引导大语言模型代理。In ICML. arXiv:2402.01030


[38] Zora Zhiruo Wang, Apurva Gandhi, Graham Neubig, and Daniel Fried. 2025. Inducing Programmatic Skills for Agentic Tasks. In Second Conference on Language Modeling. https://openreview.net/forum?id= IsAY6fWsog
[38] Zora Zhiruo Wang, Apurva Gandhi, Graham Neubig, and Daniel Fried. 2025. 诱导面向任务的程序化技能。发表于“第二届语言模型大会”。https://openreview.net/forum?id= IsAY6fWsog


[39] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou. 2022. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. In Advances in Neural Information Processing Systems, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (Eds.), Vol. 35. Curran Associates, Inc., 24824- 24837. https://proceedings.neurips.cc/paper_files/paper/2022/file/ 9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf
[39] Jason Wei、Xuezhi Wang、Dale Schuurmans、Maarten Bosma、brian ichter、Fei Xia、Ed Chi、Quoc V Le 与 Denny Zhou。2022。Chain-of-Thought Prompting 诱发大型语言模型的推理能力。收录于神经信息处理系统进展，S. Koyejo、S. Mohamed、A. Agarwal、D. Belgrave、K. Cho、A. Oh（编），第 35 卷。Curran Associates, Inc.，24824-24837。https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf


[40] Hao Wen, Yuanchun Li, Guohong Liu, Shanhui Zhao, Tao Yu, Toby Jia-Jun Li, Shiqi Jiang, Yunhao Liu, Yaqin Zhang, and Yunxin Liu. 2024. AutoDroid: LLM-powered Task Automation in Android. In Proceedings of the 30th Annual International Conference on Mobile Computing and Networking (Washington D.C., DC, USA) (ACM MobiCom '24). Association for Computing Machinery, New York, NY, USA, 543-557. doi:10.1145/3636534.3649379
[40] Hao Wen, Yuanchun Li, Guohong Liu, Shanhui Zhao, Tao Yu, Toby Jia-Jun Li, Shiqi Jiang, Yunhao Liu, Yaqin Zhang, and Yunxin Liu. 2024. AutoDroid: LLM-powered Task Automation in Android. In Proceedings of the 30th Annual International Conference on Mobile Computing and Networking (Washington D.C., DC, USA) (ACM MobiCom '24). Association for Computing Machinery, New York, NY, USA, 543-557. doi:10.1145/3636534.3649379


[41] Hao Wen, Shizuo Tian, Borislav Pavlov, Wenjie Du, Yixuan Li, Ge Chang, Shanhui Zhao, Jiacheng Liu, Yunxin Liu, Ya-Qin Zhang, and Yuanchun Li. 2025. AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation. Association for Computing Machinery, New York, NY, USA, 223-235. https://doi.org/10.1145/3711875.3729134
[41] Hao Wen、Shizuo Tian、Borislav Pavlov、Wenjie Du、Yixuan Li、Ge Chang、Shanhui Zhao、Jiacheng Liu、Yunxin Liu、Ya-Qin Zhang、Yuanchun Li。2025。AutoDroid-V2：通过代码生成提升基于SLM的GUI代理。计算机协会，纽约，美国，223-235。https://doi.org/10.1145/3711875.3729134


[42] Zhiyong Wu, Chengcheng Han, Zichen Ding, Zhenmin Weng, Zhoumi-anze Liu, Shunyu Yao, Tao Yu, and Lingpeng Kong. 2024. Os-copilot: Towards generalist computer agents with self-improvement. arXiv preprint arXiv:2402.07456 (2024).
[42] Zhiyong Wu, Chengcheng Han, Zichen Ding, Zhenmin Weng, Zhoumi-anze Liu, Shunyu Yao, Tao Yu, and Lingpeng Kong. 2024. Os-copilot: Towards generalist computer agents with self-improvement. arXiv preprint arXiv:2402.07456 (2024).


[43] Zhiyong Wu, Zhenyu Wu, Fangzhi Xu, Yian Wang, Qiushi Sun, Chengyou Jia, Kanzhi Cheng, Zichen Ding, Liheng Chen, Paul Pu Liang, et al. 2024. OS-ATLAS: A Foundation Action Model for Generalist GUI Agents. arXiv preprint arXiv:2410.23218 (2024).
[43] Zhiyong Wu, Zhenyu Wu, Fangzhi Xu, Yian Wang, Qiushi Sun, Chengyou Jia, Kanzhi Cheng, Zichen Ding, Liheng Chen, Paul Pu Liang, 等。 2024。OS-ATLAS：面向通用GUI代理的基础行动模型。 arXiv 预印本 arXiv:2410.23218 (2024)。


[44] Jiajun Xu, Zhiyuan Li, Wei Chen, Qun Wang, Xin Gao, Qi Cai, and Ziyuan Ling. 2024. On-device language models: A comprehensive review. arXiv preprint arXiv:2409.00088 (2024).
[44] Jiajun Xu, Zhiyuan Li, Wei Chen, Qun Wang, Xin Gao, Qi Cai, and Ziyuan Ling. 2024. On-device language models: A comprehensive review. arXiv preprint arXiv:2409.00088 (2024).


[45] Yifan Xu, Xiao Liu, Xinghan Liu, Jiaqi Fu, Hanchen Zhang, Bohao Jing, Shudan Zhang, Yuting Wang, Wenyi Zhao, and Yuxiao Dong. 2025. MobileRL: Online Agentic Reinforcement Learning for Mobile GUI Agents. arXiv preprint arXiv:2509.18119 (2025).
[45] Yifan Xu, Xiao Liu, Xinghan Liu, Jiaqi Fu, Hanchen Zhang, Bohao Jing, Shudan Zhang, Yuting Wang, Wenyi Zhao, and Yuxiao Dong. 2025. MobileRL: Online Agentic Reinforcement Learning for Mobile GUI Agents. arXiv preprint arXiv:2509.18119 (2025).


[46] Yifan Xu, Xiao Liu, Xueqiao Sun, Siyi Cheng, Hao Yu, Hanyu Lai, Shudan Zhang, Dan Zhang, Jie Tang, and Yuxiao Dong. 2024. Android-Lab: Training and Systematic Benchmarking of Android Autonomous Agents. arXiv:2410.24024 [cs.AI] https://arxiv.org/abs/2410.24024
[46] Yifan Xu, Xiao Liu, Xueqiao Sun, Siyi Cheng, Hao Yu, Hanyu Lai, Shudan Zhang, Dan Zhang, Jie Tang, and Yuxiao Dong. 2024. Android-Lab: Training and Systematic Benchmarking of Android Autonomous Agents. arXiv:2410.24024 [cs.AI] https://arxiv.org/abs/2410.24024


[47] An Yan, Zhengyuan Yang, Wanrong Zhu, Kevin Lin, Linjie Li, Jianfeng Wang, Jianwei Yang, Yiwu Zhong, Julian McAuley, Jianfeng Gao, et al. 2023. GPT-4V in Wonderland: Large Multimodal Models for Zero-Shot Smartphone GUI Navigation. arXiv preprint arXiv:2311.07562 (2023).
[47] An Yan, Zhengyuan Yang, Wanrong Zhu, Kevin Lin, Linjie Li, Jianfeng Wang, Jianwei Yang, Yiwu Zhong, Julian McAuley, Jianfeng Gao, 等. 2023. GPT-4V in Wonderland: Large Multimodal Models for Zero-Shot Smartphone GUI Navigation. arXiv 预印本 arXiv:2311.07562 (2023).


[48] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of Thoughts: Deliberate Problem Solving with Large Language Models. arXiv:2305.10601 [cs.CL]
[48] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of Thoughts: Deliberate Problem Solving with Large Language Models. arXiv:2305.10601 [cs.CL]


[49] Jiabo Ye, Xi Zhang, Haiyang Xu, Haowei Liu, Junyang Wang, Zhao-qing Zhu, Ziwei Zheng, Feiyu Gao, Junjie Cao, Zhengxi Lu, et al. 2025. Mobile-agent-v3: Fundamental agents for gui automation. arXiv preprint arXiv:2508.15144 (2025).
[49] Jiabo Ye, Xi Zhang, Haiyang Xu, Haowei Liu, Junyang Wang, Zhao-qing Zhu, Ziwei Zheng, Feiyu Gao, Junjie Cao, Zhengxi Lu, et al. 2025. Mobile-agent-v3: Fundamental agents for gui automation. arXiv 预印本 arXiv:2508.15144 (2025).


[50] Chaoyun Zhang, Liqun Li, Shilin He, Xu Zhang, Bo Qiao, Si Qin, Minghua Ma, Yu Kang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, and Qi Zhang. 2024. UFO: A UI-Focused Agent for Windows OS Interaction. arXiv preprint arXiv:2402.07939 (2024).
[50] Chaoyun Zhang, Liqun Li, Shilin He, Xu Zhang, Bo Qiao, Si Qin, Minghua Ma, Yu Kang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, and Qi Zhang. 2024. UFO: A UI-Focused Agent for Windows OS Interaction. arXiv 预印本 arXiv:2402.07939 (2024).


[51] Chi Zhang, Zhao Yang, Jiaxuan Liu, Yucheng Han, Xin Chen, Zebiao Huang, Bin Fu, and Gang Yu. 2023. AppAgent: Multimodal Agents as Smartphone Users. arXiv:2312.13771 [cs.CV]
[51] Chi Zhang, Zhao Yang, Jiaxuan Liu, Yucheng Han, Xin Chen, Zebiao Huang, Bin Fu, and Gang Yu. 2023. AppAgent: Multimodal Agents as Smartphone Users. arXiv:2312.13771 [cs.CV]


[52] Zhenyu Zhang, Tianyi Chen, Weiran Xu, Alex Pentland, and Jiaxin Pei. 2025. ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents. In Conference on Neural Information Processing Systems (NeurIPS).
[52] Zhenyu Zhang, Tianyi Chen, Weiran Xu, Alex Pentland, and Jiaxin Pei. 2025. ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents. In Conference on Neural Information Processing Systems (NeurIPS).


[53] Zhuosheng Zhang and Aston Zhang. 2024. You Only Look at Screens: Multimodal Chain-of-Action Agents. In Findings of the Association for Computational Linguistics: ACL 2024, Lun-Wei Ku, Andre Martins, and Vivek Srikumar (Eds.). Association for Computational Linguistics, Bangkok, Thailand, 3132-3149. doi:10.18653/v1/2024.findings-acl.186
[53] Zhuosheng Zhang and Aston Zhang. 2024. You Only Look at Screens: Multimodal Chain-of-Action Agents. In Findings of the Association for Computational Linguistics: ACL 2024, Lun-Wei Ku, Andre Martins, and Vivek Srikumar (Eds.). Association for Computational Linguistics, Bangkok, Thailand, 3132-3149. doi:10.18653/v1/2024.findings-acl.186


[54] Boyuan Zheng, Boyu Gou, Jihyung Kil, Huan Sun, and Yu Su. 2024. GPT-4V(ision) is a Generalist Web Agent, if Grounded. In Forty-first International Conference on Machine Learning (ICML'24). https:// openreview.net/forum?id=piecKJ2DlB
[54] Boyuan Zheng, Boyu Gou, Jihyung Kil, Huan Sun, and Yu Su. 2024. GPT-4V(ision) is a Generalist Web Agent, if Grounded. In Forty-first International Conference on Machine Learning (ICML'24). https:// openreview.net/forum?id=piecKJ2DlB


[55] Zijian Zhou, Ao Qu, Zhaoxuan Wu, Sunghwan Kim, Alok Prakash, Daniela Rus, Jinhua Zhao, Bryan Kian Hsiang Low, and Paul Pu Liang. 2025. MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents. https://arxiv.org/abs/2506.15841
[55] Zijian Zhou, Ao Qu, Zhaoxuan Wu, Sunghwan Kim, Alok Prakash, Daniela Rus, Jinhua Zhao, Bryan Kian Hsiang Low, and Paul Pu Liang. 2025. MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents. https://arxiv.org/abs/2506.15841


## A Syntax of Semantic Task Program
## A Syntax of Semantic Task Program


The syntax of Semantic Task Program (STP) is designed to resolve the conflict between the need for structural rigor in workflows and the inherent ambiguity of agent tasks. While Semantic Task Program adopts a natural-language-style appearance to ensure expressiveness, it is fundamentally a structured language. It imposes a rigid skeleton of control flow (loops, conditionals, functions) to maintain logical consistency, while allowing the atomic instructions within that skeleton to remain "soft" and flexible.
语义任务程序（STP）的语法旨在解决工作流对结构化严格性需求与任务本质模糊性之间的冲突。尽管语义任务程序采用自然语言风格以确保表达性，但它本质上是一种结构化语言。它对控制流（循环、条件、函数）施加刚性骨架以维护逻辑一致性，同时允许骨架内的原子指令保持“柔性”和灵活。


This design philosophy differs from traditional coding, which demands precision everywhere, and prompt engineering, which lacks structural constraints. Semantic Task Program allows developers to be precise about procedure (e.g., "iterate exactly 10 times") while being fuzzy about implementation (e.g. , "extract the sentiment"). This section outlines how Semantic Task Program implements this hybrid approach.
这种设计理念不同于要求处处精确的传统编程，也不同于缺乏结构约束的提示工程。语义任务程序允许开发者在过程上保持精确（例如“精确迭代 10 次”），同时在实现上保持模糊（如“提取情感”）。本节概述了语义任务程序如何实现这种混合方法。


### A.1 Basic Statements and Comments
### A.1 基本语句与注释


Semantic Task Program adopts an intent-based programming style. Instructions are written as imperative or declarative sentences that prioritize conveying the user's goal over adhering to strict syntactic rules.
语义任务程序采用基于意图的编程风格。指令以祈使句或陈述句书写，优先传达用户目标，而非严格遵守句法规则。


---



&nbsp;&nbsp;&nbsp;&nbsp;#This is a comment, used for human-readable annotations.
&nbsp;&nbsp;&nbsp;&nbsp;#这是一个注释，用于对人类可读的标注。


&nbsp;&nbsp;&nbsp;&nbsp;tell user "Hello, world!" # Inline comments are also supported.
&nbsp;&nbsp;&nbsp;&nbsp;告诉用户 "Hello, world!" # 行内注释也受支持。


#The following statements are also valid:
#以下语句也是有效的：


&nbsp;&nbsp;&nbsp;&nbsp;send "Hello, world!" to the user
&nbsp;&nbsp;&nbsp;&nbsp;发送 "Hello, world!" 给用户


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;notify user with message "Hello, world!"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用消息 "Hello, world!" 通知用户


send a greeting message to user
向用户发送问候消息


---



Comments are ignored by the AgentProg and serve only to document the code. Statements like tell user "..." are direct commands that are translated into actions. For familiarity, Semantic Task Program also permits Python-style syntax where appropriate (e.g., print("Hello, world!")), which the AgentProg processes as an equivalent intent rather than executing directly.
注释由 AgentProg 忽略，仅用于文档化代码。像 tell user "..." 这样的语句是直接命令，会被翻译为动作。为便于使用，Semantic Task Program 也在合适位置允许 Python 风格的语法（例如 print("Hello, world!")），AgentProg 将其作为等效意图处理而不是直接执行。


### A.2 Variables and Data Management
### A.2 变量与数据管理


In agentic workflows, data is often unstructured (e.g., natural text, web content) and does not fit neatly into the rigid types of C++ or Java. Semantic Task Program addresses this by treating variables as named containers for information, explicitly demarcated by curly braces \{\} (e.g., \{userName\}). This notation serves a dual purpose: it provides a clear anchor for the AgentProg to track state within a fuzzy instruction, and it allows the language to handle unstructured data without requiring complex schema definitions upfront.
在代理工作流中，数据往往是非结构化的（如自然文本、网页内容），并不适合直接套入 C++ 或 Java 的严格类型。Semantic Task Program 通过将变量视为信息的命名容器来解决此问题，变量由大括号 {} 明确定界（如 {userName}）。此记号具有双重用途：它为 AgentProg 在模糊指令中跟踪状态提供清晰锚点，并且允许该语言在不事先定义复杂模式的情况下处理非结构化数据。


Declaration and Assignment: Variables are declared implicitly upon their first assignment. Semantic Task Program supports multiple natural phrasings for assignment, treating them as synonyms.
声明与赋值：变量在首次赋值时隐式声明。Semantic Task Program 支持多种自然表述的赋值方式，视为同义。


---



set variable \{userName\} to "Alice"
set variable {userName} to "Alice"


&nbsp;&nbsp;&nbsp;&nbsp;store 100 into \{initialScore\}
&nbsp;&nbsp;&nbsp;&nbsp;store 100 into {initialScore}


set \{userCount\} to 0 # Python-style assignment is also valid.
set {userCount} to 0 # Python风格的赋值也有效。


---



Using Variables: To reference a variable's value, simply include its braced name within a statement. The AgentProg substitutes it with its current value during execution.
使用变量：要引用变量的值，只需在语句中包含带大括号的变量名。在执行时，AgentProg 将其替换为当前值。


---



&nbsp;&nbsp;&nbsp;&nbsp;tell user "Welcome, \{userName\}! Your score is \{initialScore\}."
&nbsp;&nbsp;&nbsp;&nbsp;告诉用户 "欢迎，{userName}！你的分数是 {initialScore}。"


calculate \{initialScore\} + 50, record as \{finalScore\}
计算 \{initialScore\} + 50，记录为 \{finalScore\}


---



Dynamic Type System: Semantic Task Program employs a dynamic type system where users are not required to declare types explicitly. The AgentProg infers and manages types-such as Text, Number, Boolean, List, and Object-based on context and value. This approach aligns with the needs of both novice programmers and LLMs, which may struggle with strict static typing. While types are inferred, users can provide hints to guide the interpreter, for instance, when interacting with an AI model.
动态类型系统：语义任务程序采用动态类型系统，用户无需显式声明类型。AgentProg 根据上下文和数值推断并管理文本、数字、布尔、列表与对象等类型。这种方法符合新手程序员和可能在严格静态类型下挣扎的大模型的需求。尽管类型会被推断，用户仍可提供提示以引导解释器，例如在与 AI 模型交互时。


- List: An ordered collection.
- 列表：有序集合。


---



record list "apples", "bananas", "cherries" as \{fruitBasket\}
将列表 "apples"、"bananas"、"cherries" 记录为 \{fruitBasket\}


---



- Object: A key-value store, akin to a dictionary or JSON object. Properties can be accessed using dot notation (\{product.price\}) or possessive phrasing (\{myCar's color\}).
- 对象：键值存储，类似字典或 JSON 对象。属性可以使用点表示法 (\{product.price\}) 或所有格表达 (\{myCar's color\}) 访问。


---



create an object \{product\} with "name" as "Laptop" and "price
创建一个对象 \{product\}，其 "name" 为 "Laptop" 且 "price


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;" as 1200



&nbsp;&nbsp;&nbsp;&nbsp;tell user "\{product.name\} is available for \{product.price\}."
&nbsp;&nbsp;&nbsp;&nbsp;告诉用户 "\{product.name\} 可用，价格为 \{product.price\}。"


---



- Table: A structured list of objects, ideal for representing tabular data.
- 表：一个结构化的对象列表，适合表示表格数据。


---



read table "sales_data.csv" as \{salesReport\}
将表 read table "sales_data.csv" 为 \{salesReport\}


---



Crucially, the AgentProg handles potential type mismatches intelligently. Instead of crashing, it attempts a reasonable type coercion (e.g., converting the text "123" to a number) or reports a descriptive, human-understandable issue.
至关重要的是，AgentProg 会聪明地处理潜在的类型不匹配。它不会崩溃，而是尝试合理的类型强制转换（例如将文本 "123" 转换为数字），或给出描述性、可理解的问题报告。


### A.3 Control Flow
### A.3 控制流


Control flow structures in Semantic Task Program use natural language keywords and rely on indentation to define code blocks, similar to Python. This maintains readability while avoiding complex bracketing.
语义任务程序中的控制流结构使用自然语言关键字并依靠缩进来定义代码块，类似于 Python。这在保持可读性的同时，避免了复杂的括号嵌套。


Conditional Statements: if, else, else if structures evaluate conditions expressed in natural language or with standard operators.
条件语句：if、else、else if 结构以自然语言表达或使用标准运算符评估条件。


---



ask user "Enter your age:", get response as \{ageInput\}
向用户提问 "Enter your age:"，将响应作为 \{ageInput\} 获取


convert \{ageInput\} to number, as \{userAge\}
将 \{ageInput\} 转换为数字，作为 \{userAge\}


if \{userAge\} < 18:
若 \{userAge\} < 18：


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tell user "You are a minor."
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tell user "你是未成年人。"


else, if \{userAge\} is between 18 and 65: # Natural language
否则，如果 {userAge} 在 18 到 65 之间： # 自然语言


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;condition allowed
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;条件允许


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tell user "You are an adult."
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tell user "你是成年人。"


else:
else:


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tell user "You are a senior citizen."
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tell user "你是老年人。"


---



Loops: Semantic Task Program supports various loop constructs, each initiated with flexible, descriptive phrasing.
Loops: 语义任务程序支持多种循环结构，每种都以灵活、描述性的措辞启动。


- Fixed Repetitions:
- 固定重复：


---



repeat 5 times:
repeat 5 times:


&nbsp;&nbsp;&nbsp;&nbsp;#\{loop.iteration\} is a special variable (1-indexed)
&nbsp;&nbsp;&nbsp;&nbsp;#{loop.iteration} 是一个特殊变量（1 代表第一轮）


&nbsp;&nbsp;&nbsp;&nbsp;tell user "This is message number \{loop.iteration\}"
&nbsp;&nbsp;&nbsp;&nbsp;tell user "这是第 {loop.iteration} 条消息"


---



- Iterating over Collections:
- 遍历集合：


---



iterate through each item in \{fruitBasket\} as \{fruit\}:
iterate through each item in {fruitBasket} as {fruit}:


&nbsp;&nbsp;&nbsp;&nbsp;tell user "Found fruit: \{fruit\}"
&nbsp;&nbsp;&nbsp;&nbsp;tell user "发现水果：{fruit}"


---



- Conditional Loops:
- 条件循环：


---



while \{systemStatus\} is "active":
while {systemStatus} is "active":


&nbsp;&nbsp;&nbsp;&nbsp;check for new messages
&nbsp;&nbsp;&nbsp;&nbsp;检查新消息


&nbsp;&nbsp;&nbsp;&nbsp;wait 10 seconds
&nbsp;&nbsp;&nbsp;&nbsp;等待 10 秒


---



### A.4 Functions
### A.4 函数


To promote modularity and code reuse, Semantic Task Program allows users to define reusable blocks of logic as functions.
为促进模块性和代码重用，语义任务程序允许用户将可重用的逻辑块定义为函数。


Defining a Function: A function is defined with a name, a list of expected inputs (parameters), and a body of instructions.
定义一个函数：函数通过名称、期望输入列表（参数）和一组指令体来定义。


---



define function named "calculateArea":
定义名为 "calculateArea" 的函数：


&nbsp;&nbsp;&nbsp;&nbsp;function inputs: \{length\} (number), \{width\} (number)
&nbsp;&nbsp;&nbsp;&nbsp;函数输入：{length}（数字）、{width}（数字）


&nbsp;&nbsp;&nbsp;&nbsp;calculate \{length\} * \{width\}, record as \{area\}
&nbsp;&nbsp;&nbsp;&nbsp;计算 \{length\} * \{width\}，将结果记为 \{area\}


&nbsp;&nbsp;&nbsp;&nbsp;function returns \{area\}
&nbsp;&nbsp;&nbsp;&nbsp;函数返回 \{area\}


---



Executing a Function: Functions are called by name, with arguments passed using a clear key-value format.
执行函数：通过名称调用函数，参数使用清晰的键值对格式传递。


---



execute function "calculateArea", with \{length\} as 10 and \{width\} as
执行函数 "calculateArea"，将 {length} 设为 10，{width} 设为


&nbsp;&nbsp;&nbsp;&nbsp;5, save result as \{roomArea\}
&nbsp;&nbsp;&nbsp;&nbsp;5，将结果保存在 \{roomArea\}


tell user "The room area is \{roomArea\} square units."
告诉用户 "房间面积是 \{roomArea\} 平方单位。"


---



### A.5 Interactions with External Tools
### A.5 与外部工具的交互


A cornerstone of Semantic Task Program is its native ability to interact with the broader digital environment, including AI models and external tools, through high-level, declarative commands.
语义任务程序的一个基石是其原生能力，通过高级、声明性命令与更广泛的数字环境（包括 AI 模型和外部工具）进行交互。


Tool Use (File System, Browser, Devices): Semantic Task Program provides a unified, high-level interface for common tool interactions. This design allows users to specify *what* they want to achieve, leaving the *how* to the AgentProg.
工具使用（文件系统、浏览器、设备）：语义任务程序提供统一的高级接口，用于常见的工具交互。这样的设计让用户明确要达到的目标，将实现方式留给 AgentProg。


---



#File System
#文件系统


read text from file "config.txt" as \{configContent\}
从配置文件 config.txt 读取文本为 \{configContent\}


save \{summary\} to file "summary.txt"
将 \{summary\} 保存到文件 "summary.txt"


#Web Browser Automation
#网页浏览器自动化


execute on device "MainBrowser":
在设备 "MainBrowser" 上执行：


&nbsp;&nbsp;&nbsp;&nbsp;open URL "https://en.wikipedia.org"
&nbsp;&nbsp;&nbsp;&nbsp;打开 URL "https://en.wikipedia.org"


&nbsp;&nbsp;&nbsp;&nbsp;search "Hello World"
&nbsp;&nbsp;&nbsp;&nbsp;搜索 "Hello World"


&nbsp;&nbsp;&nbsp;&nbsp;wait for page to load
&nbsp;&nbsp;&nbsp;&nbsp;等待页面加载


&nbsp;&nbsp;&nbsp;&nbsp;get current page content as \{wikiPageContent\}
&nbsp;&nbsp;&nbsp;&nbsp;获取当前页面内容作为 \{wikiPageContent\}


---



The AgentProg's context-aware nature is critical here. It resolves ambiguous references like "search input" or "Search button" by analyzing the current state of the web page (its DOM structure and visual layout), making automation scripts more robust and less brittle.
AgentProg 的上下文感知特性在此至关重要。它通过分析当前网页的状态（其 DOM 结构和可视布局）来解析诸如 "搜索输入框" 或 "搜索按钮" 等模糊引用，从而使自动化脚本更健壮、 menos 易碎。